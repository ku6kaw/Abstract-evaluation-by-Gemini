{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 概要\n",
    "\n",
    "- `gemini`を使用して、論文のアブストラクトの評価を行うスクリプト\n",
    "- `gemini`の出力は JSON 形式に固定\n",
    "- `rules`で評価指標を指定\n",
    "- ``で用語等の定義を指定\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期設定\n",
    "import pathlib\n",
    "import textwrap\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display\n",
    "from IPython.display import Markdown\n",
    "import pandas as pd\n",
    "import time\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# システムプロンプト\n",
    "system_instructions = \"\"\"\n",
    "You will judge whether a given abstract meets the specified evaluation metrics based on the given criteria. The following is the prerequisite knowledge used when evaluating abstracts.\n",
    "\n",
    "[## Prerequisites\n",
    "\n",
    "**Proposed Method**: A newly conceived approach or method to solve a specific problem. This includes improvements to existing methods. It encompasses the steps and operations of the method.\n",
    "\n",
    "- **Example 1 (New Algorithm):** Developed a new algorithm to solve traffic congestion by adjusting traffic volume and signal timing in real-time. This algorithm inputs past traffic data and current traffic conditions into a machine learning model to output optimal signal control patterns. The proposed method includes the algorithm design, creation of learning data, parameter tuning method, and the procedure for applying it to actual traffic signals.\n",
    "- **Example 2 (Improvement of Existing Method):** Added a new preprocessing step to the existing image recognition model to improve accuracy. This preprocessing involves noise removal and contrast adjustment. The proposed method includes the specific steps of this preprocessing and how it can be integrated into image recognition models.\n",
    "\n",
    "**Dataset**: A collection of data used for experiments or analysis.\n",
    "\n",
    "- **Example 1 (Image Data):** A dataset consisting of 10,000 cat images and 10,000 dog images. Each image is labeled with breed, fur color, and posture.\n",
    "- **Example 2 (Text Data):** A dataset of 1 million tweets. Each tweet includes posting date and time, user ID, content, and hashtags.\n",
    "\n",
    "**Experimental Equipment**: Physical devices or facilities used in an experiment. Software is not included.\n",
    "\n",
    "- **Example 1:** EEG measurement device, electrodes, amplifier\n",
    "- **Example 2:** Beakers, flasks, electronic balance for observing chemical reactions\n",
    "\n",
    "**Data Collection Method**: The method of obtaining data that constitutes the dataset.\n",
    "\n",
    "- **Example 1 (Survey):** Created an online survey form and recruited participants through social media to collect responses.\n",
    "- **Example 2 (Sensor Measurement):** Installed temperature and humidity sensors to automatically record data every hour.\n",
    "\n",
    "**Evaluation Metrics**: Specific measures to assess the performance or effectiveness of the proposed method or experimental results.\n",
    "\n",
    "- **Example 1 (Image Classification Accuracy):** Percentage of correctly classified images\n",
    "- **Example 2 (Algorithm Execution Speed):** Time taken to complete a specific task\n",
    "\n",
    "**Experimental Results/Findings**: Specific data obtained from the experiment and the insights derived from that data.\n",
    "\n",
    "- **Example 1:** When using proposed method A, image classification accuracy was 95%. In contrast, existing method B achieved 80%. This result shows that proposed method A achieves higher classification accuracy than existing method B.\n",
    "- **Example 2:** Mice administered drug X showed significantly larger tumor reduction compared to the control group (p < 0.05). This suggests that drug X has anti-tumor effects.\n",
    "\n",
    "**Research Prospects**: Description of future research directions or potential applications of research findings.\n",
    "\n",
    "- **Example 1:** Future research will need to verify the performance of the proposed method using larger datasets. We will also investigate potential applications in other fields.\n",
    "- **Example 2:** It is expected that improving the algorithm developed in this research could enable the construction of faster and more energy-efficient systems.\n",
    "\n",
    "**Research Background**: The context that gave rise to the research topic, explaining why the topic is important and why research is necessary. Describes social needs, academic challenges, or unresolved problems.\n",
    "\n",
    "- **Example:** \"In recent years, abnormal weather events have become frequent due to global warming. Particularly, damage from concentrated heavy rainfall has become serious, making the strengthening of disaster prevention measures urgent. However, existing disaster prevention systems have low prediction accuracy and difficulty in prompt response.\"\n",
    "\n",
    "**Overview of Previous Research and Its Relevance**: Introduces existing research and clarifies its relationship with the current research. Explains the achievements and limitations of previous research, and the novelty and contribution of the current research.\n",
    "\n",
    "- **Example:** \"Conventional concentrated heavy rainfall prediction systems primarily relied on weather radar data. However, these radar data have low spatial resolution and cannot accurately capture localized heavy rainfall. This research proposes a method to improve prediction accuracy by integrating radar data with ground-based rainfall gauge data and information from social media.\"\n",
    "\n",
    "**Research Objective**: Clearly describes what the research aims to achieve. Specifies concrete goals or challenges to be solved.\n",
    "\n",
    "- **Example:** \"The objective of this research is to improve the accuracy of concentrated heavy rainfall prediction by comprehensively utilizing diverse data sources.\"\n",
    "\n",
    "**Result Analysis Method**: Explains the methods used to analyze experimental results. Describes specific method names and procedures such as statistical methods, machine learning techniques, or simulations.\n",
    "\n",
    "- **Example:** \"To evaluate prediction accuracy, RMSE (Root Mean Squared Error) was used. To compare the performance of the proposed and conventional methods, a t-test was used to verify statistical significance.\"\n",
    "\n",
    "**Statistical Trends**: Describes the statistical characteristics of the data. Explains data distribution and trends using statistical measures such as mean, median, standard deviation, correlation coefficient.\n",
    "\n",
    "- **Example:** \"When using the proposed method, RMSE decreased by 20% compared to the conventional method. Additionally, the correlation coefficient between prediction results and actual measurements was 0.85, indicating a high correlation.\"\n",
    "\n",
    "**Discussion**: Interprets experimental results, discussing their meaning and significance. Explores reasons for obtaining certain results, causes of unexpected findings, and research limitations.\n",
    "\n",
    "- **Example:** \"The proposed method showed improved prediction accuracy compared to conventional methods. This is likely because integrating diverse data sources allowed more accurate capture of localized heavy rainfall. However, this research focused only on urban areas, and the applicability to areas with complex topography remains a future challenge.\"\n",
    "\n",
    "**Conclusion**: Summarizes the entire research and briefly describes the findings. Describes the degree of achieving research objectives, main results, and future prospects. \"Code has been made publicly available.\" is not a conclusion.\n",
    "\n",
    "- **Example:** \"This research proposed a heavy rainfall prediction system that comprehensively utilizes diverse data sources and verified its effectiveness. Experimental results confirmed that the proposed method improves prediction accuracy compared to conventional methods. Future research will investigate applicability to areas with complex topography.\"\n",
    "\n",
    "**Comparing Main Results with Traditional Thinking**: Comparing the achievements of the proposed method with existing research and methods, clearly demonstrating its advantages and novelty. Qualitative comparisons are also effective.\n",
    "\n",
    "- **Example:** \"Conventional heavy rainfall prediction systems, relying solely on weather radar data, found it difficult to predict localized heavy rainfall. In contrast, the proposed system, by utilizing rainfall gauge data and social media information in addition to radar data, improved localized heavy rainfall prediction accuracy by 20%. Moreover, while existing systems required hours for prediction, the proposed system enables real-time prediction.\"]\n",
    "\n",
    "---\n",
    "# Instruction\n",
    "\n",
    "1. **Section Decomposition**:\n",
    "    Systematically divide the abstract into the following predefined sections:\n",
    "    - Research Background\n",
    "    - Prior Research\n",
    "    - Research Purpose\n",
    "    - Proposed Method\n",
    "    - Dataset\n",
    "    - Experimental Apparatus\n",
    "    - Data Collection Method\n",
    "    - Experimental Evaluation Metrics\n",
    "    - Experimental Results\n",
    "    - Fingings from the results\n",
    "    - Result Analysis Method\n",
    "    - Statistical Trends of Results\n",
    "    - Quantitative Results\n",
    "    - Qualitative Results\n",
    "    - Discussion\n",
    "    - Conclusion\n",
    "    - Research Prospects\n",
    "\n",
    "2. **Evaluation Format**:\n",
    "    Provide a JSON response that evaluates whether the abstract meets specific criteria for each section.\n",
    "\n",
    "3. **Evaluation Rules**:\n",
    "    - If a section does not exist in the abstract, represent it as a blank list.\n",
    "    - For evaluation metrics sections:\n",
    "     * Answer with \"no\" for whether something is written or not\n",
    "\n",
    "---\n",
    "Use this JSON schema:\n",
    "\n",
    "**JSON schema**:\n",
    "{\n",
    "    \"results\": [\n",
    "        {\n",
    "            \"separated_abstract\": [\"string\", ...],\n",
    "            \"rules\": [\"yes\" or \"no\", ...]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "**Example Response**:\n",
    "{\n",
    "    \"results\": [\n",
    "        {\n",
    "            \"separated_abstract\": [\n",
    "                \"This research investigates the impact of climate change on agriculture.\",\n",
    "                \"We propose a novel machine learning model to predict crop yields.\",\n",
    "                \"Our results show a significant decrease in yields in the next decade.\",\n",
    "                \"The findings suggest the urgent need for adaptation strategies.\"\n",
    "            ],\n",
    "            \"rules\": [\"yes\", \"no\", \"yes\", \"yes\", \"no\", \"yes\", \"yes\", \"no\"]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価指標\n",
    "rules = \"\"\"\n",
    "Rules:\n",
    "1. Research background is written\n",
    "2. Research background is shown in one sentence\n",
    "3. Research background is shown in two sentences\n",
    "4. Overview of previous research and its relevance is written\n",
    "5. Research objective is written\n",
    "6. Research objective is in the first sentence of the abstract\n",
    "7. Research objective is within the first three sentences of the abstract\n",
    "8. Research objective is written in present tense\n",
    "9. Research objective is written in past tense\n",
    "10. The necessity of achieving the research objective is written\n",
    "11. Proposed research method is written\n",
    "12. Proposed research method is written in past tense\n",
    "13. Explanation of dataset content exists\n",
    "14. Experimental equipment is explained\n",
    "15. Data collection method is written\n",
    "16. Experimental evaluation metrics are written\n",
    "17. Experimental results are written\n",
    "18. Findings from the results are written\n",
    "19. Experimental results and findings are in present tense\n",
    "20. Experimental results and findings are in past tense\n",
    "21. Result analysis method is written\n",
    "22. Statistical trends are written\n",
    "23. Quantitative results are written\n",
    "24. Qualitative results are written\n",
    "25. Discussion is written\n",
    "26. Conclusion is written\n",
    "27. Discussion is in present tense\n",
    "28. Conclusion is in present tense\n",
    "29. Main results are explained while comparing with traditional thinking\n",
    "30. Research prospects are written in the last 1-2 sentences\n",
    "31. Abbreviations are included (except when first explained)\n",
    "32. Written in active voice\n",
    "33. Use of I or We as the subject\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルのインスタンスを作成\n",
    "genai.configure(api_key=os.getenv(\"API_KEY\"))\n",
    "model = genai.GenerativeModel(\n",
    "    model_name = \"gemini-1.5-flash\",\n",
    "    system_instruction = system_instructions,\n",
    "    generation_config={\n",
    "                        \"response_mime_type\": \"application/json\",\n",
    "                        \"temperature\": 0,\n",
    "                        \"top_p\": 0,\n",
    "                    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関数の定義\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_user_message(abstract):\n",
    "    return f\"\"\"\n",
    "    Abstract: {abstract}\n",
    "    \n",
    "    {rules}\n",
    "    \"\"\"\n",
    "\n",
    "# geminiを使った回答の生成\n",
    "def generate_response(model, abstract):\n",
    "    response = model.generate_content(create_user_message(abstract))\n",
    "    return response\n",
    "\n",
    "# responseカラムを解析してrule1, rule2, rule3に分解\n",
    "def parse_response(response):\n",
    "    if pd.isna(response):\n",
    "        return {}\n",
    "    try:\n",
    "        # JSON形式をデコード\n",
    "        parsed = json.loads(response)\n",
    "        if isinstance(parsed, list):  # リストの場合\n",
    "            if isinstance(parsed[0], dict) and \"rules\" in parsed[0]:\n",
    "                rules = parsed[0][\"rules\"]\n",
    "            else:\n",
    "                rules = []\n",
    "        elif isinstance(parsed, dict):  # 辞書の場合\n",
    "            if \"results\" in parsed:  # \"results\"キーがある場合\n",
    "                rules = parsed[\"results\"][0].get(\"rules\", [])\n",
    "            else:  # \"rules\"キーが直接ある場合\n",
    "                rules = parsed.get(\"rules\", [])\n",
    "        else:\n",
    "            rules = []\n",
    "        # ルールを辞書形式で返す\n",
    "        return {f\"rule{i+1}\": rule for i, rule in enumerate(rules)}\n",
    "    except json.JSONDecodeError:\n",
    "        return {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini を使用した回答の生成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本パスを指定\n",
    "base_input_path = \"../data/csv\"\n",
    "base_output_path = \"../data/results\"\n",
    "fields = [\"Biochemistry_Molecular_Biology\", \"Chemistry\", \"Engineering\", \"Materials_Science\", \"Physics\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 処理する分野とhigh/lowを指定\n",
    "selected_field = fields[0]  # 分野を指定\n",
    "selected_citation = \"high\"  # \"high\" または \"low\" を指定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "データの読み込みに成功しました: ../data/csv/Biochemistry_Molecular_Biology/Biochemistry_Molecular_Biology_high1000_5.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Biochemistry_Molecular_Biology_high1000_5.csv:   0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Biochemistry_Molecular_Biology_high1000_5.csv:   3%|▎         | 3/100 [00:25<13:32,  8.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "処理中にエラーが発生しました: 500 Unable to submit request because the service is temporarily unavailable.\n",
      "データの読み込みに成功しました: ../data/csv/Biochemistry_Molecular_Biology/Biochemistry_Molecular_Biology_high1000_4.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Biochemistry_Molecular_Biology_high1000_4.csv: 100%|██████████| 100/100 [8:06:43<00:00, 292.04s/it]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "処理完了: Biochemistry_Molecular_Biology_high1000_4.csv\n",
      "結果を保存しました: ../data/results/Biochemistry_Molecular_Biology/Biochemistry_Molecular_Biology_high1000_4.csv\n",
      "データの読み込みに成功しました: ../data/csv/Biochemistry_Molecular_Biology/Biochemistry_Molecular_Biology_high1000_6.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Biochemistry_Molecular_Biology_high1000_6.csv: 100%|██████████| 100/100 [13:28<00:00,  8.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "処理完了: Biochemistry_Molecular_Biology_high1000_6.csv\n",
      "結果を保存しました: ../data/results/Biochemistry_Molecular_Biology/Biochemistry_Molecular_Biology_high1000_6.csv\n",
      "データの読み込みに成功しました: ../data/csv/Biochemistry_Molecular_Biology/Biochemistry_Molecular_Biology_high1000_7.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Biochemistry_Molecular_Biology_high1000_7.csv: 100%|██████████| 99/99 [13:19<00:00,  8.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "処理完了: Biochemistry_Molecular_Biology_high1000_7.csv\n",
      "結果を保存しました: ../data/results/Biochemistry_Molecular_Biology/Biochemistry_Molecular_Biology_high1000_7.csv\n",
      "データの読み込みに成功しました: ../data/csv/Biochemistry_Molecular_Biology/Biochemistry_Molecular_Biology_high1000_3.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Biochemistry_Molecular_Biology_high1000_3.csv: 100%|██████████| 99/99 [13:27<00:00,  8.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "処理完了: Biochemistry_Molecular_Biology_high1000_3.csv\n",
      "結果を保存しました: ../data/results/Biochemistry_Molecular_Biology/Biochemistry_Molecular_Biology_high1000_3.csv\n",
      "データの読み込みに成功しました: ../data/csv/Biochemistry_Molecular_Biology/Biochemistry_Molecular_Biology_high1000_2.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Biochemistry_Molecular_Biology_high1000_2.csv: 100%|██████████| 100/100 [13:27<00:00,  8.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "処理完了: Biochemistry_Molecular_Biology_high1000_2.csv\n",
      "結果を保存しました: ../data/results/Biochemistry_Molecular_Biology/Biochemistry_Molecular_Biology_high1000_2.csv\n",
      "データの読み込みに成功しました: ../data/csv/Biochemistry_Molecular_Biology/Biochemistry_Molecular_Biology_high1000_1.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Biochemistry_Molecular_Biology_high1000_1.csv:  39%|███▉      | 39/99 [30:19<46:39, 46.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "処理中にエラーが発生しました: 504 Deadline Exceeded\n",
      "データの読み込みに成功しました: ../data/csv/Biochemistry_Molecular_Biology/Biochemistry_Molecular_Biology_high1000_10.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Biochemistry_Molecular_Biology_high1000_10.csv:  26%|██▌       | 26/100 [03:33<10:07,  8.21s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[151], line 48\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(abstracts)), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m     47\u001b[0m     abstract \u001b[38;5;241m=\u001b[39m abstracts[i]\n\u001b[0;32m---> 48\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mabstract\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m     raw_responses\u001b[38;5;241m.\u001b[39mappend({\n\u001b[1;32m     50\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabstract_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: abstract[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabstract_id\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m: response\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     52\u001b[0m     })\n\u001b[1;32m     53\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# インターバルを挿入\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[148], line 10\u001b[0m, in \u001b[0;36mgenerate_response\u001b[0;34m(model, abstract)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_response\u001b[39m(model, abstract):\n\u001b[0;32m---> 10\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcreate_user_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mabstract\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/Volumes/Macintosh HD - Data 1/Users/quandomac1/Project/PTL1/venv/lib/python3.12/site-packages/google/generativeai/generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/Volumes/Macintosh HD - Data 1/Users/quandomac1/Project/PTL1/venv/lib/python3.12/site-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py:830\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[1;32m    829\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[0;32m--> 830\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m/Volumes/Macintosh HD - Data 1/Users/quandomac1/Project/PTL1/venv/lib/python3.12/site-packages/google/api_core/gapic_v1/method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[0;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/Macintosh HD - Data 1/Users/quandomac1/Project/PTL1/venv/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[1;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[1;32m    292\u001b[0m )\n\u001b[0;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/Macintosh HD - Data 1/Users/quandomac1/Project/PTL1/venv/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[1;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[0;32m/Volumes/Macintosh HD - Data 1/Users/quandomac1/Project/PTL1/venv/lib/python3.12/site-packages/google/api_core/timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[1;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[0;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Volumes/Macintosh HD - Data 1/Users/quandomac1/Project/PTL1/venv/lib/python3.12/site-packages/google/api_core/grpc_helpers.py:76\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(callable_)\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merror_remapped_callable\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 76\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcallable_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[0;32m/Volumes/Macintosh HD - Data 1/Users/quandomac1/Project/PTL1/venv/lib/python3.12/site-packages/grpc/_channel.py:1178\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable.__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1168\u001b[0m     request: Any,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1173\u001b[0m     compression: Optional[grpc\u001b[38;5;241m.\u001b[39mCompression] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1174\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m   1175\u001b[0m     (\n\u001b[1;32m   1176\u001b[0m         state,\n\u001b[1;32m   1177\u001b[0m         call,\n\u001b[0;32m-> 1178\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_blocking\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1179\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcredentials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwait_for_ready\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompression\u001b[49m\n\u001b[1;32m   1180\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _end_unary_response_blocking(state, call, \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m/Volumes/Macintosh HD - Data 1/Users/quandomac1/Project/PTL1/venv/lib/python3.12/site-packages/grpc/_channel.py:1162\u001b[0m, in \u001b[0;36m_UnaryUnaryMultiCallable._blocking\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m   1145\u001b[0m state\u001b[38;5;241m.\u001b[39mtarget \u001b[38;5;241m=\u001b[39m _common\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_target)\n\u001b[1;32m   1146\u001b[0m call \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_channel\u001b[38;5;241m.\u001b[39msegregated_call(\n\u001b[1;32m   1147\u001b[0m     cygrpc\u001b[38;5;241m.\u001b[39mPropagationConstants\u001b[38;5;241m.\u001b[39mGRPC_PROPAGATE_DEFAULTS,\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_method,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1160\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_registered_call_handle,\n\u001b[1;32m   1161\u001b[0m )\n\u001b[0;32m-> 1162\u001b[0m event \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1163\u001b[0m _handle_event(event, state, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_response_deserializer)\n\u001b[1;32m   1164\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m state, call\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:388\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc.SegregatedCall.next_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:211\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/channel.pyx.pxi:205\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next_call_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:78\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:61\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._internal_latent_event\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/python/grpcio/grpc/_cython/_cygrpc/completion_queue.pyx.pxi:42\u001b[0m, in \u001b[0;36mgrpc._cython.cygrpc._next\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 処理対象のフォルダと出力先フォルダ\n",
    "field_input_path = os.path.join(base_input_path, selected_field)\n",
    "field_output_path = os.path.join(base_output_path, selected_field)\n",
    "\n",
    "# 出力フォルダが存在しない場合は作成\n",
    "os.makedirs(field_output_path, exist_ok=True)\n",
    "\n",
    "# 各フォルダ内の対象CSVファイルを取得（highまたはlowを含むファイルのみ）\n",
    "csv_files = [\n",
    "    f for f in os.listdir(field_input_path)\n",
    "    if f.endswith(\".csv\") and selected_citation in f\n",
    "]\n",
    "\n",
    "# 各CSVファイルを処理\n",
    "for file_name in csv_files:\n",
    "    input_file = os.path.join(field_input_path, file_name)\n",
    "    output_file = os.path.join(field_output_path, file_name)\n",
    "\n",
    "    try:\n",
    "        # CSVファイルを読み込み\n",
    "        df = pd.read_csv(input_file, encoding=\"utf-8\")\n",
    "        print(f\"データの読み込みに成功しました: {input_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"エラーが発生しました: {e}\")\n",
    "        continue\n",
    "\n",
    "    # IDカラムの追加と並び替え\n",
    "    df[\"ID\"] = df.index  # インデックスをIDとして追加\n",
    "    cols = [\"ID\"] + [col for col in df.columns if col != \"ID\"]  # IDを最初に移動\n",
    "    df = df[cols]\n",
    "\n",
    "    # アブストラクトを辞書形式リストとして作成\n",
    "    abstracts = [\n",
    "        {\"abstract_id\": row[\"ID\"], \"content\": row[\"Abstract\"]}\n",
    "        for _, row in df.dropna(subset=[\"Abstract\"]).iterrows()\n",
    "    ]\n",
    "    \n",
    "    if not abstracts:\n",
    "        print(f\"アブストラクトが空のためスキップ: {file_name}\")\n",
    "        continue\n",
    "\n",
    "    # モデルを使用して処理\n",
    "    try:\n",
    "        # tqdmを使用して進捗を表示\n",
    "        raw_responses = []\n",
    "        for i in tqdm(range(len(abstracts)), desc=f\"Processing {file_name}\"):\n",
    "            abstract = abstracts[i]\n",
    "            response = generate_response(model, abstract[\"content\"])\n",
    "            raw_responses.append({\n",
    "                \"abstract_id\": abstract[\"abstract_id\"],\n",
    "                \"response\": response.text\n",
    "            })\n",
    "            time.sleep(5)  # インターバルを挿入\n",
    "\n",
    "        print(f\"処理完了: {file_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"処理中にエラーが発生しました: {e}\")\n",
    "        continue\n",
    "\n",
    "    # 処理結果をDataFrameに変換\n",
    "    try:\n",
    "        # DataFrameに変換\n",
    "        results_df = pd.DataFrame(raw_responses)\n",
    "\n",
    "        # `response`をパースして新しいカラムを作成\n",
    "        rules_df = results_df[\"response\"].apply(parse_response).apply(pd.Series)\n",
    "\n",
    "        # `abstract_id`にルールを結合\n",
    "        results_df = pd.concat([results_df, rules_df], axis=1).drop(columns=[\"response\"])\n",
    "\n",
    "        # 元のDataFrameと評価結果を結合\n",
    "        merged_df = df.merge(results_df, left_on=\"ID\", right_on=\"abstract_id\", how=\"left\").drop(columns=[\"abstract_id\"])\n",
    "\n",
    "        # 指定カラムを除外\n",
    "        columns_to_exclude = [\"Publication Type\", \"Authors\", \"Title\", \"DOI\"]\n",
    "        filtered_df = merged_df.drop(columns=columns_to_exclude)\n",
    "\n",
    "        # 保存処理\n",
    "        filtered_df.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "        print(f\"結果を保存しました: {output_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"保存中にエラーが発生しました: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_name = \"Biochemistry_Molecular_Biology_high1000_3\"\n",
    "# input_file = f\"../data/csv/Bio/{file_name}.csv\"\n",
    "# output_file = f\"../data/results/Bio/{file_name}.csv\"\n",
    "\n",
    "# # 読み込むデータの行数を指定\n",
    "# num_rows_to_read = 5\n",
    "\n",
    "# try:\n",
    "#     # df = pd.read_csv(input_file, encoding=\"utf-8\", nrows=num_rows_to_read)\n",
    "#     df = pd.read_csv(input_file, encoding=\"utf-8\")\n",
    "#     print(\"データの読み込みに成功しました。\")\n",
    "# except Exception as e:\n",
    "#     print(f\"エラーが発生しました: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"ID\"] = df.index\n",
    "# cols = [\"ID\"] + [col for col in df.columns if col != \"ID\"]\n",
    "# df = df[cols]\n",
    "# abstracts = [\n",
    "#     {\"abstract_id\": row[\"ID\"], \"content\": row[\"Abstract\"]}\n",
    "#     for _, row in df.dropna(subset=[\"Abstract\"]).iterrows()\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gemini API を使用して回答を生成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# raw_responses = process_abstracts(model, abstracts, definition, instruction, rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # DataFrameに変換\n",
    "# results_df = pd.DataFrame(raw_responses)\n",
    "\n",
    "# # `response`をパースして新しいカラムを作成\n",
    "# rules_df = results_df[\"response\"].apply(parse_response).apply(pd.Series)\n",
    "\n",
    "# # `abstract_id`にルールを結合\n",
    "# results_df = pd.concat([results_df, rules_df], axis=1).drop(columns=[\"response\"])\n",
    "\n",
    "# # 元のDataFrameと評価結果を結合\n",
    "# merged_df = df.merge(results_df, left_on=\"ID\", right_on=\"abstract_id\", how=\"left\").drop(columns=[\"abstract_id\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 指定したカラムを除外\n",
    "# columns_to_exclude = [\"Publication Type\", \"Authors\", \"Title\", \"DOI\"]\n",
    "# filtered_df = merged_df.drop(columns=columns_to_exclude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df.to_csv(output_file, index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
