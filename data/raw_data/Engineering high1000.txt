PT	AU	BA	BE	GP	AF	BF	CA	TI	SO	SE	BS	LA	DT	CT	CY	CL	SP	HO	DE	ID	AB	C1	C3	RP	EM	RI	OI	FU	FP	FX	CR	NR	TC	Z9	U1	U2	PU	PI	PA	SN	EI	BN	J9	JI	PD	PY	VL	IS	PN	SU	SI	MA	BP	EP	AR	DI	DL	D2	EA	PG	WC	WE	SC	GA	PM	OA	HC	HP	DA	UT
J	Ren, SQ; He, KM; Girshick, R; Sun, J				Ren, Shaoqing; He, Kaiming; Girshick, Ross; Sun, Jian			Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												State-of-the-art object detection networks depend on region proposal algorithms to hypothesize object locations. Advances like SPPnet [1] and Fast R-CNN [2] have reduced the running time of these detection networks, exposing region proposal computation as a bottleneck. In this work, we introduce a Region Proposal Network (RPN) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals. An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position. The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection. We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features-using the recently popular terminology of neural networks with 'attention' mechanisms, the RPN component tells the unified network where to look. For the very deep VGG-16 model [3], our detection system has a frame rate of 5 fps (including all steps) on a GPU, while achieving state-of-the-art object detection accuracy on PASCAL VOC 2007, 2012, and MS COCO datasets with only 300 proposals per image. In ILSVRC and COCO 2015 competitions, Faster R-CNN and RPN are the foundations of the 1st-place winning entries in several tracks. Code has been made publicly available.																			0162-8828	1939-3539				JUN	2017	39	6					1137	1149		10.1109/TPAMI.2016.2577031	http://dx.doi.org/10.1109/TPAMI.2016.2577031								27295650					WOS:000401091200007
J	Wang, Z; Bovik, AC; Sheikh, HR; Simoncelli, EP				Wang, Z; Bovik, AC; Sheikh, HR; Simoncelli, EP			Image quality assessment: From error visibility to structural similarity	IEEE TRANSACTIONS ON IMAGE PROCESSING												Objective methods for assessing perceptual image quality traditionally attempted to quantify the visibility of errors (differences) between a distorted image and a reference image using a variety of known properties of the human visual system. Under the assumption that human visual perception is highly adapted for extracting structural information from a scene, we introduce an alternative complementary framework for quality assessment based on the degradation of structural information. As a specific example of this concept, we develop a Structural Similarity Index and demonstrate its promise through a set of intuitive examples, as well as comparison to both subjective ratings and state-of-the-art objective methods on a database of images compressed with JPEG and JPEG2000.(1)					Bovik, Alan/B-6717-2012	Bovik, Alan/0000-0001-6067-710X; Wang, Zhou/0000-0003-4413-4441; Simoncelli, Eero/0000-0002-1206-527X													1057-7149	1941-0042				APR	2004	13	4					600	612		10.1109/TIP.2003.819861	http://dx.doi.org/10.1109/TIP.2003.819861								15376593					WOS:000220784600014
J	Donoho, DL				Donoho, DL			Compressed sensing	IEEE TRANSACTIONS ON INFORMATION THEORY												Suppose x is an unknown vector in R-m (a digital image or signal); we plan to measure n general linear functionals of x and then reconstruct. If x is known to be compressible by transform coding with a known transform, and we reconstruct via the nonlinear procedure defined here, the number of measurements n can be dramatically smaller than the size m. Thus, certain natural classes of images with m pixels need only n = O(m(1/4) log(5/2)(m)) nonadaptive nonpixel samples for faithful recovery, as opposed to the usual m pixel samples. More specifically, suppose x has a sparse representation in some orthonormal basis (e.g., wavelet, Fourier) or tight frame (e.g., curvelet, Gabor)-so the coefficients belong to an l(p), ball for O < p <= 1. The N most important coefficients in that expansion allow reconstruction with l(2) error O(N1/2-1/p). It is possible to design n = O (N log (m)) nonadaptive measurements allowing reconstruction with accuracy comparable to that attainable with direct knowledge of the N most important coefficients. Moreover, a good approximation to those N important coefficients is extracted from the n measurements by solving a linear program-Basis Pursuit in signal processing. The nonadaptive measurements have the character of "random" linear combinations of basis/frame elements. Our results use the notions of optimal recovery, of n-widths, and information-based complexity. We estimate the Gel'fand n-widths of l(p) balls in high-dimensional Euclidean space in the case 0 < p <= 1, and give a criterion identifying near-optimal subspaces for Gel'fand n-widths. We show that "most" subspaces are near-optimal, and show that convex optimization (Basis Pursuit) is a near-optimal way to extract information derived from these near-optimal subspaces.																			0018-9448	1557-9654				APR	2006	52	4					1289	1306		10.1109/TIT.2006.871582	http://dx.doi.org/10.1109/TIT.2006.871582													WOS:000236714000001
J	Pan, SJ; Yang, QA				Pan, Sinno Jialin; Yang, Qiang			A Survey on Transfer Learning	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING												A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classification task in one domain of interest, but we only have sufficient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data-labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classification, regression, and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as covariate shift. We also explore some potential future issues in transfer learning research.					PAN, Sinno/P-6696-2014; yang, qiang/GYJ-0971-2022														1041-4347	1558-2191				OCT	2010	22	10					1345	1359		10.1109/TKDE.2009.191	http://dx.doi.org/10.1109/TKDE.2009.191													WOS:000281000500001
J	Chen, LC; Papandreou, G; Kokkinos, I; Murphy, K; Yuille, AL				Chen, Liang-Chieh; Papandreou, George; Kokkinos, Iasonas; Murphy, Kevin; Yuille, Alan L.			DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												In this work we address the task of semantic image segmentation with Deep Learning and make three main contributions that are experimentally shown to have substantial practical merit. First, we highlight convolution with upsampled filters, or 'atrous convolution', as a powerful tool in dense prediction tasks. Atrous convolution allows us to explicitly control the resolution at which feature responses are computed within Deep Convolutional Neural Networks. It also allows us to effectively enlarge the field of view of filters to incorporate larger context without increasing the number of parameters or the amount of computation. Second, we propose atrous spatial pyramid pooling (ASPP) to robustly segment objects at multiple scales. ASPP probes an incoming convolutional feature layer with filters at multiple sampling rates and effective fields-of-views, thus capturing objects as well as image context at multiple scales. Third, we improve the localization of object boundaries by combining methods from DCNNs and probabilistic graphical models. The commonly deployed combination of max-pooling and downsampling in DCNNs achieves invariance but has a toll on localization accuracy. We overcome this by combining the responses at the final DCNN layer with a fully connected Conditional Random Field (CRF), which is shown both qualitatively and quantitatively to improve localization performance. Our proposed "DeepLab" system sets the new state-of-art at the PASCAL VOC-2012 semantic image segmentation task, reaching 79.7 percent mIOU in the test set, and advances the results on three other datasets: PASCAL-Context, PASCAL-Person-Part, and Cityscapes. All of our code is made publicly available online.					Murphy, Kevin/ITV-7419-2023	Yuille, Alan L./0000-0001-5207-9249													0162-8828	1939-3539				APR	2018	40	4					834	848		10.1109/TPAMI.2017.2699184	http://dx.doi.org/10.1109/TPAMI.2017.2699184								28463186					WOS:000426687100005
J	Candès, EJ; Romberg, J; Tao, T				Candès, EJ; Romberg, J; Tao, T			Robust uncertainty principles:: Exact signal reconstruction from highly incomplete frequency information	IEEE TRANSACTIONS ON INFORMATION THEORY												This paper considers the model problem of reconstructing an object from incomplete frequency samples. Consider a discrete-time signal f is an element of C-N and a randomly chosen set of frequencies Q. Is it possible to reconstruct f from the partial knowledge of its Fourier coefficients on the set Q? A typical result of this paper is as follows. Suppose that f is a superposition of vertical bar T vertical bar spikes f(t) = E-tau is an element of T f(tau)delta(t - tau) obeying vertical bar T vertical bar <= C-M (.) (logN)(-1 .) vertical bar ohm vertical bar for some constant C-M > 0. We do not know the locations of the spikes nor their amplitudes. Then with probability at least 1 - O(N-m), f can be reconstructed exactly as the solution to the l(1) minimization problem min/g Sigma(N-1)/t=0 vertical bar g(t)vertical bar, s.t. (g) over cap(omega) = (f) over cap(omega) for al omega is an element of ohm In short, exact recovery may be obtained by solving a convex optimization problem. We give numerical values for Cm which depend on the desired probability of success. Our result may be interpreted as a novel kind of nonlinear sampling theorem. In effect, it says that any signal made out of vertical bar T vertical bar spikes may be recovered by convex programming from almost every set of frequencies of size O(vertical bar T vertical bar (.) log N). Moreover, this is nearly optimal in the sense that any method succeeding with probability 1 - O(N-M) would in general require a number of frequency samples at least proportional to vertical bar T vertical bar (.) log N. The methodology extends to a variety of other situations and higher dimensions. For example, we show how one can reconstruct a piecewise constant (one- or two-dimensional) object from incomplete frequency samples-provided that the number of jumps (discontinuities) obeys the condition above-by minimizing other convex functionals such as the total variation of f.					Tao, Terence/M-1837-2015														0018-9448	1557-9654				FEB	2006	52	2					489	509		10.1109/TIT.2005.862083	http://dx.doi.org/10.1109/TIT.2005.862083													WOS:000234944700009
J	Mirjalili, S; Mirjalili, SM; Lewis, A				Mirjalili, Seyedali; Mirjalili, Seyed Mohammad; Lewis, Andrew			Grey Wolf Optimizer	ADVANCES IN ENGINEERING SOFTWARE												This work proposes a new meta-heuristic called Grey Wolf Optimizer (GWO) inspired by grey wolves (Canis lupus). The GWO algorithm mimics the leadership hierarchy and hunting mechanism of grey wolves in nature. Four types of grey wolves such as alpha, beta, delta, and omega are employed for simulating the leadership hierarchy. In addition, the three main steps of hunting, searching for prey, encircling prey, and attacking prey, are implemented. The algorithm is then benchmarked on 29 well-known test functions, and the results are verified by a comparative study with Particle Swarm Optimization (PSO), Gravitational Search Algorithm (GSA), Differential Evolution (DE), Evolutionary Programming (EP), and Evolution Strategy (ES). The results show that the GWO algorithm is able to provide very competitive results compared to these well-known meta-heuristics. The paper also considers solving three classical engineering design problems (tension/compression spring, welded beam, and pressure vessel designs) and presents a real application of the proposed method in the field of optical engineering. The results of the classical engineering design problems and real application prove that the proposed algorithm is applicable to challenging problems with unknown search spaces. (C) 2013 Elsevier Ltd. All rights reserved.					Mirjalili, Seyed Mohammad/E-9988-2013; Mirjalili, Seyedali/P-1372-2018; Lewis, Andrew/A-7245-2011	Mirjalili, Seyedali/0000-0002-1443-9458; Lewis, Andrew/0000-0002-0122-2532													0965-9978	1873-5339				MAR	2014	69						46	61		10.1016/j.advengsoft.2013.12.007	http://dx.doi.org/10.1016/j.advengsoft.2013.12.007													WOS:000331924800006
J	Ojala, T; Pietikäinen, M; Mäenpää, T				Ojala, T; Pietikäinen, M; Mäenpää, T			Multiresolution gray-scale and rotation invariant texture classification with local binary patterns	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												This paper presents a theoretically very simple, yet efficient, multiresolution approach to gray-scale and rotation invariant texture classification based on local binary patterns and nonparametric discrimination of sample and prototype distributions. The method is based on recognizing that certain local binary patterns, termed "uniform," are fundamental properties of local image texture and their occurrence histogram is proven to be a very powerful texture feature. We derive a generalized gray-scale and rotation invariant operator presentation that allows for detecting the "uniform" patterns for any quantization of the angular space and for any spatial resolution and presents a method for combining multiple operators for multiresolution analysis. The proposed approach is very robust in terms of gray-scale variations since the operator is, by definition, invariant against any monotonic transformation of the gray scale. Another advantage is computational simplicity as the operator can be realized with a few operations in a small neighborhood and a lookup table. Excellent experimental results obtained in true problems of rotation invariance, where the classifier is trained at one particular rotation angle and tested with samples from other rotation angles, demonstrate that good discrimination can be achieved with the occurrence statistics of simple rotation invariant local binary patterns. These operators characterize the spatial configuration of local image texture and the performance can be further improved by combining them with rotation invariant variance measures that characterize the contrast of local image texture. The joint distributions of these orthogonal measures are shown to be very powerful tools for rotation invariant texture analysis.																			0162-8828	1939-3539				JUL	2002	24	7					971	987		10.1109/TPAMI.2002.1017623	http://dx.doi.org/10.1109/TPAMI.2002.1017623													WOS:000176446100009
J	Badrinarayanan, V; Kendall, A; Cipolla, R				Badrinarayanan, Vijay; Kendall, Alex; Cipolla, Roberto			SegNet: A Deep Convolutional Encoder-Decoder Architecture for Image Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												We present a novel and practical deep fully convolutional neural network architecture for semantic pixel-wise segmentation termed SegNet. This core trainable segmentation engine consists of an encoder network, a corresponding decoder network followed by a pixel-wise classification layer. The architecture of the encoder network is topologically identical to the 13 convolutional layers in the VGG16 network [1]. The role of the decoder network is to map the low resolution encoder feature maps to full input resolution feature maps for pixel-wise classification. The novelty of SegNet lies is in the manner in which the decoder upsamples its lower resolution input feature map(s). Specifically, the decoder uses pooling indices computed in the max-pooling step of the corresponding encoder to perform non-linear upsampling. This eliminates the need for learning to upsample. The upsampled maps are sparse and are then convolved with trainable filters to produce dense feature maps. We compare our proposed architecture with the widely adopted FCN [2] and also with the well known DeepLab-LargeFOV [3], DeconvNet [4] architectures. This comparison reveals the memory versus accuracy trade-off involved in achieving good segmentation performance. SegNet was primarily motivated by scene understanding applications. Hence, it is designed to be efficient both in terms of memory and computational time during inference. It is also significantly smaller in the number of trainable parameters than other competing architectures and can be trained end-to-end using stochastic gradient descent. We also performed a controlled benchmark of SegNet and other architectures on both road scenes and SUN RGB-D indoor scene segmentation tasks. These quantitative assessments show that SegNet provides good performance with competitive inference time and most efficient inference memory-wise as compared to other architectures. We also provide a Caffe implementation of SegNet and a web demo at http://mi.eng.cam.ac.uk/projects/segnet/.					Arandjelović, Ognjen/V-5255-2019														0162-8828	1939-3539				DEC	2017	39	12					2481	2495		10.1109/TPAMI.2016.2644615	http://dx.doi.org/10.1109/TPAMI.2016.2644615								28060704					WOS:000414395400012
J	Zhang, ZY				Zhang, ZY			A flexible new technique for camera calibration	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												We propose a flexible new technique to easily calibrate a camera. It only requires the camera to observe a planar pattern shown at a few (at Least two) different orientations. Either the camera or the planar pattern can be freely moved. The motion need not be known. Radial lens distortion is modeled. The proposed procedure consists of a closed-form solution, followed by a nonlinear refinement based on the maximum likelihood criterion. Both computer simulation and real data have been used to test the proposed technique and very good results have been obtained. Compared with classical techniques which use expensive equipment such as two or three orthogonal planes, the proposed technique is easy to use and flexible. it advances 3D computer vision one more step from laboratory environments to real world use. The corresponding software is available from the author's Web page.																			0162-8828	1939-3539				NOV	2000	22	11					1330	1334		10.1109/34.888718	http://dx.doi.org/10.1109/34.888718													WOS:000165355200011
J	Shi, JB; Malik, J				Shi, JB; Malik, J			Normalized cuts and image segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												We propose a novel approach for solving the perceptual grouping problem in vision. Rather than focusing on local features and their consistencies in the image data, our approach aims at extracting the global impression of an image. We treat image segmentation as a graph partitioning problem and propose a novel global criterion, the normalized cut, for segmenting the graph. The normalized cut criterion measures both the total dissimilarity between the different groups as well as the total similarity within the groups. We show that an efficient computational technique based on a generalized eigenvalue problem can be used to optimize this criterion. We have applied this approach to segmenting static images, as well as motion sequences, and found the results to be very encouraging.																			0162-8828	1939-3539				AUG	2000	22	8					888	905		10.1109/34.868688	http://dx.doi.org/10.1109/34.868688													WOS:000089321500013
J	Akyildiz, IF; Su, W; Sankarasubramaniam, Y; Cayirci, E				Akyildiz, IF; Su, W; Sankarasubramaniam, Y; Cayirci, E			Wireless sensor networks: a survey	COMPUTER NETWORKS												This paper describes the concept of sensor networks which has been made viable by the convergence of micro-electro-mechanical systems technology, wireless communications and digital electronics. First, the sensing tasks and the potential sensor networks applications are explored, and a review of factors influencing the design of sensor networks is provided. Then, the communication architecture for sensor networks is outlined, and the algorithms and protocols developed for each layer in the literature are explored. Open research issues for the realization of sensor networks are also discussed. (C) 2002 Published by Elsevier Science B.V.					SHARMA, YOGESH/H-3370-2018; Akyildiz, Ian/G-7136-2011														1389-1286	1872-7069				MAR 15	2002	38	4					393	422	PII S1389-1286(01)00302-4	10.1016/S1389-1286(01)00302-4	http://dx.doi.org/10.1016/S1389-1286(01)00302-4													WOS:000174316000001
J	Olfati-Saber, R; Murray, RM				Olfati-Saber, R; Murray, RM			Consensus problems in networks of agents with switching topology and time-delays	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												In this paper, we discuss consensus problems for networks of dynamic agents with fixed and switching topologies. We analyze three cases: 1) directed networks with fixed topology; 2) directed networks with switching topology; and 3) undirected networks with communication time-delays and fixed topology. We introduce two consensus protocols for networks with and without time-delays and provide a convergence analysis in all three cases. We establish a direct connection between the algebraic connectivity (or Fiedler eigenvalue) of the network and the performance or negotiation speed) of a linear consensus protocol. This required the generalization of the notion of algebraic connectivity of undirected graphs to digraphs. It turns out that balanced digraphs play a key role in addressing average-consensus problems. We introduce disagreement functions for convergence analysis of consensus protocols. A disagreement function is a Lyapunov function for the disagreement network dynamics. We proposed a simple disagreement function that is a common Lyapunov function for the disagreement dynamics of a directed network with switching topology. A distinctive feature of this work is to address consensus problems for networks with directed information flow. We provide analytical tools that rely on algebraic graph theory, matrix theory, and control theory. Simulations are provided that demonstrate the effectiveness of our theoretical results.					Murray, Richard/J-2518-2015	Murray, Richard/0000-0002-5785-7481													0018-9286	1558-2523				SEP	2004	49	9					1520	1533		10.1109/TAC.2004.834113	http://dx.doi.org/10.1109/TAC.2004.834113													WOS:000223851800009
J	Laneman, JN; Tse, DNC; Wornell, GW				Laneman, JN; Tse, DNC; Wornell, GW			Cooperative diversity in wireless networks: Efficient protocols and outage behavior	IEEE TRANSACTIONS ON INFORMATION THEORY					IEEE International Symposium on Information Theory	JUN 24-29, 2001	WASHINGTON, DC	IEEE				We develop and analyze low-complexity cooperative diversity protocols that combat fading induced by multipath propagation in wireless networks. The underlying techniques exploit space diversity available through cooperating terminals' relaying signals for one another. We outline several strategies employed by the cooperating radios, including fixed relaying schemes such as amplify-and-forward and decode-and-forward, selection relaying schemes that adapt based upon channel measurements between the cooperating terminals, and incremental relaying schemes that adapt based upon limited feedback from the destination terminal. We develop performance characterizations in terms of outage events and associated outage probabilities, which measure robustness of the transmissions to fading, focusing on the high signal-to-noise ratio (SNR) regime. Except for fixed decode-and-forward, all of our cooperative diversity protocols are efficient in the sense that they achieve full diversity (i.e., second-order diversity in the case of two terminals), and, moreover, are close to optimum (within 1.5 dB) in certain regimes. Thus, using distributed antennas, we can provide the powerful benefits of space diversity without need for physical arrays, though at a loss of spectral efficiency due to half-duplex operation and possibly at the cost of additional receive hardware. Applicable to any wireless setting, including cellular or ad hoc networks-wherever space constraints preclude the use of physical arrays-the performance characterizations reveal that large power or energy savings result from the use of these protocols.					Laneman, J/H-1194-2011	Wornell, Gregory/0000-0001-9166-4758													0018-9448	1557-9654				DEC	2004	50	12					3062	3080		10.1109/TIT.2004.838089	http://dx.doi.org/10.1109/TIT.2004.838089													WOS:000225363000009
J	Mirjalili, S; Lewis, A				Mirjalili, Seyedali; Lewis, Andrew			The Whale Optimization Algorithm	ADVANCES IN ENGINEERING SOFTWARE												This paper proposes a novel nature-inspired meta-heuristic optimization algorithm, called Whale Optimization Algorithm (WOA), which mimics the social behavior of humpback whales. The algorithm is inspired by the bubble-net hunting strategy. WOA is tested with 29 mathematical optimization problems and 6 structural design problems. Optimization results prove that the WOA algorithm is very competitive compared to the state-of-art meta-heuristic algorithms as well as conventional methods. The source codes of the WOA algorithm are publicly available at hrtp://www.alimirjalili,com/WOA.html (C) 2016 Elsevier Ltd. All rights reserved.					Mirjalili, Seyedali/P-1372-2018	Mirjalili, Seyedali/0000-0002-1443-9458													0965-9978	1873-5339				MAY	2016	95						51	67		10.1016/j.advengsoft.2016.01.008	http://dx.doi.org/10.1016/j.advengsoft.2016.01.008													WOS:000371899900006
J	Haykin, S				Haykin, S			Cognitive radio: Brain-empowered wireless communications	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS												Cognitive radio is viewed as a novel approach for improving the utilization of a precious natural resource: the radio electromagnetic spectrum. The cognitive radio, built on a software-defined radio, is defined as an intelligent wireless communication system that is aware of M environment and uses the methodology of understanding-by-building to learn from the environment and adapt to statistical variations in the input stimuli, with two primary objectives in mind: highly reliable communication whenever and wherever needed; efficient utilization of the radio spectrum. Following the discussion of interference temperature as a new metric for the quantification and management of interference, the paper addresses three fundamental cognitive tasks. 1) Radio-scene analysis. 2) Channel-state estimation and predictive modeling. 3) Transmit-power control and dynamic spectrum management. This paper also discusses the emergent behavior of cognitive radio.																			0733-8716	1558-0008				FEB	2005	23	2					201	220		10.1109/JSAC.2004.839380	http://dx.doi.org/10.1109/JSAC.2004.839380													WOS:000226943900002
J	Bay, H; Ess, A; Tuytelaars, T; Van Gool, L				Bay, Herbert; Ess, Andreas; Tuytelaars, Tinne; Van Gool, Luc			Speeded-Up Robust Features (SURF)	COMPUTER VISION AND IMAGE UNDERSTANDING												This article presents a novel scale- and rotation-invariant detector and descriptor, coined SURF (Speeded-Up Robust Features). SURF approximates or even outperforms previously proposed schemes with respect to repeatability, distinctiveness, and robustness, yet can be computed and compared much faster. This is achieved by relying on integral images for image convolutions; by building on the strengths of the leading existing detectors and descriptors (specifically, using a Hessian matrix-based measure for the detector, and a distribution-based descriptor); and by simplifying these methods to the essential. This leads to a combination of novel detection, description, and matching steps. The paper encompasses a detailed description of the detector and descriptor and then explores the effects of the most important parameters. We conclude the article with SURF's application to two challenging, yet converse goals: camera calibration as a special case of image registration, and object recognition. Our experiments underline SURF's usefulness in a broad range of topics in computer vision. (C) 2007 Elsevier Inc. All rights reserved.					Tuytelaars, Tinne/B-4319-2015	Tuytelaars, Tinne/0000-0003-3307-9723													1077-3142	1090-235X				JUN	2008	110	3					346	359		10.1016/j.cviu.2007.09.014	http://dx.doi.org/10.1016/j.cviu.2007.09.014													WOS:000256047300004
J	Arulampalam, MS; Maskell, S; Gordon, N; Clapp, T				Arulampalam, MS; Maskell, S; Gordon, N; Clapp, T			A tutorial on particle filters for online nonlinear/non-Gaussian Bayesian tracking	IEEE TRANSACTIONS ON SIGNAL PROCESSING												Increasingly, for many application areas, it is becoming important to include elements of nonlinearity and non-Gaussianity in order to model accurately the underlying dynamics of a physical system: Moreover, it is typically crucial to process data on-line as it arrives, both from the point of view of storage costs as well as for rapid adaptation to changing signal characteristics. In this paper, we review both optimal and suboptimal Bayesian algorithms for nonlinear/non-Gaussian tracking problems, with a focus on particle filters. Particle filters are sequential Monte Carlo methods based on point mass (or "particle") representations of probability densities, which can be applied to any state-space model and which generalize the traditional Kalman filtering methods:. Several variants of the particle filter such as SIR, ASIR; and RPF are introduced within a generic framework of the sequential importance sampling (SIS) algorithm. These are discussed and compared with the standard EKF through an illustrative example.						Gordon, Neil/0000-0002-5927-2591													1053-587X	1941-0476				FEB	2002	50	2					174	188		10.1109/78.978374	http://dx.doi.org/10.1109/78.978374													WOS:000173412600002
J	Comaniciu, D; Meer, P				Comaniciu, D; Meer, P			Mean shift: A robust approach toward feature space analysis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												A general nonparametric technique is proposed for the analysis of a complex multimodal feature space and to delineate arbitrarily shaped clusters in it. The basic computational module of the technique is an old pattern recognition procedure, the mean shift. We prove for discrete data the convergence of a recursive mean shift procedure to the nearest stationary point of the underlying density function and, thus, its utility in detecting the modes of the density. The relation of the mean shift procedure to the Nadaraya-Watson estimator from kernel regression and the robust M-estimators of location is also established. Algorithms for two low-level vision tasks, discontinuity preserving smoothing and image segmentation, are described as applications. In these algorithms, the only user set parameter is the resolution of the analysis and either gray level or color images are accepted as input. Extensive experimental results illustrate their excellent performance.						Comaniciu, Dorin/0000-0002-5238-8647													0162-8828	1939-3539				MAY	2002	24	5					603	619		10.1109/34.1000236	http://dx.doi.org/10.1109/34.1000236													WOS:000175187800004
J	Chan, TF; Vese, LA				Chan, TF; Vese, LA			Active contours without edges	IEEE TRANSACTIONS ON IMAGE PROCESSING												In this paper, we propose a new model for active contours to detect objects in a given image, based on techniques of curve evolution, Mumford-Shah functional for segmentation and level sets. Our model can detect objects whose boundaries are not necessarily defined by gradient. We minimize an energy which can he seen as a particular case of the minimal partition problem, In the level set formulation, the problem becomes a "mean-curvature flow"-like evolving the active contour, which will stop on the desired boundary. However, the stopping term does not depend on the gradient of the. image, as in the classical active contour models, hut is instead related to a particular segmentation of the image. We will give a numerical algorithm using finite differences. Finally, we will present various experimental results and in particular some examples for which the classical snakes methods based on the gradient are not applicable. Also, the initial curve can be anywhere in the image, and interior contours are automatically detected.					Chan, Tony F/A-4166-2013	Chan, Tony F/0000-0001-6196-2068													1057-7149	1941-0042				FEB	2001	10	2					266	277		10.1109/83.902291	http://dx.doi.org/10.1109/83.902291								18249617					WOS:000167016400007
J	Akyildiz, IF; Su, WL; Sankarasubramaniam, Y; Cayirci, E				Akyildiz, IF; Su, WL; Sankarasubramaniam, Y; Cayirci, E			A survey on sensor networks	IEEE COMMUNICATIONS MAGAZINE												Recent advancement in wireless communications and electronics has enabled the development of low-cost sensor networks. The sensor networks can be used for various application areas (e.g., health, military, home). For different application areas, there are different technical issues that researchers are currently resolving. The current state of the art of sensor networks is captured in this article, where solutions are discussed under their related protocol stack layer sections. This article also points out the open research issues and intends to spark new interests and developments in this field.					Akyildiz, Ian/G-7136-2011; SHARMA, YOGESH/H-3370-2018														0163-6804	1558-1896				AUG	2002	40	8					102	114		10.1109/MCOM.2002.1024422	http://dx.doi.org/10.1109/MCOM.2002.1024422													WOS:000177626400012
J	Kokubo, T; Takadama, H				Kokubo, T; Takadama, H			How useful is SBF in predicting in vivo bone bioactivity?	BIOMATERIALS												The bone-bonding ability of a material is often evaluated by examining the ability of apatite to form on its surface in a simulated body fluid (SBF) with ion concentrations nearly equal to those of human blood plasma. However, the validity of this method for evaluating bone-bonding ability has not been assessed systematically. Here, the history of SBF, correlation of the ability of apatite to form oil various materials in SBF with their in vivo bone bioactivities, and some examples of the development of novel bioactive materials based on apatite formation in SBF are reviewed. It was concluded that examination of apatite formation on a material in SBF is useful for predicting the in vivo bone bioactivity of a material, and the number of animals used in and the duration of animal experiments call be reduced remarkably by using this method. (c) 2006 Elsevier Ltd. All rights reserved.																			0142-9612	1878-5905				MAY	2006	27	15					2907	2915		10.1016/j.biomaterials.2006.01.017	http://dx.doi.org/10.1016/j.biomaterials.2006.01.017								16448693					WOS:000236434000001
J	Wright, J; Yang, AY; Ganesh, A; Sastry, SS; Ma, Y				Wright, John; Yang, Allen Y.; Ganesh, Arvind; Sastry, S. Shankar; Ma, Yi			Robust Face Recognition via Sparse Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												We consider the problem of automatically recognizing human faces from frontal views with varying expression and illumination, as well as occlusion and disguise. We cast the recognition problem as one of classifying among multiple linear regression models and argue that new theory from sparse signal representation offers the key to addressing this problem. Based on a sparse representation computed by l(1)-minimization, we propose a general classification algorithm for (image-based) object recognition. This new framework provides new insights into two crucial issues in face recognition: feature extraction and robustness to occlusion. For feature extraction, we show that if sparsity in the recognition problem is properly harnessed, the choice of features is no longer critical. What is critical, however, is whether the number of features is sufficiently large and whether the sparse representation is correctly computed. Unconventional features such as downsampled images and random projections perform just as well as conventional features such as Eigenfaces and Laplacianfaces, as long as the dimension of the feature space surpasses certain threshold, predicted by the theory of sparse representation. This framework can handle errors due to occlusion and corruption uniformly by exploiting the fact that these errors are often sparse with respect to the standard (pixel) basis. The theory of sparse representation helps predict how much occlusion the recognition algorithm can handle and how to choose the training images to maximize robustness to occlusion. We conduct extensive experiments on publicly available databases to verify the efficacy of the proposed algorithm and corroborate the above claims.					Ma, Yi/K-1458-2014; yang, yuqing/GRJ-8747-2022; GANESH, DR. A/JJD-0095-2023														0162-8828	1939-3539				FEB	2009	31	2					210	227		10.1109/TPAMI.2008.79	http://dx.doi.org/10.1109/TPAMI.2008.79								19110489					WOS:000261846800002
J	Aharon, M; Elad, M; Bruckstein, A				Aharon, Michal; Elad, Michael; Bruckstein, Alfred			K-SVD: An algorithm for designing overcomplete dictionaries for sparse representation	IEEE TRANSACTIONS ON SIGNAL PROCESSING												In recent years there has been a growing interest in the study of sparse representation of signals. Using an over-complete dictionary that contains prototype signal-atoms, signals are described by sparse linear combinations of these atoms. Applications that use sparse representation are many and include compression, regularization in inverse problems, feature extraction, and more. Recent activity in this field has concentrated mainly on the study of pursuit algorithms that decompose signals with respect to a given dictionary. Designing dictionaries to better fit the above model can be done by either selecting one from a prespecified set of linear transforms or adapting the dictionary to a set of training signals. Both of these techniques have been considered, but this topic is largely still open. In this paper we propose a novel algorithm for adapting dictionaries in order to achieve sparse signal representations. Given a set of training signals, we seek the dictionary that leads to the best representation for each member in this set, under strict sparsity constraints. We present a new method-the K-SVD algorithm-generalizing the K-means clustering process. K-SVD is an iterative method that alternates between sparse coding of the examples based on the current dictionary and a process of updating the dictionary atoms to better fit the data. The update of the dictionary columns is combined with an update of the sparse representations, thereby accelerating convergence. The K-SVD algorithm is flexible and can work with any pursuit method (e.g., basis pursuit, FOCUSS, or matching pursuit). We analyze this algorithm and demonstrate its results both on synthetic tests and in applications on real image data.					, Miki/AAH-4640-2019	Bruckstein, Alfred/0000-0001-5669-0037													1053-587X	1941-0476				NOV	2006	54	11					4311	4322		10.1109/TSP.2006.881199	http://dx.doi.org/10.1109/TSP.2006.881199													WOS:000241537700021
J	Candès, EJ; Wakin, MB				Candes, Emmanuel J.; Wakin, Michael B.			An introduction to compressive sampling	IEEE SIGNAL PROCESSING MAGAZINE																	Verhelst, Marian/E-5739-2011; Wakin, Michael/G-1582-2012	Verhelst, Marian/0000-0003-3495-9263; Wakin, Michael/0000-0002-2165-4586; Van Hoof, Chris/0000-0002-4645-3326													1053-5888					MAR	2008	25	2					21	30		10.1109/MSP.2007.914731	http://dx.doi.org/10.1109/MSP.2007.914731													WOS:000254471100005
J	Peng, HC; Long, FH; Ding, C				Peng, HC; Long, FH; Ding, C			Feature selection based on mutual information: Criteria of max-dependency, max-relevance, and min-redundancy	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Feature selection is an important problem for pattern classification systems. We study how to select good features according to the maximal statistical dependency criterion based on mutual information. Because of the difficulty in directly implementing the maximal dependency condition, we first derive an equivalent form, called minimal-redundancy-maximal-relevance criterion (mRMR), for first-order incremental feature selection. Then, we present a two-stage feature selection algorithm by combining mRMR and other more sophisticated feature selectors (e. g., wrappers). This allows us to select a compact set of superior features at very low cost. We perform extensive experimental comparison of our algorithm and other methods using three different classifiers (naive Bayes, support vector machine, and linear discriminate analysis) and four different data sets (handwritten digits, arrhythmia, NCI cancer cell lines, and lymphoma tissues). The results confirm that mRMR leads to promising improvement on feature selection and classification accuracy.					Peng, Hanchuan/A-1798-2011														0162-8828	1939-3539				AUG	2005	27	8					1226	1238		10.1109/TPAMI.2005.159	http://dx.doi.org/10.1109/TPAMI.2005.159								16119262					WOS:000229700900004
J	Litjens, G; Kooi, T; Bejnordi, BE; Setio, AAA; Ciompi, F; Ghafoorian, M; van der Laak, JAWM; van Ginneken, B; Sánchez, CI				Litjens, Geert; Kooi, Thijs; Bejnordi, Babak Ehteshami; Setio, Arnaud Arindra Adiyoso; Ciompi, Francesco; Ghafoorian, Mohsen; van der Laak, Jeroen A. W. M.; van Ginneken, Bram; Sanchez, Clara I.			A survey on deep learning in medical image analysis	MEDICAL IMAGE ANALYSIS												Deep learning algorithms, in particular convolutional networks, have rapidly become a methodology of choice for analyzing medical images. This paper reviews the major deep learning concepts pertinent to medical image analysis and summarizes over 300 contributions to the field, most of which appeared in the last year. We survey the use of deep learning for image classification, object detection, segmentation, registration, and other tasks. Concise overviews are provided of studies per application area: neuro, retinal, pulmonary, digital pathology, breast, cardiac, abdominal, musculoskeletal. We end with a summary of the current state-of-the-art, a critical discussion of open challenges and directions for future research. (C) 2017 Elsevier B.V. All rights reserved.					Gutierrez, Clara/N-3580-2014; Ghafoorian, Mohsen/AAH-7397-2019; Bejnordi, Babak/P-9534-2015; van der Laak, Jeroen/IVV-5737-2023; van Ginneken, Bram/A-3728-2012; Litjens, Geert/A-2319-2016; Ciompi, Francesco/P-5598-2015; van der Laak, Jeroen/D-3057-2015	Litjens, Geert/0000-0003-1554-1291; Ciompi, Francesco/0000-0001-8327-9606; van der Laak, Jeroen/0000-0001-7982-0754; van Ginneken, Bram/0000-0003-2028-8972													1361-8415	1361-8423				DEC	2017	42						60	88		10.1016/j.media.2017.07.005	http://dx.doi.org/10.1016/j.media.2017.07.005								28778026					WOS:000415778100005
J	Atzori, L; Iera, A; Morabito, G				Atzori, Luigi; Iera, Antonio; Morabito, Giacomo			The Internet of Things: A survey	COMPUTER NETWORKS												This paper addresses the Internet of Things. Main enabling factor of this promising paradigm is the integration of several technologies and communications solutions. Identification and tracking technologies, wired and wireless sensor and actuator networks, enhanced communication protocols (shared with the Next Generation Internet), and distributed intelligence for smart objects are just the most relevant. As one can easily imagine. any serious contribution to the advance of the Internet of Things must necessarily be the result of synergetic activities conducted in different fields of knowledge, such as telecommunications, informatics, electronics and social science. In such a complex scenario, this survey is directed to those who want to approach this complex discipline and contribute to its development. Different visions of this Internet of Things paradigm are reported and enabling technologies reviewed. What emerges is that still major issues shall be faced by the research community. The most relevant among them are addressed in details. (C) 2010 Elsevier B.V. All rights reserved.																			1389-1286	1872-7069				OCT 28	2010	54	15					2787	2805		10.1016/j.comnet.2010.05.010	http://dx.doi.org/10.1016/j.comnet.2010.05.010													WOS:000283039900014
J	Tropp, JA; Gilbert, AC				Tropp, Joel A.; Gilbert, Anna C.			Signal recovery from random measurements via orthogonal matching pursuit	IEEE TRANSACTIONS ON INFORMATION THEORY												This paper demonstrates theoretically and empirically that a greedy algorithm called Orthogonal Matching Pursuit (OMP) can reliably recover a signal with m nonzero entries in dimension d given O(m 1n d) random linear measurements of that signal. This is a massive improvement over previous results, which require O(m(2)) measurements. The new results for OMP are comparable with recent results for another approach called Basis Pursuit (BP). In some settings, the OMP algorithm is faster and easier to implement, so it is an attractive alternative to BP for signal recovery problems.					Tropp, Joel/B-1283-2013	Tropp, Joel/0000-0003-1024-1791													0018-9448	1557-9654				DEC	2007	53	12					4655	4666		10.1109/TIT.2007.909108	http://dx.doi.org/10.1109/TIT.2007.909108													WOS:000251801500016
J	Achanta, R; Shaji, A; Smith, K; Lucchi, A; Fua, P; Süsstrunk, S				Achanta, Radhakrishna; Shaji, Appu; Smith, Kevin; Lucchi, Aurelien; Fua, Pascal; Suesstrunk, Sabine			SLIC Superpixels Compared to State-of-the-Art Superpixel Methods	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Computer vision applications have come to rely increasingly on superpixels in recent years, but it is not always clear what constitutes a good superpixel algorithm. In an effort to understand the benefits and drawbacks of existing methods, we empirically compare five state-of-the-art superpixel algorithms for their ability to adhere to image boundaries, speed, memory efficiency, and their impact on segmentation performance. We then introduce a new superpixel algorithm, simple linear iterative clustering (SLIC), which adapts a k-means clustering approach to efficiently generate superpixels. Despite its simplicity, SLIC adheres to boundaries as well as or better than previous methods. At the same time, it is faster and more memory efficient, improves segmentation performance, and is straightforward to extend to supervoxel generation.					Fua, Pascal/H-3928-2011; Süsstrunk, Sabine/I-2466-2013; Smith, Kevin/AAX-6321-2021	Lucchi, Aurelien/0000-0001-7015-2710; Fua, Pascal/0000-0002-6702-9970													0162-8828	1939-3539				NOV	2012	34	11					2274	2281		10.1109/TPAMI.2012.120	http://dx.doi.org/10.1109/TPAMI.2012.120								22641706					WOS:000308755000017
J	Kolpin, DW; Furlong, ET; Meyer, MT; Thurman, EM; Zaugg, SD; Barber, LB; Buxton, HT				Kolpin, DW; Furlong, ET; Meyer, MT; Thurman, EM; Zaugg, SD; Barber, LB; Buxton, HT			Pharmaceuticals, hormones, and other organic wastewater contaminants in US streams, 1999-2000: A national reconnaissance	ENVIRONMENTAL SCIENCE & TECHNOLOGY												To provide the first nationwide reconnaissance of the occurrence of pharmaceuticals, hormones, and other organic wastewater contaminants (OWCs) in water resources, the U.S. Geological Survey used five newly developed analytical methods to measure concentrations of 95 OWCs in water samples from a network of 139 streams across 30 states during 1999 and 2000. The selection of sampling sites was biased toward streams susceptible to contamination (i.e. downstream of intense urbanization and livestock production). OWCs were prevalent during this study, being found in 80% of the streams sampled. The compounds detected represent a wide range of residential, industrial, and agricultural origins and uses with 82 of the 95 OWCs being found during this study. The most frequently detected compounds were coprostanol (fecal steroid), cholesterol (plant and animal steroid), N,N-diethyltoluamide (insect repellant), caffeine (stimulant), triclosan (antimicrobial disinfectant), tri(2-chloroethyl)phosphate (fire retardant), and 4-nonylphenol (nonionic detergent metabolite). Measured concentrations for this study were generally low and rarely exceeded drinking-water guidelines, drinking-water health advisories, or aquatic-life criteria. Many compounds, however, do not have such guidelines established. The detection of multiple OWCs was common for this study, with a median of seven and as many as 38 OWCs being found in a given water sample. Little is known about the potential interactive effects (such as synergistic or antagonistic toxicity) that may occur from complex mixtures of OWCs in the environment. In addition, results of this study demonstrate the importance of obtaining data on metabolites to fully understand not only the fate and transport of OWCs in the hydrologic system but also their ultimate overall effect on human health and the environment.					Furlong, Edward/C-3999-2011; Kolpin, Dana/AGW-6018-2022; Thurman, Earl/B-5131-2011; Meyer, Michael/N-7630-2017	Meyer, Michael/0000-0001-6006-7985; THURMAN, Earl Michael/0000-0002-2191-1407													0013-936X	1520-5851				MAR 15	2002	36	6					1202	1211		10.1021/es011055j	http://dx.doi.org/10.1021/es011055j								11944670					WOS:000174458100009
J	Dabov, K; Foi, A; Katkovnik, V; Egiazarian, K				Dabov, Kostadin; Foi, Alessandro; Katkovnik, Vladimir; Egiazarian, Karen			Image denoising by sparse 3-D transform-domain collaborative filtering	IEEE TRANSACTIONS ON IMAGE PROCESSING												We propose a novel image denoising strategy based on an enhanced sparse representation in transform domain. The enhancement of the sparsity is achieved by grouping similar 2-D image fragments (e.g., blocks) into 3-D data arrays which we call "groups." Collaborative filtering is a special procedure developed to deal with these 3-D groups. We realize it using the three successive steps: 3-D transformation of a group, shrinkage of the transform spectrum, and inverse 3-D transformation. The result is a 3-D estimate that consists of the jointly filtered grouped image blocks. By attenuating the noise, the collaborative filtering reveals even the finest details shared by grouped blocks and, at the same time, it preserves the essential unique features of each individual block. The filtered blocks are then returned to their original positions. Because these blocks are overlapping, for each pixel, we obtain many different estimates which need to be combined. Aggregation is a particular averaging procedure which is exploited to take advantage of this redundancy. A significant improvement is obtained by a specially developed collaborative Wiener filtering. An algorithm based on this novel denoising strategy and its efficient implementation are presented in full detail; an extension to color-image denoising is also developed. The experimental results demonstrate that this computationally scalable algorithm achieves state-of-the-art denoising performance in terms of both peak signal-to-noise ratio and subjective visual quality.					Eguiazarian, Karen/G-4299-2014; Katkovnik, Vladimir/Z-1227-2019; Foi, Alessandro/HKV-7567-2023; Foi, Alessandro/D-6010-2012	, Karen/0000-0002-8135-1085; Katkovnik, Vladimir/0000-0003-3478-0669; Foi, Alessandro/0000-0001-8228-3187													1057-7149	1941-0042				AUG	2007	16	8					2080	2095		10.1109/TIP.2007.901238	http://dx.doi.org/10.1109/TIP.2007.901238								17688213					WOS:000248192300015
J	Jadbabaie, A; Lin, J; Morse, AS				Jadbabaie, A; Lin, J; Morse, AS			Coordination of groups of mobile autonomous agents using nearest neighbor rules	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												In a recent Physical Review Letters article, Vicsek et al. propose a simple but compelling discrete-time model of n autonomous agents (i.e., points or particles) all moving in the plane with the same speed but with different headings. Each agent's heading is updated using a local rule based on the average of its own heading plus the headings of its "neighbors." In their paper, Vicsek et al. provide simulation results which demonstrate that the nearest neighbor rule they are studying can cause all agents to eventually move in the same direction despite the absence of centralized coordination and despite the fact that each agent's set of nearest neighbors change with time as the system evolves. This paper provides a theoretical explanation for this observed behavior. In addition, convergence results are derived for several other similarly inspired models. The Vicsek model proves to be a graphic example of a switched linear system which is stable, but for which there does not exist a common quadratic Lyapunov function.																			0018-9286					JUN	2003	48	6					988	1001		10.1109/TAC.2003.812781	http://dx.doi.org/10.1109/TAC.2003.812781													WOS:000183512100006
J	Heinzelman, WB; Chandrakasan, AP; Balakrishnan, H				Heinzelman, WB; Chandrakasan, AP; Balakrishnan, H			An application-specific protocol architecture for wireless microsensor networks	IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS												Networking together hundreds or thousands of cheap microsensor nodes allows users to accurately monitor a remote environment by intelligently combining the data from the individual nodes. These networks require robust wireless communication protocols that are energy efficient and provide low latency. In this paper, we develop and analyze low-energy adaptive clustering hierarchy (LEACH), a protocol architecture for microsensor networks that combines the ideas of energy-efficient cluster-based routing and media access together with application-specific data aggregation to achieve good performance in terms of system lifetime, latency, and application-perceived quality. LEACH includes a new, distributed cluster formation technique that enables self-organization of large numbers of nodes, algorithms for adapting clusters and rotating cluster head positions to evenly distribute the energy load among all the nodes, and techniques to enable distributed signal processing to save communication resources. Our results show that LEACH can improve system lifetime by an order of magnitude compared with general-purpose multihop approaches.						Heinzelman, Wendi/0000-0002-7541-4086													1536-1276	1558-2248				OCT	2002	1	4					660	670		10.1109/TWC.2002.804190	http://dx.doi.org/10.1109/TWC.2002.804190													WOS:000182432200014
J	Dong, C; Loy, CC; He, KM; Tang, XO				Dong, Chao; Loy, Chen Change; He, Kaiming; Tang, Xiaoou			Image Super-Resolution Using Deep Convolutional Networks	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												We propose a deep learning method for single image super-resolution (SR). Our method directly learns an end-to-end mapping between the low/high-resolution images. The mapping is represented as a deep convolutional neural network (CNN) that takes the low-resolution image as the input and outputs the high-resolution one. We further show that traditional sparse-coding-based SR methods can also be viewed as a deep convolutional network. But unlike traditional methods that handle each component separately, our method jointly optimizes all layers. Our deep CNN has a lightweight structure, yet demonstrates state-of-the-art restoration quality, and achieves fast speed for practical on-line usage. We explore different network structures and parameter settings to achieve trade-offs between performance and speed. Moreover, we extend our network to cope with three color channels simultaneously, and show better overall reconstruction quality.						Loy, Chen Change/0000-0001-5345-1591													0162-8828	1939-3539				FEB	2016	38	2					295	307		10.1109/TPAMI.2015.2439281	http://dx.doi.org/10.1109/TPAMI.2015.2439281								26761735					WOS:000369989600008
J	Andrews, JG; Buzzi, S; Choi, W; Hanly, SV; Lozano, A; Soong, ACK; Zhang, JC				Andrews, Jeffrey G.; Buzzi, Stefano; Choi, Wan; Hanly, Stephen V.; Lozano, Angel; Soong, Anthony C. K.; Zhang, Jianzhong Charlie			What Will 5G Be?	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS												What will 5G be? What it will not be is an incremental advance on 4G. The previous four generations of cellular technology have each been a major paradigm shift that has broken backward compatibility. Indeed, 5G will need to be a paradigm shift that includes very high carrier frequencies with massive bandwidths, extreme base station and device densities, and unprecedented numbers of antennas. However, unlike the previous four generations, it will also be highly integrative: tying any new 5G air interface and spectrum together with LTE and WiFi to provide universal high-rate coverage and a seamless user experience. To support this, the core network will also have to reach unprecedented levels of flexibility and intelligence, spectrum regulation will need to be rethought and improved, and energy and cost efficiencies will become even more critical considerations. This paper discusses all of these topics, identifying key challenges for future research and preliminary 5G standardization activities, while providing a comprehensive overview of the current literature, and in particular of the papers appearing in this special issue.					Choi, Wan/C-1785-2011; Hanly, Stephen/C-5909-2008; Andrews, Jeffrey/ADW-5995-2022; Buzzi, Stefano/Y-9644-2019; Lozano, Angel/A-3332-2012	Hanly, Stephen/0000-0002-0524-9927; Lozano, Angel/0000-0003-3790-0494; Choi, Wan/0000-0003-3930-7088													0733-8716	1558-0008				JUN	2014	32	6					1065	1082		10.1109/JSAC.2014.2328098	http://dx.doi.org/10.1109/JSAC.2014.2328098													WOS:000340748600001
J	Buongiorno, J				Buongiorno, J			Convective transport in nanofluids	JOURNAL OF HEAT TRANSFER-TRANSACTIONS OF THE ASME												Nanofluids are engineered colloids made of a base fluid and nanoparticles (1 - 100 nm). Nanofluids have higher thermal conductivity and single-phase heat transfer coefficients than their base fluids. In particular the heat transfer coefficient increases appear to go beyond the mere thermal-conductivity effect, and cannot be predicted by traditional pure-fluid correlations such as Dittus-Boelter's. In the nanofluid literature this behavior is generally attributed to thermal dispersion and intensified turbulence, brought about by nanoparticle motion. To test the validity of this assumption, we have considered seven slip mechanisms that can produce a relative velocity between the nanoparticles and the base fluid. These are inertia, Brownian diffusion, thermophoresis, diffusiophoresis, Magnus effect, fluid drainage, and gravity. We concluded that, of these seven, only Brownian diffusion and thermophoresis are important slip mechanisms in nanofluids. Based on this finding, we developed a two-component four-equation nonhomogeneous equilibrium model for mass, momentum, and heat transport in nanofluids. A nondimensional analysis of the equations suggests that energy transfer by nanoparticle dispersion is negligible, and thus cannot explain the abnormal heat transfer coefficient increases. Furthermore, a comparison of the nanoparticle and turbulent eddy time and length scales clearly indicates that the nanoparticles move homogeneously with the fluid in the presence of turbulent eddies, so an effect on turbulence intensity is also doubtful. Thus, we propose an alternative explanation for the abnormal heat transfer coefficient increases: the nanofluid properties may vary significantly within the boundary layer because of the effect of the temperature gradient and thermophoresis. For a heated fluid, these effects can result in a significant decrease of viscosity within the boundary layer thus leading to heat transfer enhancement. A correlation structure that captures these effects is proposed.																			0022-1481	1528-8943				MAR	2006	128	3					240	250		10.1115/1.2150834	http://dx.doi.org/10.1115/1.2150834													WOS:000236009600004
J	Yang, HP; Yan, R; Chen, HP; Lee, DH; Zheng, CG				Yang, Haiping; Yan, Rong; Chen, Hanping; Lee, Dong Ho; Zheng, Chuguang			Characteristics of hemicellulose, cellulose and lignin pyrolysis	FUEL												The pyrolysis characteristics of three main components (hemicellulose, cellulose and lignin) of biomass were investigated using, respectively, a thermogravimetric analyzer (TGA) with differential scanning calorimetry (DSC) detector and a pack bed. The releasing of main gas products from biomass pyrolysis in TGA was on-line measured using Fourier transform infrared (FTIR) spectroscopy. In thermal analysis, the pyrolysis of hemicellulose and cellulose occurred quickly, with the weight loss of hemicellulose mainly happened at 220-315 degrees C and that of cellulose at 315-400 degrees C. However, lignin was more difficult to decompose, as its weight loss happened in a wide temperature range (from 160 to 900 degrees C) and the generated solid residue was very high (similar to 40 wt.%). From the viewpoint of energy consumption in the course of pyrolysis, cellulose behaved differently from hemicellulose and lignin; the pyrolysis of the former was endothermic while that of the latter was exothermic. The main gas products from pyrolyzing the three components were similar, including CO2, CO, CH4 and some organics. The releasing behaviors of H-2 and the total gas yield were measured using Micro-GC when pyrolyzing the three components in a packed bed. It was observed that hemicellulose had higher CO2 yield, cellulose generated higher CO yield, and lignin owned higher H-2 and CH4 yield. A better understanding to the gas products releasing from biomass pyrolysis could be achieved based on this in-depth investigation on three main biomass components. (c) 2006 Elsevier Ltd. All rights reserved.																			0016-2361	1873-7153				AUG	2007	86	12-13					1781	1788		10.1016/j.fuel.2006.12.013	http://dx.doi.org/10.1016/j.fuel.2006.12.013													WOS:000248880600012
J	Wiegand, T; Sullivan, GJ; Bjontegaard, G; Luthra, A				Wiegand, T; Sullivan, GJ; Bjontegaard, G; Luthra, A			Overview of the H.264/AVC video coding standard	IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY												H.264/AVC is newest video coding standard of the ITU-T Video Coding Experts Group and the ISO/IEC Moving Picture Experts Group. The main goals of the H.264/AVC standardization effort have been enhanced compression performance and provision of a "network-friendly" video representation addressing "conversational" (video telephony) and "nonconversational" (storage, broadcast, or streaming) applications. H.264/AVC has achieved a significant improvement in rate-distortion efficiency relative-to existing standards. This article provides an overview of the technical features of H.264/AVC, describes profiles and applications for the standard, and outlines the history of the standardization process.						Sullivan, Gary/0000-0002-2350-9235													1051-8215	1558-2205				JUL	2003	13	7					560	576		10.1109/TCSVT.2003.815165	http://dx.doi.org/10.1109/TCSVT.2003.815165													WOS:000184513900002
J	Sullivan, GJ; Ohm, JR; Han, WJ; Wiegand, T				Sullivan, Gary J.; Ohm, Jens-Rainer; Han, Woo-Jin; Wiegand, Thomas			Overview of the High Efficiency Video Coding (HEVC) Standard	IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY												High Efficiency Video Coding (HEVC) is currently being prepared as the newest video coding standard of the ITU-T Video Coding Experts Group and the ISO/IEC Moving Picture Experts Group. The main goal of the HEVC standardization effort is to enable significantly improved compression performance relative to existing standards-in the range of 50% bit-rate reduction for equal perceptual video quality. This paper provides an overview of the technical features and characteristics of the HEVC standard.						Sullivan, Gary/0000-0002-2350-9235; Han, Woo-Jin/0000-0002-2232-9849													1051-8215	1558-2205				DEC	2012	22	12					1649	1668		10.1109/TCSVT.2012.2221191	http://dx.doi.org/10.1109/TCSVT.2012.2221191													WOS:000314498000003
J	Bianchi, G				Bianchi, G			Performance analysis,of the IEEE 802.11 distributed coordination function	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS												Recently, the IEEE has standardized the 802.11 protocol for Wireless Local Area Networks. The primary medium access control (MAC) technique of 802.11 is called distributed coordination function (DCF), DCF is a carrier sense multiple access with collision avoidance (CSMA/CA) scheme with binary slotted exponential backoff. This paper provides a simple, but nevertheless extremely accurate, analytical model to compute the 802.11 DCF throughput, in the assumption of finite number of terminals and ideal channel conditions. The proposed analysis applies to both the packet transmission schemes employed by DCF, namely, the basic access and the RTS/CTS access mechanisms. In addition, it also applies to a combination of the two schemes, in which packets longer than a given threshold are transmitted according to the RTS/CTS mechanism. By means of the proposed model, in this paper we provide an extensive throughput performance evaluation of both access mechanisms of the 802.11 protocol.						Bianchi, Giuseppe/0000-0001-7277-7423													0733-8716					MAR	2000	18	3					535	547		10.1109/49.840210	http://dx.doi.org/10.1109/49.840210													WOS:000086706800021
J	Jenkinson, M; Smith, S				Jenkinson, M; Smith, S			A global optimisation method for robust affine registration of brain images	MEDICAL IMAGE ANALYSIS												Registration is an important component of medical image analysis and for analysing large amounts of data it is desirable to have fully automatic registration methods. Many different automatic registration methods have been proposed to date, and almost all share a common mathematical framework - one of optimising a cost function. To date little attention has been focused on the optimisation method itself, even though the success of most registration methods hinges on the quality of this optimisation. This paper examines the assumptions underlying the problem of registration for brain images using inter-modal voxel similarity measures. It is demonstrated that the use of local optimisation methods together with the standard multi-resolution approach is not sufficient to reliably find the global minimum. To address this problem, a global optimisation method is proposed that is specifically tailored to this form of registration. A full discussion of all the necessary implementation details is included as this is an important part of any practical method. Furthermore, results are presented for inter-modal, inter-subject registration experiments that show that the proposed method is more reliable at finding the global minimum than several of the currently available registration packages in common usage. (C) 2001 Elsevier Science B.V. All rights reserved.					Jenkinson, Mark/AAC-8861-2019	Smith, Stephen/0000-0001-8166-069X; Jenkinson, Mark/0000-0001-6043-0166													1361-8415	1361-8423				JUN	2001	5	2					143	156		10.1016/S1361-8415(01)00036-6	http://dx.doi.org/10.1016/S1361-8415(01)00036-6								11516708					WOS:000169672400005
J	Gupta, P; Kumar, PR				Gupta, P; Kumar, PR			The capacity of wireless networks	IEEE TRANSACTIONS ON INFORMATION THEORY												When n identical randomly located nodes, each capable of transmitting at W bits per second and using a fixed range, form a wireless network, the throughput lambda(n) obtainable by each node for a randomly chosen destination is Theta (W/root n log n) bits per second under a noninterference protocol. If the nodes are optimally placed in a disk of unit area, traffic patterns are optimally assigned, and each transmission's range is optimally chosen, the bit-distance product that can be transported by the network per second is Theta(W root An) bit-meters per second. Thus even under optimal circumstances, the throughput is only Theta(W/root n) bits per second for each node for a destination nonvanishingly far away, Similar results also hold under an alternate physical model where a required signal-to-interference ratio is specified for successful receptions. Fundamentally, it is the need for every node all over the domain to share whatever portion of the channel it is utilizing with nodes in its local neighborhood that is the reason for the constriction in capacity, Splitting the channel into several subchannels does not change any of the results. Some implications may be worth considering by designers. Since the throughput furnished to each user diminishes to zero as the number of users is increased, perhaps networks connecting smaller numbers of users, or featuring connections mostly with nearby neighbors, may be more likely to be find acceptance.																			0018-9448	1557-9654				MAR	2000	46	2					388	404		10.1109/18.825799	http://dx.doi.org/10.1109/18.825799													WOS:000085870000004
J	Ahlswede, R; Cai, N; Li, SYR; Yeung, RW				Ahlswede, R; Cai, N; Li, SYR; Yeung, RW			Network information flow	IEEE TRANSACTIONS ON INFORMATION THEORY					IEEE International Symposium on Information Theory	AUG 16-22, 1998	MIT, CAMBRIDGE, MASSACHUSETTS	IEEE, Informat Theory Soc, Natl Sci Fdn, NASA, USN, Off Naval Res, AT&T, Motorola, Qualcomm, Lucent Technol, Bell Lab Innovat	MIT			We introduce a new class of problems called network information flow which is inspired by computer network applications. Consider a point-to-point communication network on which a number of information sources are to be mulitcast to certain sets of destinations. We assume that the information sources are mutually independent. The problem is to characterize the admissible coding rate region. This model subsumes all previously studied models along the same line. In this paper, we study the problem with one information source, and we have obtained a simple characterization of the admissible coding rate region. Our result can be regarded as the Max-flow Min-cut Theorem for network information flow. Contrary to one's intuition, our work reveals that it is in general not optimal to regard the information to be multicast as a "fluid'' which can simply be routed or replicated. Rather, by employing coding at the nodes, which we refer to as network coding, bandwidth can in general be saved. This finding may have significant impact on future design of switching systems.					Yeung, Raymond/KSL-6605-2024														0018-9448					JUL	2000	46	4					1204	1216		10.1109/18.850663	http://dx.doi.org/10.1109/18.850663													WOS:000088206200002
J	Ren, W; Beard, RW				Ren, W; Beard, RW			Consensus seeking in multiagent systems under dynamically changing interaction topologies	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												This note considers the problem of information consensus among multiple agents in the presence of limited and unreliable information exchange with dynamically changing interaction topologies. Both discrete and continuous update schemes are proposed for information consensus. This note shows that information consensus under dynamically changing interaction topologies can be achieved asymptotically if the union of the directed interaction graphs have a spanning tree frequently enough as the system evolves.					Ren, Wei/G-7369-2011														0018-9286	1558-2523				MAY	2005	50	5					655	661		10.1109/TAC.2005.846556	http://dx.doi.org/10.1109/TAC.2005.846556													WOS:000229085100010
J	Rappaport, TS; Sun, S; Mayzus, R; Zhao, H; Azar, Y; Wang, K; Wong, GN; Schulz, JK; Samimi, M; Gutierrez, F				Rappaport, Theodore S.; Sun, Shu; Mayzus, Rimma; Zhao, Hang; Azar, Yaniv; Wang, Kevin; Wong, George N.; Schulz, Jocelyn K.; Samimi, Mathew; Gutierrez, Felix			Millimeter Wave Mobile Communications for 5G Cellular: It Will Work!	IEEE ACCESS												The global bandwidth shortage facing wireless carriers has motivated the exploration of the underutilized millimeter wave (mm-wave) frequency spectrum for future broadband cellular communication networks. There is, however, little knowledge about cellular mm-wave propagation in densely populated indoor and outdoor environments. Obtaining this information is vital for the design and operation of future fifth generation cellular networks that use the mm-wave spectrum. In this paper, we present the motivation for new mm-wave cellular systems, methodology, and hardware for measurements and offer a variety of measurement results that show 28 and 38 GHz frequencies can be used when employing steerable directional antennas at base stations and mobile devices.					Wong, George/AAL-1016-2021; Sun, Shu/AAH-1270-2021; Leon, Agathe/K-9851-2015	Rappaport, Theodore (Ted)/0000-0001-7449-9957; Wong, George/0000-0001-6952-2147													2169-3536						2013	1						335	349		10.1109/ACCESS.2013.2260813	http://dx.doi.org/10.1109/ACCESS.2013.2260813													WOS:000209652700025
J	Hsu, CW; Lin, CJ				Hsu, CW; Lin, CJ			A comparison of methods for multiclass support vector machines	IEEE TRANSACTIONS ON NEURAL NETWORKS												Support vector machines (SVMs) were originally designed for binary classification. How to effectively extend it for multiclass classification is still an ongoing research issue. Several methods have been proposed where typically we construct a multiclass classifier by combining several binary classifiers. Some authors also proposed methods that consider all classes at once. As it is computationally more expensive to solve multiclass problems, comparisons of these methods using large-scale problems have not been seriously conducted. Especially for methods solving multiclass SVM in one step, a much larger optimization problem is required so up to now experiments are limited to small data sets. In this paper we give decomposition implementations for two such "all-together" methods. We then compare their performance with three methods based on binary classifications: "one-against-all," "one-against-one," and directed acyclic graph SVM (DAGSVM). Our experiments indicate that the "one-against-one" and DAG methods are more suitable for practical use than the other methods. Results also show that for large problems methods by considering all data at once in general need fewer support vectors.						Lin, Chih-Jen/0000-0003-4684-8747													1045-9227	1941-0093				MAR	2002	13	2					415	425	PII S1045-9227(02)01805-2	10.1109/72.991427	http://dx.doi.org/10.1109/72.991427								18244442					WOS:000174519400014
J	Zhang, YY; Brady, M; Smith, S				Zhang, YY; Brady, M; Smith, S			Segmentation of brain MR images through a hidden Markov random field model and the expectation-maximization algorithm	IEEE TRANSACTIONS ON MEDICAL IMAGING												The finite mixture (FM) model is the most commonly used model for statistical segmentation of brain magnetic resonance (MR) images because of its simple mathematical form and the piecewise constant nature of ideal brain MR images. However, being a histogram-based model, the FM has an intrinsic limitation-no spatial information is taken into account. This causes the FM model to work only on well-defined images with low levels of noise; unfortunately, this is often not the the case due to artifacts such as partial volume effect and bias field distortion. Under these conditions, FM model-based methods produce unreliable results. In this paper, we propose a novel hidden Markov random held (HMRF) model, which is a stochastic process generated by a MRF whose state sequence cannot be observed directly but which can be indirectly estimated through observations. Mathematically, it can be shown that the FM model is a degenerate version of the HMRF model. The advantage of the HMRF model derives from the way in which the spatial information is encoded through the mutual influences of neighboring sites. Although MRF modeling has been employed in MR image segmentation by other researchers, most reported methods are limited to using MRF as a general prior in an FM model-based approach. To fit the HMRF model, an EM algorithm is used, We show that by incorporating both the HMRF model and the Ehl algorithm into a HMRF-EM framework, an accurate and robust segmentation can be achieved. More importantly, the HMRF-EM framework can easily be combined with other techniques. As an example, we show how the bias held correction algorithm of Guillemaud and Brady (1997) can be incorporated into this framework to achieve a three-dimensional fully automated approach for brain MR image segmentation.						Smith, Stephen/0000-0001-8166-069X													0278-0062	1558-254X				JAN	2001	20	1					45	57		10.1109/42.906424	http://dx.doi.org/10.1109/42.906424								11293691					WOS:000167324900005
J	Zhang, K; Zuo, WM; Chen, YJ; Meng, DY; Zhang, L				Zhang, Kai; Zuo, Wangmeng; Chen, Yunjin; Meng, Deyu; Zhang, Lei			Beyond a Gaussian Denoiser: Residual Learning of Deep CNN for Image Denoising	IEEE TRANSACTIONS ON IMAGE PROCESSING												The discriminative model learning for image denoising has been recently attracting considerable attentions due to its favorable denoising performance. In this paper, we take one step forward by investigating the construction of feed-forward denoising convolutional neural networks (DnCNNs) to embrace the progress in very deep architecture, learning algorithm, and regularization method into image denoising. Specifically, residual learning and batch normalization are utilized to speed up the training process as well as boost the denoising performance. Different from the existing discriminative denoising models which usually train a specific model for additive white Gaussian noise at a certain noise level, our DnCNN model is able to handle Gaussian denoising with unknown noise level (i.e., blind Gaussian denoising). With the residual learning strategy, DnCNN implicitly removes the latent clean image in the hidden layers. This property motivates us to train a single DnCNN model to tackle with several general image denoising tasks, such as Gaussian denoising, single image super-resolution, and JPEG image deblocking. Our extensive experiments demonstrate that our DnCNN model can not only exhibit high effectiveness in several general image denoising tasks, but also be efficiently implemented by benefiting from GPU computing.					Zhang, Kai/ABF-3950-2020; Zhang, Lei/P-8881-2014; Zuo, Wangmeng/B-3701-2008; Meng, Deyu/KOC-3154-2024	Zuo, Wangmeng/0000-0002-3330-783X; Zhang, Lei/0000-0002-2078-4215; Zhang, Kai/0000-0002-6319-3722													1057-7149	1941-0042				JUL	2017	26	7					3142	3155		10.1109/TIP.2017.2662206	http://dx.doi.org/10.1109/TIP.2017.2662206								28166495					WOS:000401297400005
J	Candes, EJ; Tao, T				Candes, EJ; Tao, T			Decoding by linear programming	IEEE TRANSACTIONS ON INFORMATION THEORY												This paper considers a natural error correcting problem with real valued input/output. We wish to recover an input vector f is an element of R-n from corrupted measurements y = Af + e. Here, A is an m by n (coding) matrix and e is an arbitrary and unknown vector of errors. Is it possible to recover f exactly from the data y?					Tao, Terence/M-1837-2015														0018-9448	1557-9654				DEC	2005	51	12					4203	4215		10.1109/TIT.2005.858979	http://dx.doi.org/10.1109/TIT.2005.858979													WOS:000233621500010
J	Boykov, Y; Veksler, O; Zabih, R				Boykov, Y; Veksler, O; Zabih, R			Fast approximate energy minimization via graph cuts	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Many tasks in computer vision involve assigning a label (such as disparity) to every pixel. A common constraint is that the labels should vary smoothly almost everywhere while preserving sharp discontinuities that may exist, e.g., at object boundaries. These tasks are naturally stated in terms of energy minimization. In this paper, we consider a wide class of energies with various smoothness constraints. Global minimization of these energy functions is NP-hard even in the simplest discontinuity-preserving case. Therefore, our focus is on efficient approximation algorithms. We present two algorithms based on graph cuts that efficiently find a local minimum with respect to two types of large moves, namely expansion moves and swap moves. These moves can simultaneously change the labels of arbitrarily large sets of pixels. In contrast, many standard algorithms (including simulated annealing) use small moves where only one pixel changes its label at a time. Our expansion algorithm finds a labeling within a known factor of the global minimum, while our swap algorithm handles more general energy functions. Both of these algorithms allow important cases of discontinuity preserving energies. We experimentally demonstrate the effectiveness of our approach for image restoration, stereo and motion. On real data with ground truth, we achieve 98 percent accuracy.					Veksler, Olga/B-6549-2015; Boykov, Yuri/C-1718-2015	Zabih, Ramin/0000-0001-8769-5666													0162-8828	1939-3539				NOV	2001	23	11					1222	1239		10.1109/34.969114	http://dx.doi.org/10.1109/34.969114													WOS:000172108300002
J	Dragomiretskiy, K; Zosso, D				Dragomiretskiy, Konstantin; Zosso, Dominique			Variational Mode Decomposition	IEEE TRANSACTIONS ON SIGNAL PROCESSING												During the late 1990s, Huang introduced the algorithm called Empirical Mode Decomposition, which is widely used today to recursively decompose a signal into different modes of unknown but separate spectral bands. EMD is known for limitations like sensitivity to noise and sampling. These limitations could only partially be addressed by more mathematical attempts to this decomposition problem, like synchrosqueezing, empirical wavelets or recursive variational decomposition. Here, we propose an entirely non-recursive variational mode decomposition model, where the modes are extracted concurrently. The model looks for an ensemble of modes and their respective center frequencies, such that the modes collectively reproduce the input signal, while each being smooth after demodulation into baseband. In Fourier domain, this corresponds to a narrow-band prior. We show important relations to Wiener filter denoising. Indeed, the proposed method is a generalization of the classic Wiener filter into multiple, adaptive bands. Our model provides a solution to the decomposition problem that is theoretically well founded and still easy to understand. The variational model is efficiently optimized using an alternating direction method of multipliers approach. Preliminary results show attractive performance with respect to existing mode decomposition models. In particular, our proposed model is much more robust to sampling and noise. Finally, we show promising practical decomposition results on a series of artificial and real data.					Zosso, Dominique/F-4783-2010	Zosso, Dominique/0000-0001-5685-4273													1053-587X	1941-0476				FEB	2014	62	3					531	544		10.1109/TSP.2013.2288675	http://dx.doi.org/10.1109/TSP.2013.2288675													WOS:000330771300001
J	Allison, J; Amako, K; Apostolakis, J; Araujo, H; Dubois, PA; Asai, M; Barrand, G; Capra, R; Chauvie, S; Chytracek, R; Cirrone, GAP; Cooperman, G; Cosmo, G; Cuttone, G; Daquino, GG; Donszelmann, M; Dressel, M; Folger, G; Foppiano, F; Generowicz, J; Grichine, V; Guatelli, S; Gumplinger, P; Heikkinen, A; Hrivnacova, I; Howard, A; Incerti, S; Ivanchenko, V; Johnson, T; Jones, F; Koi, T; Kokoulin, R; Kossov, M; Kurashige, H; Lara, V; Larsson, S; Lei, F; Link, O; Longo, F; Maire, M; Mantero, A; Mascialino, B; McLaren, I; Lorenzo, PM; Minamimoto, K; Murakami, K; Nieminen, P; Pandola, L; Parlati, S; Peralta, L; Perl, J; Pfeiffer, A; Pia, MG; Ribon, A; Rodrigues, P; Russo, G; Sadilov, S; Santin, G; Sasaki, T; Smith, D; Starkov, N; Tanaka, S; Tcherniaev, E; Tomé, B; Trindade, A; Truscott, P; Urban, L; Verderi, M; Walkden, A; Wellisch, JP; Williams, DC; Wright, D; Yoshida, H				Allison, J; Amako, K; Apostolakis, J; Araujo, H; Dubois, PA; Asai, M; Barrand, G; Capra, R; Chauvie, S; Chytracek, R; Cirrone, GAP; Cooperman, G; Cosmo, G; Cuttone, G; Daquino, GG; Donszelmann, M; Dressel, M; Folger, G; Foppiano, F; Generowicz, J; Grichine, V; Guatelli, S; Gumplinger, P; Heikkinen, A; Hrivnacova, I; Howard, A; Incerti, S; Ivanchenko, V; Johnson, T; Jones, F; Koi, T; Kokoulin, R; Kossov, M; Kurashige, H; Lara, V; Larsson, S; Lei, F; Link, O; Longo, F; Maire, M; Mantero, A; Mascialino, B; McLaren, I; Lorenzo, PM; Minamimoto, K; Murakami, K; Nieminen, P; Pandola, L; Parlati, S; Peralta, L; Perl, J; Pfeiffer, A; Pia, MG; Ribon, A; Rodrigues, P; Russo, G; Sadilov, S; Santin, G; Sasaki, T; Smith, D; Starkov, N; Tanaka, S; Tcherniaev, E; Tomé, B; Trindade, A; Truscott, P; Urban, L; Verderi, M; Walkden, A; Wellisch, JP; Williams, DC; Wright, D; Yoshida, H			Geant4 developments and applications	IEEE TRANSACTIONS ON NUCLEAR SCIENCE												Geant4 is a software toolkit for the simulation of the passage of particles through matter. It is used by a large number of experiments and projects in a variety of application domains, including high energy physics, astrophysics and space science, medical physics and radiation protection. Its functionality and modeling capabilities continue to be extended, while its performance is enhanced. An overview of recent developments in diverse areas of the toolkit is presented. These include performance optimization for complex setups; improvements for the propagation in fields; new options for event biasing; and additions and improvements in geometry, physics processes and interactive capabilities.					Longo, Francesco/I-4336-2016; Rodrigues, Pedro/KIE-4153-2024; Ivanchenko, Vladimir/N-3953-2019; Cirrone, Giuseppe/AAF-7101-2021; cuttone, giacomo/C-4085-2009; Starkov, Nikolai/D-9293-2014; Williams, David/A-1180-2007; Incerti, Sebastien/T-3006-2017; Pandola, Luciano/AAS-8443-2021; Grichine, Vladimir/M-8526-2015; Sasaki, Takashi/K-6031-2012; Chytracek, RADOVAN/V-7349-2019; Pia, Maria/C-7034-2012; Guatelli, Susanna/C-2896-2014; russo, giorgio/K-8855-2016; Lei, Fan/KFB-0896-2024; Kokoulin, Rostislav/A-5689-2011; Hisaya, Kurashige/H-4916-2012; Arce, Pedro/L-1268-2014; Ivanchenko, Vladimir/L-5254-2017; Cirrone, Giuseppe Pablo/I-6474-2015; Russo, Giorgio/A-8100-2015; Tcherniaev, Evgueni/G-3453-2016; Tome, Bernardo/J-4410-2013; Parlati, Sandra/K-8567-2018; Chauvie, Stephane/AAF-9901-2021; Peralta, Luis/C-8369-2011	Hisaya, Kurashige/0000-0003-3932-016X; Arce, Pedro/0000-0003-3009-0484; Murakami, Koichi/0000-0001-5777-5796; Santin, Giovanni/0000-0003-4330-9449; Araujo, Henrique/0000-0002-5972-2783; Ivanchenko, Vladimir/0000-0002-1844-5433; Cirrone, Giuseppe Pablo/0000-0001-5733-9281; Lei, Fan/0000-0002-4365-988X; Apostolakis, John/0000-0003-1184-3727; Russo, Giorgio/0000-0003-1493-1087; Pia, Maria Grazia/0000-0002-3579-9639; HRIVNACOVA, Ivana/0000-0003-0120-6337; Tcherniaev, Evgueni/0000-0002-3685-0635; Tome, Bernardo/0000-0002-7564-8392; Williams, David/0000-0002-4123-9339; Incerti, Sebastien/0000-0002-0619-2053; Parlati, Sandra/0000-0001-7099-0378; Mascialino, Barbara/0000-0003-4154-4728; Chauvie, Stephane/0000-0003-4394-5031; Pandola, Luciano/0000-0003-2867-0121; Guatelli, Susanna/0000-0002-9289-7956; Amako, Katsuya/0000-0003-3307-2951; Peralta, Luis/0000-0002-3834-1762; Cuttone, Giacomo/0000-0002-9534-4855													0018-9499	1558-1578				FEB	2006	53	1	2				270	278		10.1109/TNS.2006.869826	http://dx.doi.org/10.1109/TNS.2006.869826													WOS:000236473900008
J	Chen, W; Westerhoff, P; Leenheer, JA; Booksh, K				Chen, W; Westerhoff, P; Leenheer, JA; Booksh, K			Fluorescence excitation - Emission matrix regional integration to quantify spectra for dissolved organic matter	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Excitation-emission matrix (EEM) fluorescence spectroscopy has been widely used to characterize dissolved organic matter (DOM) in water and soil. However, interpreting the >10,000 wave length-dependent fluorescence intensity data points represented in EEMs has posed a significant challenge. Fluorescence regional integration, a quantitative technique that integrates the volume beneath an EEM, was developed to analyze EEMs. EEMs were delineated into five excitation-emission regions based on fluorescence of model compounds, DOM fractions, and marine waters or freshwaters. Volumetric integration under the EEM within each region, normalized to the projected excitation-emission area within that region and dissolved organic carbon concentration, resulted in a normalized region-specific EEM volume (Phi(i,n)). Solid-state carbon nuclear magnetic resonance (C-13 NMR), Fourier transform infrared (FTIR) analysis, ultraviolet-visible absorption spectra, and EEMs were obtained for standard Suwannee River fulvic acid and 15 hydrophobic or hydrophilic acid, neutral, and base DOM fractions plus nonfractionated DOM from wastewater effluents and rivers in the southwestern United States. DOM fractions fluoresced in one or more EEM regions. The highest cumulative EEM volume (Phi(T,n) = SigmaPhi(i,n)) was observed for hydrophobic neutral DOM fractions, followed by lower Phi(T,n) values for hydrophobic acid, base, and hydrophilic acid DOM fractions, respectively. An extracted wastewater biomass DOM sample contained aromatic protein- and humic-like material and was characteristic of bacterial-soluble microbial products. Aromatic carbon and the presence of specific aromatic compounds (as indicated by solid-state C-13 NMR and FTIR data) resulted in EEMs that aided in differentiating wastewater effluent DOM from drinking water DOM.					Westerhoff, Paul/AAF-1850-2019														0013-936X	1520-5851				DEC 15	2003	37	24					5701	5710		10.1021/es034354c	http://dx.doi.org/10.1021/es034354c								14717183					WOS:000187248000031
J	Geuzaine, C; Remacle, JF				Geuzaine, Christophe; Remacle, Jean-Francois			Gmsh: A 3-D finite element mesh generator with built-in pre- and post-processing facilities	INTERNATIONAL JOURNAL FOR NUMERICAL METHODS IN ENGINEERING												Gmsh is an open-source 3-D finite element grid generator with a build-in CAD engine and post-processor. Its design goal is to provide a fast, light and user-friendly meshing tool with parametric input and advanced visualization capabilities. This paper presents the overall philosophy, the main design choices and some of the original algorithms implemented in Gmsh. Copyright (C) 2009 John Wiley & Sons, Ltd.					Geuzaine, Christophe/HSG-2308-2023; remacle, jean-francois/A-8034-2012	remacle, jean-francois/0000-0002-4798-6458; Geuzaine, Christophe/0000-0001-9970-358X													0029-5981	1097-0207				SEP 10	2009	79	11					1309	1331		10.1002/nme.2579	http://dx.doi.org/10.1002/nme.2579													WOS:000269903700001
J	Candes, EJ; Tao, T				Candes, Emmanuel J.; Tao, Terence			Near-optimal signal recovery from random projections: Universal encoding strategies?	IEEE TRANSACTIONS ON INFORMATION THEORY					Conference on Multiscale Geometry and Analysis in High Dimensions	OCT, 2004	Los Angeles, CA					Suppose we are given a vector f in a class F subset of R-N e.g., a class of digital signals or digital images. How many linear measurements do we need to make about f to be able to recover f to within precision is an element of in the Euclidean (l(2)) metric? This paper shows that if the objects of interest are sparse in a fixed basis or compressible, then it is possible to reconstruct f to within very high accuracy from a small number of random measurements by solving a simple linear program. More precisely, suppose that the,nth largest entry of the vector If I (or of its coefficients in a fixed basis) obeys vertical bar f vertical bar((n)) < R (.) n(-1/P), where R > 0 and p > 0. Suppose that we take measurements y(k) = < f, X-k >; k = 1..., K, where the X-k are N-dimensional Gaussian vectors with independent standard normal entries. Then for each f obeying the decay estimate above for some 0 < p < 1 and with overwhelming probability, our reconstruction f(#) defined as the solution to the constraints y(k) = < f(#), X-k > with minimal l(1) norm, obeys parallel to f - f(#)parallel to(l2) <= C-p (.) R (.) (K/log N)(-r), r = 1/p - 1/2 There is a sense in which this result is optimal; it is generally impossible to obtain a higher accuracy from any set of K measurements whatsoever. The methodology extends to various other random measurement ensembles; for example, we show that similar results hold if one observes a few randomly sampled Fourier coefficients of f. In fact, the results are quite general and require only two hypotheses on the measurement ensemble which are detailed.					Tao, Terence/M-1837-2015														0018-9448	1557-9654				DEC	2006	52	12					5406	5425		10.1109/TIT.2006.885507	http://dx.doi.org/10.1109/TIT.2006.885507													WOS:000242503300015
J	Sendonaris, A; Erkip, E; Aazhang, B				Sendonaris, A; Erkip, E; Aazhang, B			User cooperation diversity - Part 1: System description	IEEE TRANSACTIONS ON COMMUNICATIONS												Mobile users' data rate and quality of service are limited by the fact that, within the duration of any given call, they experience severe variations in signal attenuation, thereby necessitating the use of some type of diversity. In this two-part paper, we propose a new form of spatial diversity, in which diversity gains are achieved via the cooperation of mobile users. Part I describes the user cooperation strategy, while Part II focuses on implementation issues and performance analysis. Results show that, even though the interuser channel is noisy, cooperation leads not only to an increase in capacity for both users but also to a more robust system, where users' achievable rates are less susceptible to channel variations.					Erkip, Elza/A-2992-2012	Erkip, Elza/0000-0001-8718-8648													0090-6778	1558-0857				NOV	2003	51	11					1927	1938		10.1109/TCOMM.2003.818096	http://dx.doi.org/10.1109/TCOMM.2003.818096													WOS:000186646800025
J	Hughes, TJR; Cottrell, JA; Bazilevs, Y				Hughes, TJR; Cottrell, JA; Bazilevs, Y			Isogeometric analysis: CAD, finite elements, NURBS, exact geometry and mesh refinement	COMPUTER METHODS IN APPLIED MECHANICS AND ENGINEERING												The concept of isogeometric analysis is proposed. Basis functions generated from NURBS (Non-Uniform Rational B-Splines) are employed to construct an exact geometric model. For purposes of analysis, the basis is refined and/or its order elevated without changing the geometry or its parameterization. Analogues of finite element h- and p-refinement schemes are presented and a new, more efficient, higher-order concept, k-refinement, is introduced. Refinements are easily implemented and exact geometry is maintained at all levels without the necessity of subsequent communication with a CAD (Computer Aided Design) description. In the context of structural mechanics, it is established that the basis functions are complete with respect to affine transformations, meaning that all rigid body motions and constant strain states are exactly represented. Standard patch tests are likewise satisfied. Numerical examples exhibit optimal rates of convergence for linear elasticity problems and convergence to thin elastic shell solutions. A k-refinement strategy is shown to converge toward monotone solutions for advection-diffusion processes with sharp internal and boundary layers, a very surprising result. It is argued that isogeometric analysis is a viable alternative to standard, polynomial-based, finite element analysis and possesses several advantages. (c) 2005 Elsevier B.V. All rights reserved.					Bazilevs, Yuri/A-9063-2013; Hughes, Thomas/AAL-8013-2020	Hughes, Thomas J. R./0000-0001-7024-8368													0045-7825	1879-2138					2005	194	39-41					4135	4195		10.1016/j.cma.2004.10.008	http://dx.doi.org/10.1016/j.cma.2004.10.008													WOS:000230451400006
J	Robeson, LM				Robeson, Lloyd M.			The upper bound revisited	JOURNAL OF MEMBRANE SCIENCE												The empirical upper bound relationship for membrane separation of gases initially published in 1991 has been reviewed with the myriad of data now presently available. The upper bound correlation follows the relationship P-i = ka(ij)(n), where P-i is the permeability of the fast gas, alpha(ij) (P-i/P-j) is the separation factor, k is referred to as the "front factor" and n is the slope of the log-log plot of the noted relationship. Below this line on a plot of log aij versus log P-i, virtually all the experimental data points exist. In spite of the intense investigation resulting in a much larger clataset than the original correlation, the upper bound position has had only minor shifts in position for many gas pairs. Where more significant shifts are observed, they are almost exclusively due to data now in the literature on a series of perfluorinated polymers and involve many of the gas pairs comprising He. The shift observed is primarily due to a change in the front factor, k, whereas the slope of the resultant upper bound relationship remains similar to the prior data correlations. This indicates a different solubility selectivity relationship for perfluorinated polymers compared to hydrocarbon/aromatic polymers as has been noted in the literature. Two additional upper bound relationships are included in this analysis; CO2/N-2 and N-2/CH4. In addition to the perfluorinated polymers resulting in significant upper bound shifts, minor shifts were observed primarily due to polymers exhibiting rigid, glassy structures including ladder-type polymers. The upper bound correlation can be used to qualitatively determine where the permeability process changes from solution-diffusion to Knudsen diffusion. (C) 2008 Elsevier B.V. All rights reserved.																			0376-7388	1873-3123				JUL 15	2008	320	1-2					390	400		10.1016/j.memsci.2008.04.030	http://dx.doi.org/10.1016/j.memsci.2008.04.030													WOS:000257834700044
J	Marzetta, TL				Marzetta, Thomas L.			Noncooperative Cellular Wireless with Unlimited Numbers of Base Station Antennas	IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS												A cellular base station serves a multiplicity of single-antenna terminals over the same time-frequency interval. Time-division duplex operation combined with reverse-link pilots enables the base station to estimate the reciprocal forward-and reverse-link channels. The conjugate-transpose of the channel estimates are used as a linear precoder and combiner respectively on the forward and reverse links. Propagation, unknown to both terminals and base station, comprises fast fading, log-normal shadow fading, and geometric attenuation. In the limit of an infinite number of antennas a complete multi-cellular analysis, which accounts for inter-cellular interference and the overhead and errors associated with channel-state information, yields a number of mathematically exact conclusions and points to a desirable direction towards which cellular wireless could evolve. In particular the effects of uncorrelated noise and fast fading vanish, throughput and the number of terminals are independent of the size of the cells, spectral efficiency is independent of bandwidth, and the required transmitted energy per bit vanishes. The only remaining impairment is inter-cellular interference caused by re-use of the pilot sequences in other cells ( pilot contamination) which does not vanish with unlimited number of antennas.					Marzetta, Thomas/AEB-0112-2022														1536-1276	1558-2248				NOV	2010	9	11					3590	3600		10.1109/TWC.2010.092810.091092	http://dx.doi.org/10.1109/TWC.2010.092810.091092													WOS:000284224100029
J	Zimmerman, RD; Murillo-Sánchez, CE; Thomas, RJ				Zimmerman, Ray Daniel; Edmundo Murillo-Sanchez, Carlos; Thomas, Robert John			MATPOWER: Steady-State Operations, Planning, and Analysis Tools for Power Systems Research and Education	IEEE TRANSACTIONS ON POWER SYSTEMS												MATPOWER is an open-source Matlab-based power system simulation package that provides a high-level set of power flow, optimal power flow (OPF), and other tools targeted toward researchers, educators, and students. The OPF architecture is designed to be extensible, making it easy to add user-defined variables, costs, and constraints to the standard OPF problem. This paper presents the details of the network modeling and problem formulations used by MATPOWER, including its extensible OPF architecture. This structure is used internally to implement several extensions to the standard OPF problem, including piece-wise linear cost functions, dispatchable loads, generator capability curves, and branch angle difference limits. Simulation results are presented for a number of test cases comparing the performance of several available OPF solvers and demonstrating MATPOWER's ability to solve large-scale AC and DC OPF problems.																			0885-8950	1558-0679				FEB	2011	26	1					12	19		10.1109/TPWRS.2010.2051168	http://dx.doi.org/10.1109/TPWRS.2010.2051168													WOS:000286516100002
J	Scarselli, F; Gori, M; Tsoi, AC; Hagenbuchner, M; Monfardini, G				Scarselli, Franco; Gori, Marco; Tsoi, Ah Chung; Hagenbuchner, Markus; Monfardini, Gabriele			The Graph Neural Network Model	IEEE TRANSACTIONS ON NEURAL NETWORKS												Many underlying relationships among data in several areas of science and engineering, e.g., computer vision, molecular chemistry, molecular biology, pattern recognition, and data mining, can be represented in terms of graphs. In this paper, we propose a new neural network model, called graph neural network (GNN) model, that extends existing neural network methods for processing the data represented in graph domains. This GNN model, which can directly process most of the practically useful types of graphs, e.g., acyclic, cyclic, directed, and undirected, implements a function T(G, n) is an element of R-m that maps a graph G and one of its nodes n into an m-dimensional Euclidean space. A supervised learning algorithm is derived to estimate the parameters of the proposed GNN model. The computational cost of the proposed algorithm is also considered. Some experimental results are shown to validate the proposed learning algorithm, and to demonstrate its generalization capabilities.					scarselli, franco/B-9326-2013	SCARSELLI, Franco/0000-0003-1307-0772; Tsoi, Ah Chung/0000-0003-2904-7008; Hagenbuchner, Markus/0000-0002-4884-753X													1045-9227	1941-0093				JAN	2009	20	1					61	80		10.1109/TNN.2008.2005605	http://dx.doi.org/10.1109/TNN.2008.2005605								19068426					WOS:000262429700005
J	Han, JQ				Han, Jingqing			From PID to Active Disturbance Rejection Control	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS												Active disturbance rejection control (ADRC) can be summarized as follows: it inherits from proportional-integral-derivative (PID) the quality that makes it such a success: the error driven, rather than model-based, control law; it takes from modern control theory its best offering: the state observer; it embraces the power of nonlinear feedback and puts it to full use; it is a useful digital control technology developed out of an experimental platform rooted in computer simulations. ADRC is made possible only when control is taken as an experimental science, instead of a mathematical one. It is motivated by the ever increasing demands from industry that requires the control technology to move beyond PID, which has dominated the practice for over 80 years. Specifically, there are four areas of weakness in PID that we strive to address: 1) the error computation; 2) noise degradation in the derivative control; 3) oversimplification and the loss of performance in the control law in the form of a linear weighted sum; and 4) complications brought by the integral control. Correspondingly, we propose four distinct measures: 1) a simple differential equation as a transient trajectory generator; 2) a noise-tolerant tracking differentiator; 3) the nonlinear control laws; and 4) the concept and method of total disturbance estimation and rejection. Together, they form a new set of tools and a new way of control design. Times and again in experiments and on factory floors, ADRC proves to be a capable replacement of PID with unmistakable advantage in performance and practicality, providing solutions to pressing engineering problems of today. With the new outlook and possibilities that ADRC represents, we further believe that control engineering may very well break the hold of classical PID and enter a new era, an era that brings back the spirit of innovations.																			0278-0046	1557-9948				MAR	2009	56	3					900	906		10.1109/TIE.2008.2011621	http://dx.doi.org/10.1109/TIE.2008.2011621													WOS:000263927700032
J	Mikolajczyk, K; Schmid, C				Mikolajczyk, K; Schmid, C			A performance evaluation of local descriptors	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												In this paper, we compare the performance of descriptors computed for local interest regions, as, for example, extracted by the Harris-Affine detector [32]. Many different descriptors have been proposed in the literature. It is unclear which descriptors are more appropriate and how their performance depends on the interest region detector. The descriptors should be distinctive and at the same time robust to changes in viewing conditions as well as to errors of the detector. Our evaluation uses as criterion recall with respect to precision and is carried out for different image transformations. We compare shape context [3], steerable filters [12], PCA-SIFT [19], differential invariants [20], spin images [21], SIFT [26], complex filters [37], moment invariants [43], and cross-correlation for different types of interest regions. We also propose an extension of the SIFT descriptor and show that it outperforms the original method. Furthermore, we observe that the ranking of the descriptors is mostly independent of the interest region detector and that the SIFT-based descriptors perform best. Moments and steerable filters show the best performance among the low dimensional descriptors.																			0162-8828	1939-3539				OCT	2005	27	10					1615	1630		10.1109/TPAMI.2005.188	http://dx.doi.org/10.1109/TPAMI.2005.188								16237996					WOS:000231086700009
J	Julier, SJ; Uhlmann, JK				Julier, SJ; Uhlmann, JK			Unscented filtering and nonlinear estimation	PROCEEDINGS OF THE IEEE												The extended Kalman filter (EKF) is probably the most widely used estimation algorithm for nonlinear systems. However more than 35 years of experience in the estimation community has shown that is difficult to implement, difficult to tune, and only reliable for systems that are almost linear on the time scale of the updates. Many of these difficulties arise from its use of linearization. To overcome this limitation, the unscented transformation (UT) was developed as a method to propagate mean and covariance information through nonlinear transformations. It is more accurate, easier to implement, and uses the same order of calculations as linearization. This paper reviews the motivation, development, use, and implications of the UT.																			0018-9219	1558-2256				MAR	2004	92	3					401	422		10.1109/JPROC.2003.823141	http://dx.doi.org/10.1109/JPROC.2003.823141													WOS:000220005300002
J	Saliba, M; Matsui, T; Seo, JY; Domanski, K; Correa-Baena, JP; Nazeeruddin, MK; Zakeeruddin, SM; Tress, W; Abate, A; Hagfeldt, A; Grätzel, M				Saliba, Michael; Matsui, Taisuke; Seo, Ji-Youn; Domanski, Konrad; Correa-Baena, Juan-Pablo; Nazeeruddin, Mohammad Khaja; Zakeeruddin, Shaik M.; Tress, Wolfgang; Abate, Antonio; Hagfeldt, Anders; Gratzel, Michael			Cesium-containing triple cation perovskite solar cells: improved stability, reproducibility and high efficiency	ENERGY & ENVIRONMENTAL SCIENCE												Today's best perovskite solar cells use a mixture of formamidinium and methylammonium as the monovalent cations. With the addition of inorganic cesium, the resulting triple cation perovskite compositions are thermally more stable, contain less phase impurities and are less sensitive to processing conditions. This enables more reproducible device performances to reach a stabilized power output of 21.1% and similar to 18% after 250 hours under operational conditions. These properties are key for the industrialization of perovskite photovoltaics.					Correa-Baena, Juan-Pablo/AAE-7688-2019; Hagfeldt, Anders/B-8123-2014; Graetzel, Michael/G-4870-2011; Zakeeruddin, Mohammed/D-3244-2014; Nazeeruddin, Mohammad/B-1323-2008; Abate, Antonio/F-2419-2010; Correa-Baena, Juan-Pablo/N-3143-2016; Saliba, Michael/I-1945-2016; Tress, Wolfgang/B-7171-2017	Nazeeruddin, Mohammad Khaja/0000-0001-5955-4786; Abate, Antonio/0000-0002-3012-3541; Correa-Baena, Juan-Pablo/0000-0002-3860-1149; Saliba, Michael/0000-0002-6818-9781; Tress, Wolfgang/0000-0002-4010-239X													1754-5692	1754-5706					2016	9	6					1989	1997		10.1039/c5ee03874j	http://dx.doi.org/10.1039/c5ee03874j								27478500					WOS:000378244200005
J	Pérez-Lombard, L; Ortiz, J; Pout, C				Perez-Lombard, Luis; Ortiz, Jose; Pout, Christine			A review on buildings energy consumption information	ENERGY AND BUILDINGS												The rapidly growing world energy use has already raised concerns over supply difficulties, exhaustion of energy resources and heavy environmental impacts (ozone layer depletion, global warming, climate change, etc.). The global contribution from buildings towards energy consumption, both residential and commercial, has steadily increased reaching figures between 20% and 40% in developed countries, and has exceeded the other major sectors: industrial and transportation. Growth in population, increasing demand for building services and comfort levels, together with the rise in time spent inside buildings, assure the upward trend in energy demand will continue in the future. For this reason, energy efficiency in buildings is today a prime objective for energy policy at regional, national and international levels. Among building services, the growth in HVAC systems energy use is particularly significant (50% of building consumption and 20% of total consumption in the USA). This paper analyses available information concerning energy consumption in buildings, and particularly related to HVAC systems. Many questions arise: Is the necessary information available? Which are the main building types? What end uses should be considered in the breakdown? Comparisons between different countries are presented specially for commercial buildings. The case of offices is analysed in deeper detail. (c) 2007 Elsevier B.V. All rights reserved.					PEREZ-LOMBARD, LUIS/G-2415-2016	Perez-Lombard Martin de Oliva, Luis/0000-0002-8887-1833													0378-7788	1872-6178					2008	40	3					394	398		10.1016/j.enbuild.2007.03.007	http://dx.doi.org/10.1016/j.enbuild.2007.03.007													WOS:000252604700026
J	Rodríguez, J; Lai, JS; Peng, FZ				Rodríguez, J; Lai, JS; Peng, FZ			Multilevel inverters:: A survey of topologies, controls, and applications	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS												Multilevel inverter technology has emerged recently as a very important alternative in the area of high-power medium-voltage energy control. This paper presents the most important topologies like diode-clamped inverter (neutral-point clamped), capacitor-clamped (flying capacitor), and cascaded multicell with separate dc sources. Emerging topologies like asymmetric hybrid cells and soft-switched multilevel inverters are also discussed. This paper also presents the most relevant control and modulation methods developed for this family of converters: multilevel sinusoidal pulsewidth modulation, multilevel selective harmonic elimination, and space-vector modulation. Special attention is dedicated to the latest and more relevant applications of these converters such as laminators, conveyor belts, and unified power-How controllers. The need of an active front end at the input side for those inverters supplying regenerative loads is also discussed, and the circuit topology options are also presented. Finally, the peripherally developing areas such as high-voltage high-power devices and optical sensors and other opportunities for future development are addressed.					Rodriguez, Jose/A-2534-2013; Lai, Jihsheng/I-1762-2016	Rodriguez, Jose/0000-0002-1410-4121; Lai, Jihsheng/0000-0003-2315-8460													0278-0046	1557-9948				AUG	2002	49	4					724	738		10.1109/TIE.2002.801052	http://dx.doi.org/10.1109/TIE.2002.801052													WOS:000177191000002
J	Henriques, JF; Caseiro, R; Martins, P; Batista, J				Henriques, Joao F.; Caseiro, Rui; Martins, Pedro; Batista, Jorge			High-Speed Tracking with Kernelized Correlation Filters	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												The core component of most modern trackers is a discriminative classifier, tasked with distinguishing between the target and the surrounding environment. To cope with natural image changes, this classifier is typically trained with translated and scaled sample patches. Such sets of samples are riddled with redundancies-any overlapping pixels are constrained to be the same. Based on this simple observation, we propose an analytic model for datasets of thousands of translated patches. By showing that the resulting data matrix is circulant, we can diagonalize it with the discrete Fourier transform, reducing both storage and computation by several orders of magnitude. Interestingly, for linear regression our formulation is equivalent to a correlation filter, used by some of the fastest competitive trackers. For kernel regression, however, we derive a new kernelized correlation filter (KCF), that unlike other kernel algorithms has the exact same complexity as its linear counterpart. Building on it, we also propose a fast multi-channel extension of linear correlation filters, via a linear kernel, which we call dual correlation filter (DCF). Both KCF and DCF outperform top-ranking trackers such as Struck or TLD on a 50 videos benchmark, despite running at hundreds of frames-per-second, and being implemented in a few lines of code (Algorithm 1). To encourage further developments, our tracking framework was made open-source.					Martins, Pedro/GWC-7702-2022; Batista, Jorge/A-4196-2011	Batista, Jorge/0000-0003-2387-5961; Martins, Pedro/0000-0001-8984-4506													0162-8828	1939-3539				MAR	2015	37	3					583	596		10.1109/TPAMI.2014.2345390	http://dx.doi.org/10.1109/TPAMI.2014.2345390								26353263					WOS:000349626200008
J	He, KM; Sun, J; Tang, XO				He, Kaiming; Sun, Jian; Tang, Xiaoou			Single Image Haze Removal Using Dark Channel Prior	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												In this paper, we propose a simple but effective image prior-dark channel prior to remove haze from a single input image. The dark channel prior is a kind of statistics of outdoor haze-free images. It is based on a key observation-most local patches in outdoor haze-free images contain some pixels whose intensity is very low in at least one color channel. Using this prior with the haze imaging model, we can directly estimate the thickness of the haze and recover a high-quality haze-free image. Results on a variety of hazy images demonstrate the power of the proposed prior. Moreover, a high-quality depth map can also be obtained as a byproduct of haze removal.																			0162-8828	1939-3539				DEC	2011	33	12					2341	2353		10.1109/TPAMI.2010.168	http://dx.doi.org/10.1109/TPAMI.2010.168								20820075					WOS:000295980000003
J	Belongie, S; Malik, J; Puzicha, J				Belongie, S; Malik, J; Puzicha, J			Shape matching and object recognition using shape contexts	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												We present a novel approach to measuring similarity between shapes and exploit it for object recognition. In our framework, the measurement of similarity is preceded by 1) solving for correspondences between points on the two shapes, 2) using the correspondences to estimate an aligning transform. In order to solve the correspondence problem, we attach a descriptor, the shape context, to each point. The shape context at a reference point captures the distribution of the remaining points relative to it, thus offering a globally discriminative characterization. Corresponding points on two similar shapes will have similar shape contexts, enabling us to solve for correspondences as an optimal assignment problem. Given the point correspondences, we estimate the transformation that best aligns the two shapes; regularized thin-plate splines provide a flexible class of transformation maps for this purpose. The dissimilarity between the two shapes is computed as a sum of matching errors between corresponding points, together with a term measuring the magnitude of the aligning transform. We treat recognition in a nearest-neighbor classification framework as the problem of finding the stored prototype shape that is maximally similar to that in the image. Results are presented for silhouettes, trademarks, handwritten digits, and the COIL data set.						Belongie, Serge/0000-0002-0388-5217													0162-8828	1939-3539				APR	2002	24	4					509	522		10.1109/34.993558	http://dx.doi.org/10.1109/34.993558													WOS:000174574100007
J	Hutmacher, DW				Hutmacher, DW			Scaffolds in tissue engineering bone and cartilage	BIOMATERIALS												Musculoskeletal tissue, bone and cartilage are under extensive investigation in tissue engineering research. A number of biodegradable and bioresorbable materials, as well as scaffold designs, have been experimentally and/or clinically studied. Ideally, a scaffold should have the following characteristics: (i) three-dimensional and highly porous with an interconnected pore network for cell growth and flow transport of nutrients and metabolic waste; (ii) biocompatible and bioresorbable with a controllable degradation and resorption rate to match cell/tissue growth in vitro and/or in vivo; (iii) suitable surface chemistry for cell attachment, proliferation, and differentation and (iv) mechanical properties to match those of the tissues at the site of implantation. This paper reviews research on the tissue engineering of bone and cartilage from the polymeric scaffold point of view. (C) 2000 Elsevier Science Ltd. All rights reserved.					Hutmacher, Dietmar/AEO-9578-2022	Hutmacher, Dietmar Werner/0000-0001-5678-2134													0142-9612	1878-5905				DEC	2000	21	24			SI		2529	2543		10.1016/S0142-9612(00)00121-6	http://dx.doi.org/10.1016/S0142-9612(00)00121-6								11071603					WOS:000089861700006
J	Kschischang, FR; Frey, BJ; Loeliger, HA				Kschischang, FR; Frey, BJ; Loeliger, HA			Factor graphs and the sum-product algorithm	IEEE TRANSACTIONS ON INFORMATION THEORY					35th Annual Allerton Conference on Communication, Control, and Computing	SEP 29-OCT 01, 1997	UNIV ILLINOIS, ALLERTON HOUSE, URBANA, ILLINOIS		UNIV ILLINOIS, ALLERTON HOUSE			Algorithms that must deal with complicated global functions of many variables often exploit the manner in which the given functions factor as a product of "local" functions, each of which depends on a subset of the variables. Such a factorization can be visualized with a bipartite graph that we call a factor graph. In this tutorial paper, we present a generic message-passing algorithm, the sum-product algorithm, that operates in a factor graph, Following a single, simple computational rule, the sum-product algorithm computes-either exactly or approximately-various marginal functions derived from the global function. A wide variety of algorithms developed in artificial intelligence, signal processing, and digital communications can be derived as specific instances of the sum-product algorithm, including the forward/backward algorithm, the Viterbi algorithm, the iterative "turbo" decoding algorithm, Pearl's belief propagation algorithm for Bayesian networks, the Kalman filter, and certain fast Fourier transform (FFT) algorithms.					Kschischang, Frank/V-3393-2019; Kschischang, Frank/G-2657-2012	Kschischang, Frank/0000-0002-4274-1785													0018-9448					FEB	2001	47	2					498	519		10.1109/18.910572	http://dx.doi.org/10.1109/18.910572													WOS:000167491700002
J	Wang, Z; Bovik, AC				Wang, Z; Bovik, AC			A universal image quality index	IEEE SIGNAL PROCESSING LETTERS												We propose a new universal objective image quality index, which is easy to calculate and applicable to various image processing applications. Instead of using traditional error summation methods, the proposed index is designed by modeling any image distortion as a combination of three factors: loss of correlation, luminance distortion, and contrast distortion. Although the new index is mathematically defined and no human visual system model is explicitly employed, our experiments on various image distortion types indicate that it performs significantly better than the widely used distortion metric mean squared error. Demonstrative images and an efficient MATLAB implementation of the algorithm are available online at http:Hanchovy.ece.utexas.edu/-zwang/research/quaIity-index/demo.html.					Bovik, Alan/B-6717-2012	Bovik, Alan/0000-0001-6067-710X; Wang, Zhou/0000-0003-4413-4441													1070-9908					MAR	2002	9	3					81	84	PII S 1070-9908(02)04819-8	10.1109/97.995823	http://dx.doi.org/10.1109/97.995823													WOS:000175079000002
J	He, KM; Sun, J; Tang, XO				He, Kaiming; Sun, Jian; Tang, Xiaoou			Guided Image Filtering	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												In this paper, we propose a novel explicit image filter called guided filter. Derived from a local linear model, the guided filter computes the filtering output by considering the content of a guidance image, which can be the input image itself or another different image. The guided filter can be used as an edge-preserving smoothing operator like the popular bilateral filter [1], but it has better behaviors near edges. The guided filter is also a more generic concept beyond smoothing: It can transfer the structures of the guidance image to the filtering output, enabling new filtering applications like dehazing and guided feathering. Moreover, the guided filter naturally has a fast and nonapproximate linear time algorithm, regardless of the kernel size and the intensity range. Currently, it is one of the fastest edge-preserving filters. Experiments show that the guided filter is both effective and efficient in a great variety of computer vision and computer graphics applications, including edge-aware smoothing, detail enhancement, HDR compression, image matting/ feathering, dehazing, joint upsampling, etc.																			0162-8828	1939-3539				JUN	2013	35	6					1397	1409		10.1109/TPAMI.2012.213	http://dx.doi.org/10.1109/TPAMI.2012.213								23599054					WOS:000317857900010
J	Elad, M; Aharon, M				Elad, Michael; Aharon, Michal			Image denoising via sparse and redundant representations over learned dictionaries	IEEE TRANSACTIONS ON IMAGE PROCESSING												We address the image denoising problem, where zero-mean white and homogeneous Gaussian additive noise is to be removed from a given image. The approach taken is based on sparse and redundant representations over trained dictionaries. Using the K-SVD algorithm, we obtain a dictionary that describes the image content effectively. Two training options are considered: using the corrupted image itself, or training on a corpus of high-quality image database. Since the K-SVD is limited in handling small image patches, we extend its deployment to arbitrary image sizes by defining a global image prior that forces sparsity over patches in every location in the image. We show how such Bayesian treatment leads to a simple and effective denoising algorithm. This leads to a state-of-the-art denoising performance, equivalent and sometimes surpassing recently published leading alternative denoising methods.					, Miki/AAH-4640-2019														1057-7149	1941-0042				DEC	2006	15	12					3736	3745		10.1109/TIP.2006.881969	http://dx.doi.org/10.1109/TIP.2006.881969								17153947					WOS:000242362900010
J	Yang, JC; Wright, J; Huang, TS; Ma, Y				Yang, Jianchao; Wright, John; Huang, Thomas S.; Ma, Yi			Image Super-Resolution Via Sparse Representation	IEEE TRANSACTIONS ON IMAGE PROCESSING												This paper presents a new approach to single-image superresolution, based upon sparse signal representation. Research on image statistics suggests that image patches can be well-represented as a sparse linear combination of elements from an appropriately chosen over-complete dictionary. Inspired by this observation, we seek a sparse representation for each patch of the low-resolution input, and then use the coefficients of this representation to generate the high-resolution output. Theoretical results from compressed sensing suggest that under mild conditions, the sparse representation can be correctly recovered from the downsampled signals. By jointly training two dictionaries for the low-and high-resolution image patches, we can enforce the similarity of sparse representations between the low-resolution and high-resolution image patch pair with respect to their own dictionaries. Therefore, the sparse representation of a low-resolution image patch can be applied with the high-resolution image patch dictionary to generate a high-resolution image patch. The learned dictionary pair is a more compact representation of the patch pairs, compared to previous approaches, which simply sample a large amount of image patch pairs [1], reducing the computational cost substantially. The effectiveness of such a sparsity prior is demonstrated for both general image super-resolution (SR) and the special case of face hallucination. In both cases, our algorithm generates high-resolution images that are competitive or even superior in quality to images produced by other similar SR methods. In addition, the local sparse modeling of our approach is naturally robust to noise, and therefore the proposed algorithm can handle SR with noisy inputs in a more unified framework.					Zhao, Mingyu/HHS-0141-2022; Ma, Yi/K-1458-2014	Yan, Shuicheng/0000-0001-8906-3777													1057-7149	1941-0042				NOV	2010	19	11					2861	2873		10.1109/TIP.2010.2050625	http://dx.doi.org/10.1109/TIP.2010.2050625								20483687					WOS:000283445600007
J	Pope, CA; Dockery, DW				Pope, C. Arden, III; Dockery, Douglas W.			Health effects of fine particulate air pollution: Lines that connect	JOURNAL OF THE AIR & WASTE MANAGEMENT ASSOCIATION					99th Annual Meeting of the Air-and-Waste-Management-Association	JUN 20-23, 2006	New Orleans, LA	Air & Waste Management Assoc				Efforts to understand and mitigate the health effects of particulate matter (PM) air pollution have a rich and interesting history. This review focuses on six substantial lines of research that have been pursued since 1997 that have helped elucidate our understanding about the effects of PM on human health. There has been substantial progress in the evaluation of PM health effects at different time-scales of exposure and in the exploration of the shape of the concentration-response function. There has also been emerging evidence of PM-related cardiovascular health effects and growing knowledge regarding interconnected general pathophysiological pathways that link PM exposure with cardiopulmonary morbidity and mortality. Despite important gaps in scientific knowledge and continued reasons for some skepticism, a comprehensive evaluation of the research findings provides persuasive evidence that exposure to fine particulate air pollution has adverse effects on cardiopulmonary health. Although much of this research has been motivated by environmental public health policy, these results have important scientific, medical, and public health implications that are broader than debates over legally mandated air quality standards.					Pope, C./ABD-5522-2021; , dwdockery/AAO-7272-2021; Watson, John/E-6869-2010	Dockery, Douglas/0000-0002-6052-4880; Watson, John/0000-0002-1752-6899													1096-2247	2162-2906				JUN	2006	56	6					709	742		10.1080/10473289.2006.10464485	http://dx.doi.org/10.1080/10473289.2006.10464485								16805397					WOS:000238176000002
J	Ferretti, A; Prati, C; Rocca, F				Ferretti, A; Prati, C; Rocca, F			Permanent scatterers in SAR interferometry	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING												Temporal and geometrical decorrelation often prevents SAR interferometry from being an operational tool for surface deformation monitoring and topographic profile reconstruction. Moreover, atmospheric disturbances can strongly compromise the accuracy of the results. In this paper, we present a complete procedure for the identification and exploitation of stable natural reflectors or permanent scatterers (PSs) starting from long temporal series of interferometric SAR images. When, as it often happens, the dimension of the PS is smaller than the resolution cell, the coherence is goad even for interferograms with baselines larger than the decorrelation one, and all the available images of the ESA ERS data set can be successfully exploited. On these pixels, submeter DEM accuracy and millimetric terrain motion detection can be achieved, since atmospheric phase screen (APS) contributions can be estimated and removed. Examples are then shown of small motion measurements, DEM refinement, and BPS estimation and removal in the case of a sliding area in Ancona, Italy ERS data have been used.					Ferretti, Alessandro/K-3811-2019	Ferretti, Alessandro/0000-0002-7802-5019; Rocca, Fabio/0000-0002-2266-6212													0196-2892	1558-0644				JAN	2001	39	1					8	20		10.1109/36.898661	http://dx.doi.org/10.1109/36.898661													WOS:000166738100002
J	Felzenszwalb, PF; Girshick, RB; McAllester, D; Ramanan, D				Felzenszwalb, Pedro F.; Girshick, Ross B.; McAllester, David; Ramanan, Deva			Object Detection with Discriminatively Trained Part-Based Models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												We describe an object detection system based on mixtures of multiscale deformable part models. Our system is able to represent highly variable object classes and achieves state-of-the-art results in the PASCAL object detection challenges. While deformable part models have become quite popular, their value had not been demonstrated on difficult benchmarks such as the PASCAL data sets. Our system relies on new methods for discriminative training with partially labeled data. We combine a margin-sensitive approach for data-mining hard negative examples with a formalism we call latent SVM. A latent SVM is a reformulation of MI-SVM in terms of latent variables. A latent SVM is semiconvex, and the training problem becomes convex once latent information is specified for the positive examples. This leads to an iterative training algorithm that alternates between fixing latent values for positive examples and optimizing the latent SVM objective function.																			0162-8828	1939-3539				SEP	2010	32	9					1627	1645		10.1109/TPAMI.2009.167	http://dx.doi.org/10.1109/TPAMI.2009.167								20634557					WOS:000279969000007
J	Akyildiz, IF; Lee, WY; Vuran, MC; Mohanty, S				Akyildiz, Ian F.; Lee, Won-Yeol; Vuran, Mehmet C.; Mohanty, Shantidev			NeXt generation/dynamic spectrum access/cognitive radio wireless networks: A survey	COMPUTER NETWORKS												Today's wireless networks are characterized by a fixed spectrum assignment policy. However, a large portion of the assigned spectrum is used sporadically and geographical variations in the utilization of assigned spectrum ranges from 15% to 85% with a high variance in time. The limited available spectrum and the inefficiency in the spectrum usage necessitate a new communication paradigm to exploit the existing wireless spectrum opportunistically. This new networking paradigm is referred to as NeXt Generation (xG) Networks as well as Dynamic Spectrum Access (DSA) and cognitive radio networks. The term xG networks is used throughout the paper. The novel functionalities and current research challenges of the xG networks are explained in detail. More specifically, a brief overview of the cognitive radio technology is provided and the xG network architecture is introduced. Moreover, the xG network functions such as spectrum management, spectrum mobility and spectrum sharing are explained in detail. The influence of these functions on the performance of the upper layer protocols such as routing and transport are investigated and open research issues in these areas are also outlined. Finally, the cross-layer design challenges in xG networks are discussed. (c) 2006 Elsevier B.V. All rights reserved.					Akyildiz, Ian/G-7136-2011; Vuran, Mehmet/AAB-7868-2021	Vuran, Mehmet C./0000-0001-7894-6611													1389-1286	1872-7069				SEP 15	2006	50	13					2127	2159		10.1016/j.comnet.2006.05.001	http://dx.doi.org/10.1016/j.comnet.2006.05.001													WOS:000239225500001
J	Ahonen, T; Hadid, A; Pietikäinen, M				Ahonen, Timo; Hadid, Abdenour; Pietikainen, Matti			Face description with local binary patterns:: Application to face recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												This paper presents a novel and efficient facial image representation based on local binary pattern (LBP) texture features. The face image is divided into several regions from which the LBP feature distributions are extracted and concatenated into an enhanced feature vector to be used as a face descriptor. The performance of the proposed method is assessed in the face recognition problem under different challenges. Other applications and several extensions are also discussed.																			0162-8828	1939-3539				DEC	2006	28	12					2037	2041		10.1109/TPAMI.2006.244	http://dx.doi.org/10.1109/TPAMI.2006.244								17108377					WOS:000241195700013
J	Potyondy, DO; Cundall, PA				Potyondy, DO; Cundall, PA			A bonded-particle model for rock	INTERNATIONAL JOURNAL OF ROCK MECHANICS AND MINING SCIENCES												A numerical model for rock is proposed in which the rock is represented by a dense packing of non-uniformized circular or spherical particles that are bonded together at their contact points and whose mechanical behavior is simulated by the distinct-element method Using the two- and three-dimensional discontinuum programs PFC2D and PFC3D. The microproperties consist of stiffness and strength parameters for the particles and the bonds. Damage is represented explicitly as broken bonds. which form, and coalesce into macroscopic fractures when load is applied. The model reproduces many features of rock behavior includinq elasticity fracturing, acoustic emission, damage accumulation producing material anisotropy, hysteresis, dilation. post-peak softening and strength increase with confinement. These behaviors are emergent properties of the model that arise from a relatively simple Set of microproperties. A material-,genesis procedure and microproperties to represent Lac du Bonnet granite are presented. The behaviour of this model is described for two- and three-dimensional biaxial. triaxial and Brazilian tests and for two-dimensional tunnel simulations in which breakout notches form in the region of maximum compressive stress. The sensitivity of the to microproperties, including particle size, is investigated. Particle size is not a free paranieter that only controls resolution: instead. it affects the fracture toughness and thereby influences damage processes (such as notch formation) in which damage localizes at macrofracture tips experiencing extensile loading. (C) 2004 Elsevier Ltd. All rights reserved.																			1365-1609	1873-4545				DEC	2004	41	8					1329	1364		10.1016/j.ijrmms.2004.09.011	http://dx.doi.org/10.1016/j.ijrmms.2004.09.011													WOS:000225810500007
J	Tustison, NJ; Avants, BB; Cook, PA; Zheng, YJ; Egan, A; Yushkevich, PA; Gee, JC				Tustison, Nicholas J.; Avants, Brian B.; Cook, Philip A.; Zheng, Yuanjie; Egan, Alexander; Yushkevich, Paul A.; Gee, James C.			N4ITK: Improved N3 Bias Correction	IEEE TRANSACTIONS ON MEDICAL IMAGING												A variant of the popular nonparametric nonuniform intensity normalization (N3) algorithm is proposed for bias field correction. Given the superb performance of N3 and its public availability, it has been the subject of several evaluation studies. These studies have demonstrated the importance of certain parameters associated with the B-spline least-squares fitting. We propose the substitution of a recently developed fast and robust B-spline approximation routine and a modified hierarchical optimization scheme for improved bias field correction over the original N3 algorithm. Similar to the N3 algorithm, we also make the source code, testing, and technical documentation of our contribution, which we denote as "N4ITK," available to the public through the Insight Toolkit of the National Institutes of Health. Performance assessment is demonstrated using simulated data from the publicly available Brainweb database, hyperpolarized He-3 lung image data, and 9.4T postmortem hippocampus data.					; Yushkevich, Paul/O-6115-2014	TUSTISON, NICHOLAS/0000-0001-9418-5103; Yushkevich, Paul/0000-0001-8543-4016; avants, brian/0000-0002-4212-3362													0278-0062	1558-254X				JUN	2010	29	6					1310	1320		10.1109/TMI.2010.2046908	http://dx.doi.org/10.1109/TMI.2010.2046908								20378467					WOS:000278535800009
J	Zhang, L; Zhang, L; Mou, XQ; Zhang, D				Zhang, Lin; Zhang, Lei; Mou, Xuanqin; Zhang, David			FSIM: A Feature Similarity Index for Image Quality Assessment	IEEE TRANSACTIONS ON IMAGE PROCESSING												Image quality assessment (IQA) aims to use computational models to measure the image quality consistently with subjective evaluations. The well-known structural similarity index brings IQA from pixel- to structure-based stage. In this paper, a novel feature similarity (FSIM) index for full reference IQA is proposed based on the fact that human visual system (HVS) understands an image mainly according to its low-level features. Specifically, the phase congruency (PC), which is a dimensionless measure of the significance of a local structure, is used as the primary feature in FSIM. Considering that PC is contrast invariant while the contrast information does affect HVS' perception of image quality, the image gradient magnitude (GM) is employed as the secondary feature in FSIM. PC and GM play complementary roles in characterizing the image local quality. After obtaining the local quality map, we use PC again as a weighting function to derive a single quality score. Extensive experiments performed on six benchmark IQA databases demonstrate that FSIM can achieve much higher consistency with the subjective evaluations than state-of-the-art IQA metrics.					Zhang, Lei/P-8881-2014; Zhang, David/O-9396-2016	Zhang, Lei/0000-0002-2078-4215; Mou, Xuanqin/0000-0003-1381-5260; Zhang, Lin/0000-0002-4360-5523; Zhang, David/0000-0002-5027-5286													1057-7149	1941-0042				AUG	2011	20	8					2378	2386		10.1109/TIP.2011.2109730	http://dx.doi.org/10.1109/TIP.2011.2109730								21292594					WOS:000293692300026
J	Olfati-Saber, R				Olfati-Saber, R			Flocking for multi-agent dynamic systems: Algorithms and theory	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												In this paper, we present a theoretical framework for design and analysis of distributed flocking algorithms. Two cases of flocking in free-space and presence of multiple obstacles are considered. We present three flocking algorithms: two for free-flocking and one for constrained flocking. A comprehensive analysis of the first two algorithms is provided. We demonstrate the first algorithm embodies all three rules of Reynolds. This is a formal approach to extraction of interaction rules that lead to the emergence of collective behavior. We show that the first algorithm generically leads to regular fragmentation, whereas the second and third algorithms both lead to flocking. A systematic method is provided for construction of cost functions (or collective potentials) for flocking. These collective potentials penalize deviation from a class of lattice-shape objects called alpha-lattices. We use a multi-species framework for construction of collective potentials that consist of flock-members, or alpha-agents, and virtual agents associated with alpha-agents called beta- and gamma-agents. We show that migration of flocks can be performed using a peer-to-peer network of agents, i.e., "flocks need no leaders." A "universal" definition of flocking for particle systems with similarities to Lyapunov stability is given. Several simulation results are provided that demonstrate performing 2-D and 3-D flocking, split/rejoin maneuver, and squeezing maneuver for hundreds of agents using the proposed algorithms.																			0018-9286	1558-2523				MAR	2006	51	3					401	420		10.1109/TAC.2005.864190	http://dx.doi.org/10.1109/TAC.2005.864190													WOS:000236055100002
J	Arbeláez, P; Maire, M; Fowlkes, C; Malik, J				Arbelaez, Pablo; Maire, Michael; Fowlkes, Charless; Malik, Jitendra			Contour Detection and Hierarchical Image Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												This paper investigates two fundamental problems in computer vision: contour detection and image segmentation. We present state-of-the-art algorithms for both of these tasks. Our contour detector combines multiple local cues into a globalization framework based on spectral clustering. Our segmentation algorithm consists of generic machinery for transforming the output of any contour detector into a hierarchical region tree. In this manner, we reduce the problem of image segmentation to that of contour detection. Extensive experimental evaluation demonstrates that both our contour detection and segmentation methods significantly outperform competing algorithms. The automatically generated hierarchical segmentations can be interactively refined by user-specified annotations. Computation at multiple image resolutions provides a means of coupling our system to recognition applications.						Arbelaez, Pablo/0000-0001-5244-2407													0162-8828	1939-3539				MAY	2011	33	5					898	916		10.1109/TPAMI.2010.161	http://dx.doi.org/10.1109/TPAMI.2010.161								20733228					WOS:000288677800004
J	Henseler, J; Hubona, G; Ray, PA				Henseler, Jorg; Hubona, Geoffrey; Ray, Pauline Ash			Using PLS path modeling in new technology research: updated guidelines	INDUSTRIAL MANAGEMENT & DATA SYSTEMS												Purpose - Partial least squares (PLS) path modeling is a variance-based structural equation modeling (SEM) technique that is widely applied in business and social sciences. Its ability to model composites and factors makes it a formidable statistical tool for new technology research. Recent reviews, discussions, and developments have led to substantial changes in the understanding and use of PLS. The paper aims to discuss these issues. Design/methodology/approach - This paper aggregates new insights and offers a fresh look at PLS path modeling. It presents new developments, such as consistent PLS, confirmatory composite analysis, and the heterotrait-monotrait ratio of correlations. Findings - PLS path modeling is the method of choice if a SEM contains both factors and composites. Novel tests of exact fit make a confirmatory use of PLS path modeling possible. Originality/value - This paper provides updated guidelines of how to use PLS and how to report and interpret its results.					Henseler, Jorg/D-4047-2012	Henseler, Jorg/0000-0002-9736-3048													0263-5577	1758-5783					2016	116	1					2	20		10.1108/IMDS-09-2015-0382	http://dx.doi.org/10.1108/IMDS-09-2015-0382													WOS:000374152400001
J	Avants, BB; Epstein, CL; Grossman, M; Gee, JC				Avants, B. B.; Epstein, C. L.; Grossman, M.; Gee, J. C.			Symmetric diffeomorphic image registration with cross-correlation: Evaluating automated labeling of elderly and neurodegenerative brain	MEDICAL IMAGE ANALYSIS					3rd International Workshop on Biomedical Image Registration	JUL 09-11, 2006	Utrecht Univ, Utrecht, NETHERLANDS	Philips Med Syst	Utrecht Univ			One of the most challenging problems in modern neuroimaging is detailed characterization of neurodegeneration. Quantifying spatial and longitudinal atrophy patterns is an important component of this process. These spatiotemporal signals will aid in discriminating between related diseases, such as frontotemporal dementia (FTD) and Alzheimer's disease (AD), which manifest themselves in the same at-risk population. Here, we develop a novel symmetric image normalization method (SyN) for maximizing the cross-correlation within the space of diffeomorphic maps and provide the Euler-Lagrange equations necessary for this optimization. We then turn to a careful evaluation of our method. Our evaluation uses gold standard, human cortical segmentation to contrast SyN's performance with a related elastic method and with the standard ITK implementation of Thirion's Demons algorithm. The new method compares favorably with both approaches, in particular when the distance between the template brain and the target brain is large. We then report the correlation of volumes gained by algorithmic cortical labelings of FTD and control subjects with those gained by the manual rater. This comparison shows that, of the three methods tested, SyN's volume measurements are the most strongly correlated with volume measurements gained by expert labeling. This study indicates that SyN, with cross-correlation, is a reliable method for normalizing and making anatomical measurements in volumetric MRI of patients and at-risk elderly individuals. Published by Elsevier B.V.						avants, brian/0000-0002-4212-3362													1361-8415	1361-8423				FEB	2008	12	1					26	41		10.1016/j.media.2007.06.004	http://dx.doi.org/10.1016/j.media.2007.06.004								17659998					WOS:000254032800004
J	Blaabjerg, F; Teodorescu, R; Liserre, M; Timbus, AV				Blaabjerg, Frede; Teodorescu, Remus; Liserre, Marco; Timbus, Adrian V.			Overview of control and grid synchronization for distributed power generation systems	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS					IEEE International Symposium on Industrial Electronics	JUN 20-23, 2005	Dubrovnik, CROATIA	IEEE Ind Elect Soc, Univ Zagreb, KoREMA, Soc Instrument & Control Engineers, IEEE Reg 8, Power Engn Soc, IEEE Croatia Sect, Univ Dubrovnik				Renewable energy sources like wind, sun, and hydro are seen as a reliable alternative to the traditional energy sources such as oil, natural gas, or coal. Distributed power generation systems (DPGSs) based on renewable energy sources experience a large development worldwide, with Germany, Denmark, Japan, and USA as leaders in the development in this field. Due to the increasing number of DPGSs connected to the utility network, new and stricter standards in respect to power quality, safe running, and islanding protection are issued. As a consequence, the control of distributed generation systems should be improved to meet the requirements for grid interconnection. This paper gives an overview of the structures for the DPGS based on fuel cell, photovoltaic, and wind turbines. In addition, control structures of the grid-side converter are presented, and the possibility of compensation for low-order harmonics is also discussed. Moreover, control strategies when running on grid faults are treated. This paper ends up with an overview of synchronization methods and a discussion about their importance in the control.					Liserre, Marco/C-2857-2011; Teodorescu, Remus/O-5224-2015; Blaabjerg, Frede/A-5008-2008	Teodorescu, Remus/0000-0002-2617-7168; Blaabjerg, Frede/0000-0001-8311-7412													0278-0046	1557-9948				OCT	2006	53	5					1398	1409		10.1109/TIE.2006.881997	http://dx.doi.org/10.1109/TIE.2006.881997													WOS:000241050400002
J	Kanungo, T; Mount, DM; Netanyahu, NS; Piatko, CD; Silverman, R; Wu, AY				Kanungo, T; Mount, DM; Netanyahu, NS; Piatko, CD; Silverman, R; Wu, AY			An efficient <i>k</i>-means clustering algorithm:: Analysis and implementation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												In k-means clustering, we are given a set of n data points in d-dimensional space R-d and an integer k and the problem is to determine a set of k points in R-d, called centers, so as to minimize the mean squared distance from each data point to its nearest center. A popular heuristic for k-means clustering is Lloyd's algorithm. In this paper, we present a simple and efficient implementation of Lloyd's k-means clustering algorithm, which we call the filtering algorithm. This algorithm is easy to implement, requiring a kd-tree as the only major data structure. We establish the practical efficiency of the filtering algorithm in two ways. First, we present a data-sensitive analysis of the algorithm's running time, which shows that the algorithm runs faster as the separation between clusters increases. Second, we present a number of empirical studies both on synthetically generated data and on real data sets from applications in color quantization, data compression, and image segmentation.					Piatko, Christine/H-3422-2013; Silverman, Ruth/GYE-3363-2022	Mount, David/0000-0002-3290-8932; Piatko, Christine/0000-0002-5295-9112													0162-8828	1939-3539				JUL	2002	24	7					881	892		10.1109/TPAMI.2002.1017616	http://dx.doi.org/10.1109/TPAMI.2002.1017616													WOS:000176446100002
J	Cootes, TF; Edwards, GJ; Taylor, CJ				Cootes, TF; Edwards, GJ; Taylor, CJ			Active appearance models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												We describe a new method of matching statistical models of appearance to images. A set of model parameters control modes of shape and gray-level variation learned from a training set. We construct an efficient iterative matching algorithm by learning the relationship between perturbations in the model parameters and the induced image errors.					Taylor, Christopher/A-3909-2009														0162-8828	1939-3539				JUN	2001	23	6					681	685		10.1109/34.927467	http://dx.doi.org/10.1109/34.927467													WOS:000169037600011
J	Mittal, A; Soundararajan, R; Bovik, AC				Mittal, Anish; Soundararajan, Rajiv; Bovik, Alan C.			Making a "Completely Blind" Image Quality Analyzer	IEEE SIGNAL PROCESSING LETTERS												An important aim of research on the blind image quality assessment (IQA) problem is to devise perceptual models that can predict the quality of distorted images with as little prior knowledge of the images or their distortions as possible. Current state-of-the-art "general purpose" no reference (NR) IQA algorithms require knowledge about anticipated distortions in the form of training examples and corresponding human opinion scores. However we have recently derived a blind IQA model that only makes use of measurable deviations from statistical regularities observed in natural images, without training on human-rated distorted images, and, indeed without any exposure to distorted images. Thus, it is "completely blind." The new IQA model, which we call the Natural Image Quality Evaluator (NIQE) is based on the construction of a "quality aware" collection of statistical features based on a simple and successful space domain natural scene statistic (NSS) model. These features are derived from a corpus of natural, undistorted images. Experimental results show that the new index delivers performance comparable to top performing NR IQA models that require training on large databases of human opinions of distorted images. A software release is available at http://live.ece.utexas.edu/research/quality/niqe_release.zip.					Soundararajan, Rajiv/ABF-9013-2021; Bovik, Alan/B-6717-2012	Bovik, Alan/0000-0001-6067-710X													1070-9908	1558-2361				MAR	2013	20	3					209	212		10.1109/LSP.2012.2227726	http://dx.doi.org/10.1109/LSP.2012.2227726													WOS:000314723300001
J	Georghiades, AS; Belhumeur, PN; Kriegman, DJ				Georghiades, AS; Belhumeur, PN; Kriegman, DJ			From few to many: Illumination cone models for face recognition under variable lighting and pose	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												We present a generative appearance-based method for recognizing human faces under variation in lighting and viewpoint. Our method exploits the fact that the set of images of an object in fixed pose, but under all possible illumination conditions, is a convex cone in the space of images. Using a small number of training images of each face taken with different lighting directions, the shape and albedo of the face can be reconstructed. In turn, this reconstruction serves as a generative model that can be used to render-or synthesize-images of the face under novel poses and illumination conditions. The pose space is then sampled and, for each pose. the corresponding illumination cone is approximated by a low-dimensional linear subspace whose basis vectors are estimated using the generative model. Our recognition algorithm assigns to a test image the identity of the closest approximated illumination cone (based on Euclidean distance within the image space). We test our face recognition method on 4,050 images from the Yale Face Database B; these images contain 405 viewing conditions (9 poses x 45 illumination conditions) for 10 individuals. The method performs almost without error, except on the most extreme lighting directions, and significantly outperforms popular recognition methods that do not use a generative model.																			0162-8828	1939-3539				JUN	2001	23	6					643	660		10.1109/34.927464	http://dx.doi.org/10.1109/34.927464													WOS:000169037600008
J	Berardino, P; Fornaro, G; Lanari, R; Sansosti, E				Berardino, P; Fornaro, G; Lanari, R; Sansosti, E			A new algorithm for surface deformation monitoring based on small baseline differential SAR interferograms	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING												We present a new differential synthetic aperture radar (SAR) interferometry algorithm for monitoring the temporal evolution of surface deformations. The presented technique is based on an appropriate combination of differential interferograms produced by data pairs characterized by a small orbital separation (baseline) in order to limit the spatial decorrelation phenomena. The application of the singular value decomposition method allows us to easily "link" independent SAR acquisition datasets, separated by large baselines, thus increasing the observation temporal sampling rate. The availability of both spatial and temporal information in the processed data is used to identify and filter out atmospheric phase artifacts. We present results obtained on the data acquired from 1992 to 2000 by the European Remote Sensing satellites and relative to the Campi Flegrei caldera and to the city of Naples, Italy that demonstrate the capability of the proposed approach to follow the dynamics of the detected deformations.					Sansosti, Eugenio/F-7297-2011; Fornaro, Gianfranco/C-1345-2017	LANARI, RICCARDO/0000-0002-7296-2749; Sansosti, Eugenio/0000-0002-5051-4056													0196-2892					NOV	2002	40	11					2375	2383		10.1109/TGRS.2002.803792	http://dx.doi.org/10.1109/TGRS.2002.803792													WOS:000180486900004
J	Mittal, A; Moorthy, AK; Bovik, AC				Mittal, Anish; Moorthy, Anush Krishna; Bovik, Alan Conrad			No-Reference Image Quality Assessment in the Spatial Domain	IEEE TRANSACTIONS ON IMAGE PROCESSING												We propose a natural scene statistic-based distortion-generic blind/no-reference (NR) image quality assessment (IQA) model that operates in the spatial domain. The new model, dubbed blind/referenceless image spatial quality evaluator (BRISQUE) does not compute distortion-specific features, such as ringing, blur, or blocking, but instead uses scene statistics of locally normalized luminance coefficients to quantify possible losses of "naturalness" in the image due to the presence of distortions, thereby leading to a holistic measure of quality. The underlying features used derive from the empirical distribution of locally normalized luminances and products of locally normalized luminances under a spatial natural scene statistic model. No transformation to another coordinate frame (DCT, wavelet, etc.) is required, distinguishing it from prior NR IQA approaches. Despite its simplicity, we are able to show that BRISQUE is statistically better than the full-reference peak signal-to-noise ratio and the structural similarity index, and is highly competitive with respect to all present-day distortion-generic NR IQA algorithms. BRISQUE has very low computational complexity, making it well suited for real time applications. BRISQUE features may be used for distortion-identification as well. To illustrate a new practical application of BRISQUE, we describe how a nonblind image denoising algorithm can be augmented with BRISQUE in order to perform blind image denoising. Results show that BRISQUE augmentation leads to performance improvements over state-of-the-art methods. A software release of BRISQUE is available online: http://live.ece.utexas.edu/research/quality/BRISQUE_release.zip for public use and evaluation.					Bovik, Alan/B-6717-2012	Bovik, Alan/0000-0001-6067-710X													1057-7149	1941-0042				DEC	2012	21	12					4695	4708		10.1109/TIP.2012.2214050	http://dx.doi.org/10.1109/TIP.2012.2214050								22910118					WOS:000311363200002
J	Shin, HC; Roth, HR; Gao, MC; Lu, L; Xu, ZY; Nogues, I; Yao, JH; Mollura, D; Summers, RM				Shin, Hoo-Chang; Roth, Holger R.; Gao, Mingchen; Lu, Le; Xu, Ziyue; Nogues, Isabella; Yao, Jianhua; Mollura, Daniel; Summers, Ronald M.			Deep Convolutional Neural Networks for Computer-Aided Detection: CNN Architectures, Dataset Characteristics and Transfer Learning	IEEE TRANSACTIONS ON MEDICAL IMAGING												Remarkable progress has been made in image recognition, primarily due to the availability of large-scale annotated datasets and deep convolutional neural networks (CNNs). CNNs enable learning data-driven, highly representative, hierarchical image features from sufficient training data. However, obtaining datasets as comprehensively annotated as ImageNet in the medical imaging domain remains a challenge. There are currently three major techniques that successfully employ CNNs to medical image classification: training the CNN from scratch, using off-the-shelf pre-trained CNN features, and conducting unsupervised CNN pre-training with supervised fine-tuning. Another effective method is transfer learning, i.e., fine-tuning CNN models pre-trained from natural image dataset to medical image tasks. In this paper, we exploit three important, but previously understudied factors of employing deep convolutional neural networks to computer-aided detection problems. We first explore and evaluate different CNN architectures. The studied models contain 5 thousand to 160 million parameters, and vary in numbers of layers. We then evaluate the influence of dataset scale and spatial image context on performance. Finally, we examine when and why transfer learning from pre-trained ImageNet (via fine-tuning) can be useful. We study two specific computer-aided detection (CADe) problems, namely thoraco-abdominal lymph node (LN) detection and interstitial lung disease (ILD) classification. We achieve the state-of-the-art performance on the mediastinal LN detection, and report the first five-fold cross-validation classification results on predicting axial CT slices with ILD categories. Our extensive empirical evaluation, CNN model analysis and valuable insights can be extended to the design of high performance CAD systems for other medical imaging tasks.					Lu, Le/AAD-7619-2020; Summers, Ronald/AAX-6290-2021; Yao, Jianhua/GQZ-6627-2022; Xu, Ziyue/K-9438-2014; Gao, Mingchen/I-5544-2017	Lu, Le/0000-0002-6799-9416; Roth, Holger R./0000-0002-3662-8743; Xu, Ziyue/0000-0002-5728-6869; Gao, Mingchen/0000-0002-5488-8514; Yao, Jianhua/0000-0001-9157-9596													0278-0062	1558-254X				MAY	2016	35	5			SI		1285	1298		10.1109/TMI.2016.2528162	http://dx.doi.org/10.1109/TMI.2016.2528162								26886976					WOS:000375550500013
J	Larsson, EG; Edfors, O; Tufvesson, F; Marzetta, TL				Larsson, Erik G.; Edfors, Ove; Tufvesson, Fredrik; Marzetta, Thomas L.			Massive MIMO for Next Generation Wireless Systems	IEEE COMMUNICATIONS MAGAZINE												Multi-user MIMO offers big advantages over conventional point-to-point MIMO: it works with cheap single-antenna terminals, a rich scattering environment is not required, and resource allocation is simplified because every active terminal utilizes all of the time-frequency bins. However, multi-user MIMO, as originally envisioned, with roughly equal numbers of service antennas and terminals and frequency-division duplex operation, is not a scalable technology. Massive MIMO (also known as large-scale antenna systems, very large MIMO, hyper MIMO, full-dimension MIMO, and ARGOS) makes a clean break with current practice through the use of a large excess of service antennas over active terminals and time-division duplex operation. Extra antennas help by focusing energy into ever smaller regions of space to bring huge improvements in throughput and radiated energy efficiency. Other benefits of massive MIMO include extensive use of inexpensive low-power components, reduced latency, simplification of the MAC layer, and robustness against intentional jamming. The anticipated throughput depends on the propagation environment providing asymptotically orthogonal channels to the terminals, but so far experiments have not disclosed any limitations in this regard. While massive MIMO renders many traditional research problems irrelevant, it uncovers entirely new problems that urgently need attention: the challenge of making many low-cost low-precision components that work effectively together, acquisition and synchronization for newly joined terminals, the exploitation of extra degrees of freedom provided by the excess of service antennas, reducing internal power consumption to achieve total energy efficiency reductions, and finding new deployment scenarios. This article presents an overview of the massive MIMO concept and contemporary research on the topic.					Marzetta, Thomas/AEB-0112-2022; Larsson, Erik/ADV-7383-2022														0163-6804	1558-1896				FEB	2014	52	2					186	195		10.1109/MCOM.2014.6736761	http://dx.doi.org/10.1109/MCOM.2014.6736761													WOS:000331904900024
J	Guerrero, JM; Vasquez, JC; Matas, J; de Vicuña, LG; Castilla, M				Guerrero, Josep M.; Vasquez, Juan C.; Matas, Jose; Garci de Vicuna, Luis; Castilla, Miguel			Hierarchical Control of Droop-Controlled AC and DC Microgrids-A General Approach Toward Standardization	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS												AC and dc microgrids (MGs) are key elements for integrating renewable and distributed energy resources as well as distributed energy-storage systems. In the last several years, efforts toward the standardization of these MGs have been made. In this sense, this paper presents the hierarchical control derived from ISA-95 and electrical dispatching standards to endow smartness and flexibility to MGs. The hierarchical control proposed consists of three levels: 1) The primary control is based on the droop method, including an output-impedance virtual loop; 2) the secondary control allows the restoration of the deviations produced by the primary control; and 3) the tertiary control manages the power flow between the MG and the external electrical distribution system. Results from a hierarchical-controlled MG are provided to show the feasibility of the proposed approach.					Castilla, Miguel/N-1166-2014; Guerrero, Josep/D-5519-2014; Vasquez, Juan C./J-2247-2014; Matas, Jose/I-2326-2014	Castilla, Miguel/0000-0002-3284-860X; Guerrero, Josep/0000-0001-5236-4592; Vasquez, Juan C./0000-0001-6332-385X; Matas, Jose/0000-0003-3854-1526; Garcia de Vicuna, Luis/0000-0003-2947-849X													0278-0046	1557-9948				JAN	2011	58	1					158	172		10.1109/TIE.2010.2066534	http://dx.doi.org/10.1109/TIE.2010.2066534													WOS:000285248900016
J	Greff, K; Srivastava, RK; Koutník, J; Steunebrink, BR; Schmidhuber, J				Greff, Klaus; Srivastava, Rupesh K.; Koutnik, Jan; Steunebrink, Bas R.; Schmidhuber, Juergen			LSTM: A Search Space Odyssey	IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS												Several variants of the long short-term memory (LSTM) architecture for recurrent neural networks have been proposed since its inception in 1995. In recent years, these networks have become the state-of-the-art models for a variety of machine learning problems. This has led to a renewed interest in understanding the role and utility of various computational components of typical LSTM variants. In this paper, we present the first large-scale analysis of eight LSTM variants on three representative tasks: speech recognition, handwriting recognition, and polyphonic music modeling. The hyperparameters of all LSTM variants for each task were optimized separately using random search, and their importance was assessed using the powerful functional ANalysis Of VAriance framework. In total, we summarize the results of 5400 experimental runs (approximate to 15 years of CPU time), which makes our study the largest of its kind on LSTM networks. Our results show that none of the variants can improve upon the standard LSTM architecture significantly, and demonstrate the forget gate and the output activation function to be its most critical components. We further observe that the studied hyperparameters are virtually independent and derive guidelines for their efficient adjustment.																			2162-237X	2162-2388				OCT	2017	28	10					2222	2232		10.1109/TNNLS.2016.2582924	http://dx.doi.org/10.1109/TNNLS.2016.2582924								27411231					WOS:000411293200001
J	Feng, QL; Wu, J; Chen, GQ; Cui, FZ; Kim, TN; Kim, JO				Feng, QL; Wu, J; Chen, GQ; Cui, FZ; Kim, TN; Kim, JO			A mechanistic study of the antibacterial effect of silver ions on <i>Escherichia coli</i> and <i>Staphylococcus aureus</i>	JOURNAL OF BIOMEDICAL MATERIALS RESEARCH												To investigate the mechanism of inhibition of silver ions on microorganisms, two strains of bacteria, namely Gram-negative Escherichia coli (E. coli and Gram-positive Staphylococcus aureus (S. aureus), were treated with AgNO3 and studied using combined electron microscopy and X-ray microanalysis. Similar morphological changes occurred in both E.coli and S. aureus cells after Ag+ treatment. The cytoplasm membrane detached from the cell wall. A remarkable electron-light region appeared in the center of the cells, which contained condensed deoxyribonucleic acid (DNA) molecules. There are many small electron-dense granules either surrounding the cell wall or depositing inside the cells. The existence of elements of silver and sulfur in the electron-dense granules and cytoplasm detected by X-ray microanalysis suggested the antibacterial mechanism of silver: DNA lost its replication ability and the protein became inactivated after Ag+ treatment. The slighter morphological changes of S. aureus compared with E. coli recommended a defense system of S. aureus against the inhibitory effects of Ag+ ions. (C) 2000 John Wiley & Sons, Inc.					Kim, Tae/D-9792-2015; Ahn, Hyun Joo/HJA-9552-2022														0021-9304					DEC 15	2000	52	4					662	668		10.1002/1097-4636(20001215)52:4<662::AID-JBM10>3.0.CO;2-3	http://dx.doi.org/10.1002/1097-4636(20001215)52:4<662::AID-JBM10>3.0.CO;2-3								11033548					WOS:000089576600010
J	Tabuada, P				Tabuada, Paulo			Event-triggered real-time scheduling of stabilizing control tasks	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												In this note, we revisit the problem of scheduling stabilizing control tasks on embedded processors. We start from the paradigm that a real-time scheduler could be regarded as a feedback controller that decides which task is executed at any given instant. This controller has for objective guaranteeing that (control unrelated) software tasks meet their deadlines and that stabilizing control tasks asymptotically stabilize the plant. We investigate a simple event-triggered scheduler based on this feedback paradigm and show how it leads to guaranteed performance thus relaxing the more traditional periodic execution requirements.					Tabuada, Paulo/ABD-5728-2021	Tabuada, Paulo/0000-0002-3417-0951													0018-9286	1558-2523				SEP	2007	52	9					1680	1685		10.1109/TAC.2007.904277	http://dx.doi.org/10.1109/TAC.2007.904277													WOS:000249665900012
J	Fax, JA; Murray, RM				Fax, JA; Murray, RM			Information flow and cooperative control of vehicle formations	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												We consider the problem of cooperation among a collection of vehicles performing a shared task using intervehicle communication to coordinate their actions. Tools from algebraic graph theory prove useful in modeling the communication network and relating its topology to formation stability. We prove a Nyquist criterion that uses the eigenvalues of the graph Laplacian matrix to determine the effect of the communication topology on formation stability. We also propose a method for decentralized information exchange between vehicles. This approach realizes a dynamical system that supplies each vehicle with a common reference to be used for cooperative motion. We prove a separation principle that decomposes formation stability into two components: Stability of the is achieved information flow for the given graph and stability of an individual vehicle for the given controller. The information flow can thus be rendered highly robust to changes in the graph, enabling tight formation control despite limitations in intervehicle communication capability.					Murray, Richard/J-2518-2015	Murray, Richard/0000-0002-5785-7481													0018-9286	1558-2523				SEP	2004	49	9					1465	1476		10.1109/TAC.2004.834433	http://dx.doi.org/10.1109/TAC.2004.834433													WOS:000223851800005
J	Eperon, GE; Stranks, SD; Menelaou, C; Johnston, MB; Herz, LM; Snaith, HJ				Eperon, Giles E.; Stranks, Samuel D.; Menelaou, Christopher; Johnston, Michael B.; Herz, Laura M.; Snaith, Henry J.			Formamidinium lead trihalide: a broadly tunable perovskite for efficient planar heterojunction solar cells	ENERGY & ENVIRONMENTAL SCIENCE												Perovskite-based solar cells have attracted significant recent interest, with power conversion efficiencies in excess of 15% already superceding a number of established thin-film solar cell technologies. Most work has focused on a methylammonium lead trihalide perovskites, with a bandgaps of similar to 1.55 eV and greater. Here, we explore the effect of replacing the methylammonium cation in this perovskite, and show that with the slightly larger formamidinium cation, we can synthesise formamidinium lead trihalide perovskites with a bandgap tunable between 1.48 and 2.23 eV. We take the 1.48 eV-bandgap perovskite as most suited for single junction solar cells, and demonstrate long-range electron and hole diffusion lengths in this material, making it suitable for planar heterojunction solar cells. We fabricate such devices, and due to the reduced bandgap we achieve high short-circuit currents of >23 mA cm(-2), resulting in power conversion efficiencies of up to 14.2%, the highest efficiency yet for solution processed planar heterojunction perovskite solar cells. Formamidinium lead triiodide is hence promising as a new candidate for this class of solar cell.					Snaith, Henry/A-7367-2016; Johnston, Michael/B-9813-2008; Stranks, Sam/M-7837-2015; Eperon, Giles/J-2316-2015; Herz, Laura/B-9789-2008	Snaith, Henry/0000-0001-8511-790X; Johnston, Michael/0000-0002-0301-8033; Stranks, Sam/0000-0002-8303-7292; Eperon, Giles/0000-0001-9600-4847; Herz, Laura/0000-0001-9621-334X; Africa, Josephine/0000-0002-8117-9211													1754-5692	1754-5706				MAR	2014	7	3					982	988		10.1039/c3ee43822h	http://dx.doi.org/10.1039/c3ee43822h													WOS:000333203900012
J	Menze, BH; Jakab, A; Bauer, S; Kalpathy-Cramer, J; Farahani, K; Kirby, J; Burren, Y; Porz, N; Slotboom, J; Wiest, R; Lanczi, L; Gerstner, E; Weber, MA; Arbel, T; Avants, BB; Ayache, N; Buendia, P; Collins, DL; Cordier, N; Corso, JJ; Criminisi, A; Das, T; Delingette, H; Demiralp, Ç; Durst, CR; Dojat, M; Doyle, S; Festa, J; Forbes, F; Geremia, E; Glocker, B; Golland, P; Guo, XT; Hamamci, A; Iftekharuddin, KM; Jena, R; John, NM; Konukoglu, E; Lashkari, D; Mariz, JA; Meier, R; Pereira, S; Precup, D; Price, SJ; Raviv, TR; Reza, SMS; Ryan, M; Sarikaya, D; Schwartz, L; Shin, HC; Shotton, J; Silva, CA; Sousa, N; Subbanna, NK; Szekely, G; Taylor, TJ; Thomas, OM; Tustison, NJ; Unal, G; Vasseur, F; Wintermark, M; Ye, DH; Zhao, L; Zhao, BS; Zikic, D; Prastawa, M; Reyes, M; Van Leemput, K				Menze, Bjoern H.; Jakab, Andras; Bauer, Stefan; Kalpathy-Cramer, Jayashree; Farahani, Keyvan; Kirby, Justin; Burren, Yuliya; Porz, Nicole; Slotboom, Johannes; Wiest, Roland; Lanczi, Levente; Gerstner, Elizabeth; Weber, Marc-Andre; Arbel, Tal; Avants, Brian B.; Ayache, Nicholas; Buendia, Patricia; Collins, D. Louis; Cordier, Nicolas; Corso, Jason J.; Criminisi, Antonio; Das, Tilak; Delingette, Herve; Demiralp, Cagatay; Durst, Christopher R.; Dojat, Michel; Doyle, Senan; Festa, Joana; Forbes, Florence; Geremia, Ezequiel; Glocker, Ben; Golland, Polina; Guo, Xiaotao; Hamamci, Andac; Iftekharuddin, Khan M.; Jena, Raj; John, Nigel M.; Konukoglu, Ender; Lashkari, Danial; Mariz, Jose Antonio; Meier, Raphael; Pereira, Sergio; Precup, Doina; Price, Stephen J.; Raviv, Tammy Riklin; Reza, Syed M. S.; Ryan, Michael; Sarikaya, Duygu; Schwartz, Lawrence; Shin, Hoo-Chang; Shotton, Jamie; Silva, Carlos A.; Sousa, Nuno; Subbanna, Nagesh K.; Szekely, Gabor; Taylor, Thomas J.; Thomas, Owen M.; Tustison, Nicholas J.; Unal, Gozde; Vasseur, Flor; Wintermark, Max; Ye, Dong Hye; Zhao, Liang; Zhao, Binsheng; Zikic, Darko; Prastawa, Marcel; Reyes, Mauricio; Van Leemput, Koen			The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)	IEEE TRANSACTIONS ON MEDICAL IMAGING												In this paper we report the set-up and results of the Multimodal Brain Tumor Image Segmentation Benchmark (BRATS) organized in conjunction with the MICCAI 2012 and 2013 conferences. Twenty state-of-the-art tumor segmentation algorithms were applied to a set of 65 multi-contrast MR scans of low-and high-grade glioma patients-manually annotated by up to four raters-and to 65 comparable scans generated using tumor image simulation software. Quantitative evaluations revealed considerable disagreement between the human raters in segmenting various tumor sub-regions (Dice scores in the range 74%-85%), illustrating the difficulty of this task. We found that different algorithms worked best for different sub-regions (reaching performance comparable to human inter-rater variability), but that no single algorithm ranked in the top for all sub-regions simultaneously. Fusing several good algorithms using a hierarchical majority vote yielded segmentations that consistently ranked above all individual algorithms, indicating remaining opportunities for further methodological improvements. The BRATS image data and manual annotations continue to be publicly available through an online evaluation system as an ongoing benchmarking resource.					Sarikaya, Duygu/S-1253-2017; Pereira, Sérgio/K-5591-2019; Collins, D. Louis/ABD-7708-2021; Hamamci, Andac/AAG-7280-2019; Weber, Marc-Andre/C-4452-2016; Prastawa, Marcel/G-6335-2012; Raviv, Tammy/A-3462-2013; Zhao, Liang/JEF-0353-2023; Jakab, András/U-9436-2019; Iftekharuddin, Khan/AAT-5217-2020; Kirby, Justin/AAI-7607-2020; Konukoglu, Ender/D-6719-2013; Ye, Dong Hye/AAS-5624-2020; Das, Tilak/AAY-5310-2020; Price, Stephen/B-1068-2011; Sousa, Nuno/N-9137-2017; Thomas, Owen/LIH-4216-2024; Unal, Gozde/A-2360-2013; Dojat, Michel/G-7758-2011; Silva, Carlos/J-1190-2014; Pereira, Sergio/N-9642-2015; Van Leemput, Koen/A-9197-2009; Menze, Bjoern/JOK-2720-2023	Hamamci, Andac/0000-0003-3438-3727; Price, Stephen/0000-0002-7535-3009; Wiest, Roland/0000-0001-7030-2045; Sousa, Nuno/0000-0002-8755-5126; Thomas, Owen/0000-0003-2877-3075; Prastawa, Marcel/0000-0002-0278-9637; Zhao, Liang/0000-0002-7556-8800; Unal, Gozde/0000-0001-5942-8966; Buendia, Patricia/0000-0001-7612-8842; Cordier, Nicolas/0000-0002-8794-8747; Dojat, Michel/0000-0003-2747-6845; Kirby, Justin/0000-0003-3487-8922; Das, Tilak/0000-0003-0655-412X; Collins, D. Louis/0000-0002-8432-7021; Delingette, Herve/0000-0001-6050-5949; Corso, Jason/0000-0001-6454-9594; Konukoglu, Ender/0000-0002-2542-3611; Silva, Carlos/0000-0002-1015-5095; Durst, Christopher/0000-0003-4236-7524; Pereira, Sergio/0000-0002-4298-0903; Jakab, Andras/0000-0001-6291-9889; Glocker, Ben/0000-0002-4897-9356; Riklin-Raviv, Tammy/0000-0003-2532-5875; TUSTISON, NICHOLAS/0000-0001-9418-5103; avants, brian/0000-0002-4212-3362; Ye, Dong Hye/0000-0002-9186-4095; Van Leemput, Koen/0000-0001-6466-5309; Menze, Bjoern/0000-0003-4136-5690; Festa, Joana/0000-0003-3358-4033; Das, Dhritiman/0000-0001-6627-0618													0278-0062	1558-254X				OCT	2015	34	10					1993	2024		10.1109/TMI.2014.2377694	http://dx.doi.org/10.1109/TMI.2014.2377694								25494501					WOS:000362358000001
J	Weishaar, JL; Aiken, GR; Bergamaschi, BA; Fram, MS; Fujii, R; Mopper, K				Weishaar, JL; Aiken, GR; Bergamaschi, BA; Fram, MS; Fujii, R; Mopper, K			Evaluation of specific ultraviolet absorbance as an indicator of the chemical composition and reactivity of dissolved organic carbon	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Specific UV absorbance (SUVA) is defined as the UV absorbance of a water sample at a given wavelength normalized for dissolved organic carbon (DOC) concentration. Our data indicate that SUVA, determined at 254 nm, is strongly correlated with percent aromaticity as determined by C-13 NMR for 13 organic matter isolates obtained from a variety of aquatic environments. SUVA, therefore, is shown to be a useful parameter for estimating the dissolved aromatic carbon content in aquatic systems. Experiments involving the reactivity of DOC with chlorine and tetramethylammoniurn hydroxide (TMAH), however, show a wide range of reactivity for samples with similar SUVA values. These results indicate that, while SUVA measurements are good predictors of general chemical characteristics of DOC, they do not provide information about reactivity of DOC derived from different types of source materials. Sample pH, nitrate, and iron were found to influence SUVA measurements.					Mopper, Kenneth/J-1761-2012; Bergamaschi, Brian/D-8325-2012	MOPPER, KENNETH/0000-0001-8089-6019; Bergamaschi, Brian/0000-0002-9610-5581; Fram, Miranda/0000-0002-6337-059X													0013-936X					OCT 15	2003	37	20					4702	4708		10.1021/es030360x	http://dx.doi.org/10.1021/es030360x								14594381					WOS:000186133000025
J	Zanella, A; Bui, N; Castellani, A; Vangelista, L; Zorzi, M				Zanella, Andrea; Bui, Nicola; Castellani, Angelo; Vangelista, Lorenzo; Zorzi, Michele			Internet of Things for Smart Cities	IEEE INTERNET OF THINGS JOURNAL												The Internet of Things (IoT) shall be able to incorporate transparently and seamlessly a large number of different and heterogeneous end systems, while providing open access to selected subsets of data for the development of a plethora of digital services. Building a general architecture for the IoT is hence a very complex task, mainly because of the extremely large variety of devices, link layer technologies, and services that may be involved in such a system. In this paper, we focus specifically to an urban IoT system that, while still being quite a broad category, are characterized by their specific application domain. Urban IoTs, in fact, are designed to support the Smart City vision, which aims at exploiting the most advanced communication technologies to support added-value services for the administration of the city and for the citizens. This paper hence provides a comprehensive survey of the enabling technologies, protocols, and architecture for an urban IoT. Furthermore, the paper will present and discuss the technical solutions and best-practice guidelines adopted in the Padova Smart City project, a proof-of-concept deployment of an IoT island in the city of Padova, Italy, performed in collaboration with the city municipality.					Vangelista, Lorenzo/AAA-3159-2020; zanella, Andrea/J-4736-2012; Zorzi, Michele/GQQ-2252-2022	xiaobing, lv/0009-0002-3773-0595; Bui, Nicola/0000-0002-4026-6562; VANGELISTA, LORENZO/0000-0002-4898-6951													2327-4662					FEB	2014	1	1					22	32		10.1109/JIOT.2014.2306328	http://dx.doi.org/10.1109/JIOT.2014.2306328													WOS:000209672000004
J	Gupta, HV; Kling, H; Yilmaz, KK; Martinez, GF				Gupta, Hoshin V.; Kling, Harald; Yilmaz, Koray K.; Martinez, Guillermo F.			Decomposition of the mean squared error and NSE performance criteria: Implications for improving hydrological modelling	JOURNAL OF HYDROLOGY												The mean squared error (MSE) and the related normalization, the Nash-Sutcliffe efficiency (NSE), are the two criteria most widely used for calibration and evaluation of hydrological models with observed data. Here, we present a diagnostically interesting decomposition of NSE (and hence MSE), which facilitates analysis of the relative importance of its different components in the context of hydrological modelling, and show how model calibration problems can arise due to interactions among these components. The analysis is illustrated by calibrating a simple conceptual precipitation-runoff model to daily data for a number of Austrian basins having a broad range of hydro-meteorological characteristics. Evaluation of the results clearly demonstrates the problems that can be associated with any calibration based on the NSE (or MSE) criterion. While we propose and test an alternative criterion that can help to reduce model calibration problems, the primary purpose of this Study is not to present an improved measure of model performance. Instead, we seek to show that there are systematic problems inherent with any optimization based on formulations related to the MSE. The analysis and results have implications to the manner in which we calibrate and evaluate environmental models, we discuss these and suggest possible ways forward that may move us towards an improved and diagnostically meaningful approach to model performance evaluation and identification. (C) 2009 Elsevier B.V. All rights reserved.					Gupta, Hoshin/D-1642-2010; YILMAZ, Koray K./A-6053-2010	YILMAZ, Koray K./0000-0002-6244-8826; Gupta, Hoshin/0000-0001-9855-2839; Kling, Harald/0000-0002-5974-0965													0022-1694	1879-2707				OCT 20	2009	377	1-2					80	91		10.1016/j.jhydrol.2009.08.003	http://dx.doi.org/10.1016/j.jhydrol.2009.08.003													WOS:000271125800009
J	Qin, SJ; Badgwell, TA				Qin, SJ; Badgwell, TA			A survey of industrial model predictive control technology	CONTROL ENGINEERING PRACTICE												This paper provides an overview of commercially available model predictive control (MPC) technology, both linear and nonlinear, based primarily on data provided by MPC vendors. A brief history of industrial MPC technology is presented first, followed by results of our vendor survey of MPC control and identification technology. A general MPC control algorithm is presented, and approaches taken by each vendor for the different aspects of the calculation are described. Identification technology is reviewed to determine similarities and differences between the various approaches. MPC applications performed by each vendor are summarized by application area. The final section presents a vision of the next generation of MPC technology, with an emphasis on potential business and research opportunities. (C) 2002 Elsevier Science Ltd. All rights reserved.					Qin, S. Joe/A-4234-2010	Qin, S. Joe/0000-0001-7631-2535													0967-0661					JUL	2003	11	7					733	764	PII S0967-0661(02)00186-7	10.1016/S0967-0661(02)00186-7	http://dx.doi.org/10.1016/S0967-0661(02)00186-7													WOS:000183650900002
J	Gu, JX; Wang, ZH; Kuen, J; Ma, LY; Shahroudy, A; Shuai, B; Liu, T; Wang, XX; Wang, G; Cai, JF; Chen, T				Gu, Jiuxiang; Wang, Zhenhua; Kuen, Jason; Ma, Lianyang; Shahroudy, Amir; Shuai, Bing; Liu, Ting; Wang, Xingxing; Wang, Gang; Cai, Jianfei; Chen, Tsuhan			Recent advances in convolutional neural networks	PATTERN RECOGNITION												In the last few years, deep learning has led to very good performance on a variety of problems, such as visual recognition, speech recognition and natural language processing. Among different types of deep neural networks, convolutional neural networks have been most extensively studied. Leveraging on the rapid growth in the amount of the annotated data and the great improvements in the strengths of graphics processor units, the research on convolutional neural networks has been emerged swiftly and achieved state-of-the-art results on various tasks. In this paper, we provide a broad survey of the recent advances in convolutional neural networks. We detailize the improvements of CNN on different aspects, including layer design, activation function, loss function, regularization, optimization and fast computation. Besides, we also introduce various applications of convolutional neural networks in computer vision, speech and natural language processing. (C) 2017 Elsevier Ltd. All rights reserved.					Shuai, Bing/LJM-2494-2024; Chen, Tupei/A-5061-2011; Kuen, Jason/AAA-1809-2020; Wang, Zhenhua/GYJ-4052-2022; Cai, Jianfei/A-3691-2011; Shahroudy, Amir/T-2261-2017	Cai, Jianfei/0000-0002-9444-3763; Chen, Tsuhan/0000-0003-3951-7931; Shahroudy, Amir/0000-0002-1045-6437													0031-3203	1873-5142				MAY	2018	77						354	377		10.1016/j.patcog.2017.10.013	http://dx.doi.org/10.1016/j.patcog.2017.10.013													WOS:000426222800028
J	Ji, SW; Xu, W; Yang, M; Yu, K				Ji, Shuiwang; Xu, Wei; Yang, Ming; Yu, Kai			3D Convolutional Neural Networks for Human Action Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												We consider the automated recognition of human actions in surveillance videos. Most current methods build classifiers based on complex handcrafted features computed from the raw inputs. Convolutional neural networks (CNNs) are a type of deep model that can act directly on the raw inputs. However, such models are currently limited to handling 2D inputs. In this paper, we develop a novel 3D CNN model for action recognition. This model extracts features from both the spatial and the temporal dimensions by performing 3D convolutions, thereby capturing the motion information encoded in multiple adjacent frames. The developed model generates multiple channels of information from the input frames, and the final feature representation combines information from all channels. To further boost the performance, we propose regularizing the outputs with high-level features and combining the predictions of a variety of different models. We apply the developed models to recognize human actions in the real-world environment of airport surveillance videos, and they achieve superior performance in comparison to baseline methods.					Yang, Ming-Hsuan/T-9533-2019	Ji, Shuiwang/0000-0002-4205-4563; Yang, Ming/0000-0003-1691-6817													0162-8828	1939-3539				JAN	2013	35	1					221	231		10.1109/TPAMI.2012.59	http://dx.doi.org/10.1109/TPAMI.2012.59								22392705					WOS:000311127700019
J	Mirjalili, S; Gandomi, AH; Mirjalili, SZ; Saremi, S; Faris, H; Mirjalili, SM				Mirjalili, Seyedali; Gandomi, Amir H.; Mirjalili, Seyedeh Zahra; Saremi, Shahrzad; Faris, Hossam; Mirjalili, Seyed Mohammad			Salp Swarm Algorithm: A bio-inspired optimizer for engineering design problems	ADVANCES IN ENGINEERING SOFTWARE												This work proposes two novel optimization algorithms called Salp Swarm Algorithm (SSA) and Multiobjective Salp Swarm Algorithm (MSSA) for solving optimization problems with single and multiple objectives. The main inspiration of SSA and MSSA is the swarming behaviour of salps when navigating and foraging in oceans. These two algorithms are tested on several mathematical optimization functions to observe and confirm their effective behaviours in finding the optimal solutions for optimization problems. The results on the mathematical functions show that the SSA algorithm is able to improve the initial random solutions effectively and converge towards the optimum. The results of MSSA show that this algorithm can approximate Pareto optimal solutions with high convergence and coverage. The paper also considers solving several challenging and computationally expensive engineering design problems (e.g. airfoil design and marine propeller design) using SSA and MSSA. The results of the real case studies demonstrate the merits of the algorithms proposed in solving real-world problems with difficult and unknown search spaces. (C) 2017 Elsevier Ltd. All rights reserved.					Faris, Hossam/C-2392-2015; Mirjalili, Seyed Mohammad/E-9988-2013; Saremi, Shahrzad/AAA-7696-2019; Mirjalili, S. Z./ABD-9714-2021; Mirjalili, Seyedali/P-1372-2018; Gandomi, Amir/J-7595-2013	Mirjalili, Seyedali/0000-0002-1443-9458; Gandomi, Amir/0000-0002-2798-0104													0965-9978	1873-5339				DEC	2017	114						163	191		10.1016/j.advengsoft.2017.07.002	http://dx.doi.org/10.1016/j.advengsoft.2017.07.002													WOS:000415593800013
J	Frigo, M; Johnson, SG				Frigo, M; Johnson, SG			The design and implementation of FFTW3	PROCEEDINGS OF THE IEEE												FFTW is an implementation of the discrete Fourier transform (LEFT) that adapts to the hardware in order to maximize performance. This paper shows that such an approach can yield an implementation that is competitive with hand-optimized libraries, and describes the software structure that makes our current FFTW3 version flexible and adaptive. We further discuss a new algorithm for real-data DFTs of prime size, a new way of implementing DFTs by means of machine-specific single-instruction, multiple-data (SIMD) instructions, and how a special-purpose compiler can derive optimized implementations of the discrete cosine and sine transforms automatically from a DFT algorithm.						Johnson, Steven/0000-0001-7327-4967													0018-9219	1558-2256				FEB	2005	93	2					216	231		10.1109/JPROC.2004.840301	http://dx.doi.org/10.1109/JPROC.2004.840301													WOS:000226542300002
J	Phillips, PJ; Moon, H; Rizvi, SA; Rauss, PJ				Phillips, PJ; Moon, H; Rizvi, SA; Rauss, PJ			The FERET evaluation methodology for face-recognition algorithms	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems. The Face Recognition Technology (FERET) program has addressed both issues through the FERET database of facial images and the establishment of the FERET tests. To date, 14,126 images from 1,199 individuals are included in the FERET database, which is divided into development and sequestered portions of the database. In September 1996, the FERET program administered the third in a series of FERET face-recognition tests. The primary objectives of the third test were to 1) assess the slate of the art, 2) identify future areas of research, and 3) measure algorithm performance.					Rauss, Patrick/A-3029-2011	Rauss, Patrick/0000-0003-0118-5994													0162-8828	1939-3539				OCT	2000	22	10					1090	1104		10.1109/34.879790	http://dx.doi.org/10.1109/34.879790													WOS:000165067100003
J	Esram, T; Chapman, PL				Esram, Trishan; Chapman, Patrick L.			Comparison of photovoltaic array maximum power point tracking techniques	IEEE TRANSACTIONS ON ENERGY CONVERSION												The many different techniques for maximum power point tracking of photovoltaic (PV) arrays are discussed. The techniques are taken from the literature dating back to the earliest methods. It is shown that at least 19 distinct methods have been introduced in the literature, with many variations on implementation. This paper should serve as a convenient reference for future work in PV power generation.																			0885-8969	1558-0059				JUN	2007	22	2					439	449		10.1109/TEC.2006.874230	http://dx.doi.org/10.1109/TEC.2006.874230													WOS:000246863000025
J	Melgani, F; Bruzzone, L				Melgani, F; Bruzzone, L			Classification of hyperspectral remote sensing images with support vector machines	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING												This paper addresses the problem of the classification of hyperspectral remote sensing images by support vector machines (SVMs). First, we propose a theoretical discussion and experimental analysis aimed at understanding and assessing the potentialities of SVM classifiers in hyperdimensional feature spaces. Then, we assess the effectiveness of SVMs with respect to conventional feature-reduction-based approaches and their performances in hypersubspaces of various dimensionalities. To sustain such an analysis, the performances of SVMs are compared with those of two other nonparametric classifiers (i.e., radial basis function neural networks and the K-nearest neighbor classifier). Finally, we study the potentially critical issue of applying binary SVMs to multiclass problems in hyperspectral data. In particular, four different multiclass strategies are analyzed and compared: the one-against-all, the one:against-one, and two hierarchical tree-based strategies. Different performance indicators have been used to support our experimental studies in a detailed and accurate way, i.e., the classification accuracy, the computational time, the stability to parameter setting, and the complexity of the multiclass architecture. The results obtained on a real Airborne Visible/Infrared Imaging Spectroradiometer hyperspectral dataset allow to conclude that, whatever the multiclass strategy adopted, SVMs are a valid and effective alternative to conventional pattern recognition approaches (feature-reduction procedures combined with a classification method) for the classification of hyperspectral remote sensing data.					Melgani, Farid/A-7076-2013; Bruzzone, Lorenzo/JPL-7703-2023; Bruzzone, Lorenzo/A-2076-2012	Bruzzone, Lorenzo/0000-0002-6036-459X													0196-2892	1558-0644				AUG	2004	42	8					1778	1790		10.1109/TGRS.2004.831865	http://dx.doi.org/10.1109/TGRS.2004.831865													WOS:000223296300019
J	Prince, M				Prince, M			Does active learning work? A review of the research	JOURNAL OF ENGINEERING EDUCATION												This study examines the evidence for the effectiveness of active learning. It defines the common forms of active learning most relevant for engineering faculty and critically examines the core element of each method. It is found that there is broad but uneven support for the core elements of active, collaborative, cooperative and problem-based learning.						Nguyen, Huan/0000-0002-6178-0085													1069-4730	2168-9830				JUL	2004	93	3					223	231		10.1002/j.2168-9830.2004.tb00809.x	http://dx.doi.org/10.1002/j.2168-9830.2004.tb00809.x													WOS:000226629800009
J	Wernet, G; Bauer, C; Steubing, B; Reinhard, J; Moreno-Ruiz, E; Weidema, B				Wernet, Gregor; Bauer, Christian; Steubing, Bernhard; Reinhard, Jurgen; Moreno-Ruiz, Emilia; Weidema, Bo			The ecoinvent database version 3 (part I): overview and methodology	INTERNATIONAL JOURNAL OF LIFE CYCLE ASSESSMENT												Good background data are an important requirement in LCA. Practitioners generally make use of LCI databases for such data, and the ecoinvent database is the largest transparent unit-process LCI database worldwide. Since its first release in 2003, it has been continuously updated, and version 3 was published in 2013. The release of version 3 introduced several significant methodological and technological improvements, besides a large number of new and updated datasets. The aim was to expand the content of the database, set the foundation for a truly global database, support regionalized LCIA, offer multiple system models, allow for easier integration of data from different regions, and reduce maintenance efforts. This article describes the methodological developments. Modeling choices and raw data were separated in version 3, which enables the application of different sets of modeling choices, or system models, to the same raw data with little effort. This includes one system model for Consequential LCA. Flow properties were added to all exchanges in the database, giving more information on the inventory and allowing a fast calculation of mass and other balances. With version 3.1, the database is generally water-balanced, and water use and consumption can be determined. Consumption mixes called market datasets were consistently added to the database, and global background data was added, often as an extrapolation from regional data. In combination with hundreds of new unit processes from regions outside Europe, these changes lead to an improved modeling of global supply chains, and a more realistic distribution of impacts in regionalized LCIA. The new mixes also facilitate further regionalization due to the availability of background data for all regions. With version 3, the ecoinvent database substantially expands the goals and scopes of LCA studies it can support. The new system models allow new, different studies to be performed. Global supply chains and market datasets significantly increase the relevance of the database outside of Europe, and regionalized LCA is supported by the data. Datasets are more transparent, include more information, and support, e.g., water balances. The developments also support easier collaboration with other database initiatives, as demonstrated by a first successful collaboration with a data project in Qu,bec. Version 3 has set the foundation for expanding ecoinvent from a mostly regional into a truly global database and offers many new insights beyond the thousands of new and updated datasets it also introduced.					Weidema, Bo/M-3264-2019	Steubing, Bernhard/0000-0002-1307-6376; Weidema, Bo/0000-0003-1863-6528; Moreno Ruiz, Emilia/0000-0003-4238-7306; Bauer, Christian/0000-0002-1083-9200													0948-3349	1614-7502				SEP	2016	21	9					1218	1230		10.1007/s11367-016-1087-8	http://dx.doi.org/10.1007/s11367-016-1087-8													WOS:000382172800002
J	Kreutz, D; Ramos, FMV; Veríssimo, PE; Rothenberg, CE; Azodolmolky, S; Uhlig, S				Kreutz, Diego; Ramos, Fernando M. V.; Verissimo, Paulo Esteves; Rothenberg, Christian Esteve; Azodolmolky, Siamak; Uhlig, Steve			Software-Defined Networking: A Comprehensive Survey	PROCEEDINGS OF THE IEEE												The Internet has led to the creation of a digital society, where (almost) everything is connected and is accessible from anywhere. However, despite their widespread adoption, traditional IP networks are complex and very hard to manage. It is both difficult to configure the network according to predefined policies, and to reconfigure it to respond to faults, load, and changes. To make matters even more difficult, current networks are also vertically integrated: the control and data planes are bundled together. Software-defined networking (SDN) is an emerging paradigm that promises to change this state of affairs, by breaking vertical integration, separating the network's control logic from the underlying routers and switches, promoting (logical) centralization of network control, and introducing the ability to program the network. The separation of concerns, introduced between the definition of network policies, their implementation in switching hardware, and the forwarding of traffic, is key to the desired flexibility: by breaking the network control problem into tractable pieces, SDN makes it easier to create and introduce new abstractions in networking, simplifying network management and facilitating network evolution. In this paper, we present a comprehensive survey on SDN. We start by introducing the motivation for SDN, explain its main concepts and how it differs from traditional networking, its roots, and the standardization activities regarding this novel paradigm. Next, we present the key building blocks of an SDN infrastructure using a bottom-up, layered approach. We provide an in-depth analysis of the hardware infrastructure, southbound and northbound application programming interfaces (APIs), network virtualization layers, network operating systems (SDN controllers), network programming languages, and network applications. We also look at cross-layer problems such as debugging and troubleshooting. In an effort to anticipate the future evolution of this new paradigm, we discuss the main ongoing research efforts and challenges of SDN. In particular, we address the design of switches and control platforms-with a focus on aspects such as resiliency, scalability, performance, security, and dependability-as well as new opportunities for carrier transport networks and cloud providers. Last but not least, we analyze the position of SDN as a key enabler of a software-defined environment.					Ramos, Fernando/AAL-5992-2020; Uhlig, Steve/P-3202-2019; Esteve Rothenberg, Christian/J-7148-2012; Uhlig, Steve/B-5581-2016; Ramos, Fernando/O-7657-2015	Esteve Rothenberg, Christian/0000-0003-3109-4305; Kreutz, Diego/0000-0003-0830-0238; Uhlig, Steve/0000-0001-6251-6836; Ramos, Fernando/0000-0003-3585-8587													0018-9219	1558-2256				JAN	2015	103	1					14	76		10.1109/JPROC.2014.2371999	http://dx.doi.org/10.1109/JPROC.2014.2371999													WOS:000346768700003
J	Comaniciu, D; Ramesh, V; Meer, P				Comaniciu, D; Ramesh, V; Meer, P			Kernel-based object tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE					IEEE Conference on Computer Vision and Pattern Recognition (CVPR 2000)	JUN 13-15, 2000	HILTON HEAD ISL, SC	IEEE Comp Soc, IEEE Comp Soc, Tech Comm Pattern Anal & Machine Intelligence				A new approach toward target representation and localization, the central component in visual tracking of nonrigid objects, is proposed. The feature histogram-based target representations are regularized by spatial masking with an isotropic kernel. The masking induces spatially-smooth similarity functions suitable for gradient-based optimization, hence, the target localization problem can be formulated using the basin of attraction of the local maxima. We employ a metric derived from the Bhattacharyya coefficient as similarity measure, and use the mean shift procedure to perform the optimization. In the presented tracking examples, the new method successfully coped with camera motion, partial occlusions, clutter, and target scale variations. Integration with motion filters and data association techniques is also discussed. We describe only a few of the potential applications: exploitation of background information, Kalman tracking using motion models, and face tracking.						Comaniciu, Dorin/0000-0002-5238-8647													0162-8828	1939-3539				MAY	2003	25	5					564	577		10.1109/TPAMI.2003.1195991	http://dx.doi.org/10.1109/TPAMI.2003.1195991													WOS:000182342300003
J	Palomares, V; Serras, P; Villaluenga, I; Hueso, KB; Carretero-González, J; Rojo, T				Palomares, Veronica; Serras, Paula; Villaluenga, Irune; Hueso, Karina B.; Carretero-Gonzalez, Javier; Rojo, Teofilo			Na-ion batteries, recent advances and present challenges to become low cost energy storage systems	ENERGY & ENVIRONMENTAL SCIENCE												Energy production and storage have become key issues concerning our welfare in daily life. Present challenges for batteries are twofold. In the first place, the increasing demand for powering systems of portable electronic devices and zero-emission vehicles stimulates research towards high energy and high voltage systems. In the second place, low cost batteries are required in order to advance towards smart electric grids that integrate discontinuous energy flow from renewable sources, optimizing the performance of clean energy sources. Na-ion batteries can be the key for the second point, because of the huge availability of sodium, its low price and the similarity of both Li and Na insertion chemistries. In spite of the lower energy density and voltage of Na-ion based technologies, they can be focused on applications where the weight and footprint requirement is less drastic, such as electrical grid storage. Much work has to be done in the field of Na-ion in order to catch up with Li-ion technology. Cathodic and anodic materials must be optimized, and new electrolytes will be the key point for Na-ion success. This review will gather the up-to-date knowledge about Na-ion battery materials, with the aim of providing a wide view of the systems that have already been explored and a starting point for the new research on this battery technology.					Rojo, Teofilo/B-5197-2015; Villaluenga, Irune/ABH-5243-2020; Serras, Paula/AAF-8117-2019; PALOMARES DURAN, VERONICA/H-1898-2018	Hueso, Karina/0000-0001-9329-9037; Carretero Gonzalez, Javier/0000-0002-8008-5715; SERRAS MALILLOS, PAULA/0000-0001-9543-7720; PALOMARES DURAN, VERONICA/0000-0002-3269-8656													1754-5692	1754-5706				MAR	2012	5	3					5884	5901		10.1039/c2ee02781j	http://dx.doi.org/10.1039/c2ee02781j													WOS:000300710600002
J	Boykov, Y; Kolmogorov, V				Boykov, Y; Kolmogorov, V			An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												After [15], [31], [19], [8], [25], [5], minimum cut/maximum flow algorithms on graphs emerged as an increasingly useful tool for exact or approximate energy minimization in low-level vision. The combinatorial optimization literature provides many min-cut/max-flow algorithms with different polynomial time complexity. Their practical efficiency, however, has to date been studied mainly outside the scope of computer vision. The goal of this paper is to provide an experimental comparison of the efficiency of min-cut/maxflow algorithms for applications in vision. We compare the running times of several standard algorithms, as well as a new algorithm that we have recently developed. The algorithms we study include both Goldberg-Tarjan style "push-relabel" methods and algorithms based on Ford-Fulkerson style "augmenting paths." We benchmark these algorithms on a number of typical graphs in the contexts of image restoration, stereo, and segmentation. In many cases, our new algorithm works several times faster than any of the other methods, making near real-time performance possible. An implementation of our max-flow/min-cut algorithm is available upon request for research purposes.					Boykov, Yuri/C-1718-2015														0162-8828	1939-3539				SEP	2004	26	9					1124	1137		10.1109/TPAMI.2004.60	http://dx.doi.org/10.1109/TPAMI.2004.60								15742889					WOS:000222605100003
J	Pan, SJ; Tsang, IW; Kwok, JT; Yang, QA				Pan, Sinno Jialin; Tsang, Ivor W.; Kwok, James T.; Yang, Qiang			Domain Adaptation via Transfer Component Analysis	IEEE TRANSACTIONS ON NEURAL NETWORKS												Domain adaptation allows knowledge from a source domain to be transferred to a different but related target domain. Intuitively, discovering a good feature representation across domains is crucial. In this paper, we first propose to find such a representation through a new learning method, transfer component analysis (TCA), for domain adaptation. TCA tries to learn some transfer components across domains in a reproducing kernel Hilbert space using maximum mean miscrepancy. In the subspace spanned by these transfer components, data properties are preserved and data distributions in different domains are close to each other. As a result, with the new representations in this subspace, we can apply standard machine learning methods to train classifiers or regression models in the source domain for use in the target domain. Furthermore, in order to uncover the knowledge hidden in the relations between the data labels from the source and target domains, we extend TCA in a semisupervised learning setting, which encodes label information into transfer components learning. We call this extension semisupervised TCA. The main contribution of our work is that we propose a novel dimensionality reduction framework for reducing the distance between domains in a latent space for domain adaptation. We propose both unsupervised and semisupervised feature extraction approaches, which can dramatically reduce the distance between domain distributions by projecting data onto the learned transfer components. Finally, our approach can handle large datasets and naturally lead to out-of-sample generalization. The effectiveness and efficiency of our approach are verified by experiments on five toy datasets and two real-world applications: cross-domain indoor WiFi localization and cross-domain text classification.					Tsang, Ivor/E-8653-2011; Pan, Sinno Jialin/IWV-0607-2023; yang, qiang/GYJ-0971-2022														1045-9227	1941-0093				FEB	2011	22	2					199	210		10.1109/TNN.2010.2091281	http://dx.doi.org/10.1109/TNN.2010.2091281								21095864					WOS:000287097500003
J	Egbert, GD; Erofeeva, SY				Egbert, GD; Erofeeva, SY			Efficient inverse Modeling of barotropic ocean tides	JOURNAL OF ATMOSPHERIC AND OCEANIC TECHNOLOGY												A computationally efficient relocatable system for generalized inverse (GI) modeling of barotropic ocean tides is described. The GI penalty functional is minimized using a representer method, which requires repeated solution of the forward and adjoint linearized shallow water equations (SWEs). To make representer computations efficient, the SWEs are solved in the frequency domain by factoring the coefficient matrix for a finite-difference discretization of the second-order wave equation in elevation. Once this matrix is factored representers can be calculated rapidly. By retaining the first-order SWE system (defined in terms of both elevations and currents) in the definition of the discretized GI penalty functional, complete generality in the choice of dynamical error covariances is retained. This allows rational assumptions about errors in the SWE, with soft momentum balance constraints (e. g., to account for inaccurate parameterization of dissipation), but holds mass conservation constraints. While the dynamical calculations involve elevations alone, depth-averaged currents can be directly assimilated into the tidal model with this approach. The efficient representer calculation forms the basis for the Oregon State University (OSU) Tidal Inversion Software (OTIS). OTIS includes software for generating grids, prior model covariances, and boundary conditions; for time stepping the nonlinear shallow water equations to generate a first guess or prior solution; for preliminary processing of TOPEX/Poseidon altimeter data; for solution of the GI problem; and for computation of posterior error bars. Approximate GI solution methods, based on using a reduced set of representers, allow very large datasets to be inverted. OTIS regional and local GI tidal modeling (with grids containing up to 10(5) nodes) require only a few hours on a common desktop workstation. Use of OTIS is illustrated by developing a new regional-scale (1/68) model of tides in the Indonesian Seas.						Erofeeva, Svetlana/0000-0002-4489-7505													0739-0572						2002	19	2					183	204		10.1175/1520-0426(2002)019<0183:EIMOBO>2.0.CO;2	http://dx.doi.org/10.1175/1520-0426(2002)019<0183:EIMOBO>2.0.CO;2													WOS:000173418200004
J	Vamvatsikos, D; Cornell, CA				Vamvatsikos, D; Cornell, CA			Incremental dynamic analysis	EARTHQUAKE ENGINEERING & STRUCTURAL DYNAMICS												Incremental dynamic analysis (IDA) is a parametric analysis method that has recently emerged in several different forms to estimate more thoroughly structural performance under seismic loads. It involves subjecting a structural model to one (or more) ground motion record(s), each scaled to multiple levels of intensity, thus producing one (or more) curve(s) of response parameterized versus intensity level. To establish a common frame of reference, the fundamental concepts are analysed, a unified terminology is proposed. suitable algorithms are presented, and properties of the IDA curve are looked into for both single-degree-of-freedom and multi-degree-of-freedom structures. In addition, summarization techniques for multi-record IDA studies and the association of the IDA study with the conventional static pushover analysis and the yield reduction R-factor are discussed. Finally, in the framework of performance-based earthquake engineering, the assessment of demand and capacity is viewed through the lens of an IDA study. Copyright (C) 2001 John Wiley Sons, Ltd.					Vamvatsikos, Dimitrios/S-8461-2019	Vamvatsikos, Dimitrios/0000-0002-4016-5040													0098-8847					MAR	2002	31	3					491	514		10.1002/eqe.141	http://dx.doi.org/10.1002/eqe.141													WOS:000173870500002
J	Browne, MA; Crump, P; Niven, SJ; Teuten, E; Tonkin, A; Galloway, T; Thompson, R				Browne, Mark Anthony; Crump, Phillip; Niven, Stewart J.; Teuten, Emma; Tonkin, Andrew; Galloway, Tamara; Thompson, Richard			Accumulation of Microplastic on Shorelines Woldwide: Sources and Sinks	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Plastic debris < 1 mm (defined here as microplastic) is accumulating in marine habitats. Ingestion of microplastic provides a potential pathway for the transfer of pollutants, monomers, and plastic-additives to organisms with uncertain consequences for their health. Here, we show that microplastic contaminates the shorelines at 18 sites worldwide representing six continents from the poles to the equator, with more material in densely populated areas, but no clear relationship between the abundance of miocroplastics and the mean size-distribution of natural particulates. An important source of microplastic appears to be through sewage contaminated by fibers from washing clothes. Forensic evaluation of microplastic from sediments showed that the proportions of polyester and acrylic fibers used in clothing resembled those found in habitats that receive sewage-discharges and sewage-effluent itself. Experiments sampling wastewater from domestic washing machines demonstrated that a single garment can produce > 1900 fibers per wash. This suggests that a large proportion of microplastic fibers found in the marine environment may be derived from sewage as a consequence of washing of clothes. As the human population grows and people use more synthetic textiles, contamination of habitats and animals by microplastic is likely to increase.					Thompson, Richard/J-8879-2014	Browne, Mark Anthony/0000-0002-7508-1015; Thompson, Richard/0000-0003-2262-6621													0013-936X	1520-5851				NOV 1	2011	45	21					9175	9179		10.1021/es201811s	http://dx.doi.org/10.1021/es201811s								21894925					WOS:000296212700011
J	Izhikevich, EM				Izhikevich, EM			Simple model of spiking neurons	IEEE TRANSACTIONS ON NEURAL NETWORKS												A model is presented that reproduces spiking and bursting behavior of known types of cortical neurons. The model combines the biologically plausibility of Hodgkin-Huxley-type dynamics and the computational efficiency of integrate-and-fire neurons. Using this model, one can simulate tens of thousands of spiking cortical neurons in real time (1 ms resolution) using a desktop PC.																			1045-9227					NOV	2003	14	6					1569	1572		10.1109/TNN.2003.820440	http://dx.doi.org/10.1109/TNN.2003.820440								18244602					WOS:000188260400014
J	Delp, SL; Anderson, FC; Arnold, AS; Loan, P; Habib, A; John, CT; Guendelman, E; Thelen, DG				Delp, Scott L.; Anderson, Frank C.; Arnold, Allison S.; Loan, Peter; Habib, Ayman; John, Chand T.; Guendelman, Eran; Thelen, Darryl G.			OpenSim: open-source software to create and analyze dynamic Simulations of movement	IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING												Dynamic simulations of movement allow one to study neuromuscular coordination, analyze athletic performance, and estimate internal loading of the musculoskeletal system. Simulations can also be used to identify the sources of pathological movement and establish a scientific basis for treatment planning. We have developed a freely available, open-source software system (OpenSim) that lets users develop models of musculoskeletal structures and create dynamic simulations of a wide variety of movements. We are using this system to simulate the dynamics of individuals with pathological gait and to explore the biomechanical effects of treatments. OpenSim provides a platform on which the biomechanics community can build a library of simulations that can be exchanged, tested, analyzed, and improved through a multi-institutional collaboration. Developing software that enables a concerted effort from many investigators poses technical and sociological challenges. Meeting those challenges will accelerate the discovery of principles that govern movement control and improve treatments for individuals with movement pathologies.						Thelen, Darryl/0000-0002-7873-2477; Delp, Scott/0000-0002-9643-7551													0018-9294	1558-2531				NOV	2007	54	11					1940	1950		10.1109/TBME.2007.901024	http://dx.doi.org/10.1109/TBME.2007.901024								18018689					WOS:000250449200004
J	Celik, IB; Ghia, U; Roache, PJ; Freitas, CJ				Celik, Ishmail B.; Ghia, Urmila; Roache, Patrick J.; Freitas, Christopher J.			Procedure for estimation and reporting of uncertainty due to discretization in CFD applications	JOURNAL OF FLUIDS ENGINEERING-TRANSACTIONS OF THE ASME												Since 1990, the Fluids Engineering Division of ASME has pursued activities concerning the detection, estimation and control of numerical uncertainty and/or error in computational fluid dynamics (CFD) studies. The first quality-control measures in this area were issued in 1986 (1986, "Editorial Policy Statement on Control of Numerical Accuracy," ASME J. Fluids Eng., 108, p. 2) and revised in 1993 (1993, "Journal of Fluids Engineering Editorial Policy Statement on the Control of Numerical Accuracy," ASME J. Fluids Eng., 115, pp. 339-340). Given the continued increase in CFD related publications, and the many significant advancements in computational techniques and computer technology, it has become necessary to revisit the issue and formulate a more detailed policy to further improve the quality of publications in this area. This brief note provides specific guidelines for prospective authors for calculation and reporting of discretization error estimates in CFD simulations where experimental data may or may not be available for comparison. The underlying perspective is that CFD-related studies will eventually aim to predict the outcome of a physical event for which experimental data is not available. It should be emphasized that the requirements outlined in this note do not preclude those already published in the previous two policy statements. It is also important to keep in mind that the procedure recommended in this note cannot possibly encompass all possible scenarios or applications.						Raad, Peter/0000-0001-7030-4825													0098-2202	1528-901X				JUL	2008	130	7							078001	10.1115/1.2960953	http://dx.doi.org/10.1115/1.2960953													WOS:000257878800015
J	Chandrashekar, G; Sahin, F				Chandrashekar, Girish; Sahin, Ferat			A survey on feature selection methods	COMPUTERS & ELECTRICAL ENGINEERING												Plenty of feature selection methods are available in literature due to the availability of data with hundreds of variables leading to data with very high dimension. Feature selection methods provides us a way of reducing computation time, improving prediction performance, and a better understanding of the data in machine learning or pattern recognition applications. In this paper we provide an overview of some of the methods present in literature. The objective is to provide a generic introduction to variable elimination which can be applied to a wide array of machine learning problems. We focus on Filter, Wrapper and Embedded methods. We also apply some of the feature selection techniques on standard datasets to demonstrate the applicability of feature selection techniques. (C) 2013 Elsevier Ltd. All rights reserved.					Sahin, Ferat/R-4170-2019														0045-7906	1879-0755				JAN	2014	40	1					16	28		10.1016/j.compeleceng.2013.11.024	http://dx.doi.org/10.1016/j.compeleceng.2013.11.024													WOS:000331922800003
J	Klein, S; Staring, M; Murphy, K; Viergever, MA; Pluim, JPW				Klein, Stefan; Staring, Marius; Murphy, Keelin; Viergever, Max A.; Pluim, Josien P. W.			elastix: A Toolbox for Intensity-Based Medical Image Registration	IEEE TRANSACTIONS ON MEDICAL IMAGING												Medical image registration is an important task in medical image processing. It refers to the process of aligning data sets, possibly from different modalities (e. g., magnetic resonance and computed tomography), different time points (e. g., follow-up scans), and/or different subjects (in case of population studies). A large number of methods for image registration are described in the literature. Unfortunately, there is not one method that works for all applications. We have therefore developed elastix, a publicly available computer program for intensity-based medical image registration. The software consists of a collection of algorithms that are commonly used to solve medical image registration problems. The modular design of elastix allows the user to quickly configure, test, and compare different registration methods for a specific application. The command-line interface enables automated processing of large numbers of data sets, by means of scripting. The usage of elastix for comparing different registration methods is illustrated with three example experiments, in which individual components of the registration method are varied.					Staring, Marius/A-9517-2009; Viergever, Max/J-1215-2014; Murphy, Keelin/AAC-6485-2019; Klein, Stefan/JAX-2520-2023	Staring, Marius/0000-0003-2885-5812; Murphy, Keelin/0000-0001-6831-4020													0278-0062	1558-254X				JAN	2010	29	1					196	205		10.1109/TMI.2009.2035616	http://dx.doi.org/10.1109/TMI.2009.2035616								19923044					WOS:000273334400018
J	Zhang, QQ; Ying, GG; Pan, CG; Liu, YS; Zhao, JL				Zhang, Qian-Qian; Ying, Guang-Guo; Pan, Chang-Gui; Liu, You-Sheng; Zhao, Jian-Liang			Comprehensive Evaluation of Antibiotics Emission and Fate in the River Basins of China: Source Analysis, Multimedia Modeling, and Linkage to Bacterial Resistance	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Antibiotics are widely used in humans and animals, but there is a big concern about their negative impacts on ecosystem and human health after use. So far there is a lack of information on emission inventory and environmental fate of antibiotics in China. We studied national consumption, emissions, and multimedia fate of 36 frequently detected antibiotics in China by market survey, data analysis, and level III fugacity modeling tools. Based on our survey, the total usage for the 36 chemicals was 92700 tons in 2013, an estimated 54000 tons of the antibiotics was excreted by human and animals, and eventually 53800 tons of them entered into the receiving environment following various wastewater treatments. The fugacity model successfully predicted environmental concentrations (PECs) in all 58 river basins of China, which are comparable to the reported measured environmental concentrations (MECs) available in some basins. The bacterial resistance rates in the hospitals and aquatic environments were found to be related to the PECs and antibiotic usages, especially for those antibiotics used in the most recent period. This is the first comprehensive study which demonstrates an alarming usage and emission of various antibiotics in China.					Ying, Guang-Guo/ABE-7532-2020; Zhao, Jian-Liang/E-6764-2011	Zhao, Jian-Liang/0000-0002-1380-0264													0013-936X	1520-5851				JUN 2	2015	49	11					6772	6782		10.1021/acs.est.5b00729	http://dx.doi.org/10.1021/acs.est.5b00729								25961663					WOS:000355779100049
J	Polyakov, A				Polyakov, Andrey			Nonlinear Feedback Design for Fixed-Time Stabilization of Linear Control Systems	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												Two types of nonlinear control algorithms are presented for uncertain linear plants. Controllers of the first type are stabilizing polynomial feedbacks that allow to adjust a guaranteed convergence time of system trajectories into a prespecified neighborhood of the origin independently on initial conditions. The control design procedure uses block control principles and finite-time attractivity properties of polynomial feedbacks. Controllers of the second type are modifications of the second order sliding mode control algorithms. They provide global finite-time stability of the closed-loop system and allow to adjust a guaranteed settling time independently on initial conditions. Control algorithms are presented for both single-input and multi-input systems. Theoretical results are supported by numerical simulations.					Polyakov, Andrey/G-9326-2011	Polyakov, Andrey/0000-0002-5876-3495													0018-9286	1558-2523				AUG	2012	57	8			SI		2106	U1		10.1109/TAC.2011.2179869	http://dx.doi.org/10.1109/TAC.2011.2179869													WOS:000306916900024
J	Bruneau, M; Chang, SE; Eguchi, RT; Lee, GC; O'Rourke, TD; Reinhorn, AM; Shinozuka, M; Tierney, K; Wallace, WA; von Winterfeldt, D				Bruneau, M; Chang, SE; Eguchi, RT; Lee, GC; O'Rourke, TD; Reinhorn, AM; Shinozuka, M; Tierney, K; Wallace, WA; von Winterfeldt, D			A framework to quantitatively assess and enhance the seismic resilience of communities	EARTHQUAKE SPECTRA												This paper presents a conceptual framework to define seismic resilience of communities and quantitative measures of resilience that can be useful for a coordinated research effort focusing on enhancing this resilience. This framework relies on the complementary measures of resilience: "Reduced failure probabilities," "Reduced consequences from failures," and "Reduced time to recovery." The framework also includes quantitative measures of the "ends" of robustness and rapidity, and the "means" of resourcefulness and redundancy, and integrates those measures into the four dimensions of community resilience-technical, organizational, social, and economic-all of which can be used to quantify measures of resilience for various types of physical and organizational systems. Systems diagrams then establish the tasks required to achieve these objectives. This framework can be useful in future research to determine the resiliency of different units of analysis and systems, and to develop resiliency targets and detailed analytical procedures to generate these values.					Reinhorn, Andrei/AAC-9609-2020; Bruneau, Michel/F-2740-2011	Bruneau, Michel/0000-0003-1170-468X; Reinhorn, Andrei/0000-0001-6418-3721													8755-2930	1944-8201				NOV	2003	19	4					733	752		10.1193/1.1623497	http://dx.doi.org/10.1193/1.1623497													WOS:000188461800001
J	Reynolds, DA; Quatieri, TF; Dunn, RB				Reynolds, DA; Quatieri, TF; Dunn, RB			Speaker verification using adapted Gaussian mixture models	DIGITAL SIGNAL PROCESSING					5th Annual NIST Speaker Recognition Workshop	JUN 03-04, 1999	UNIV MARYLAND, BALTIMORE, MD	NIST	UNIV MARYLAND			In this paper we describe the major elements of MIT Lincoln Laboratory's Gaussian mixture model (GMM)-based speaker verification system used successfully in several NIST Speaker Recognition Evaluations (SREs). The system is built around the likelihood ratio test for verification, using simple but effective GMMs for likelihood functions, a universal background model (UBM) for alternative speaker representation, and a form of Bayesian adaptation to derive speaker models from the UBM. The development and use of a handset detector and score normalization to greatly improve verification performance is also described and discussed. Finally representative performance benchmarks and system behavior experiments on NIST SRE corpora are presented. (C) 2000 Academic Press.																			1051-2004					JAN-JUL	2000	10	1-3					19	41		10.1006/dspr.1999.0361	http://dx.doi.org/10.1006/dspr.1999.0361													WOS:000087583600003
J	Laneman, JN; Wornell, GW				Laneman, JN; Wornell, GW			Distributed space-time-coded protocols for exploiting cooperative diversity in wireless networks	IEEE TRANSACTIONS ON INFORMATION THEORY					IEEE Global Telecommunications Conference (GLOBECOM 02)	NOV 17-21, 2002	TAIPEI, TAIWAN	IEEE, ICC GLOBECOM				We develop and analyze space-time coded cooperative diversity protocols for combating multipath fading across multiple protocol layers in a wireless network. The protocols exploit spatial diversity available among a collection of distributed terminals that relay messages for one another in such a manner that the destination terminal can average the fading, even though it is unknown a priori which terminals will be involved. In particular, a source initiates transmission to its destination, and many relays potentially receive the transmission. Those terminals that can fully decode the transmission utilize a space-time code to cooperatively relay to the destination. We demonstrate that these protocols achieve full spatial diversity in the number of cooperating terminals, not just the number of decoding relays, and can be used effectively for higher spectral efficiencies than repetition-based schemes. We discuss issues related to space-time code design for these protocols, emphasizing codes that readily allow for appealing distributed versions.					Laneman, J/H-1194-2011	Wornell, Gregory/0000-0001-9166-4758													0018-9448	1557-9654				OCT	2003	49	10					2415	2425		10.1109/TIT.2003.817829	http://dx.doi.org/10.1109/TIT.2003.817829													WOS:000185861400008
J	Xu, LD; He, W; Li, SC				Xu, Li Da; He, Wu; Li, Shancang			Internet of Things in Industries: A Survey	IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS												Internet of Things (IoT) has provided a promising opportunity to build powerful industrial systems and applications by leveraging the growing ubiquity of radio-frequency identification (RFID), and wireless, mobile, and sensor devices. A wide range of industrial IoT applications have been developed and deployed in recent years. In an effort to understand the development of IoT in industries, this paper reviews the current research of IoT, key enabling technologies, major IoT applications in industries, and identifies research trends and challenges. A main contribution of this review paper is that it summarizes the current state-of-the-art IoT in industries systematically.																			1551-3203	1941-0050				NOV	2014	10	4					2233	2243		10.1109/TII.2014.2300753	http://dx.doi.org/10.1109/TII.2014.2300753													WOS:000344995800025
J	Kouro, S; Malinowski, M; Gopakumar, K; Pou, J; Franquelo, LG; Wu, B; Rodriguez, J; Pérez, MA; Leon, JI				Kouro, Samir; Malinowski, Mariusz; Gopakumar, K.; Pou, Josep; Franquelo, Leopoldo G.; Wu, Bin; Rodriguez, Jose; Perez, Marcelo A.; Leon, Jose I.			Recent Advances and Industrial Applications of Multilevel Converters	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS												Multilevel converters have been under research and development for more than three decades and have found successful industrial application. However, this is still a technology under development, and many new contributions and new commercial topologies have been reported in the last few years. The aim of this paper is to group and review these recent contributions, in order to establish the current state of the art and trends of the technology, to provide readers with a comprehensive and insightful review of where multilevel converter technology stands and is heading. This paper first presents a brief overview of well-established multilevel converters strongly oriented to their current state in industrial applications to then center the discussion on the new converters that have made their way into the industry. In addition, new promising topologies are discussed. Recent advances made in modulation and control of multilevel converters are also addressed. A great part of this paper is devoted to show nontraditional applications powered by multilevel converters and how multilevel converters are becoming an enabling technology in many industrial sectors. Finally, some future trends and challenges in the further development of this technology are discussed to motivate future contributions that address open problems and explore new possibilities.					Leon, Jose/AAF-9843-2019; Pou, Josep/D-4323-2017; Perez, Marcelo/E-9076-2012; Malinowski, Mariusz/J-4260-2018; Rodriguez, Jose/A-2534-2013; Kouro, Samir/E-9167-2012; Leon, Jose I./L-2409-2014; Pou, Josep/E-5956-2016; Franquelo, Leopoldo Garcia/D-5450-2009	Malinowski, Mariusz/0000-0002-4697-8261; Rodriguez, Jose/0000-0002-1410-4121; Kouro, Samir/0000-0002-1690-4624; Leon, Jose I./0000-0001-5760-8066; Perez, Marcelo/0000-0003-4166-448X; Pou, Josep/0000-0002-3114-781X; Franquelo, Leopoldo Garcia/0000-0002-1976-9747													0278-0046	1557-9948				AUG	2010	57	8					2553	2580		10.1109/TIE.2010.2049719	http://dx.doi.org/10.1109/TIE.2010.2049719													WOS:000282030800001
J	Shelhamer, E; Long, J; Darrell, T				Shelhamer, Evan; Long, Jonathan; Darrell, Trevor			Fully Convolutional Networks for Semantic Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, improve on the previous best result in semantic segmentation. Our key insight is to build "fully convolutional" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional networks achieve improved segmentation of PASCAL VOC (30% relative improvement to 67.2% mean IU on 2012), NYUDv2, SIFT Flow, and PASCAL-Context, while inference takes one tenth of a second for a typical image.																			0162-8828	1939-3539				APR	2017	39	4					640	651		10.1109/TPAMI.2016.2572683	http://dx.doi.org/10.1109/TPAMI.2016.2572683								27244717					WOS:000397717600003
J	Arikan, E				Arikan, Erdal			Channel Polarization: A Method for Constructing Capacity-Achieving Codes for Symmetric Binary-Input Memoryless Channels	IEEE TRANSACTIONS ON INFORMATION THEORY					IEEE International Symposium on Information Theory	JUL 06-11, 2008	Toronto, CANADA	IEEE, RIM, Ontario Cent Excellence, IBM Res, Microsoft Res				A method is proposed, called channel polarization, to construct code sequences that achieve the symmetric capacity I(W) of any given binary-input discrete memoryless channel (B-DMC) W. The symmetric capacity is the highest rate achievable subject to using the input letters of the channel with equal probability. Channel polarization refers to the fact that it is possible to synthesize, out of N independent copies of a given B-DMC W, a second set of N binary-input channels {W(N)((i)) : 1 <= i <= N} such that, as N becomes large, the fraction of indices i for which I(W(N)((i))) is near 1 approaches I(W) and the fraction for which I(W(N)((i))) is near 0 approaches 1 - I(W). The polarized channels {W(N)((i))} are well-conditioned for channel coding: one need only send data at rate 1 through those with capacity near 1 and at rate 0 through the remaining. Codes constructed on the basis of this idea are called polar codes. The paper proves that, given any B-DMC W with I(W) > 0 and any target rate R < I(W), there exists a sequence of polar codes {C(n); n >= 1} such that (C(n) has block-length N = 2(n), rate >= R, and probability of block error under successive cancellation decoding bounded as P(e) (N, R) <= O (N(-1/4)) independently of the code rate. This performance is achievable by encoders and decoders with complexity O(N log N) for each.																			0018-9448					JUL	2009	55	7					3051	3073		10.1109/TIT.2009.2021379	http://dx.doi.org/10.1109/TIT.2009.2021379													WOS:000267222000009
J	Hirschmüller, H				Hirschmueller, Heiko			Stereo processing by Semiglobal Matching and Mutual Information	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												This paper describes the Semiglobal Matching ( SGM) stereo method. It uses a pixelwise, Mutual Information (MI)-based matching cost for compensating radiometric differences of input images. Pixelwise matching is supported by a smoothness constraint that is usually expressed as a global cost function. SGM performs a fast approximation by pathwise optimizations from all directions. The discussion also addresses occlusion detection, subpixel refinement, and multibaseline matching. Additionally, postprocessing steps for removing outliers, recovering from specific problems of structured environments, and the interpolation of gaps are presented. Finally, strategies for processing almost arbitrarily large images and fusion of disparity images using orthographic projection are proposed. A comparison on standard stereo images shows that SGM is among the currently top-ranked algorithms and is best, if subpixel accuracy is considered. The complexity is linear to the number of pixels and disparity range, which results in a runtime of just 1-2 seconds on typical test images. An in depth evaluation of the MI-based matching cost demonstrates a tolerance against a wide range of radiometric transformations. Finally, examples of reconstructions from huge aerial frame and pushbroom images demonstrate that the presented ideas are working well on practical problems.																			0162-8828	1939-3539				FEB	2008	30	2					328	341		10.1109/TPAMI.2007.1166	http://dx.doi.org/10.1109/TPAMI.2007.1166								18084062					WOS:000251580300010
J	Hespanha, JP; Naghshtabrizi, P; Xu, YG				Hespanha, Joao P.; Naghshtabrizi, Payam; Xu, Yonggang			A survey of recent results in networked control systems	PROCEEDINGS OF THE IEEE												Networked control systems (NCSs) are spatially distributed systems for which the communication between sensors, actuators, and controllers is supported by a shared communication network. We review several recent results on estimation, analysis, and controller synthesis for NCSs. The results surveyed address channel limitations in terms of packet-rates, sampling, network delay, and packet dropouts. The results are presented in a tutorial fashion, comparing alternative methodologies.					Xu, Yonggang/JXN-1651-2024; Hespanha, Joao/C-2569-2008	Xu, Yonggang/0000-0002-2206-8968													0018-9219	1558-2256				JAN	2007	95	1					138	162		10.1109/JPROC.2006.887288	http://dx.doi.org/10.1109/JPROC.2006.887288													WOS:000244875400009
J	Deb, K				Deb, K			An efficient constraint handling method for genetic algorithms	COMPUTER METHODS IN APPLIED MECHANICS AND ENGINEERING												Many real-world starch and optimization problems involve inequality and/or equality constraints and are thus posed as constrained optimization problems. In trying to solve constrained optimization problems using genetic algorithms (GAs) or classical optimization methods, penalty function methods have been the most popular approach, because of their simplicity and ease of implementation. However, since the penalty function approach is generic and applicable to any type of constraint (linear or nonlinear), their performance is not always satisfactory. Thus, researchers have developed sophisticated penalty functions specific to the problem at hand and the search algorithm used for optimization. However, the most difficult aspect of the penalty function approach is to find appropriate penalty parameters needed to guide the search towards the constrained optimum. In this paper, GA's population-based approach and ability to make pair-wise comparison in tournament selection operator are exploited to devise a penalty function approach that does not require any penalty parameter. Careful comparisons among feasible and infeasible solutions are made so as to provide a search direction towards the feasible region. Once sufficient feasible solutions are found, a niching method (along with a controlled mutation operator) is used to maintain diversity among feasible solutions. This allows a real-parameter GA's crossover operator to continuously find better feasible solutions, gradually leading the search near the true optimum solution. GAs with this constraint handling approach have been tested on nine problems commonly used in the literature, including an engineering design problem. In all cases, the proposed approach has been able to repeatedly find solutions closer to the true optimum solution than that reported earlier. (C) 2000 Elsevier Science S.A. All rights reserved.					Deb, Kalyanmoy/B-1563-2009														0045-7825	1879-2138					2000	186	2-4					311	338		10.1016/S0045-7825(99)00389-8	http://dx.doi.org/10.1016/S0045-7825(99)00389-8													WOS:000087538300010
J	Zheng, LZ; Tse, DNC				Zheng, LZ; Tse, DNC			Diversity and multiplexing: A fundamental tradeoff in multiple-antenna channels	IEEE TRANSACTIONS ON INFORMATION THEORY												Multiple antennas can be used for increasing the amount of diversity or the number of degrees of freedom in wireless communication systems. In this paper, we propose the point of view that both types of gains can be simultaneously obtained for a given multiple-antenna channel, but there is a fundamental tradeoff between how much of each any coding scheme can get. For the richly scattered Rayleigh-fading channel, we give a simple characterization of the optimal tradeoff curve and use it to evaluate the performance of existing multiple antenna schemes.																			0018-9448	1557-9654				MAY	2003	49	5					1073	1096		10.1109/TIT.2003.810646	http://dx.doi.org/10.1109/TIT.2003.810646													WOS:000182711200001
J	Sheikh, HR; Bovik, AC				Sheikh, HR; Bovik, AC			Image information and visual quality	IEEE TRANSACTIONS ON IMAGE PROCESSING												Measurement of visual quality is of fundamental importance to numerous image and video processing applications. The goal of quality assessment (QA) research is to design algorithms that can automatically assess the quality of images or videos in a perceptually consistent manner. Image QA algorithms generally interpret image quality as fidelity or similarity with a "reference" or "perfect" image in some perceptual space. Such "full-reference" QA methods attempt to achieve consistency in quality prediction by modeling salient physiological and psychovisual features of the human visual system (HVS), or by signal fidelity measures. In this paper, we approach the image QA problem as an information fidelity problem. Specifically, we propose to quantify the loss of image information to the distortion process and explore the relationship between image information and visual quality. QA systems are invariably involved with judging the visual quality of "natural" images and videos that are meant for "human consumption." Researchers have developed sophisticated models to capture the statistics of such natural signals. Using these models, we previously presented an information fidelity criterion for image QA that related image quality with the amount of information shared between a reference and a distorted image. In this paper, we propose an image information measure that quantifies the information that is present in the reference image and how much of this reference information can be extracted from the distorted image. Combining these two quantities, we propose a visual information fidelity measure for image QA. We validate the performance of our algorithm with an extensive subjective study involving 779 images and show that our method outperforms recent state-of-the-art image QA algorithms by a sizeable margin in our simulations. The code and the data from the subjective study are available at the LIVE website.					Bovik, Alan/B-6717-2012	Bovik, Alan/0000-0001-6067-710X													1057-7149	1941-0042				FEB	2006	15	2					430	444		10.1109/TIP.2005.859378	http://dx.doi.org/10.1109/TIP.2005.859378								16479813					WOS:000234761400017
J	Ricker, GR; Winn, JN; Vanderspek, R; Latham, DW; Bakos, GA; Bean, JL; Berta-Thompson, ZK; Brown, TM; Buchhave, L; Butler, NR; Butler, RP; Chaplin, WJ; Charbonneau, D; Christensen-Dalsgaard, J; Clampin, M; Deming, D; Doty, J; De Lee, N; Dressing, C; Dunham, EW; Endl, M; Fressin, F; Ge, J; Henning, T; Holman, MJ; Howard, AW; Ida, S; Jenkins, JM; Jernigan, G; Johnson, JA; Kaltenegger, L; Kawai, N; Kjeldsen, H; Laughlin, G; Levine, AM; Lin, D; Lissauer, JJ; MacQueen, P; Marcy, G; McCullough, PR; Morton, TD; Narita, N; Paegert, M; Palle, E; Pepe, F; Pepper, J; Quirrenbach, A; Rinehart, SA; Sasselov, D; Sato, B; Seager, S; Sozzetti, A; Stassun, KG; Sullivan, P; Szentgyorgyi, A; Torres, G; Udry, S; Villasenor, J				Ricker, George R.; Winn, Joshua N.; Vanderspek, Roland; Latham, David W.; Bakos, Gaspar A.; Bean, Jacob L.; Berta-Thompson, Zachory K.; Brown, Timothy M.; Buchhave, Lars; Butler, Nathaniel R.; Butler, R. Paul; Chaplin, William J.; Charbonneau, David; Christensen-Dalsgaard, Jorgen; Clampin, Mark; Deming, Drake; Doty, John; De Lee, Nathan; Dressing, Courtney; Dunham, Edward W.; Endl, Michael; Fressin, Francois; Ge, Jian; Henning, Thomas; Holman, Matthew J.; Howard, Andrew W.; Ida, Shigeru; Jenkins, Jon M.; Jernigan, Garrett; Johnson, John Asher; Kaltenegger, Lisa; Kawai, Nobuyuki; Kjeldsen, Hans; Laughlin, Gregory; Levine, Alan M.; Lin, Douglas; Lissauer, Jack J.; MacQueen, Phillip; Marcy, Geoffrey; McCullough, Peter R.; Morton, Timothy D.; Narita, Norio; Paegert, Martin; Palle, Enric; Pepe, Francesco; Pepper, Joshua; Quirrenbach, Andreas; Rinehart, Stephen A.; Sasselov, Dimitar; Sato, Bun'ei; Seager, Sara; Sozzetti, Alessandro; Stassun, Keivan G.; Sullivan, Peter; Szentgyorgyi, Andrew; Torres, Guillermo; Udry, Stephane; Villasenor, Joel			Transiting Exoplanet Survey Satellite	JOURNAL OF ASTRONOMICAL TELESCOPES INSTRUMENTS AND SYSTEMS												The Transiting Exoplanet Survey Satellite (TESS) will search for planets transiting bright and nearby stars. TESS has been selected by NASA for launch in 2017 as an Astrophysics Explorer mission. The spacecraft will be placed into a highly elliptical 13.7-day orbit around the Earth. During its 2-year mission, TESS will employ four wide-field optical charge-coupled device cameras to monitor at least 200,000 main-sequence dwarf stars with I-C approximate to 4-13 for temporary drops in brightness caused by planetary transits. Each star will be observed for an interval ranging from 1 month to 1 year, depending mainly on the star's ecliptic latitude. The longest observing intervals will be for stars near the ecliptic poles, which are the optimal locations for follow-up observations with the James Webb Space Telescope. Brightness measurements of preselected target stars will be recorded every 2 min, and full frame images will be recorded every 30 min. TESS stars will be 10 to 100 times brighter than those surveyed by the pioneering Kepler mission. This will make TESS planets easier to characterize with follow-up observations. TESS is expected to find more than a thousand planets smaller than Neptune, including dozens that are comparable in size to the Earth. Public data releases will occur every 4 months, inviting immediate community-wide efforts to study the new planets. The TESS legacy will be a catalog of the nearest and brightest stars hosting transiting planets, which will endure as highly favorable targets for detailed investigations. (C) The Authors. Published by SPIE under a Creative Commons Attribution 3.0 Unported License. Distribution or reproduction of this work in whole or in part requires full attribution of the original publication, including its DOI.					Palle, Enric/AAE-4492-2019; Buchhave, Lars/ABF-2000-2020; Klahr, Hubert/AAY-6238-2021; Clampin, mark/D-2738-2012; Jenkins, Jon/Y-2722-2019; Pepe, Fabrizio/AAC-5714-2022; Chaplin, William/M-9160-2018; Sozzetti, Alessandro/F-2943-2018; Kaltenegger, Lisa/F-1176-2018	Buchhave, Lars A./0000-0003-1605-5666; Quirrenbach, Andreas/0000-0002-3302-1962; Ricker, George/0000-0003-2058-6662; Chaplin, William/0000-0002-5714-8618; Stassun, Keivan/0000-0002-3481-9052; De Lee, Nathan/0000-0002-3657-0705; udry, Stephane/0000-0001-7576-6236; Pepper, Joshua/0000-0002-3827-8417; Sozzetti, Alessandro/0000-0002-7504-365X; Berta-Thompson, Zachory/0000-0002-3321-4924; Paegert, Martin/0000-0001-8120-7457; Pepe, Francesco/0000-0002-9815-773X; Kaltenegger, Lisa/0000-0002-0436-1802; Bean, Jacob/0000-0003-4733-6532; Bakos, Gaspar/0000-0001-7204-6727													2329-4124	2329-4221				JAN-MAR	2015	1	1							014003	10.1117/1.JATIS.1.1.014003	http://dx.doi.org/10.1117/1.JATIS.1.1.014003													WOS:000371879500004
J	He, KM; Zhang, XY; Ren, SQ; Sun, J				He, Kaiming; Zhang, Xiangyu; Ren, Shaoqing; Sun, Jian			Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Existing deep convolutional neural networks (CNNs) require a fixed-size (e.g., 224x224) input image. This requirement is "artificial" and may reduce the recognition accuracy for the images or sub-images of an arbitrary size/scale. In this work, we equip the networks with another pooling strategy, "spatial pyramid pooling", to eliminate the above requirement. The new network structure, called SPP-net, can generate a fixed-length representation regardless of image size/scale. Pyramid pooling is also robust to object deformations. With these advantages, SPP-net should in general improve all CNN-based image classification methods. On the ImageNet 2012 dataset, we demonstrate that SPP-net boosts the accuracy of a variety of CNN architectures despite their different designs. On the Pascal VOC 2007 and Caltech101 datasets, SPP-net achieves state-of-the-art classification results using a single full-image representation and no fine-tuning. The power of SPP-net is also significant in object detection. Using SPP-net, we compute the feature maps from the entire image only once, and then pool features in arbitrary regions (sub-images) to generate fixed-length representations for training the detectors. This method avoids repeatedly computing the convolutional features. In processing test images, our method is 24-102x faster than the R-CNN method, while achieving better or comparable accuracy on Pascal VOC 2007. In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, our methods rank #2 in object detection and #3 in image classification among all 38 teams. This manuscript also introduces the improvement made for this competition.					Zhang, Xiangyu/H-9255-2013														0162-8828	1939-3539				SEP	2015	37	9					1904	1916		10.1109/TPAMI.2015.2389824	http://dx.doi.org/10.1109/TPAMI.2015.2389824								26353135					WOS:000359216600013
J	Villalva, MG; Gazoli, JR; Ruppert, E				Villalva, Marcelo Gradella; Gazoli, Jonas Rafael; Ruppert Filho, Ernesto			Comprehensive Approach to Modeling and Simulation of Photovoltaic Arrays	IEEE TRANSACTIONS ON POWER ELECTRONICS												This paper proposes a method of modeling and simulation of photovoltaic arrays. The main objective is to find the parameters of the nonlinear I-V equation by adjusting the curve at three points: open circuit, maximum power, and short circuit. Given these three points, which are provided by all commercial array datasheets, the method finds the best I-V equation for the single-diode photovoltaic (PV) model including the effect of the series and parallel resistances, and warranties that the maximum power of the model matches with the maximum power of the real array. With the parameters of the adjusted I-V equation, one can build a PV circuit model with any circuit simulator by using basic math blocks. The modeling method and the proposed circuit model are useful for power electronics designers who need a simple, fast, accurate, and easy-to-use modeling method for using in simulations of PV systems. In the first pages, the reader will find a tutorial on PV devices and will understand the parameters that compose the single-diode PV model. The modeling method is then introduced and presented in details. The model is validated with experimental data of commercial PV arrays.					Villalva, Marcelo/AAZ-4720-2021	Gradella Villalva, Marcelo/0000-0003-1654-2173													0885-8993	1941-0107				MAY-JUN	2009	24	5-6					1198	1208		10.1109/TPEL.2009.2013862	http://dx.doi.org/10.1109/TPEL.2009.2013862													WOS:000267036200006
J	Dehak, N; Kenny, PJ; Dehak, R; Dumouchel, P; Ouellet, P				Dehak, Najim; Kenny, Patrick J.; Dehak, Reda; Dumouchel, Pierre; Ouellet, Pierre			Front-End Factor Analysis for Speaker Verification	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING												This paper presents an extension of our previous work which proposes a new speaker representation for speaker verification. In this modeling, a new low-dimensional speaker-and channel-dependent space is defined using a simple factor analysis. This space is named the total variability space because it models both speaker and channel variabilities. Two speaker verification systems are proposed which use this new representation. The first system is a support vector machine-based system that uses the cosine kernel to estimate the similarity between the input data. The second system directly uses the cosine similarity as the final decision score. We tested three channel compensation techniques in the total variability space, which are within-class covariance normalization (WCCN), linear discriminate analysis (LDA), and nuisance attribute projection (NAP). We found that the best results are obtained when LDA is followed by WCCN. We achieved an equal error rate (EER) of 1.12% and MinDCF of 0.0094 using the cosine distance scoring on the male English trials of the core condition of the NIST 2008 Speaker Recognition Evaluation dataset. We also obtained 4% absolute EER improvement for both-gender trials on the 10 s-10 s condition compared to the classical joint factor analysis scoring.					DEHAK, Reda/GYR-0771-2022; Dumouchel, Pierre/H-4401-2013	Dehak, Najim/0000-0002-4489-5753; Dumouchel, Pierre/0000-0001-5584-4428													1558-7916	1558-7924				MAY	2011	19	4					788	798		10.1109/TASL.2010.2064307	http://dx.doi.org/10.1109/TASL.2010.2064307													WOS:000307581600012
J	Gross, J; Sadowski, G				Gross, J; Sadowski, G			Perturbed-chain SAFT: An equation of state based on a perturbation theory for chain molecules	INDUSTRIAL & ENGINEERING CHEMISTRY RESEARCH												A modified SAFT equation of state is developed by applying the perturbation theory of Barker and Henderson to a hard-chain reference fluid. With conventional one-fluid mixing rules, the equation of state is applicable to mixtures of small spherical molecules such as gases, nonspherical solvents, and chainlike polymers. The three pure-component parameters required for nonassociating molecules were identified for 78 substances by correlating vapor pressures and Liquid volumes. The equation of state gives good fits to these properties and agrees well with caloric properties. When applied to vapor-liquid equilibria of mixtures, the equation of state shows substantial predictive capabilities and good precision for correlating mixtures. Comparisons to the SAFT version of Huang and Radosz reveal a clear improvement of the proposed model. A brief comparison with the Peng-Robinson model is also given for vapor-liquid equilibria of binary systems, confirming the good performance of the suggested equation of state. The applicability of the proposed model to polymer systems was demonstrated for high-pressure liquid-liquid equilibria of a polyethylene mixture. The pure-component parameters of polyethylene were obtained by extrapolating pure-component parameters of the n-alkane series to high molecular weights.					Gross, Joachim/B-9633-2017	Gross, Joachim/0000-0001-8632-357X; Sadowski, Gabriele/0000-0002-5038-9152													0888-5885					FEB 21	2001	40	4					1244	1260		10.1021/ie0003887	http://dx.doi.org/10.1021/ie0003887													WOS:000167061500031
J	Peterson, AA; Abild-Pedersen, F; Studt, F; Rossmeisl, J; Norskov, JK				Peterson, Andrew A.; Abild-Pedersen, Frank; Studt, Felix; Rossmeisl, Jan; Norskov, Jens K.			How copper catalyzes the electroreduction of carbon dioxide into hydrocarbon fuels	ENERGY & ENVIRONMENTAL SCIENCE												Density functional theory calculations explain copper's unique ability to convert CO2 into hydrocarbons, which may open up (photo-)electrochemical routes to fuels.					Studt, Felix/C-7874-2017; Abild-Pedersen, Frank/C-3248-2014; Norskov, Jens/D-2539-2017; Rossmeisl, Jan/A-5714-2011	Studt, Felix/0000-0001-6841-4232; Abild-Pedersen, Frank/0000-0002-1911-074X; Norskov, Jens/0000-0002-4427-7728; Rossmeisl, Jan/0000-0001-7749-6567													1754-5692	1754-5706				SEP	2010	3	9					1311	1315		10.1039/c0ee00071j	http://dx.doi.org/10.1039/c0ee00071j													WOS:000282334000016
J	Carrasco, JM; Franquelo, LG; Bialasiewicz, JT; Galván, E; Portillo, R; Prats, MM; León, JI; Moreno-Alfonso, N				Manuel Carrasco, Juan; Franquelo, Leopoldo G.; Bialasiewicz, Jan T.; Galvan, Eduardo; Portillo, Ramon; Martin Prats, Maria; Ignacio Leon, Jose; Moreno-Alfonso, Narciso			Power-electronic systems for the grid integration of renewable energy sources:: A survey	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS												The use of distributed energy resources is increasingly being pursued as a supplement and an alternative to large conventional central power stations. The specification of a power-electronic interface is subject to requirements related not only to the renewable energy source itself but also to its effects on the power-system operation, especially where the intermittent energy source constitutes a significant part of the total system capacity. In this paper, new trends in power electronics for the integration of wind and photovoltaic (PV) power generators are presented. A review of the appropriate storage-system technology used for the integration of intermittent renewable energy sources is also introduced. Discussions about common and future trends in renewable energy systems based on reliability and maturity of each technology are presented.					Solis, Juan/R-3820-2019; Leon, Jose/AAF-9843-2019; Galvan Diez, Eduardo/I-4192-2015; Leon, Jose I./L-2409-2014; Portillo, Ramon/M-1439-2014; Martin Prats, Maria Angeles/L-9043-2014; Moreno-Alfonso, Narciso/D-9864-2014; Franquelo, Leopoldo Garcia/D-5450-2009	Galvan Diez, Eduardo/0000-0001-9000-087X; Carrasco Solis, Juan Manuel/0000-0003-1994-7416; Leon, Jose I./0000-0001-5760-8066; Portillo, Ramon/0000-0001-6453-8617; Martin Prats, Maria Angeles/0000-0002-6499-7925; Moreno-Alfonso, Narciso/0000-0002-1743-5970; Franquelo, Leopoldo Garcia/0000-0002-1976-9747													0278-0046	1557-9948				AUG	2006	53	4					1002	1016		10.1109/TIE.2006.878356	http://dx.doi.org/10.1109/TIE.2006.878356													WOS:000239554200002
J	Liu, GC; Lin, ZC; Yan, SC; Sun, J; Yu, Y; Ma, Y				Liu, Guangcan; Lin, Zhouchen; Yan, Shuicheng; Sun, Ju; Yu, Yong; Ma, Yi			Robust Recovery of Subspace Structures by Low-Rank Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												In this paper, we address the subspace clustering problem. Given a set of data samples (vectors) approximately drawn from a union of multiple subspaces, our goal is to cluster the samples into their respective subspaces and remove possible outliers as well. To this end, we propose a novel objective function named Low-Rank Representation (LRR), which seeks the lowest rank representation among all the candidates that can represent the data samples as linear combinations of the bases in a given dictionary. It is shown that the convex program associated with LRR solves the subspace clustering problem in the following sense: When the data is clean, we prove that LRR exactly recovers the true subspace structures; when the data are contaminated by outliers, we prove that under certain conditions LRR can exactly recover the row space of the original data and detect the outlier as well; for data corrupted by arbitrary sparse errors, LRR can also approximately recover the row space with theoretical guarantees. Since the subspace membership is provably determined by the row space, these further imply that LRR can perform robust subspace clustering and error correction in an efficient and effective way.					Yan, Shuicheng/HCI-1431-2022; zhang, lu/KGL-6144-2024; Liu, Guangcan/J-1391-2014; Ma, Yi/K-1458-2014; Sun, Ju/Q-1200-2015	Sun, Ju/0000-0002-2017-5903													0162-8828	1939-3539				JAN	2013	35	1					171	184		10.1109/TPAMI.2012.88	http://dx.doi.org/10.1109/TPAMI.2012.88								22487984					WOS:000311127700016
J	Altman, GH; Diaz, F; Jakuba, C; Calabro, T; Horan, RL; Chen, JS; Lu, H; Richmond, J; Kaplan, DL				Altman, GH; Diaz, F; Jakuba, C; Calabro, T; Horan, RL; Chen, JS; Lu, H; Richmond, J; Kaplan, DL			Silk-based biomaterials	BIOMATERIALS												Silk from the silkworm, Bombyx mori, has been used as biomedical suture material for centuries. The unique mechanical properties of these fibers provided important clinical repair options for many applications. During the past 20 years, some biocompatibility problems have been reported for silkworm silk; however, contamination from residual sericin (glue-like proteins) was the likely cause. More recent studies with well-defined silkworm silk fibers and films suggest that the core silk fibroin fibers exhibit comparable biocompatibility in vitro and in vivo with other commonly used biomaterials such as polylactic acid and collagen. Furthermore, the unique mechanical properties of the silk fibers, the diversity of side chain chemistries for 'decoration' with growth and adhesion factors, and the ability to genetically tailor the protein provide additional rationale for the exploration of this family of fibrous proteins for biomaterial applications. For example, in designing scaffolds for tissue engineering these properties are particularly relevant and recent results with bone and ligament formation in vitro support the potential role for this biomaterial in future applications. To date, studies with silks to address biomaterial and matrix scaffold needs have focused on silkworm silk. With the diversity of silk-like fibrous proteins from spiders and insects, a range of native or bioengineered variants can be expected for application to a diverse set of clinical needs. (C) 2002 Elsevier Science Ltd. All rights reserved.					Diaz, Frank/AAI-8488-2021	Kaplan, David/0000-0002-9245-7774; Li, pengcheng/0009-0004-6334-051X; Diaz, Frank/0000-0003-3526-1852													0142-9612	1878-5905				FEB	2003	24	3					401	416	PII S0142-9612(02)00353-8	10.1016/S0142-9612(02)00353-8	http://dx.doi.org/10.1016/S0142-9612(02)00353-8								12423595					WOS:000179382300004
J	Wu, G; van der Helm, FCT; Veeger, HEJ; Makhsous, M; Van Roy, P; Anglin, C; Nagels, J; Karduna, AR; McQuade, K; Wang, XG; Werner, FW; Buchholz, B				Wu, G; van der Helm, FCT; Veeger, HEJ; Makhsous, M; Van Roy, P; Anglin, C; Nagels, J; Karduna, AR; McQuade, K; Wang, XG; Werner, FW; Buchholz, B			ISB recommendation on definitions of joint coordinate systems of various joints for the reporting of human joint motion - Part II: shoulder, elbow, wrist and hand	JOURNAL OF BIOMECHANICS												In this communication, the Standardization and Terminology Committee (STC) of the International Society of Biomechanics proposes a definition of a joint coordinate system (JCS) for the shoulder, elbow, wrist, and hand. For each joint, a standard for the local axis system in each articulating segment or bone is generated. These axes then standardize the JCS. The STC is publishing these recommendations so as to encourage their use, to stimulate feedback and discussion, and to facilitate further revisions. Adopting these standards will lead to better communication among researchers and clinicians. (c) 2004 Elsevier Ltd. All rights reserved.					van der Helm, Frans/C-3321-2011; veeger, dirkjan/G-4012-2010; Wang, Xuguang/K-8848-2019; Karduna, Andrew/ABA-7373-2021; mcquade, kevin/AAJ-6243-2020	Karduna, Andrew/0000-0003-4859-4330; Wang, Xuguang/0000-0001-9181-6045; veeger, dirkjan/0000-0003-0292-6520													0021-9290	1873-2380				MAY	2005	38	5					981	992		10.1016/j.jbiomech.2004.05.042	http://dx.doi.org/10.1016/j.jbiomech.2004.05.042								15844264					WOS:000228404700002
J	Shuman, DI; Narang, SK; Frossard, P; Ortega, A; Vandergheynst, P				Shuman, David I.; Narang, Sunil K.; Frossard, Pascal; Ortega, Antonio; Vandergheynst, Pierre			The Emerging Field of Signal Processing on Graphs	IEEE SIGNAL PROCESSING MAGAZINE																	Vandergheynst, Pierre/ISU-3951-2023; Kumar, Sunil/JBJ-5151-2023; Frossard, Pascal/AAF-2268-2019; Ortega, Antonio/N-4542-2019	Shuman, David/0000-0002-1989-3190; Vandergheynst, Pierre/0000-0002-9070-900X													1053-5888	1558-0792				MAY	2013	30	3					83	98		10.1109/MSP.2012.2235192	http://dx.doi.org/10.1109/MSP.2012.2235192													WOS:000317780300009
J	Do, MN; Vetterli, M				Do, MN; Vetterli, M			The contourlet transform: An efficient directional multiresolution image representation	IEEE TRANSACTIONS ON IMAGE PROCESSING												The limitations of commonly used separable extensions of one-dimensional transforms, such as the Fourier and wavelet transforms, in capturing the geometry of image edges are well known. In this paper, we pursue a "true" two-dimensional transform that can capture the intrinsic geometrical structure that is key in visual information. The main challenge in exploring geometry in images comes from the discrete nature of the data. Thus, unlike other approaches, such as curvelets, that first develop a transform in the continuous domain and then discretize for sampled data, our approach starts with a discrete-domain construction and then studies its convergence to an expansion in the continuous domain. Specifically, we construct a discrete-domain multiresolution and multidirection expansion using nonseparable filter banks, in much the same way that wavelets were derived from filter banks. This construction results in a flexible multiresolution, local, and directional image expansion using contour segments, and, thus, it is named the contourlet transform. The discrete contourlet transform has a fast iterated filter bank algorithm that requires an order N operations for N-pixel images. Furthermore, we establish a precise link between the developed filter bank and the associated continuous-domain contourlet expansion via a directional multiresolution analysis framework. We show that with parabolic scaling and sufficient directional vanishing moments, contourlets achieve the optimal approximation rate for piecewise smooth functions with discontinuities along twice continuously differentiable curves. Finally, we show some numerical experiments demonstrating the potential of contourlets in several image processing applications.					Do, Minh/AAX-8498-2020; Vetterli, Martin/B-3612-2010	Vetterli, Martin/0000-0002-6122-1216													1057-7149	1941-0042				DEC	2005	14	12					2091	2106		10.1109/TIP.2005.859376	http://dx.doi.org/10.1109/TIP.2005.859376								16370462					WOS:000233473800013
J	Kreuer, KD				Kreuer, KD			On the development of proton conducting polymer membranes for hydrogen and methanol fuel cells	JOURNAL OF MEMBRANE SCIENCE												The transport properties and the swelling behaviour of NAFION and different sulfonated polyetherketones are explained in terms of distinct differences on the microstructures and in the pK(a) of the acidic functional groups. The less pronounced hydrophobic/hydrophilic separation of sulfonated polyetherketones compared to NAFION corresponds to narrower, less connected hydrophilic channels and to larger separations between less acidic sulfonic acid functional groups. At high water contents, this is shown to significantly reduce electroosmotic drag and water permeation whilst maintaining high proton conductivity. Blending of sulfonated polyetherketones with other polyaryls even further reduces the solvent permeation (a factor of 20 compared to NAFION), increases the membrane flexibility in the dry state and leads to an improved swelling behaviour. Therefore, polymers based on sulfonated polyetherketones are not only interesting low-cost alternative membrane material for hydrogen fuel cell applications, they may also help to reduce the problems associated with high water drag and high methanol cross-over in direct liquid methanol fuel cells (DMFC). The relatively high conductivities observed for oligomers containing imidazole as functional groups may be exploited in fully polymeric proton conducting systems with no volatile proton solvent operating at temperatures significantly beyond 100 degreesC, where methanol vapour may be used as a fuel in DMFCs. (C) 2001 Elsevier Science B.V. All rights reserved.																			0376-7388	1873-3123				APR 15	2001	185	1			SI		29	39		10.1016/S0376-7388(00)00632-3	http://dx.doi.org/10.1016/S0376-7388(00)00632-3													WOS:000168080600003
J	Staal, J; Abràmoff, MD; Niemeijer, M; Viergever, MA; van Ginneken, B				Staal, J; Abràmoff, MD; Niemeijer, M; Viergever, MA; van Ginneken, B			Ridge-based vessel segmentation in color images of the retina	IEEE TRANSACTIONS ON MEDICAL IMAGING												A method is presented for automated segmentation of vessels in two-dimensional color images of the retina. This method can be used in computer analyses of retinal images, e.g., in automated screening for diabetic retinopathy. The system is based on extraction of image ridges, which coincide approximately with vessel centerlines. The ridges are used to compose primitives in the form of line elements. With the line elements an image is partitioned into patches by assigning each image pixel to the closest line element. Every line element constitutes a local coordinate frame for its corresponding patch. For every pixel, feature vectors are computed that make use of properties of the patches and the line elements. The feature vectors are classified using a kNN-classifier and sequential forward feature selection. The algorithm was tested on a database consisting of 40 manually labeled images. The method achieves an area under the receiver operating characteristic curve of 0.952. The method is compared with two recently published rule-based methods of Hoover et al. [1] and Jiang et al. [2]. The results show that our method is significantly better than the two rule-based methods (p < 0.01). The accuracy of our method is 0.944 versus 0.947 for a second observer.					Abramoff, Michael/IZP-9416-2023; Viergever, Max/J-1215-2014; van Ginneken, Bram/A-3728-2012; Abramoff, Michael/A-5836-2009	Abramoff, Michael/0000-0002-3490-0037; van Ginneken, Bram/0000-0003-2028-8972; Staal, Joes/0000-0002-4410-8318													0278-0062	1558-254X				APR	2004	23	4					501	509		10.1109/TMI.2004.825627	http://dx.doi.org/10.1109/TMI.2004.825627								15084075					WOS:000220611800010
J	Kalal, Z; Mikolajczyk, K; Matas, J				Kalal, Zdenek; Mikolajczyk, Krystian; Matas, Jiri			Tracking-Learning-Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												This paper investigates long-term tracking of unknown objects in a video stream. The object is defined by its location and extent in a single frame. In every frame that follows, the task is to determine the object's location and extent or indicate that the object is not present. We propose a novel tracking framework (TLD) that explicitly decomposes the long-term tracking task into tracking, learning, and detection. The tracker follows the object from frame to frame. The detector localizes all appearances that have been observed so far and corrects the tracker if necessary. The learning estimates the detector's errors and updates it to avoid these errors in the future. We study how to identify the detector's errors and learn from them. We develop a novel learning method (P-N learning) which estimates the errors by a pair of "experts": 1) P-expert estimates missed detections, and 2) N-expert estimates false alarms. The learning process is modeled as a discrete dynamical system and the conditions under which the learning guarantees improvement are found. We describe our real-time implementation of the TLD framework and the P-N learning. We carry out an extensive quantitative evaluation which shows a significant improvement over state-of-the-art approaches.					, Matas/AAW-3282-2020	Matas, Jiri/0000-0003-0863-4844													0162-8828	1939-3539				JUL	2012	34	7					1409	1422		10.1109/TPAMI.2011.239	http://dx.doi.org/10.1109/TPAMI.2011.239								22156098					WOS:000304138300012
S	Blin, F		Caws, C; Hamel, MJ		Blin, Francoise			The theory of affordances	LANGUAGE-LEARNER COMPUTER INTERACTIONS: THEORY, METHODOLOGY AND CALL APPLICATIONS	Language Studies Science and Engineering											In the last decade, the term "affordance", coined by the ecological psychologist James Gibson (1986), has become a buzzword in CALL research. Often used to denote possibilities offered by technologies, the concept has been imported into CALL from cognate domains, such as human-computer Interaction (HCI). However, the CALL community has yet to engage in in-depth discussions on its meaning and usefulness for CALL research and design. The concept remains confusing, often misunderstood, and, at times, misused. This chapter provides an introduction to the concept of affordances, with a view to clarify its meaning and potential applications within CALL. Following a brief overview of Gibson's theory of affordance, it presents and discusses leading HCI interpretations and conceptualizations of affordance that are particularly relevant to CALL researchers and designers. More specifically, it explicates HCI cognitivist and post-cognitivist views of affordances before exploring their relation to CALL affordances and their possible place within a CALL research agenda focusing more particularly on learner-computer interactions.																			2210-7029		978-90-272-6698-9; 978-90-272-5751-2				2016	2						41	64		10.1075/lsse.2.03bli	http://dx.doi.org/10.1075/lsse.2.03bli	10.1075/lsse.2												WOS:000573273700003
J	Boccardi, F; Heath, RW; Lozano, A; Marzetta, TL; Popovski, P				Boccardi, Federico; Heath, Robert W., Jr.; Lozano, Angel; Marzetta, Thomas L.; Popovski, Petar			Five Disruptive Technology Directions for 5G	IEEE COMMUNICATIONS MAGAZINE												New research directions will lead to fundamental changes in the design of future fifth generation (5G) cellular networks. This article describes five technologies that could lead to both architectural and component disruptive design changes: device-centric architectures, millimeter wave, massive MIMO, smarter devices, and native support for machine-to-machine communications. The key ideas for each technology are described, along with their potential impact on 5G and the research challenges that remain.					Heath, Robert/AAY-4148-2020; Marzetta, Thomas/AEB-0112-2022; Popovski, Petar/B-2453-2013; Heath, Robert/A-5366-2010; Lozano, Angel/A-3332-2012	Popovski, Petar/0000-0001-6195-4797; Heath, Robert/0000-0002-4666-5628; Lozano, Angel/0000-0003-3790-0494													0163-6804	1558-1896				FEB	2014	52	2					74	80		10.1109/MCOM.2014.6736746	http://dx.doi.org/10.1109/MCOM.2014.6736746													WOS:000331904900009
J	Anipsitakis, GP; Dionysiou, DD				Anipsitakis, GP; Dionysiou, DD			Radical generation by the interaction of transition metals with common oxidants	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Nine transition metals were tested for the activation of three oxidants and the generation of inorganic radical species such as sulfate, peroxymonosulfate, and hydroxyl radicals. From the 27 combinations, 14 M/Ox couples demonstrated significant reactivity toward transforming a model organic substrate such as 2,4-dichlorophenol and are further discussed here. It was found that COO and Ru(III) are the best metal catalysts for the activation of peroxymonosulfate. As expected on the basis of the Fenton reagent, Fe(III) and Fe(II) were the most efficient transition metals for the activation of hydrogen peroxide. Finally, Ag(I) showed the best results toward activating persulfate. Quenching studies with specific alcohols (tert-butyl alcohol and ethanol) were also performed to identify the primary radical species formed from the reactive M/Ox interactions. The determination of these transient species allowed us to postulate the rate-determining step of the redox reactions taking place when a metal is coupled with an oxidant in aqueous solution. It was found that when Co(II), Ru(III), and Fe(II) interact with peroxymonosulfate, freely diffusible sulfate radicals are the primary species formed. The same was proven for the interaction of Ag(I) with persulfate, but in this case caged or bound to the metal sulfate radicals might be formed as well. The conjunction of Ce(III), Mn(II), and Ni(II) with peroxymonosulfate showed also to generate caged or bound to the metal sulfate radicals. A combination of sulfate and hydroxyl radicals was formed from the conjunction of V(III) with peroxymonosulfate and from Fe(II) with persulfate. Finally, the conjunction of Fe(III), FOIL and Ru(III) with hydrogen peroxide led primarily to the generation of hydroxyl radicals. It is also suggested here that the redox behavior of a particular metal in solution cannot be predicted based exclusively on its size and charge. Additional phenomena such as metal hydrolysis as well as complexation with other counterions present in solution might affect the thermodynamics of the overall process and are further discussed here.																			0013-936X	1520-5851				JUL 1	2004	38	13					3705	3712		10.1021/es035121o	http://dx.doi.org/10.1021/es035121o								15296324					WOS:000222396400040
J	Julier, S; Uhlmann, J; Durrant-Whyte, HF				Julier, S; Uhlmann, J; Durrant-Whyte, HF			A new method for the nonlinear transformation of means and covariances in filters and estimators	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												This paper describes a new approach for generalizing the Kalman filter to nonlinear systems. A set of samples are used to parameterize the mean and covariance of a (not necessarily Gaussian) probability distribution. The method yields a filter that is more accurate than an extended Kalman filter (EKF) and easier to implement than an EKF or a Gauss second-order filter. Its effectiveness is demonstrated using an example.																			0018-9286					MAR	2000	45	3					477	482		10.1109/9.847726	http://dx.doi.org/10.1109/9.847726													WOS:000087712300008
J	Khanafer, K; Vafai, K; Lightstone, M				Khanafer, K; Vafai, K; Lightstone, M			Buoyancy-driven heat transfer enhancement in a two-dimensional enclosure utilizing nanofluids	INTERNATIONAL JOURNAL OF HEAT AND MASS TRANSFER												Heat transfer enhancement in a two-dimensional enclosure utilizing nanofluids is investigated for various pertinent parameters. A model is developed to analyze heat transfer performance of nanofluids inside an enclosure taking into account the solid particle dispersion. The transport equations are solved numerically using the finite-volume approach along with the alternating direct implicit procedure. Comparisons with previously published work on the basis of special cases are performed and found to be in excellent agreement. The effect of suspended ultrafine metallic nanoparticles on the fluid flow and heat transfer processes within the enclosure is analyzed and effective thermal conductivity enhancement maps are developed for various controlling parameters. In addition, an analysis of variants based on the thermophysical properties of nanofluid is developed and presented. It is shown that the variances within different models have substantial effects on the results. Finally, a heat transfer correlation of the average Nusselt number for various Grashof numbers and volume fractions is presented. (C) 2003 Elsevier Ltd. All rights reserved.					Vafai, Kambiz/IYS-7906-2023; Khanafer, Khalil/JRY-7160-2023														0017-9310	1879-2189				SEP	2003	46	19					3639	3653		10.1016/S0017-9310(03)00156-X	http://dx.doi.org/10.1016/S0017-9310(03)00156-X													WOS:000184310000008
J	Zeng, Y; Zhang, R; Lim, TJ				Zeng, Yong; Zhang, Rui; Lim, Teng Joon			Wireless Communications with Unmanned Aerial Vehicles: Opportunities and Challenges	IEEE COMMUNICATIONS MAGAZINE												Wireless communication systems that include unmanned aerial vehicles promise to provide cost-effective wireless connectivity for devices without infrastructure coverage. Compared to terrestrial communications or those based on high-altitude platforms, on-demand wireless systems with low-altitude UAVs are in general faster to deploy, more flexibly reconfigured, and likely to have better communication channels due to the presence of short-range line-of-sight links. However, the utilization of highly mobile and energy-constrained UAVs for wireless communications also introduces many new challenges. In this article, we provide an overview of UAV-aided wireless communications, by introducing the basic networking architecture and main channel characteristics, highlighting the key design considerations as well as the new opportunities to be exploited.					Zeng, Yong/AFM-8040-2022; Lim, Teng Joon/K-4184-2012; Zhang, Rui/C-2657-2011	Lim, Teng Joon/0000-0002-3356-2240; Zhang, Rui/0000-0002-8729-8393													0163-6804	1558-1896				MAY	2016	54	5					36	42		10.1109/mcom.2016.7470933	http://dx.doi.org/10.1109/mcom.2016.7470933													WOS:000377104900004
J	Ho, YS; McKay, G				Ho, YS; McKay, G			The kinetics of sorption of divalent metal ions onto sphagnum moss peat	WATER RESEARCH												A pseudo-second order rate equation describing the kinetics of sorption of divalent metal ions onto sphagnum moss peat at different initial metal ion concentrations and pear doses has been developed. The kinetics of sorption were followed based on the amounts of metal sorbed at various time intervals. Results show that sorption (chemical bonding) might be rate-limiting in the sorption of divalent metal ions onto peat during agitated batch contact time experiments. The rate constant, the equilibrium sorption capacity and the initial sorption rate were calculated. From these parameters, an empirical model for predicting the sorption capacity of metal ions sorbed was derived. (C) 2000 Elsevier Science Ltd. All rights reserved.					Ho, Yuh-Shan/C-8624-2009; McKay, Gareth/HNJ-3797-2023	Ho, Yuh-Shan/0000-0002-2557-8736; McKay, Gordon/0000-0001-9965-7659													0043-1354					FEB	2000	34	3					735	742		10.1016/S0043-1354(99)00232-8	http://dx.doi.org/10.1016/S0043-1354(99)00232-8													WOS:000084822200004
J	Moody, GA; Mark, RG				Moody, GA; Mark, RG			The impact of the MIT-BIH arrhythmia database	IEEE ENGINEERING IN MEDICINE AND BIOLOGY MAGAZINE																															0739-5175	1937-4186				MAY-JUN	2001	20	3					45	50		10.1109/51.932724	http://dx.doi.org/10.1109/51.932724								11446209					WOS:000169673500008
J	Wu, Y; Lim, J; Yang, MH				Wu, Yi; Lim, Jongwoo; Yang, Ming-Hsuan			Object Tracking Benchmark	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Object tracking has been one of the most important and active research areas in the field of computer vision. A large number of tracking algorithms have been proposed in recent years with demonstrated success. However, the set of sequences used for evaluation is often not sufficient or is sometimes biased for certain types of algorithms. Many datasets do not have common ground-truth object positions or extents, and this makes comparisons among the reported quantitative results difficult. In addition, the initial conditions or parameters of the evaluated tracking algorithms are not the same, and thus, the quantitative results reported in literature are incomparable or sometimes contradictory. To address these issues, we carry out an extensive evaluation of the state-of-the-art online object-tracking algorithms with various evaluation criteria to understand how these methods perform within the same framework. In this work, we first construct a large dataset with ground-truth object positions and extents for tracking and introduce the sequence attributes for the performance analysis. Second, we integrate most of the publicly available trackers into one code library with uniform input and output formats to facilitate large-scale performance evaluation. Third, we extensively evaluate the performance of 31 algorithms on 100 sequences with different initialization settings. By analyzing the quantitative results, we identify effective approaches for robust tracking and provide potential future research directions in this field.					wu, yi/C-1037-2018; Yang, Ming-Hsuan/T-9533-2019														0162-8828	1939-3539				SEP	2015	37	9					1834	1848		10.1109/TPAMI.2014.2388226	http://dx.doi.org/10.1109/TPAMI.2014.2388226								26353130					WOS:000359216600008
J	He, XF; Yan, SC; Hu, YX; Niyogi, P; Zhang, HJ				He, XF; Yan, SC; Hu, YX; Niyogi, P; Zhang, HJ			Face recognition using Laplacianfaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												We propose an appearance-based face recognition method called the Laplacianface approach. By using Locality Preserving Projections (LPP), the face images are mapped into a face subspace for analysis. Different from Principal Component Analysis (PCA) and Linear Discriminant Analysis (LDA) which effectively see only the Euclidean structure of face space, LPP finds an embedding that preserves local information, and obtains a face subspace that best detects the essential face manifold structure. The Laplacianfaces are the optimal linear approximations to the eigenfunctions of the Laplace Beltrami operator on the face manifold. In this way, the unwanted variations resulting from changes in lighting, facial expression, and pose may be eliminated or reduced. Theoretical analysis shows that PCA, LDA, and LPP can be obtained from different graph models. We compare the proposed Laplacianface approach with Eigenface and Fisherface methods on three different face data sets. Experimental results suggest that the proposed Laplacianface approach provides a better representation and achieves lower error rates in face recognition.																			0162-8828	1939-3539				MAR	2005	27	3					328	340		10.1109/TPAMI.2005.55	http://dx.doi.org/10.1109/TPAMI.2005.55								15747789					WOS:000226300200003
J	Nedic, A; Ozdaglar, A				Nedic, Angelia; Ozdaglar, Asurrian			Distributed Subgradient Methods for Multi-Agent Optimization	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												We study a distributed computation model for optimizing a sum of convex objective functions corresponding to multiple agents. For solving this (not necessarily smooth) optimization problem, we consider a subgradient method that is distributed among the agents. The method involves every agent minimizing his/her own objective function while exchanging information locally with other agents in the network over a time-varying topology. We provide convergence results and convergence rate estimates for the subgradient method. Our convergence rate results explicitly characterize the tradeoff between a desired accuracy of the generated approximate optimal solutions and the number of iterations needed to achieve the accuracy.						Nedich, Angelia/0000-0001-9365-6321													0018-9286	1558-2523				JAN	2009	54	1					48	61		10.1109/TAC.2008.2009515	http://dx.doi.org/10.1109/TAC.2008.2009515													WOS:000262817100004
J	Luo, ZQ; Ma, WK; So, AMC; Ye, YY; Zhang, SZ				Luo, Zhi-Quan; Ma, Wing-Kin; So, Anthony Man-Cho; Ye, Yinyu; Zhang, Shuzhong			Semidefinite Relaxation of Quadratic Optimization Problems	IEEE SIGNAL PROCESSING MAGAZINE																	Liu, Zhiming/J-5328-2019; So, Anthony Man-Cho/F-6001-2011; Ma, Wing-Kin/K-2433-2013	So, Anthony Man-Cho/0000-0003-2588-7851; Ma, Wing-Kin/0000-0001-7314-3537													1053-5888	1558-0792				MAY	2010	27	3					20	34		10.1109/MSP.2010.936019	http://dx.doi.org/10.1109/MSP.2010.936019													WOS:000276819100006
J	Entekhabi, D; Njoku, EG; O'Neill, PE; Kellogg, KH; Crow, WT; Edelstein, WN; Entin, JK; Goodman, SD; Jackson, TJ; Johnson, J; Kimball, J; Piepmeier, JR; Koster, RD; Martin, N; McDonald, KC; Moghaddam, M; Moran, S; Reichle, R; Shi, JC; Spencer, MW; Thurman, SW; Tsang, L; Van Zyl, J				Entekhabi, Dara; Njoku, Eni G.; O'Neill, Peggy E.; Kellogg, Kent H.; Crow, Wade T.; Edelstein, Wendy N.; Entin, Jared K.; Goodman, Shawn D.; Jackson, Thomas J.; Johnson, Joel; Kimball, John; Piepmeier, Jeffrey R.; Koster, Randal D.; Martin, Neil; McDonald, Kyle C.; Moghaddam, Mahta; Moran, Susan; Reichle, Rolf; Shi, J. C.; Spencer, Michael W.; Thurman, Samuel W.; Tsang, Leung; Van Zyl, Jakob			The Soil Moisture Active Passive (SMAP) Mission	PROCEEDINGS OF THE IEEE												The Soil Moisture Active Passive (SMAP) mission is one of the first Earth observation satellites being developed by NASA in response to the National Research Council's Decadal Survey. SMAP will make global measurements of the soil moisture present at the Earth's land surface and will distinguish frozen from thawed land surfaces. Direct observations of soil moisture and freeze/thaw state from space will allow significantly improved estimates of water, energy, and carbon transfers between the land and the atmosphere. The accuracy of numerical models of the atmosphere used in weather prediction and climate projections are critically dependent on the correct characterization of these transfers. Soil moisture measurements are also directly applicable to flood assessment and drought monitoring. SMAP observations can help monitor these natural hazards, resulting in potentially great economic and social benefits. SMAP observations of soil moisture and freeze/thaw timing will also reduce a major uncertainty in quantifying the global carbon balance by helping to resolve an apparent missing carbon sink on land over the boreal latitudes. The SMAP mission concept will utilize L-band radar and radiometer instruments sharing a rotating 6-m mesh reflector antenna to provide high-resolution and high-accuracy global maps of soil moisture and freeze/thaw state every two to three days. In addition, the SMAP project will use these observations with advanced modeling and data assimilation to provide deeper root-zone soil moisture and net ecosystem exchange of carbon. SMAP is scheduled for launch in the 2014-2015 time frame.					Kimball, John/B-9234-2011; Crow, Wade/ABC-9227-2020; Reichle, Rolf/E-1419-2012; Koster, Randal/F-5881-2012; O'Neill, Peggy/D-2904-2013	Reichle, Rolf/0000-0001-5513-0150; Kimball, John S./0000-0002-5493-5878; Crow, Wade/0000-0002-8217-261X; Koster, Randal/0000-0001-6418-6383; O'Neill, Peggy/0000-0002-2596-8670; Moghaddam, Mahta/0000-0001-5304-2616													0018-9219	1558-2256				MAY	2010	98	5					704	716		10.1109/JPROC.2010.2043918	http://dx.doi.org/10.1109/JPROC.2010.2043918													WOS:000277493400006
J	Bangor, A; Kortum, PT; Miller, JT				Bangor, Aaron; Kortum, Philip T.; Miller, James T.			An empirical evaluation of the System Usability Scale	INTERNATIONAL JOURNAL OF HUMAN-COMPUTER INTERACTION												This article presents nearly 10 year's worth of System Usability Scale (SUS) data collected on numerous products in all phases of the development lifecycle. The SUS, developed by Brooke (1996), reflected a strong need in the usability community for a tool that could quickly and easily collect a user's subjective rating of a product's usability. The data in this study indicate that the SUS fulfills that need. Results from the analysis of this large number of SUS scores show that the SUS is a highly robust and versatile tool for usability professionals. The article presents these results and discusses their implications, describes nontraditional uses of the SUS, explains a proposed modification to the SUS to provide an adjective rating that correlates with a given score, and provides details of what constitutes an acceptable SUS score.																			1044-7318	1532-7590				AUG	2008	24	6					574	594		10.1080/10447310802205776	http://dx.doi.org/10.1080/10447310802205776													WOS:000258821600003
J	Adadi, A; Berrada, M				Adadi, Amina; Berrada, Mohammed			Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI)	IEEE ACCESS												At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artificial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society. However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency. Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained. This issue has triggered a new debate on explainable AI (XAI). A research field holds substantial promise for improving trust and transparency of AI-based systems. It is recognized as the sine qua non for AI to continue making steady progress without disruption. This survey provides an entry point for interested researchers and practitioners to learn key aspects of the young and rapidly growing body of research related to XAI. Through the lens of the literature, we review the existing approaches regarding the topic, discuss trends surrounding its sphere, and present major research trajectories.					ADADI, AMINA/AAA-1238-2021	BERRADA, Mohammed/0000-0003-4167-2324													2169-3536						2018	6						52138	52160		10.1109/ACCESS.2018.2870052	http://dx.doi.org/10.1109/ACCESS.2018.2870052													WOS:000447797600001
J	Holzapfel, GA; Gasser, TC; Ogden, RW				Holzapfel, GA; Gasser, TC; Ogden, RW			A new constitutive framework for arterial wall mechanics and a comparative study of material models	JOURNAL OF ELASTICITY												In this paper we develop a new constitutive law for the description of the (passive) mechanical response of arterial tissue. The artery is modeled as a thick-walled nonlinearly elastic circular cylindrical tube consisting of two layers corresponding to the media and adventitia (the solid mechanically relevant layers in healthy tissue). Each layer is treated as a fiber-reinforced material with the fibers corresponding to the collagenous component of the material and symmetrically disposed with respect to the cylinder axis. The resulting constitutive law is orthotropic in each layer. Fiber orientations obtained from a statistical analysis of histological sections from each arterial layer are used. A specific form of the law, which requires only three material parameters for each layer, is used to study the response of an artery under combined axial extension, inflation and torsion. The characteristic and very important residual stress in an artery in vitro is accounted for by assuming that the natural (unstressed and unstrained) configuration of the material corresponds to an open sector of a tube, which is then closed by an initial bending to form a load-free, but stressed, circular cylindrical configuration prior to application of the extension, inflation and torsion. The effect of residual stress on the stress distribution through the deformed arterial wall in the physiological state is examined. The model is fitted to available data on arteries and its predictions are assessed for the considered combined loadings. It is explained how the new model is designed to avoid certain mechanical, mathematical and computational deficiencies evident in currently available phenomenological models. A critical review of these models is provided by way of background to the development of the new model.					Ogden, Ray/B-3906-2008	Ogden, Ray/0000-0002-7002-7028; Holzapfel, Gerhard/0000-0001-8119-5775													0374-3535	1573-2681					2000	61	1-3					1	48		10.1023/A:1010835316564	http://dx.doi.org/10.1023/A:1010835316564													WOS:000169741700003
J	Camp, T; Boleng, J; Davies, V				Camp, T; Boleng, J; Davies, V			A survey of mobility models for ad hoc network research	WIRELESS COMMUNICATIONS & MOBILE COMPUTING												In the performance evaluation of a protocol for an ad hoc network, the protocol should be tested under realistic conditions including, but not limited to, a sensible transmission range, limited buffer space for the storage of messages, representative data traffic models and realistic movements of the mobile users (i.e. a mobility model). This paper is a survey of mobility models that are used in the simulations of ad hoc networks. We describe several mobility models that represent mobile nodes whose movements are independent of each other (i.e. entity mobility models) and several mobility models that represent mobile nodes whose movements are dependent on each other (i.e. group mobility models). The goal of this paper is to present a number of mobility models in order to offer researchers more informed choices when they are deciding on a mobility model to use in their performance evaluations. Lastly, we present simulation results that illustrate the importance of choosing a mobility model in the simulation of an ad hoc network protocol. Specifically, we illustrate how the performance results of an ad hoc network protocol drastically change as a result of changing the mobility model simulated. Copyright (C) 2002 John Wiley Sons, Ltd.					Boleng, Jeff/F-6110-2012														1530-8669	1530-8677				AUG	2002	2	5					483	502		10.1002/wcm.72	http://dx.doi.org/10.1002/wcm.72													WOS:000178438800005
J	Richard, JP				Richard, JP			Time-delay systems: an overview of some recent advances and open problems	AUTOMATICA												After presenting some motivations for the study of time-delay system, this paper recalls modifications (models, stability, structure) arising from the presence of the delay phenomenon. A brief overview of some control approaches is then provided, the sliding mode and time-delay controls in particular. Lastly, some open problems are discussed: the constructive use of the delayed inputs, the digital implementation of distributed delays, the control via the delay, and the handling of information related to the delay value. (C) 2003 Elsevier Ltd. All rights reserved.					Richard, Jean-Pierre/K-7385-2012	Richard, Jean-Pierre/0000-0002-9497-0432													0005-1098	1873-2836				OCT	2003	39	10					1667	1694		10.1016/S0005-1098(03)00167-5	http://dx.doi.org/10.1016/S0005-1098(03)00167-5													WOS:000185273900001
J	Luo, X; Wang, JH; Dooner, M; Clarke, J				Luo, Xing; Wang, Jihong; Dooner, Mark; Clarke, Jonathan			Overview of current development in electrical energy storage technologies and the application potential in power system operation	APPLIED ENERGY												Electrical power generation is changing dramatically across the world because of the need to reduce greenhouse gas emissions and to introduce mixed energy sources. The power network faces great challenges in transmission and distribution to meet demand with unpredictable daily and seasonal variations. Electrical Energy Storage (EES) is recognized as underpinning technologies to have great potential in meeting these challenges, whereby energy is stored in a certain state, according to the technology used, and is converted to electrical energy when needed. However, the wide variety of options and complex characteristic matrices make it difficult to appraise a specific EES technology for a particular application. This paper intends to mitigate this problem by providing a comprehensive and clear picture of the state-of-the-art technologies available, and where they would be suited for integration into a power generation and distribution system. The paper starts with an overview of the operation principles, technical and economic performance features and the current research and development of important EES technologies, sorted into six main categories based on the types of energy stored. Following this, a comprehensive comparison and an application potential analysis of the reviewed technologies are presented. (C) 2014 The Authors. Published by Elsevier Ltd.					Clarke, Jonathan/S-8958-2019	Wang, Jihong/0000-0001-7847-460X; Clarke, Jonathan/0000-0003-1495-7746													0306-2619	1872-9118				JAN 1	2015	137						511	536		10.1016/j.apenergy.2014.09.081	http://dx.doi.org/10.1016/j.apenergy.2014.09.081													WOS:000348006700048
J	Yang, J; Zhang, D; Frangi, AF; Yang, JY				Yang, J; Zhang, D; Frangi, AF; Yang, JY			Two-dimensional PCA: A new approach to appearance-based face representation and recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												In this paper, a new technique coined two-dimensional principal component analysis (2DPCA) is developed for image representation. As opposed to PCA, 2DPCA is based on 2D image matrices rather than 1 D vectors so the image matrix does not need to be transformed into a vector prior to feature extraction. Instead, an image covariance matrix is constructed directly using the original image matrices, and its eigenvectors are derived for image feature extraction. To test 2DPCA and evaluate its performance, a series of experiments were performed on three face image databases: ORL, AR, and Yale face databases. The recognition rate across all trials was higher using 2DPCA than PCA. The experimental results also indicated that the extraction of image features is computationally more efficient using 2DPCA than PCA.					; Frangi, Alejandro/C-6500-2008; Zhang, David/O-9396-2016	Anam, Mohammad Ashraful/0000-0001-7349-3772; Frangi, Alejandro/0000-0002-2675-528X; Zhang, David/0000-0002-5027-5286													0162-8828	1939-3539				JAN	2004	26	1					131	137		10.1109/TPAMI.2004.1261097	http://dx.doi.org/10.1109/TPAMI.2004.1261097								15382693					WOS:000187161400012
J	Jain, AK; Ross, A; Prabhakar, S				Jain, AK; Ross, A; Prabhakar, S			An introduction to biometric recognition	IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY												A wide variety of systems requires reliable personal recognition schemes to either confirm or determine the identity of an individual requesting their services. The purpose of such schemes is to ensure that the rendered services are accessed only by a legitimate user and no one else. Examples of such applications include secure access to buildings, computer systems, laptops, cellular phones, and ATMs. In the absence of robust personal recognition schemes, these systems are vulnerable to the wiles of an impostor. Biometric recognition or, simply, biometrics refers to the automatic recognition of individuals based on their physiological and/or behavioral characteristics. By using biometrics, it is possible to confirm or establish an individual's identity based on "who she is," rather than by "what she possesses" (e.g., an ID card) or "what she remembers" (e.g., a password). In this paper, we give a brief overview of the field of biometrics and summarize some of its advantages, disadvantages, strengths, limitations, and related privacy concerns.																			1051-8215	1558-2205				JAN	2004	14	1					4	20		10.1109/TCSVT.2003.818349	http://dx.doi.org/10.1109/TCSVT.2003.818349													WOS:000188198000002
J	Rocabert, J; Luna, A; Blaabjerg, F; Rodríguez, P				Rocabert, Joan; Luna, Alvaro; Blaabjerg, Frede; Rodriguez, Pedro			Control of Power Converters in AC Microgrids	IEEE TRANSACTIONS ON POWER ELECTRONICS												The enabling of ac microgrids in distribution networks allows delivering distributed power and providing grid support services during regular operation of the grid, as well as powering isolated islands in case of faults and contingencies, thus increasing the performance and reliability of the electrical system. The high penetration of distributed generators, linked to the grid through highly controllable power processors based on power electronics, together with the incorporation of electrical energy storage systems, communication technologies, and controllable loads, opens new horizons to the effective expansion of microgrid applications integrated into electrical power systems. This paper carries out an overview about microgrid structures and control techniques at different hierarchical levels. At the power converter level, a detailed analysis of the main operation modes and control structures for power converters belonging to microgrids is carried out, focusing mainly on grid-forming, grid-feeding, and grid-supporting configurations. This analysis is extended as well toward the hierarchical control scheme of microgrids, which, based on the primary, secondary, and tertiary control layer division, is devoted to minimize the operation cost, coordinating support services, meanwhile maximizing the reliability and the controllability of microgrids. Finally, the main grid services that microgrids can offer to the main network, as well as the future trends in the development of their operation and control for the next future, are presented and discussed.					RODRIGUEZ, PEDRO/AAD-7311-2020; Rocabert, Joan/ABG-6986-2020; Luna, Alvaro/AAE-2370-2020; Blaabjerg, Frede/A-5008-2008; RODRIGUEZ, PEDRO/C-8038-2013; Rocabert, Joan/B-8920-2009	Blaabjerg, Frede/0000-0001-8311-7412; RODRIGUEZ, PEDRO/0000-0002-1865-0461; Rocabert, Joan/0000-0002-6634-5306													0885-8993	1941-0107				NOV	2012	27	11			SI		4734	4749		10.1109/TPEL.2012.2199334	http://dx.doi.org/10.1109/TPEL.2012.2199334													WOS:000305750000036
J	El Ayach, O; Rajagopal, S; Abu-Surra, S; Pi, ZY; Heath, RW				El Ayach, Omar; Rajagopal, Sridhar; Abu-Surra, Shadi; Pi, Zhouyue; Heath, Robert W., Jr.			Spatially Sparse Precoding in Millimeter Wave MIMO Systems	IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS												Millimeter wave (mmWave) signals experience orders-of-magnitude more pathloss than the microwave signals currently used in most wireless applications and all cellular systems. MmWave systems must therefore leverage large antenna arrays, made possible by the decrease in wavelength, to combat pathloss with beamforming gain. Beamforming with multiple data streams, known as precoding, can be used to further improve mmWave spectral efficiency. Both beamforming and precoding are done digitally at baseband in traditional multiantenna systems. The high cost and power consumption of mixed-signal devices in mmWave systems, however, make analog processing in the RF domain more attractive. This hardware limitation restricts the feasible set of precoders and combiners that can be applied by practical mmWave transceivers. In this paper, we consider transmit precoding and receiver combining in mmWave systems with large antenna arrays. We exploit the spatial structure of mmWave channels to formulate the precoding/combining problem as a sparse reconstruction problem. Using the principle of basis pursuit, we develop algorithms that accurately approximate optimal unconstrained precoders and combiners such that they can be implemented in low-cost RF hardware. We present numerical results on the performance of the proposed algorithms and show that they allow mmWave systems to approach their unconstrained performance limits, even when transceiver hardware constraints are considered.					Heath, Robert/AAY-4148-2020; Heath, Robert/A-5366-2010	Heath, Robert/0000-0002-4666-5628													1536-1276	1558-2248				MAR	2014	13	3					1499	1513		10.1109/TWC.2014.011714.130846	http://dx.doi.org/10.1109/TWC.2014.011714.130846													WOS:000333538100030
J	Kjaer, SB; Pedersen, JK; Blaabjerg, F				Kjaer, SB; Pedersen, JK; Blaabjerg, F			A review of single-phase grid-connected inverters for photovoltaic modules	IEEE TRANSACTIONS ON INDUSTRY APPLICATIONS					Annual Meeting of the Industry-Applications-Society	OCT 13-18, 2002	PITTSBURGH, PA	Ind Applicat Soc				This review focuses on inverter technologies for connecting photovoltaic (PV) modules to a single-phase grid. The inverters are categorized into four classifications: 1) the number of power processing stages in cascade; 2) the type of power decoupling between the PV module(s) and the single-phase grid; 3) whether they utilizes a transformer (either line or high frequency) or not; and 4) the type of grid-connected power stage. Various inverter topologies are presented, compared, and evaluated against demands, lifetime, component ratings, and cost. Finally, some of the topologies are pointed out as the best candidates for either single PV module or multiple PV module applications.					Blaabjerg, Frede/A-5008-2008	Blaabjerg, Frede/0000-0001-8311-7412													0093-9994	1939-9367				SEP-OCT	2005	41	5					1292	1306		10.1109/TIA.2005.853371	http://dx.doi.org/10.1109/TIA.2005.853371													WOS:000232012000018
J	Figueiredo, MAT; Nowak, RD; Wright, SJ				Figueiredo, Mario A. T.; Nowak, Robert D.; Wright, Stephen J.			Gradient Projection for Sparse Reconstruction: Application to Compressed Sensing and Other Inverse Problems	IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING												Many problems in signal processing and statistical inference involve finding sparse solutions to under-determined, or ill-conditioned, linear systems of equations. A standard approach consists in minimizing an objective function which includes a quadratic (squared l(2)) error term combined with a sparseness-inducing (l(1)) regularization term. Basis pursuit, the least absolute shrinkage and selection operator (LASSO), wavelet-based deconvolution, and compressed sensing are a few well-known examples of this approach. This paper proposes gradient projection (GP) algorithms for the bound-constrained quadratic programming (BCQP) formulation of these problems. We test variants of this approach that select the line search parameters in different ways, including techniques based on the Barzilai-Borwein method. Computational experiments show that these GP approaches perform well in a wide range of applications, often being significantly faster (in terms of computation time) than competing methods. Although the performance of GP methods tends to degrade as the regularization term is de-emphasized, we show how they can be embedded in a continuation scheme to recover their efficient practical performance.					Figueiredo, Mario/C-5428-2008	Figueiredo, Mario/0000-0002-0970-7745													1932-4553	1941-0484				DEC	2007	1	4					586	597		10.1109/JSTSP.2007.910281	http://dx.doi.org/10.1109/JSTSP.2007.910281													WOS:000265494900006
J	Andrews, JG; Baccelli, F; Ganti, RK				Andrews, Jeffrey G.; Baccelli, Francois; Ganti, Radha Krishna			A Tractable Approach to Coverage and Rate in Cellular Networks	IEEE TRANSACTIONS ON COMMUNICATIONS												Cellular networks are usually modeled by placing the base stations on a grid, with mobile users either randomly scattered or placed deterministically. These models have been used extensively but suffer from being both highly idealized and not very tractable, so complex system-level simulations are used to evaluate coverage/outage probability and rate. More tractable models have long been desirable. We develop new general models for the multi-cell signal-to-interference-plus-noise ratio (SINR) using stochastic geometry. Under very general assumptions, the resulting expressions for the downlink SINR CCDF (equivalent to the coverage probability) involve quickly computable integrals, and in some practical special cases can be simplified to common integrals (e. g., the Q-function) or even to simple closed-form expressions. We also derive the mean rate, and then the coverage gain (and mean rate loss) from static frequency reuse. We compare our coverage predictions to the grid model and an actual base station deployment, and observe that the proposed model is pessimistic (a lower bound on coverage) whereas the grid model is optimistic, and that both are about equally accurate. In addition to being more tractable, the proposed model may better capture the increasingly opportunistic and dense placement of base stations in future networks.					Andrews, Jeffrey/ADW-5995-2022; Baccelli, Francois/IWU-5360-2023	Ganti, Radha Krishna/0000-0002-5211-5657													0090-6778	1558-0857				NOV	2011	59	11					3122	3134		10.1109/TCOMM.2011.100411.100541	http://dx.doi.org/10.1109/TCOMM.2011.100411.100541													WOS:000297589000024
J	Wu, QQ; Zhang, R				Wu, Qingqing; Zhang, Rui			Intelligent Reflecting Surface Enhanced Wireless Network via Joint Active and Passive Beamforming	IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS												Intelligent reflecting surface (IRS) is a revolutionary and transformative technology for achieving spectrum and energy efficient wireless communication cost-effectively in the future. Specifically, an IRS consists of a large number of low-cost passive elements each being able to reflect the incident signal independently with an adjustable phase shift so as to collaboratively achieve three-dimensional (3D) passive beamforming without the need of any transmit radio-frequency (RF) chains. In this paper, we study an IRS-aided single-cell wireless system where one IRS is deployed to assist in the communications between a multi-antenna access point (AP) and multiple single-antenna users. We formulate and solve new problems to minimize the total transmit power at the AP by jointly optimizing the transmit beamforming by active antenna array at the AP and reflect beamforming by passive phase shifters at the IRS, subject to users' individual signal-to-interference-plus-noise ratio (SINR) constraints. Moreover, we analyze the asymptotic performance of IRS's passive beamforming with infinitely large number of reflecting elements and compare it to that of the traditional active beamforming/relaying. Simulation results demonstrate that an IRS-aided MIMO system can achieve the same rate performance as a benchmark massive MIMO system without using IRS, but with significantly reduced active antennas/RF chains. We also draw useful insights into optimally deploying IRS in future wireless systems.					Wu, Qingqing/IAM-7302-2023; Zhang, Rui/GXN-3801-2022	Wu, Qingqing/0000-0002-0043-3266													1536-1276	1558-2248				NOV	2019	18	11					5394	5409		10.1109/TWC.2019.2936025	http://dx.doi.org/10.1109/TWC.2019.2936025													WOS:000496947800026
J	Davison, AJ; Reid, ID; Molton, ND; Stasse, O				Davison, Andrew J.; Reid, Ian D.; Molton, Nicholas D.; Stasse, Olivier			MonoSLAM: Real-time single camera SLAM	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												We present a real-time algorithm which can recover the 3D trajectory of a monocular camera, moving rapidly through a previously unknown scene. Our system, which we dub MonoSLAM, is the first successful application of the SLAM methodology from mobile robotics to the "pure vision" domain of a single uncontrolled camera, achieving real time but drift-free performance inaccessible to Structure from Motion approaches. The core of the approach is the online creation of a sparse but persistent map of natural landmarks within a probabilistic framework. Our key novel contributions include an active approach to mapping and measurement, the use of a general motion model for smooth camera movement, and solutions for monocular feature initialization and feature orientation estimation. Together, these add up to an extremely efficient and robust algorithm which runs at 30 Hz with standard PC and camera hardware. This work extends the range of robotic systems in which SLAM can be usefully applied, but also opens up new areas. We present applications of MonoSLAM to real-time 3D localization and mapping for a high-performance full-size humanoid robot and live augmented reality with a hand-held camera.					Stasse, Olivier/E-6220-2010	STASSE, Olivier/0000-0001-8569-6155; Reid, Ian/0000-0001-7790-6423													0162-8828	1939-3539				JUN	2007	29	6					1052	1067		10.1109/TPAMI.2007.1049	http://dx.doi.org/10.1109/TPAMI.2007.1049								17431302					WOS:000245600800010
J	Houas, A; Lachheb, H; Ksibi, M; Elaloui, E; Guillard, C; Herrmann, JM				Houas, A; Lachheb, H; Ksibi, M; Elaloui, E; Guillard, C; Herrmann, JM			Photocatalytic degradation pathway of methylene blue in water	APPLIED CATALYSIS B-ENVIRONMENTAL												The TiO(2)/UV photocatalytic degradation of methylene blue (MB) has been investigated in aqueous heterogeneous suspensions. In addition to a prompt removal of the color, TiO(2)/LTV-based photocatalysis was simultaneously able to oxidize the dye, with an almost complete mineralization of carbon and of nitrogen and sulfur heteroatoms into CO(2) NH(4)(+), NO(3)(-) and SO(4)(2-) respectively. A detailed degradation pathway has been determined by a careful identification of intermediate products, in particular aromatics, whose successive hydroxylations lead to the aromatic ring opening. These results suggest that TiO(2)/UV photocatalysis may be envisaged as a method for treatment of diluted waste waters in textile industries. (C) 2001 Elsevier Science B.V, All rights reserved.					ksibi, Mohamed/AAI-4759-2020														0926-3373					MAY 4	2001	31	2					145	157		10.1016/S0926-3373(00)00276-9	http://dx.doi.org/10.1016/S0926-3373(00)00276-9													WOS:000168628100007
J	Leyland, A; Matthews, A				Leyland, A; Matthews, A			On the significance of the <i>H/E</i> ratio in wear control:: a nanocomposite coating approach to optimised tribological behaviour	WEAR												Although hardness has long been regarded as a primary material property which defines wear resistance, there is strong evidence to suggest that the elastic modulus can also have an important influence on wear behaviour. In particular, the elastic strain to failure, which is related to the ratio of hardness (H) and elastic modulus (E), has been shown by a number of authors to be a more suitable parameter for predicting wear resistance than is hardness alone. There is presently considerable interest in the development of nanostructured and nanolayered coatings, due to the fact that materials with extreme mechanical properties (which are difficult to synthesise by other methods) can be created, particularly when using plasma-assisted vacuum processing techniques. Until now, scientific research has been directed mainly towards the achievement of ultra-high hardness, with associated high elastic modulus, the latter of which, conventional fracture mechanics theory would suggest, is also desirable for wear improvement (by preventing crack propagation). In this study, we discuss the concept of nanocomposite coatings with high hardness and low elastic modulus, which can exhibit improved toughness, and are therefore better suited for optimising the wear resistance of 'real' industrial substrate materials (i.e. steels and Light alloys, with similarly low moduli). Recent advances in the development of ceramic-ceramic, ceramic-amorphous and ceramic-metal nanocomposite coatings are summarised and discussed in terms of their relevance to practical applications. We also discuss the significance of elastic strain to failure (which is related to H/E) and fracture toughness in determining tribological behaviour and introduce the topic of metallic nanocomposite coatings which, although not necessarily exhibiting extreme hardness, may provide superior wear resistance when deposited on the types of substrate material which industry needs to use. (C) 2000 Elsevier Science S.A. All rights reserved.					Matthews, Allan/N-3386-2019; Leyland, Adrian/A-4714-2009; Matthews, Allan/H-2394-2012	Leyland, Adrian/0000-0002-5569-7293; Matthews, Allan/0000-0002-9282-1425													0043-1648					NOV	2000	246	1-2					1	11		10.1016/S0043-1648(00)00488-9	http://dx.doi.org/10.1016/S0043-1648(00)00488-9													WOS:000165326100001
J	Kuhl, KP; Cave, ER; Abram, DN; Jaramillo, TF				Kuhl, Kendra P.; Cave, Etosha R.; Abram, David N.; Jaramillo, Thomas F.			New insights into the electrochemical reduction of carbon dioxide on metallic copper surfaces	ENERGY & ENVIRONMENTAL SCIENCE												We report new insights into the electrochemical reduction of CO2 on a metallic copper surface, enabled by the development of an experimental methodology with unprecedented sensitivity for the identification and quantification of CO2 electroreduction products. This involves a custom electrochemical cell designed to maximize product concentrations coupled to gas chromatography and nuclear magnetic resonance for the identification and quantification of gas and liquid products, respectively. We studied copper across a range of potentials and observed a total of 16 different CO2 reduction products, five of which are reported here for the first time, thus providing the most complete view of the reaction chemistry reported to date. Taking into account the chemical identities of the wide range of C-1-C-3 products generated and the potential-dependence of their turnover frequencies, mechanistic information is deduced. We discuss a scheme for the formation of multicarbon products involving enol-like surface intermediates as a possible pathway, accounting for the observed selectivity for eleven distinct C2+ oxygenated products including aldehydes, ketones, alcohols, and carboxylic acids.					Jaramillo, Thomas/C-4174-2014	Jaramillo, Thomas/0000-0001-9900-0622													1754-5692					MAY	2012	5	5					7050	7059		10.1039/c2ee21234j	http://dx.doi.org/10.1039/c2ee21234j													WOS:000303251500047
J	Yan, SC; Xu, D; Zhang, BY; Zhang, HJ; Yang, Q; Lin, S				Yan, Shuicheng; Xu, Dong; Zhang, Benyu; Zhang, Hong-Jiang; Yang, Qiang; Lin, Stephen			Graph embedding and extensions: A general framework for dimensionality reduction	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Over the past few decades, a large family of algorithms-supervised or unsupervised; stemming from statistics or geometry theory-has been designed to provide different solutions to the problem of dimensionality reduction. Despite the different motivations of these algorithms, we present in this paper a general formulation known as graph embedding to unify them within a common framework. In graph embedding, each algorithm can be considered as the direct graph embedding or its linear/kernel/tensor extension of a specific intrinsic graph that describes certain desired statistical or geometric properties of a data set, with constraints from scale normalization or a penalty graph that characterizes a statistical or geometric property that should be avoided. Furthermore, the graph embedding framework can be used as a general platform for developing new dimensionality reduction algorithms. By utilizing this framework as a tool, we propose a new supervised dimensionality reduction algorithm called Marginal Fisher Analysis in which the intrinsic graph characterizes the intraclass compactness and connects each data point with its neighboring points of the same class, while the penalty graph connects the marginal points and characterizes the interclass separability. We show that MFA effectively overcomes the limitations of the traditional Linear Discriminant Analysis algorithm due to data distribution assumptions and available projection directions. Real face recognition experiments show the superiority of our proposed MFA in comparison to LDA, also for corresponding kernel and tensor extensions.					yang, qiang/GYJ-0971-2022; Xu, Dong/A-3694-2011; Yan, Shuicheng/HCI-1431-2022	Yang, Qiang/0000-0001-5059-8360													0162-8828	1939-3539				JAN	2007	29	1					40	51		10.1109/TPAMI.2007.250598	http://dx.doi.org/10.1109/TPAMI.2007.250598								17108382					WOS:000241988300004
J	Komine, T; Nakagawa, M				Komine, T; Nakagawa, M			Fundamental analysis for visible-light communication system using LED lights	IEEE TRANSACTIONS ON CONSUMER ELECTRONICS												White LED offers advantageous properties such as high brightness, reliability, lower power consumption and long lifetime. White LEDs are expected to serve in the next generation of lamps. An indoor visible-light communication system utilizing white LED lights has been proposed from our laboratory. In the proposed system, these devices are used not only for illuminating rooms but also for an optical wireless communication system. Generally, plural lights are installed in our room. So, their optical path difference must be considered. In this paper, we discuss about the influence of interference and reflection. Based on numerical analyses, we show that the system will expect as indoor communication of next generation(1).																			0098-3063	1558-4127				FEB	2004	50	1					100	107		10.1109/TCE.2004.1277847	http://dx.doi.org/10.1109/TCE.2004.1277847													WOS:000220257600015
J	Zhang, ML; Zhou, ZH				Zhang, Min-Ling; Zhou, Zhi-Hua			ML-KNN: A lazy learning approach to multi-label leaming	PATTERN RECOGNITION												Multi-label learning originated from the investigation of text categorization problem, where each document may belong to several predefined topics simultaneously. In multi-label learning, the training set is composed of instances each associated with a set of labels, and the task is to predict the label sets of unseen instances through analyzing training instances with known label sets. In this paper, a multi-label lazy learning approach named ML-KNN is presented, which is derived from the traditional K-nearest neighbor (KNN) algorithm. In detail, for each unseen instance, its K nearest neighbors in the training set are firstly identified. After that, based on statistical information gained from the label sets of these neighboring instances, i.e. the number of neighboring instances belonging to each possible class, maximum a posteriori (MAP) principle is utilized to determine the label set for the unseen instance. Experiments on three different real-world multi-label learning problems, i.e. Yeast gene functional analysis, natural scene classification and automatic web page categorization, show that ML-KNN achieves superior performance to some well-established multi-label learning algorithms. (c) 2007 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.					Zhang, Min-Ling/AAH-1958-2020	Zhang, Min-Ling/0000-0003-1880-5918													0031-3203	1873-5142				JUL	2007	40	7					2038	2048		10.1016/j.patcog.2006.12.019	http://dx.doi.org/10.1016/j.patcog.2006.12.019													WOS:000246332300016
J	Martìnez, AM; Kak, AC				Martìnez, AM; Kak, AC			PCA versus LDA	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												In the context of the appearance-based paradigm for object recognition, it is generally believed that algorithms based on LDA (Linear Discriminant Analysis) are superior to those based on PCA (Principal Components Analysis). in this communication, we show that this is not always the case. We present our case first by using intuitively plausible arguments and, then. by showing actual results on a face database. Our overall conclusion is that when the training data set is small, PCA can outperform LDA and, also, that PCA is less sensitive to different training data sets.					Martinez, Aleix/A-2380-2008														0162-8828	1939-3539				FEB	2001	23	2					228	233		10.1109/34.908974	http://dx.doi.org/10.1109/34.908974													WOS:000166933500013
J	Polyanskiy, Y; Poor, HV; Verdú, S				Polyanskiy, Yury; Poor, H. Vincent; Verdu, Sergio			Channel Coding Rate in the Finite Blocklength Regime	IEEE TRANSACTIONS ON INFORMATION THEORY												This paper investigates the maximal channel coding rate achievable at a given blocklength and error probability. For general classes of channels new achievability and converse bounds are given, which are tighter than existing bounds for wide ranges of parameters of interest, and lead to tight approximations of the maximal achievable rate for blocklengths n as short as 100. It is also shown analytically that the maximal rate achievable with error probability c is closely approximated by C -root V/n Q(-1()c) where C is the capacity, V is a characteristic of the channel referred to as channel dispersion, and Q is the complementary Gaussian cumulative distribution function.					Poor, H./S-5027-2016	Poor, H. Vincent/0000-0002-2062-131X													0018-9448	1557-9654				MAY	2010	56	5					2307	2359		10.1109/TIT.2010.2043769	http://dx.doi.org/10.1109/TIT.2010.2043769													WOS:000278067900019
J	Schwarz, H; Marpe, D; Wiegand, T				Schwarz, Heiko; Marpe, Detlev; Wiegand, Thomas			Overview of the Scalable Video Coding extension of the H.264/AVC standard	IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY												With the introduction of the H.264/AVC video coding standard, significant improvements have recently been demonstrated in video compression capability. The Joint Video Team of the ITU-T VCEG and the ISO/IEC MPEG has now also standardized a Scalable Video Coding (SVC) extension of the H.264/AVC standard. SVC enables the transmission and decoding of partial bit streams to provide video services with lower temporal or spatial resolutions or reduced fidelity while retaining a reconstruction quality that is high relative to the rate of the partial bit streams. Hence, SVC provides functionalities such as graceful degradation in lossy transmission environments as well as bit rate, format, and power adaptation. These functionalities provide enhancements to transmission and storage applications. SVC has achieved significant improvements in coding efficiency with an increased degree of supported scalability relative to the scalable profiles of prior video coding standards. This paper provides an overview of the basic concepts for extending H.264/AVC towards SVC. Moreover, the basic tools for providing temporal, spatial, and quality scalability are described in detail and experimentally analyzed regarding their efficiency and complexity.																			1051-8215	1558-2205				SEP	2007	17	9					1103	1120		10.1109/TCSVT.2007.905532	http://dx.doi.org/10.1109/TCSVT.2007.905532													WOS:000249774800003
J	Tropp, JA				Tropp, JA			Greed is good: Algorithmic results for sparse approximation	IEEE TRANSACTIONS ON INFORMATION THEORY												This article presents new results on using a greedy algorithm, orthogonal matching pursuit (OMP), to solve the sparse approximation problem over redundant dictionaries. It provides a sufficient condition under which both OMP and Donoho's basis pursuit (BP) paradigm can recover the optimal representation of an exactly sparse signal. It leverages this theory to show that both OMP and BP succeed for every sparse input signal from a wide class of dictionaries. These quasi-incoherent dictionaries offer a natural generalization of incoherent dictionaries, and the cumulative coherence function is introduced to quantify the level of incoherence. This analysis unifies all the recent results on BP and extends them to OMP. Furthermore, the paper develops a sufficient condition under which OMP can identify atoms from an optimal approximation of a nonsparse signal. From there, it argues that OMP is an approximation algorithm for the sparse problem over a quasi-incoherent dictionary. That is, for every input signal, OMP calculates a sparse approximant whose error is only a small factor worse than the minimal error that can be attained with the same number of terms.					Tropp, Joel/B-1283-2013	Tropp, Joel/0000-0003-1024-1791													0018-9448	1557-9654				OCT	2004	50	10					2231	2242		10.1109/TIT.2004.834793	http://dx.doi.org/10.1109/TIT.2004.834793													WOS:000224067600002
J	Wang, MY; Wang, XM; Guo, DM				Wang, MY; Wang, XM; Guo, DM			A level set method for structural topology optimization	COMPUTER METHODS IN APPLIED MECHANICS AND ENGINEERING												This paper presents a new approach to structural topology optimization. We represent the structural boundary by a level set model that is embedded in a scalar function of a higher dimension. Such level set models are flexible in handling complex topological changes and are concise in describing the boundary shape of the structure. Furthermore, a well-founded mathematical procedure leads to a numerical algorithm that describes a structural optimization as a sequence of motions of the implicit boundaries converging to an optimum solution and satisfying specified constraints. The result is a 3D topology optimization technique that demonstrates outstanding flexibility of handling topological changes, fidelity of boundary representation and degree of automation. We have implemented the algorithm with the use of several robust and efficient numerical techniques of level set methods. The benefit and the advantages of the proposed method are illustrated with several 2D examples that are widely used in the recent literature of topology optimization, especially in the homogenization based methods. (C) 2002 Elsevier Science B.V. All rights reserved.					Wang, Michael/C-2219-2009														0045-7825	1879-2138					2003	192	1-2					227	246	PII S0045-7825(02)00559-5	10.1016/S0045-7825(02)00559-5	http://dx.doi.org/10.1016/S0045-7825(02)00559-5													WOS:000180348100012
J	Ngo, HQ; Larsson, EG; Marzetta, TL				Hien Quoc Ngo; Larsson, Erik G.; Marzetta, Thomas L.			Energy and Spectral Efficiency of Very Large Multiuser MIMO Systems	IEEE TRANSACTIONS ON COMMUNICATIONS												A multiplicity of autonomous terminals simultaneously transmits data streams to a compact array of antennas. The array uses imperfect channel-state information derived from transmitted pilots to extract the individual data streams. The power radiated by the terminals can be made inversely proportional to the square-root of the number of base station antennas with no reduction in performance. In contrast if perfect channel-state information were available the power could be made inversely proportional to the number of antennas. Lower capacity bounds for maximum-ratio combining (MRC), zero-forcing (ZF) and minimum mean-square error (MMSE) detection are derived. An MRC receiver normally performs worse than ZF and MMSE. However as power levels are reduced, the cross-talk introduced by the inferior maximum-ratio receiver eventually falls below the noise level and this simple receiver becomes a viable option. The tradeoff between the energy efficiency (as measured in bits/J) and spectral efficiency (as measured in bits/channel use/terminal) is quantified for a channel model that includes small-scale fading but not large-scale fading. It is shown that the use of moderately large antenna arrays can improve the spectral and energy efficiency with orders of magnitude compared to a single-antenna system.					Marzetta, Thomas/AEB-0112-2022; Ngo, Hien/AAJ-5745-2020; Larsson, Erik/ADV-7383-2022														0090-6778	1558-0857				APR	2013	61	4					1436	1449		10.1109/TCOMM.2013.020413.110848	http://dx.doi.org/10.1109/TCOMM.2013.020413.110848													WOS:000318998100022
J	Kundur, P; Paserba, J; Ajjarapu, V; Andersson, G; Bose, A; Canizares, C; Hatziargyriou, N; Hill, D; Stankovic, A; Taylor, C; Van Cutsem, T; Vittal, V				Kundur, P; Paserba, J; Ajjarapu, V; Andersson, G; Bose, A; Canizares, C; Hatziargyriou, N; Hill, D; Stankovic, A; Taylor, C; Van Cutsem, T; Vittal, V			Definition and classification of power system stability	IEEE TRANSACTIONS ON POWER SYSTEMS												The problem of defining and classifying power system stability has been addressed by several previous CIGRE and IEEE Task Force reports. These earlier efforts, however, do not completely reflect current industry needs, experiences and understanding. In particular, the definitions are not precise and the classifications do not encompass all practical instability scenarios. This report developed by a Task Force, set up jointly by the CIGRE Study Committee 38 and the IEEE Power System Dynamic Performance Committee, addresses the issue of stability definition and classification in power systems from a fundamental viewpoint and closely examines the practical ramifications. The report aims to define power system stability more precisely, provide a systematic basis for its classification, and discuss linkages to related issues such as power system reliability and security.					Hatziargyriou, Nikos/AAA-3899-2021; Vittal, Vijay/AAP-8220-2020; Hill, David/AAG-2576-2019; Stankovic, Alex/G-6539-2013; Hill, David John/L-2218-2013	Hill, David John/0000-0003-4036-0839; Stankovic, Alex/0000-0002-5144-8580													0885-8950	1558-0679				AUG	2004	19	3					1387	1401		10.1109/TPWRS.2004.825981	http://dx.doi.org/10.1109/TPWRS.2004.825981													WOS:000222975800018
J	Satyanarayanan, M; Bahl, P; Cáceres, R; Davies, N				Satyanarayanan, Mahadev; Bahl, Paramvir; Caceres, Ramon; Davies, Nigel			The Case for VM-Based Cloudlets in Mobile Computing	IEEE PERVASIVE COMPUTING																		Satyanarayanan, Mahadev/0000-0002-2187-2049; Davies, Nigel/0000-0002-4136-5300													1536-1268	1558-2590				OCT-DEC	2009	8	4					14	23		10.1109/MPRV.2009.82	http://dx.doi.org/10.1109/MPRV.2009.82													WOS:000270818700004
J	Scrosati, B; Hassoun, J; Sun, YK				Scrosati, Bruno; Hassoun, Jusef; Sun, Yang-Kook			Lithium-ion batteries. A look into the future	ENERGY & ENVIRONMENTAL SCIENCE												A critical overview of the latest developments in the lithium ion batteries technology is reported. We first describe the evolution in the electrolyte area with particular attention to ionic liquids, discussing the expected application of these room temperature molten salts and listing the issues that still prevent their practical implementation. The attention is then focused on the electrode materials presently considered the most promising for enhancing the energy density of the batteries. At the anode side a discussion is provided on the status of development of high capacity tin and silicon lithium alloys. We show that the morphology that is the most likely to ensure commercial exploitation of these alloy electrodes is that involving carbon-based nanocomposites. We finally touch on super-high-capacity batteries, discussing the key cases of lithium-sulfur and lithium-air and attempting to forecast their chances to eventually reach the status of practically appealing energy storage systems. We conclude with a brief reflection on the amount of lithium reserves in view of its large use in the case of global conversion from gasoline-powered cars to hybrid and electric cars.					Sun, Yang-Kook/B-9157-2013; Hassoun, Jusef/J-9951-2017; Scrosati, Bruno/C-7768-2014	Sun, Yang-Kook/0000-0002-0117-0170; Hassoun, Jusef/0000-0002-8218-5680													1754-5692	1754-5706				SEP	2011	4	9					3287	3295		10.1039/c1ee01388b	http://dx.doi.org/10.1039/c1ee01388b													WOS:000294306900013
J	Arasaratnam, I; Haykin, S				Arasaratnam, Ienkaran; Haykin, Simon			Cubature Kalman Filters	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												In this paper, we present a new nonlinear filter for high-dimensional state estimation, which we have named the cubature Kalman filter (CKF). The heart of the CKF is a spherical-radial cubature rule, which makes it possible to numerically compute multivariate moment integrals encountered in the nonlinear Bayesian filter. Specifically, we derive a third-degree spherical-radial cubature rule that provides a set of cubature points scaling linearly with the state-vector dimension. The CKF may therefore provide a systematic solution for high-dimensional nonlinear filtering problems. The paper also includes the derivation of a square-root version of the CKF for improved numerical stability. The CKF is tested experimentally in two nonlinear state estimation problems. In the first problem, the proposed cubature rule is used to compute the second-order statistics of a nonlinearly transformed Gaussian random variable. The second problem addresses the use of the CKF for tracking a maneuvering aircraft. The results of both experiments demonstrate the improved performance of the CKF over conventional nonlinear filters.																			0018-9286	1558-2523				JUN	2009	54	6					1254	1269		10.1109/TAC.2009.2019800	http://dx.doi.org/10.1109/TAC.2009.2019800													WOS:000267064000007
J	Czernik, S; Bridgwater, AV				Czernik, S; Bridgwater, AV			Overview of applications of biomass fast pyrolysis oil	ENERGY & FUELS												Fast pyrolysis of biomass is one of the most recent renewable energy processes to have been introduced. It offers the advantages of a liquid product, bio-oil that can be readily stored and transported. Bio-oil is a renewable liquid fuel and can also be used for production of chemicals. Fast pyrolysis has now achieved a commercial success for production of chemicals and is being actively developed for producing liquid fuels. Bio-oils have been successfully tested in engines, turbines, and boilers, and have been upgraded to high-quality hydrocarbon fuels, although at a presently unacceptable energetic and financial cost. The paper critically reviews scientific and technical developments in applications of bio-oil to date and concludes with some suggestions for research and strategic developments.					Bridgwater, Tony/ABE-1659-2020	Bridgwater, Tony/0000-0001-7362-6205													0887-0624					MAR-APR	2004	18	2					590	598		10.1021/ef034067u	http://dx.doi.org/10.1021/ef034067u													WOS:000220287400041
J	Konak, A; Coit, DW; Smith, AE				Konak, Abdullah; Coit, David W.; Smith, Alice E.			Multi-objective optimization using genetic algorithms: A tutorial	RELIABILITY ENGINEERING & SYSTEM SAFETY												Multi-objective formulations are realistic models for many complex engineering optimization problems. In many real-life problems, objectives under consideration conflict with each other, and optimizing a particular solution with respect to a single objective can result in unacceptable results with respect to the other objectives. A reasonable solution to a multi-objective problem is to investigate a set of solutions, each of which satisfies the objectives at an acceptable level without being dominated by any other solution. In this paper, an overview and tutorial is presented describing genetic algorithms (GA) developed specifically for problems with multiple objectives. They differ primarily from traditional GA by using specialized fitness functions and introducing methods to promote solution diversity. (C) 2005 Elsevier Ltd. All rights reserved.					Smith, Alice/AAK-2318-2021	Smith, Alice/0000-0001-8808-0663; Konak, Abdullah/0000-0001-6250-7825													0951-8320	1879-0836				SEP	2006	91	9					992	1007		10.1016/j.ress.2005.11.018	http://dx.doi.org/10.1016/j.ress.2005.11.018													WOS:000239648900003
J	Xuan, YM; Roetzel, W				Xuan, YM; Roetzel, W			Conceptions for heat transfer correlation of nanofluids	INTERNATIONAL JOURNAL OF HEAT AND MASS TRANSFER												The nanofluid is a solid-liquid mixture in which metallic or nonmetallic nanoparticles are suspended. The suspended ultrafine particles change transport properties and heat transfer performance of the nanofluid, which exhibits a great potential in enhancing heat transfer. The mechanism of heat transfer enhancement of the nanofluid is investigated. Based on the assumption that the nanofluid behaves more like a fluid rather than a conventional solid-fluid mixture, this article proposes two different approaches for deriving heat transfer correlation of the nanofluid. The effects of transport properties of the nanofluid and thermal dispersion are included. (C) 2000 Elsevier Science Ltd, All rights reserved.																			0017-9310	1879-2189				OCT	2000	43	19					3701	3707		10.1016/S0017-9310(99)00369-5	http://dx.doi.org/10.1016/S0017-9310(99)00369-5													WOS:000088479100016
J	Spencer, QH; Swindlehurst, AL; Haardt, M				Spencer, QH; Swindlehurst, AL; Haardt, M			Zero-forcing methods for downlink spatial multiplexing in multiuser MIMO channels	IEEE TRANSACTIONS ON SIGNAL PROCESSING												The use of space-division multiple access (SDMA) in the downlink of a multiuser multiple-input, multiple-output (MIMO) wireless communications network can provide a substantial gain in system throughput. The challenge in such, multiuser systems is designing transmit vectors while considering the co-channel interference of other users. Typical optimization problems of interest include the capacity problem-maximizing the sum information rate subject to a power constraint-or the power control problem-minimizing transmitted power such that a certain quality-of-service metric for each user is met. Neither of these problems possess closed-form solutions for the general multiuser MIMO channel, but the imposition of certain constraints can lead to closed-form solutions. This paper presents two such constrained solutions. The first, referred to as "block-diagonalization," is a generalization of channel inversion when there are multiple antennas at each receiver. It is easily adapted to optimize for either maximum transmission rate or minimum power and approaches the optimal solution at high SNR. The second, known as "successive optimization," is an alternative method for solving the power minimization problem one user at a time, and it yields superior results in some (e.g., low SNR) situations. Both of these algorithms are limited to cases where the transmitter has more antennas than all receive antennas combined. In order to accommodate more general scenarios, we also propose a framework for coordinated transmitter-receiver processing that generalizes the two algorithms to cases involving more receive than transmit antennae. While the proposed algorithms are suboptimal, they lead to simpler transmitter and receiver structures and allow for a reasonable tradeoff between performance and complexity.					Haardt, Martin/B-5857-2011; Swindlehurst, A. Lee/J-4806-2017	Swindlehurst, A. Lee/0000-0002-0521-3107													1053-587X	1941-0476				FEB	2004	52	2					461	471		10.1109/TSP.2003.821107	http://dx.doi.org/10.1109/TSP.2003.821107													WOS:000188209700013
J	Park, P; Ko, JW; Jeong, C				Park, PooGyeon; Ko, Jeong Wan; Jeong, Changki			Reciprocally convex approach to stability of systems with time-varying delays	AUTOMATICA												Whereas the upper bound lemma for matrix cross-product, introduced by Park (1999) and modified by Moon, Park, Kwon, and Lee (2001), plays a key role in guiding various delay-dependent criteria for delayed systems, the Jensen inequality has become an alternative as a way of reducing the number of decision variables. It directly relaxes the integral term of quadratic quantities into the quadratic term of the integral quantities, resulting in a linear combination of positive functions weighted by the inverses of convex parameters. This paper suggests the lower bound lemma for such a combination, which achieves performance behavior identical to approaches based on the integral inequality lemma but with much less decision variables, comparable to those based on the Jensen inequality lemma. (C) 2010 Elsevier Ltd. All rights reserved.					PARK, POOGYEON/C-1589-2013	Park, PooGyeon/0000-0002-8249-5427													0005-1098					JAN	2011	47	1					235	238		10.1016/j.automatica.2010.10.014	http://dx.doi.org/10.1016/j.automatica.2010.10.014													WOS:000286704500029
J	Keiluweit, M; Nico, PS; Johnson, MG; Kleber, M				Keiluweit, Marco; Nico, Peter S.; Johnson, Mark G.; Kleber, Markus			Dynamic Molecular Structure of Plant Biomass-Derived Black Carbon (Biochar)	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Char black carbon (BC), the solid residue of incomplete combustion, is continuously being added to soils and sediments due to natural vegetation fires, anthropogenic pollution, and new strategies for carbon sequestration ("biochar"). Here we present a molecular-level assessment of the physical organization and chemical complexity of biomass-derived chars and, specifically, that of aromatic carbon in char structures. Brunauer-Emmett-Teller (BET)-N-2 surface area (SA), X-ray diffraction (XRD), synchrotron-based near-edge X-ray absorption fine structure (NEXAFS), and Fourier transform infrared (FT-IR) spectroscopy are used to show how two plant materials (wood and grass) undergo analogous but quantitatively different physical-chemical transitions as charring temperature increases from 100 to 700 degrees C. These changes suggest the existence of four distinct categories of char consisting of a unique mixture of chemical phases and physical states: (i) in transition chars,the crystalline character of the precursor materials is preserved; (ii) in amorphous chars, the heat-altered molecules and incipient aromatic polycondensates are randomly mixed; (iii) composite chars consist of poorly ordered graphene stacks embedded in amorphous phases; and (iv) turbostratic chars are dominated by disordered graphitic crystallites. Molecular variations among the different char categories likely translate into differences in their ability to persist in the environment and function as environmental sorbents.					Kleber, Markus/M-1381-2019; Keiluweit, Marco/ABA-1814-2021; Nico, Peter/F-6997-2010	Keiluweit, Marco/0000-0002-7061-8346; Nico, Peter/0000-0002-4180-9397													0013-936X	1520-5851				FEB 15	2010	44	4					1247	1253		10.1021/es9031419	http://dx.doi.org/10.1021/es9031419								20099810					WOS:000274347800016
J	Cadambe, VR; Jafar, SA				Cadambe, Viveck R.; Jafar, Syed Ali			Interference alignment and degrees of freedom of the <i>K</i>-user interference channel	IEEE TRANSACTIONS ON INFORMATION THEORY					45th Annual Allerton Conference on Communication, Control and Computing	SEP, 2007	Monticello, IL					For the fully connected K user wireless interference channel where the channel coefficients are time-varying and are drawn from a continuous distribution, the sum capacity is characterized as C(SNR) = K/2 log(SNR) + o(log(SNR)). Thus, the K user time-varying interference channel almost surely has K/2 degrees of freedom. Achievability is based on the idea of interference alignment. Examples are also provided of fully connected K user interference channels with constant (not time-varying) coefficients where the capacity is exactly achieved by interference alignment at all SNR values.					Jafar, Syed/G-2477-2010	Jafar, Syed/0000-0003-2038-2977; Cadambe, Viveck/0000-0001-6786-8785													0018-9448	1557-9654				AUG	2008	54	8					3425	3441		10.1109/TIT.2008.926344	http://dx.doi.org/10.1109/TIT.2008.926344													WOS:000257861400004
J	Zhou, BL; Lapedriza, A; Khosla, A; Oliva, A; Torralba, A				Zhou, Bolei; Lapedriza, Agata; Khosla, Aditya; Oliva, Aude; Torralba, Antonio			Places: A 10 Million Image Database for Scene Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												The rise of multi-million-item dataset initiatives has enabled data-hungry machine learning algorithms to reach near-human semantic classification performance at tasks such as visual object and scene recognition. Here we describe the Places Database, a repository of 10 million scene photographs, labeled with scene semantic categories, comprising a large and diverse list of the types of environments encountered in the world. Using the state-of-the-art Convolutional Neural Networks (CNNs), we provide scene classification CNNs (Places-CNNs) as baselines, that significantly outperform the previous approaches. Visualization of the CNNs trained on Places shows that object detectors emerge as an intermediate representation of scene classification. With its high-coverage and high-diversity of exemplars, the Places Database along with the Places-CNNs offer a novel resource to guide future progress on scene recognition problems.						Zhou, Bolei/0000-0003-4030-0684; Lapedriza, Agata/0000-0002-5248-0443													0162-8828	1939-3539				JUN	2018	40	6					1452	1464		10.1109/TPAMI.2017.2723009	http://dx.doi.org/10.1109/TPAMI.2017.2723009								28692961					WOS:000431524700013
J	Xuan, YM; Li, Q				Xuan, YM; Li, Q			Heat transfer enhancement of nanofluids	INTERNATIONAL JOURNAL OF HEAT AND FLUID FLOW												This paper presents a procedure for preparing a nanofluid which is a suspension consisting of nanophase powders and a base liquid. By means of the procedure, some sample nanofluids are prepared. Their TEM photographs are given to illustrate the stability and evenness of suspension. The theoretical study of the thermal conductivity of nanofluids is introduced. The hot-wire apparatus is used to measure the thermal conductivity of nanofluids with suspended copper nanophase powders. Some factors such as the volume fraction, dimensions, shapes and properties of the nanoparticles are discussed. A theoretical model is proposed to describe heat transfer performance of the nanofluid flowing in a tube, with accounting for dispersion of solid particles; (C) 2000 Elsevier Science Inc. All rights reserved.																			0142-727X	1879-2278				FEB	2000	21	1					58	64		10.1016/S0142-727X(99)00067-3	http://dx.doi.org/10.1016/S0142-727X(99)00067-3													WOS:000086271100007
J	Peng, FZ				Peng, FZ			Z-source inverter	IEEE TRANSACTIONS ON INDUSTRY APPLICATIONS					Annual Meeting of the Industry-Applications-Society	OCT 13-18, 2002	PITTSBURGH, PENNSYLVANIA	Ind Applicat Soc				This paper presents an impedance-source (or impedance-fed) power converter (abbreviated as Z-source converter) and its control method for implementing dc-to-ac, ac-to-dc, ac-to-ac, and dc-to-dc power conversion. The Z-source converter employs a unique impedance network (or circuit) to couple the converter main circuit to the power source, thus providing unique features that cannot be obtained in the traditional voltage-source (or voltage-fed) and current-source (or current-fed) converters where a capacitor and inductor are used, respectively. The Z-source converter overcomes the conceptual and theoretical barriers and limitations of the traditional voltage-source converter (abbreviated as V-source converter) and current-source converter (abbreviated as I-source converter) and provides a,novel power conversion concept. The Z-source concept can be applied to all dc-to-ac, ac-to-dc, ac-to-ac, and dc-to-dc power conversion. To describe the operating principle and control, this paper focuses on an example: a Z-source inverter for dc-ac power conversion needed in fuel cell applications. Simulation and experimental results will be presented to demonstrate the new features.																			0093-9994					MAR-APR	2003	39	2					504	510		10.1109/TIA.2003.808920	http://dx.doi.org/10.1109/TIA.2003.808920													WOS:000181757500026
J	Mirjalili, S				Mirjalili, Seyedali			The Ant Lion Optimizer	ADVANCES IN ENGINEERING SOFTWARE												This paper proposes a novel nature-inspired algorithm called Ant Lion Optimizer (ALO). The ALO algorithm mimics the hunting mechanism of antlions in nature. Five main steps of hunting prey such as the random walk of ants, building traps, entrapment of ants in traps, catching preys, and re-building traps are implemented. The proposed algorithm is benchmarked in three phases. Firstly, a set of 19 mathematical functions is employed to test different characteristics of ALO. Secondly, three classical engineering problems (three-bar truss design, cantilever beam design, and gear train design) are solved by ALO. Finally, the shapes of two ship propellers are optimized by ALO as challenging constrained real problems. In the first two test phases, the ALO algorithm is compared with a variety of algorithms in the literature. The results of the test functions prove that the proposed algorithm is able to provide very competitive results in terms of improved exploration, local optima avoidance, exploitation, and convergence. The ALO algorithm also finds superior optimal designs for the majority of classical engineering problems employed, showing that this algorithm has merits in solving constrained problems with diverse search spaces. The optimal shapes obtained for the ship propellers demonstrate the applicability of the proposed algorithm in solving real problems with unknown search spaces as well. Note that the source codes of the proposed ALO algorithm are publicly available at http://www.alimirjalili.com/ALO.html. (C) 2015 Elsevier Ltd. All rights reserved.					Mirjalili, Seyedali/P-1372-2018	Mirjalili, Seyedali/0000-0002-1443-9458													0965-9978	1873-5339				MAY	2015	83						80	98		10.1016/j.advengsoft.2015.01.010	http://dx.doi.org/10.1016/j.advengsoft.2015.01.010													WOS:000351798000008
J	Bemporad, A; Morari, M; Dua, V; Pistikopoulos, EN				Bemporad, A; Morari, M; Dua, V; Pistikopoulos, EN			The explicit linear quadratic regulator for constrained systems	AUTOMATICA												For discrete-time linear time invariant systems with constraints on inputs and states, we develop an algorithm to determine explicitly, the state feedback control law which minimizes a quadratic performance criterion. We show that the control law is piece-wise linear and continuous for both the finite horizon problem (model predictive control) and the usual infinite time measure (constrained linear quadratic regulation). Thus, the on-line control computation reduces to the simple evaluation of an explicitly defined piecewise linear function. By computing the inherent underlying controller structure, we also solve the equivalent of the Hamilton-Jacobi-Bellman equation for discrete-time linear constrained systems. Control based on on-line optimization has long been recognized as a superior alternative for constrained systems, The technique proposed in this paper is attractive for a wide range of practical problems where the computational complexity of on-line optimization is prohibitive. It also provides an insight into the structure underlying optimization-based controllers. (C) 2001 Elsevier Science Ltd. All rights reserved.					Dua, Vivek/A-1750-2009; Bemporad, Alessandro/D-1507-2018	Pistikopoulos, Stratos/0000-0001-6220-818X; Dua, Vivek/0000-0002-0165-7421													0005-1098					JAN	2002	38	1					3	20		10.1016/S0005-1098(01)00174-1	http://dx.doi.org/10.1016/S0005-1098(01)00174-1													WOS:000172541600002
J	Elhamifar, E; Vidal, R				Elhamifar, Ehsan; Vidal, Rene			Sparse Subspace Clustering: Algorithm, Theory, and Applications	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Many real-world problems deal with collections of high-dimensional data, such as images, videos, text, and web documents, DNA microarray data, and more. Often, such high-dimensional data lie close to low-dimensional structures corresponding to several classes or categories to which the data belong. In this paper, we propose and study an algorithm, called sparse subspace clustering, to cluster data points that lie in a union of low-dimensional subspaces. The key idea is that, among the infinitely many possible representations of a data point in terms of other points, a sparse representation corresponds to selecting a few points from the same subspace. This motivates solving a sparse optimization program whose solution is used in a spectral clustering framework to infer the clustering of the data into subspaces. Since solving the sparse optimization program is in general NP-hard, we consider a convex relaxation and show that, under appropriate conditions on the arrangement of the subspaces and the distribution of the data, the proposed minimization program succeeds in recovering the desired sparse representations. The proposed algorithm is efficient and can handle data points near the intersections of subspaces. Another key advantage of the proposed algorithm with respect to the state of the art is that it can deal directly with data nuisances, such as noise, sparse outlying entries, and missing entries, by incorporating the model of the data into the sparse optimization program. We demonstrate the effectiveness of the proposed algorithm through experiments on synthetic data as well as the two real-world problems of motion segmentation and face clustering.					Vidal, Rene/A-3367-2010														0162-8828	1939-3539				NOV	2013	35	11					2765	2781		10.1109/TPAMI.2013.57	http://dx.doi.org/10.1109/TPAMI.2013.57								24051734					WOS:000324830900015
J	Wong, HSP; Lee, HY; Yu, SM; Chen, YS; Wu, Y; Chen, PS; Lee, B; Chen, FT; Tsai, MJ				Wong, H. -S. Philip; Lee, Heng-Yuan; Yu, Shimeng; Chen, Yu-Sheng; Wu, Yi; Chen, Pang-Shiu; Lee, Byoungil; Chen, Frederick T.; Tsai, Ming-Jinn			Metal-Oxide RRAM	PROCEEDINGS OF THE IEEE												In this paper, recent progress of binary metal-oxide resistive switching random access memory (RRAM) is reviewed. The physical mechanism, material properties, and electrical characteristics of a variety of binary metal-oxide RRAM are discussed, with a focus on the use of RRAM for nonvolatile memory application. A review of recent development of large-scale RRAM arrays is given. Issues such as uniformity, endurance, retention, multibit operation, and scaling trends are discussed.					Chen, Yu-Li/K-7063-2015; , shen/GXH-0183-2022; Huang, James/ADK-6342-2022; Wu, Yi/D-9414-2014; Yu, Shimeng/D-5704-2012; Blankert, Jean Philippe/C-3008-2017	Yu, Shimeng/0000-0002-0068-3652; Blankert, Jean Philippe/0000-0001-5955-580X													0018-9219	1558-2256				JUN	2012	100	6			SI		1951	1970		10.1109/JPROC.2012.2190369	http://dx.doi.org/10.1109/JPROC.2012.2190369													WOS:000309840600006
J	Herrera, F; Martínez, L				Herrera, F; Martínez, L			A 2-tuple fuzzy linguistic representation model for computing with words	IEEE TRANSACTIONS ON FUZZY SYSTEMS												The fuzzy linguistic approach has been applied successfully to many problems, However, there is a limitation of this approach imposed by its information representation model and the computation methods used when fusion processes are performed on linguistic values, This limitation is the loss of information caused by the need to express the results in the initial expression domain that is discrete via an approximate process. This loss of information implies a lack of precision in the final results from the fusion of linguistic information. In this paper, we present tools for overcoming this limitation, The linguistic information will be expressed by means of 2-tuples, which are composed by a linguistic term and a numeric value assessed in [-0.5, 0.5), This model allows a continuous representation of the linguistic information on its domain, therefore, it-can represent any counting of information obtained in a aggregation process. Together with the 2-tuple representation model we shall develop a computational technique for computing with words (CW) without any loss of information. Finally, different classical aggregation operators will be extended to deal with the 2-tuple linguistic model.					Herrera, Francisco/K-9019-2017; Martinez, Luis/A-1746-2009	Martinez, Luis/0000-0003-4245-8813; Herrera, Francisco/0000-0002-7283-312X													1063-6706					DEC	2000	8	6					746	752		10.1109/91.890332	http://dx.doi.org/10.1109/91.890332													WOS:000165855600008
J	Bletsas, A; Khisti, A; Reed, DP; Lippman, A				Bletsas, A; Khisti, A; Reed, DP; Lippman, A			A simple cooperative diversity method based on network path selection	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS												Cooperative diversity has been recently proposed as a way to form virtual antenna arrays that provide dramatic gains in slow fading wireless environments. However, most of the proposed solutions require distributed space-time coding algorithms, the careful design of which is left for future investigation if there is more than one cooperative relay. We propose a novel scheme that alleviates these problems and provides diversity gains on the order of the number of relays in the network. Our scheme first selects the best relay from a set of M available relays and then uses this "best" relay for cooperation between the source and the destination. We develop and analyze a distributed method to select the best relay that requires no topology information and is based on local measurements of the instantaneous channel conditions. This method also requires no explicit communication among the relays. The success (or failure) to select the best available path depends on the statistics of the wireless channel, and a methodology to evaluate performance for any kind of wireless channel statistics, is provided. Information theoretic analysis of outage probability shows that our scheme achieves the same diversity-multiplexing tradeoff as achieved by more complex protocols, where coordination and distributed space-time coding for M relay nodes is required, such as those proposed by Laneman and Wornell (2003). The simplicity of the technique allows for immediate implementation in existing radio hardware and its adoption could provide for improved flexibility, reliability, and efficiency in future 4G wireless systems.					Khisti, Ashish/F-9908-2010; Bletsas, Aggelos/AAU-3892-2021														0733-8716	1558-0008				MAR	2006	24	3					659	672		10.1109/JSAC.2005.862417	http://dx.doi.org/10.1109/JSAC.2005.862417													WOS:000236289300023
J	Huang, CW; Zappone, A; Alexandropoulos, GC; Debbah, M; Yuen, C				Huang, Chongwen; Zappone, Alessio; Alexandropoulos, George C.; Debbah, Merouane; Yuen, Chau			Reconfigurable Intelligent Surfaces for Energy Efficiency in Wireless Communication	IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS												The adoption of a reconfigurahle intelligent surface (RIS) for downlink multi-user communication from a multi-antenna base station is investigated in this paper. We develop energy-efficient designs for both the transmit power allocation and the phase shifts of the surface reflecting elements subject to individual link budget guarantees for the mobile users. This leads to non-convex design optimization problems for which to tackle we propose two computationally affordable approaches, capitalizing on alternating maximization, gradient descent search, and sequential fractional programming. Specifically, one algorithm employs gradient descent for obtaining the RIS phase coefficients, and fractional programming for optimal transmit power allocation. Instead, the second algorithm employs sequential fractional programming for the optimization of the RIS phase shifts. In addition, a realistic power consumption model for RIS-based systems is presented, and the performance of the proposed methods is analyzed in a realistic outdoor environment. In particular, our results show that the proposed RIS-based resource allocation methods are able to provide up to 300% higher energy efficiency in comparison with the use of regular multi-antenna amplify-and-forward relaying.					Alexandropoulos, George/JCE-5800-2023; An, Jiancheng/ABW-9188-2022; Huang, chongwen/V-4540-2019; Debbah, Merouane/B-6261-2011; Yuen, Chau/C-5493-2013	Yuen, Chau/0000-0002-9307-2120; Huang, Chongwen/0000-0001-8398-8437; Alexandropoulos, George/0000-0002-6587-1371; Debbah, Merouane/0000-0001-8941-8080													1536-1276	1558-2248				AUG	2019	18	8					4157	4170		10.1109/TWC.2019.2922609	http://dx.doi.org/10.1109/TWC.2019.2922609													WOS:000480661000028
J	Sze, V; Chen, YH; Yang, TJ; Emer, JS				Sze, Vivienne; Chen, Yu-Hsin; Yang, Tien-Ju; Emer, Joel S.			Efficient Processing of Deep Neural Networks: A Tutorial and Survey	PROCEEDINGS OF THE IEEE												Deep neural networks (DNNs) are currently widely used for many artificial intelligence (AI) applications including computer vision, speech recognition, and robotics. While DNNs deliver state-of-the-art accuracy on many AI tasks, it comes at the cost of high computational complexity. Accordingly, techniques that enable efficient processing of DNNs to improve energy efficiency and throughput without sacrificing application accuracy or increasing hardware cost are critical to the wide deployment of DNNs in AI systems. This article aims to provide a comprehensive tutorial and survey about the recent advances toward the goal of enabling efficient processing of DNNs. Specifically, it will provide an overview of DNNs, discuss various hardware platforms and architectures that support DNNs, and highlight key trends in reducing the computation cost of DNNs either solely via hardware design changes or via joint hardware design and DNN algorithm changes. It will also summarize various development resources that enable researchers and practitioners to quickly get started in this field, and highlight important benchmarking metrics and design considerations that should be used for evaluating the rapidly growing number of DNN hardware designs, optionally including algorithmic codesigns, being proposed in academia and industry. The reader will take away the following concepts from this article: understand the key design considerations for DNNs; be able to evaluate different DNN hardware implementations with benchmarks and comparison metrics; understand the tradeoffs between various hardware architectures and platforms; be able to evaluate the utility of various DNN design techniques for efficient processing; and understand recent implementation trends and opportunities.						/0000-0002-3459-5466													0018-9219	1558-2256				DEC	2017	105	12					2295	2329		10.1109/JPROC.2017.2761740	http://dx.doi.org/10.1109/JPROC.2017.2761740													WOS:000416244800002
J	Christidis, K; Devetsikiotis, M				Christidis, Konstantinos; Devetsikiotis, Michael			Blockchains and Smart Contracts for the Internet of Things	IEEE ACCESS												Motivated by the recent explosion of interest around blockchains, we examine whether they make a good fit for the Internet of Things (IoT) sector. Blockchains allow us to have a distributed peer-to-peer network where non-trusting members can interact with each other without a trusted intermediary, in a verifiable manner. We review how this mechanism works and also look into smart contracts-scripts that reside on the blockchain that allow for the automation of multi-step processes. We then move into the IoT domain, and describe how a blockchain-IoT combination: 1) facilitates the sharing of services and resources leading to the creation of a marketplace of services between devices and 2) allows us to automate in a cryptographically verifiable manner several existing, time-consuming workflows. We also point out certain issues that should be considered before the deployment of a blockchain network in an IoT setting: from transactional privacy to the expected value of the digitized assets traded on the network. Wherever applicable, we identify solutions and workarounds. Our conclusion is that the blockchain-IoT combination is powerful and can cause significant transformations across several industries, paving the way for new business models and novel, distributed applications.																			2169-3536						2016	4						2292	2303		10.1109/ACCESS.2016.2566339	http://dx.doi.org/10.1109/ACCESS.2016.2566339													WOS:000402029000001
J	Al-Karaki, JN; Kamal, AE				Al-Karaki, JN; Kamal, AE			Routing techniques in wireless sensor networks: A survey	IEEE WIRELESS COMMUNICATIONS												Wireless sensor networks consist of small nodes with sensing, computation, and wireless communications capabilities. Many routing, power management, and data dissemination protocols have been specifically designed for WSNs where energy awareness is an essential design issue. Routing protocols in WSNs might differ depending on the application and network architecture. In this article we present a survey of state-of-the-art routing techniques in WSNs. We first outline the design challenges for routing protocols in WSNs followed by a comprehensive survey of routing techniques. Overall, the routing techniques are classified into three categories based on the underlying network structure: flit, hierarchical, and location-based routing. Furthermore, these protocols can be classified into multipath-based, query-based, negotiation-based, QoS-based, and coherent-based depending on the protocol operation. We study the design trade-offs between energy and communication overhead savings in every routing paradigm. We also highlight the advantages and performance issues of each routing technique. The article concludes with possible future research areas.					Al-Karaki, Jamal/HKF-7177-2023														1536-1284	1558-0687				DEC	2004	11	6					6	28		10.1109/MWC.2004.1368893	http://dx.doi.org/10.1109/MWC.2004.1368893													WOS:000225807500003
J	Kamnitsas, K; Ledig, C; Newcombe, VFJ; Sirnpson, JP; Kane, AD; Menon, DK; Rueckert, D; Glocker, B				Kamnitsas, Konstantinos; Ledig, Christian; Newcombe, Virginia F. J.; Sirnpson, Joanna P.; Kane, Andrew D.; Menon, David K.; Rueckert, Daniel; Glocker, Ben			Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation	MEDICAL IMAGE ANALYSIS												We propose a dual pathway, 11-layers deep, three-dimensional Convolutional Neural Network for the challenging task of brain lesion segmentation. The devised architecture is the result of an in-depth analysis of the limitations of current networks proposed for similar applications. To overcome the computational burden of processing 3D medical scans, we have devised an efficient and effective dense training scheme which joins the processing of adjacent image patches into one pass through the network while automatically adapting to the inherent class imbalance present in the data. Further, we analyze the development of deeper, thus more discriminative 3D CNNs. In order to incorporate both local and larger contextual information, we employ a dual pathway architecture that processes the input images at multiple scales simultaneously. For post-processing of the network's soft segmentation, we use a 3D fully connected Conditional Random Field which effectively removes false positives. Our pipeline is extensively evaluated on three challenging tasks of lesion segmentation in multi-channel MRI patient data with traumatic brain injuries, brain tumours, and ischemic stroke. We improve on the state-of-the-art for all three applications, with top ranking performance on the public benchmarks BRATS 2015 and ISLES 2015. Our method is computationally efficient, which allows its adoption in a variety of research and clinical settings. The source code of our implementation is made publicly available. (C) 2016 The Authors. Published by Elsevier B.V.					Rueckert, Daniel/C-4393-2008; Menon, David/AEX-7615-2022; Kane, Andrew/C-5876-2013	Glocker, Ben/0000-0002-4897-9356; Kane, Andrew/0000-0001-9488-4086; Ledig, Christian/0000-0003-4862-3138; Kamnitsas, Konstantinos/0000-0003-3281-6509; Newcombe, Virginia/0000-0001-6044-9035													1361-8415	1361-8423				FEB	2017	36						61	78		10.1016/j.media.2016.10.004	http://dx.doi.org/10.1016/j.media.2016.10.004								27865153					WOS:000393247900007
J	Roundy, S; Wright, PK; Rabaey, J				Roundy, S; Wright, PK; Rabaey, J			A study of low level vibrations as a power source for wireless sensor nodes	COMPUTER COMMUNICATIONS												Advances in low power VLSI design, along with the potentially low duty cycle of wireless sensor nodes open up the possibility of powering small wireless computing devices from scavenged ambient power. A broad review of potential power scavenging technologies and conventional energy sources is first presented. Low-level vibrations occurring in common household and office environments as a potential power source are studied in depth. The goal of this paper is not to suggest that the conversion of vibrations is the best or most versatile method to scavenge ambient power, but to study its potential as a viable power source for applications where vibrations are present. Different conversion mechanisms are investigated and evaluated leading to specific optimized designs for both capacitive MicroElectroMechancial Systems (MEMS) and piezoelectric converters. Simulations show that the potential power density from piezoelectric conversion is significantly higher. Experiments using an off-the-shelf PZT piezoelectric bimorph verify the accuracy of the models for piezoelectric converters. A power density of 70 muW/cm(3) has been demonstrated with the PZT bimorph. Simulations show that an optimized design would be capable of 250 muW/cm(3) from a vibration source with an acceleration amplitude of 2.5 m/s(2) at 120 Hz. (C) 2002 Elsevier Science B.V.. All rights reserved.						Roundy, Shad/0000-0002-5256-628X													0140-3664	1873-703X				JUL 1	2003	26	11					1131	1144	PII S0140-3664(02)00248-7	10.1016/S0140-3664(02)00248-7	http://dx.doi.org/10.1016/S0140-3664(02)00248-7													WOS:000183435500002
J	Richardson, TJ; Shokrollahi, MA; Urbanke, RL				Richardson, TJ; Shokrollahi, MA; Urbanke, RL			Design of capacity-approaching irregular low-density parity-check codes	IEEE TRANSACTIONS ON INFORMATION THEORY					IEEE International Symposium on Information Theory	JUN 24-30, 2000	SORRENTO, ITALY	IEEE, Informat Theory Soc				We design low-density parity-check (LDPC) codes that perform at rates extremely close to the Shannon capacity The codes are built from highly irregular bipartite graphs with carefully chosen degree patterns on both sides. Our theoretical analysis of the codes is based on [1], Assuming that the underlying communication channel is symmetric, we prove that the probability densities at the message nodes of the graph possess a certain symmetry, Using this symmetry property we then show that, under the assumption of no cycles, the message densities always converge as the number of iterations tends to infinity. Furthermore, we prove a stability condition which implies an upper bound on the fraction of errors that a belief-propagation decoder can correct when applied to a code induced from a bipartite graph with a given degree distribution. Our codes are found by optimizing the degree structure of the underlying graphs. We develop several strategies to perform this optimization. We also present some simulation results for the codes found which show that the performance of the codes is very close to the asymptotic theoretical bounds.					Urbanke, Ruediger/K-6310-2016	Urbanke, Ruediger/0000-0002-4839-821X													0018-9448	1557-9654				FEB	2001	47	2					619	637		10.1109/18.910578	http://dx.doi.org/10.1109/18.910578													WOS:000167491700008
J	Liang, YC; Zeng, YH; Peh, ECY; Hoang, AT				Liang, Ying-Chang; Zeng, Yonghong; Peh, Edward C. Y.; Hoang, Anh Tuan			Sensing-throughput tradeoff for cognitive radio networks	IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS					IEEE Global Telecommunications Conference (GLOBECOM 07)	NOV 26-30, 2007	Washington, DC	IEEE				In a cognitive radio. network, the secondary users are allowed to utilize the frequency bands of primary users when these bands are not currently being used. To support this spectrum reuse functionality, the secondary users are required to sense the radio frequency environment, and once the prmiary users are found to be active, the secondary users are required to vacate the channel within a certain amount of time. Therefore, spectrum sensing is of significant importance in cognitive radio networks. There are two parameters associated with spectrum sensing: probability of detection and probability of false alarm. The higher the probability of detection, the better the primary users are protected. However, from the secondary users' perspective, the lower the probability of false alarm, the more chances the channel can be reused when it is available, thus the higher the achievable throughput for the secondary network. In this paper, we study the problem of designing the sensing duration to maximize the achievable throughput for the secondary network under the constraint that the primary users are sufficiently protected. We formulate the sensing-throughput tradeoff problem mathematically, and use energy detection sensing scheme to prove that the formulated problem indeed has one optimal sensing time which yields the highest throughput for the secondary network. Cooperative sensing using multiple mini-slots or multiple secondary users are also studied using the methodology proposed in this paper. Computer simulations have shown that for a 6MHz channel, when the frame duration is 100ms, and the signal-to-noise ratio of primary user at the secondary receiver is -20dB, the optimal sensing time achieving the highest throughput while maintaining 90% detection probability is 14.2ms. This optimal sensing time decreases when distributed spectrum sensing is applied.					; Liang, Ying-Chang/G-1294-2014	Zeng, Yonghong/0000-0002-9451-105X; Liang, Ying-Chang/0000-0003-2671-5090													1536-1276	1558-2248				APR	2008	7	4					1326	1337		10.1109/TWC.2008.060869	http://dx.doi.org/10.1109/TWC.2008.060869													WOS:000257755000031
J	Li, SYR; Yeung, RW; Cai, N				Li, SYR; Yeung, RW; Cai, N			Linear network coding	IEEE TRANSACTIONS ON INFORMATION THEORY					IEEE Information Theory and Networking Workshop	JUN 27-JUL 01, 1999	METSOVO, GREECE	IEEE				Consider a communication network. in which certain source nodes multicast information to other nodes on the network in the multihop fashion where every node can pass on any of its received data to others. We are interested in how fast each node can receive the complete information, or equivalently, what the information rate arriving at each node is. Allowing a node to encode its received data before passing it on, the question involves optimization of the multicast mechanisms at the nodes. Among the simplest coding schemes is linear coding, which regards a block of data as a vector over a certain base field and allows a node to apply a linear transformation to a vector before passing it on. We formulate this multicast problem and prove that linear coding suffices to achieve the optimum, which is the max-flow from the source to each receiving node.					Yeung, Raymond/KSL-6605-2024; Li, Shuo/F-9736-2017	Li, Shuo/0000-0002-5184-3230													0018-9448					FEB	2003	49	2					371	381		10.1109/TIT.2002.807285	http://dx.doi.org/10.1109/TIT.2002.807285													WOS:000181265500002
J	Bioucas-Dias, JM; Plaza, A; Dobigeon, N; Parente, M; Du, Q; Gader, P; Chanussot, J				Bioucas-Dias, Jose M.; Plaza, Antonio; Dobigeon, Nicolas; Parente, Mario; Du, Qian; Gader, Paul; Chanussot, Jocelyn			Hyperspectral Unmixing Overview: Geometrical, Statistical, and Sparse Regression-Based Approaches	IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING												Imaging spectrometers measure electromagnetic energy scattered in their instantaneous field view in hundreds or thousands of spectral channels with higher spectral resolution than multispectral cameras. Imaging spectrometers are therefore often referred to as hyperspectral cameras (HSCs). Higher spectral resolution enables material identification via spectroscopic analysis, which facilitates countless applications that require identifying materials in scenarios unsuitable for classical spectroscopic analysis. Due to low spatial resolution of HSCs, microscopic material mixing, and multiple scattering, spectra measured by HSCs are mixtures of spectra of materials in a scene. Thus, accurate estimation requires unmixing. Pixels are assumed to be mixtures of a few materials, called endmembers. Unmixing involves estimating all or some of: the number of endmembers, their spectral signatures, and their abundances at each pixel. Unmixing is a challenging, ill-posed inverse problem because of model inaccuracies, observation noise, environmental conditions, endmember variability, and data set size. Researchers have devised and investigated many models searching for robust, stable, tractable, and accurate unmixing algorithms. This paper presents an overview of unmixing methods from the time of Keshava and Mustard's unmixing tutorial [1] to the present. Mixing models are first discussed. Signal-subspace, geometrical, statistical, sparsity-based, and spatial-contextual unmixing algorithms are described. Mathematical problems and potential solutions are described. Algorithm characteristics are illustrated experimentally.					Du, Qian/AAB-8840-2022; Chanussot, Jocelyn/Y-2395-2019; Plaza, Antonio/C-4455-2008; Dobigeon, Nicolas/O-6479-2018; Bioucas-Dias, Jose/C-5479-2009	Plaza, Antonio/0000-0002-9613-1659; Dobigeon, Nicolas/0000-0001-8127-350X; Bioucas-Dias, Jose/0000-0002-0166-5149; Du, Qian/0000-0001-8354-7500													1939-1404	2151-1535				APR	2012	5	2			SI		354	379		10.1109/JSTARS.2012.2194696	http://dx.doi.org/10.1109/JSTARS.2012.2194696													WOS:000304612300002
J	Topcuoglu, H; Hariri, S; Wu, MY				Topcuoglu, H; Hariri, S; Wu, MY			Performance-effective and low-complexity task scheduling for heterogeneous computing	IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS												Efficient application scheduling is critical for achieving high performance in heterogeneous computing environments. The application scheduling problem has been shown to be NP-complete in general cases as well as in several restricted cases. Because of its key importance, this problem has been extensively studied and various algorithms have been proposed in the literature which are mainly for systems with homogeneous processors. Although there are a few algorithms in the literature for heterogeneous processors, they usually require significantly high scheduling costs and they may not deliver good quality schedules with lower costs. In this paper, we present two novel scheduling algorithms for a bounded number of heterogeneous processors with an objective to simultaneously meet high performance and fast scheduling time, which are called the Heterogeneous Earliest-Finish-Time (HEFT) algorithm and the Critical-Path-on-a-Processor (CPOP) algorithm. The HEFT algorithm selects the task with the highest upward rank value at each step and assigns the selected task to the processor, which minimizes its earliest finish time with an insertion-based approach. On the other hand, the CPOP algorithm uses the summation of upward and downward rank values for prioritizing tasks. Another difference is in the processor selection phase, which schedules the critical tasks onto the processor that minimizes the total execution time of the critical tasks. In order to provide a robust and unbiased comparison with the related work, a parametric graph generator was designed to generate weighted directed acyclic graphs with various characteristics. The comparison study, based on both randomly generated graphs and the graphs of some real applications, shows that our scheduling algorithms significantly surpass previous approaches in terms of both quality and cost of schedules, which are mainly presented with schedule length ratio, speedup, frequency of best results, and average scheduling time metrics.					Wu, MinYou/B-3780-2009; Topcuoglu, Haluk/JBS-0035-2023	Topcuoglu, Haluk/0000-0003-1577-3930													1045-9219	1558-2183				MAR	2002	13	3					260	274		10.1109/71.993206	http://dx.doi.org/10.1109/71.993206													WOS:000174338100005
J	Zhang, R; Ho, CK				Zhang, Rui; Ho, Chin Keong			MIMO Broadcasting for Simultaneous Wireless Information and Power Transfer	IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS												Wireless power transfer (WPT) is a promising new solution to provide convenient and perpetual energy supplies to wireless networks. In practice, WPT is implementable by various technologies such as inductive coupling, magnetic resonate coupling, and electromagnetic (EM) radiation, for short-/mid-/long-range applications, respectively. In this paper, we consider the EM or radio signal enabled WPT in particular. Since radio signals can carry energy as well as information at the same time, a unified study on simultaneous wireless information and power transfer (SWIPT) is pursued. Specifically, this paper studies a multiple-input multiple-output (MIMO) wireless broadcast system consisting of three nodes, where one receiver harvests energy and another receiver decodes information separately from the signals sent by a common transmitter, and all the transmitter and receivers may be equipped with multiple antennas. Two scenarios are examined, in which the information receiver and energy receiver are separated and see different MIMO channels from the transmitter, or co-located and see the identical MIMO channel from the transmitter. For the case of separated receivers, we derive the optimal transmission strategy to achieve different tradeoffs for maximal information rate versus energy transfer, which are characterized by the boundary of a so-called rate-energy (R-E) region. For the case of co-located receivers, we show an outer bound for the achievable R-E region due to the potential limitation that practical energy harvesting receivers are not yet able to decode information directly. Under this constraint, we investigate two practical designs for the co-located receiver case, namely time switching and power splitting, and characterize their achievable R-E regions in comparison to the outer bound.					Zhang, Rui/C-2657-2011	Zhang, Rui/0000-0002-8729-8393													1536-1276	1558-2248				MAY	2013	12	5					1989	2001		10.1109/TWC.2013.031813.120224	http://dx.doi.org/10.1109/TWC.2013.031813.120224													WOS:000321199800003
J	Cha, YJ; Choi, W; Büyüköztürk, O				Cha, Young-Jin; Choi, Wooram; Buyukozturk, Oral			Deep Learning-Based Crack Damage Detection Using Convolutional Neural Networks	COMPUTER-AIDED CIVIL AND INFRASTRUCTURE ENGINEERING												A number of image processing techniques (IPTs) have been implemented for detecting civil infrastructure defects to partially replace human-conducted onsite inspections. These IPTs are primarily used to manipulate images to extract defect features, such as cracks in concrete and steel surfaces. However, the extensively varying real-world situations (e.g., lighting and shadow changes) can lead to challenges to the wide adoption of IPTs. To overcome these challenges, this article proposes a vision-based method using a deep architecture of convolutional neural networks (CNNs) for detecting concrete cracks without calculating the defect features. As CNNs are capable of learning image features automatically, the proposed method works without the conjugation of IPTs for extracting features. The designed CNN is trained on 40 K images of 256 x 256 pixel resolutions and, consequently, records with about 98% accuracy. The trained CNN is combined with a sliding window technique to scan any image size larger than 256 x 256 pixel resolutions. The robustness and adaptability of the proposed approach are tested on 55 images of 5,888 x 3,584 pixel resolutions taken from a different structure which is not used for training and validation processes under various conditions (e.g., strong light spot, shadows, and very thin cracks). Comparative studies are conducted to examine the performance of the proposed CNN using traditional Canny and Sobel edge detection methods. The results show that the proposed method shows quite better performances and can indeed find concrete cracks in realistic situations.					Cha, Young-Jin/ABH-3680-2020	Cha, Young-Jin/0000-0002-0738-5615													1093-9687	1467-8667				MAY	2017	32	5					361	378		10.1111/mice.12263	http://dx.doi.org/10.1111/mice.12263													WOS:000398581900001
J	Pogaku, N; Prodanovic, M; Green, TC				Pogaku, Nagaraju; Prodanovic, Milan; Green, Timothy C.			Modeling, analysis and testing of autonomous operation of an inverter-based microgrid	IEEE TRANSACTIONS ON POWER ELECTRONICS												The analysis of the small-signal stability of conventional power systems is well established, but for inverter based microgrids there is a need to establish how circuit and control features give rise to particular oscillatory modes and which of these have poor damping. This paper develops the modeling and analysis of autonomous operation of inverter-based microgrids. Each sub-module is modeled in state-space form and all are combined together on a common reference frame. The model captures the detail of the control loops of the inverter but not the switching action. Some inverter modes are found at relatively high frequency and so a full dynamic model of the network (rather than an algebraic impedance model) is used. The complete model is linearized around an operating point and the resulting system matrix is used to derive the eigenvalues. The eigenvalues (termed "modes") indicate the frequency and damping of oscillatory components in the transient response. A sensitivity analysis is also presented which helps identifying the origin of each of the modes and identify possible feedback signals for design of controllers to improve the system stability. With experience it is possible to simplify the model (reduce the order) if particular modes are not of interest as is the case with synchronous machine models. Experimental results from a microgrid of three 10-kW inverters are used to verify the results obtained from the model.					Green, Tim/M-1165-2014; Prodanovic, Milan/E-5930-2017	Green, Tim/0000-0003-3893-2439; Prodanovic, Milan/0000-0001-5500-9799													0885-8993	1941-0107				MAR	2007	22	2					613	625		10.1109/TPEL.2006.890003	http://dx.doi.org/10.1109/TPEL.2006.890003													WOS:000245158200029
J	Xu, ZS				Xu, Zeshui			Intuitionistic fuzzy aggregation operators	IEEE TRANSACTIONS ON FUZZY SYSTEMS												An intuitionistic fuzzy set, characterized by a membership function and a non-membership function, is a generalization of fuzzy set. In this paper, based on score function,and accuracy function, we introduce a method for the comparison between two intuitionistic fuzzy values and then develop some aggregation operators, such as the intuitionistic fuzzy weighted averaging operator, intuitionistic fuzzy ordered weighted averaging operator, and intuitionistic fuzzy hybrid aggregation operator, for aggregating intuitionistic fuzzy values and establish various properties of these operators.					Xu, Zeshui/N-8908-2013	Xu, Zeshui/0000-0003-3547-2908													1063-6706	1941-0034				DEC	2007	15	6					1179	1187		10.1109/TFUZZ.2006.890678	http://dx.doi.org/10.1109/TFUZZ.2006.890678													WOS:000251699000015
J	Tee, KP; Ge, SS; Tay, EH				Tee, Keng Peng; Ge, Shuzhi Sam; Tay, Eng Hock			Barrier Lyapunov Functions for the control of output-constrained nonlinear systems	AUTOMATICA												In this paper, we present control designs for single-input single-output (SISO) nonlinear systems in strict feedback form with an output constraint. To prevent constraint violation, we employ a Barrier Lyapunov Function, which grows to infinity when its arguments approach some limits. By ensuring boundedness of the Barrier Lyapunov Function in the closed loop, we ensure that those limits are not transgressed. Besides the nominal case where full knowledge of the plant is available, we also tackle scenarios wherein parametric uncertainties are present. Asymptotic tracking is achieved without violation of the constraint, and all closed loop signals remain bounded, under a mild condition on the initial output. Furthermore, we explore the use of an Asymmetric Barrier Lyapunov Function as a generalized approach that relaxes the requirements on the initial conditions. We also compare our control with one that is based on a Quadratic Lyapunov Function, and we show that our control requires less restrictive initial conditions. A numerical example is provided to illustrate the performance of the proposed control. (C) 2008 Elsevier Ltd. All rights reserved.					Tay, Eng/J-1467-2014; Ge, Shuzhi/ABJ-5567-2022	Ge, Shuzhi Sam/0000-0001-5549-312X													0005-1098	1873-2836				APR	2009	45	4					918	927		10.1016/j.automatica.2008.11.017	http://dx.doi.org/10.1016/j.automatica.2008.11.017													WOS:000265155700008
J	Criminisi, A; Pérez, P; Toyama, K				Criminisi, A; Pérez, P; Toyama, K			Region filling and object removal by exemplar-based image inpainting	IEEE TRANSACTIONS ON IMAGE PROCESSING												A new algorithm is proposed for removing large objects from digital images. The challenge is to fill in the hole that is left behind in a visually plausible way. In the past, this problem has been addressed by two classes of algorithms: 1) "texture synthesis" algorithms for generating large image regions from sample textures and 2) "inpainting" techniques for filling in small image gaps. The former has been demonstrated for "textures"-repeating two-dimensional patterns with some stochasticity; the latter focus on linear "structures" which can be thought of as one-dimensional patterns, such as lines and object contours. This paper presents a novel and efficient algorithm that combines the advantages of these two approaches. We first note that exemplar-based texture synthesis contains the essential process required to replicate both texture and structure; the success of structure propagation, however, is highly dependent on the order in which the filling proceeds. We propose a best-first algorithm in which the confidence in the synthesized pixel values is propagated in a manner similar to the propagation of information in inpainting. The actual color values are computed using exemplar-based synthesis. In this paper, the simultaneous propagation of texture and structure information is achieved by a single, efficient algorithm. Computational efficiency is achieved by a block-based sampling process. A number of examples on real and synthetic images demonstrate the effectiveness of our algorithm in removing large occluding objects, as well as thin scratches. Robustness with respect to the shape of the manually selected target region is also demonstrated. Our results compare favorably to those obtained by existing techniques.						Toyama, Kentaro/0000-0002-9128-2255													1057-7149	1941-0042				SEP	2004	13	9					1200	1212		10.1109/TIP.2004.833105	http://dx.doi.org/10.1109/TIP.2004.833105								15449582					WOS:000223356600004
J	Lin, H; Antsaklis, PJ				Lin, Hai; Antsaklis, Panos J.			Stability and Stabilizability of Switched Linear Systems: A Survey of Recent Results	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												During the past several years, there have been increasing research activities in the field of stability analysis and switching stabilization for switched systems. This paper aims to briefly survey recent results in this field. First, the stability analysis for switched systems is reviewed. We focus on the stability analysis for switched linear systems under arbitrary switching, and we highlight necessary and sufficient conditions for asymptotic stability. After a brief review of the stability analysis under restricted switching and the multiple Lyapunov function theory, the switching stabilization problem is studied, and a variety of switching stabilization methods found in the literature are outlined. Then the switching stabilizability problem is investigated, that is under what condition it is possible to stabilize a switched system by properly designing switching control laws. Note that the switching stabilizability problem has been one of the most elusive problems in the switched systems literature. A necessary and sufficient condition for asymptotic stabilizability of switched linear systems is described here.																			0018-9286	1558-2523				FEB	2009	54	2					308	322		10.1109/TAC.2008.2012009	http://dx.doi.org/10.1109/TAC.2008.2012009													WOS:000263567000010
J	Dollár, P; Wojek, C; Schiele, B; Perona, P				Dollar, Piotr; Wojek, Christian; Schiele, Bernt; Perona, Pietro			Pedestrian Detection: An Evaluation of the State of the Art	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Pedestrian detection is a key problem in computer vision, with several applications that have the potential to positively impact quality of life. In recent years, the number of approaches to detecting pedestrians in monocular images has grown steadily. However, multiple data sets and widely varying evaluation protocols are used, making direct comparisons difficult. To address these shortcomings, we perform an extensive evaluation of the state of the art in a unified framework. We make three primary contributions: 1) We put together a large, well-annotated, and realistic monocular pedestrian detection data set and study the statistics of the size, position, and occlusion patterns of pedestrians in urban scenes, 2) we propose a refined per-frame evaluation methodology that allows us to carry out probing and informative comparisons, including measuring performance in relation to scale and occlusion, and 3) we evaluate the performance of sixteen pretrained state-of-the-art detectors across six data sets. Our study allows us to assess the state of the art and provides a framework for gauging future efforts. Our experiments show that despite significant progress, performance still has much room for improvement. In particular, detection is disappointing at low resolutions and for partially occluded pedestrians.																			0162-8828	1939-3539				APR	2012	34	4					743	761		10.1109/TPAMI.2011.155	http://dx.doi.org/10.1109/TPAMI.2011.155								21808091					WOS:000300581700009
J	Giesy, JP; Kannan, K				Giesy, JP; Kannan, K			Global distribution of perfluorooctane sulfonate in wildlife	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Here we report, for the first time, on the global distribution of perfluorooctanesulfonate (PFOS), a fluorinated organic contaminant. PFOS was measured in the tissues of wildlife, including, fish, birds, and marine mammals. Some of the species studied include bald eagles, polar bears, albatrosses, and various species of seals. Samples were collected from urbanized areas in North America, especially the Great Lakes region and coastal marine areas and rivers, and Europe. Samples were also collected from a number of more remote, less urbanized locations such as the Arctic and the North Pacific Oceans. The results demonstrated that PFOS is widespread in the environment. Concentrations of PFOS in animals from relatively more populated and industrialized regions, such as the North American Great Lakes, Baltic Sea, and Mediterranean Sea, were greater than those in animals from remote marine locations. Fish-eating, predatory animals such as mink and bald eagles contained concentrations of PFOS that were greater than the concentrations in their diets. This suggests that PFOS can bioaccumulate to higher trophic levels of the food chain. Currently available data indicate that the concentrations of PFOS in wildlife are less than those required to cause adverse effects in laboratory animals.					Kannan, Kayambu/I-6919-2016; Kannan, Kurunthachalam/ACA-0037-2022	Giesy, John/0000-0003-1931-9962; Kannan, Kurunthachalam/0000-0002-1926-7456													0013-936X					APR 1	2001	35	7					1339	1342		10.1021/es001834k	http://dx.doi.org/10.1021/es001834k								11348064					WOS:000167817000021
J	Yu, SH; Yu, XH; Shirinzadeh, B; Man, ZH				Yu, SH; Yu, XH; Shirinzadeh, B; Man, ZH			Continuous finite-time control for robotic manipulators with terminal sliding mode	AUTOMATICA												A continuous finite-time control scheme for rigid robotic manipulators is proposed using a new form of terminal sliding modes. The robustness of the controller is established using the Lyapunov stability theory. Theoretical analysis and simulation results show that faster and high-precision tracking performance is obtained compared with the conventional continuous sliding mode control method. (c) 2005 Elsevier Ltd. All rights reserved.					Sui, Xinghua/HZM-5992-2023; Man, Zhihong/AAH-7200-2020; Yu, Xinghuo/D-8423-2013	Man, Zhihong/0000-0002-8338-2125; Yu, Xinghuo/0000-0001-8093-9787													0005-1098	1873-2836				NOV	2005	41	11					1957	1964		10.1016/j.automatica.2005.07.001	http://dx.doi.org/10.1016/j.automatica.2005.07.001													WOS:000232674300012
J	Stauffer, C; Grimson, WEL				Stauffer, C; Grimson, WEL			Learning patterns of activity using real-time tracking	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Our goal is to develop a visual monitoring system that passively observes moving objects in a site and learns patterns of activity from those observations. For extended sites, the system will require multiple cameras. Thus, key elements of the system are motion tracking, camera coordination, activity classification, and event detection. In this paper, we focus on motion tracking and show how one can use observed motion to learn patterns of activity in a site. Motion segmentation is based on an adaptive background subtraction method that models each pixel as a mixture of Gaussians and uses an on-line approximation to update the model. The Gaussian distributions are then evaluated to determine which are most likely to result from a background process. This yields a stable. real-time outdoor tracker that reliably deals with lighting changes, repetitive motions from clutter, and long-term scene changes. While a tracking system is unaware of the identity of any object it tracks, the identity remains the same for the entire tracking sequence. Our system leverages this information by accumulating joint co-occurrences of the representations within a sequence. These joint cooccurrence statistics are then used to create a hierarchical binary-tree classification of the representations. This method is useful for classifying sequences, as well as individual instances of activities in a site.																			0162-8828	1939-3539				AUG	2000	22	8					747	757		10.1109/34.868677	http://dx.doi.org/10.1109/34.868677													WOS:000089321500002
J	Thackeray, MM; Wolverton, C; Isaacs, ED				Thackeray, Michael M.; Wolverton, Christopher; Isaacs, Eric D.			Electrical energy storage for transportation-approaching the limits of, and going beyond, lithium-ion batteries	ENERGY & ENVIRONMENTAL SCIENCE												The escalating and unpredictable cost of oil, the concentration of major oil resources in the hands of a few politically sensitive nations, and the long-term impact of CO2 emissions on global climate constitute a major challenge for the 21st century. They also constitute a major incentive to harness alternative sources of energy and means of vehicle propulsion. Today's lithium-ion batteries, although suitable for small-scale devices, do not yet have sufficient energy or life for use in vehicles that would match the performance of internal combustion vehicles. Energy densities 2 and 5 times greater are required to meet the performance goals of a future generation of plug-in hybrid-electric vehicles (PHEVs) with a 40-80 mile all-electric range, and all-electric vehicles (EVs) with a 300-400 mile range, respectively. Major advances have been made in lithium-battery technology over the past two decades by the discovery of new materials and designs through intuitive approaches, experimental and predictive reasoning, and meticulous control of surface structures and chemical reactions. Further improvements in energy density of factors of two to three may yet be achievable for current day lithium-ion systems; factors of five or more may be possible for lithium-oxygen systems, ultimately leading to our ability to confine extremely high potential energy in a small volume without compromising safety, but only if daunting technological barriers can be overcome.					Wolverton, Christopher/B-7542-2009														1754-5692	1754-5706				JUL	2012	5	7					7854	7863		10.1039/c2ee21892e	http://dx.doi.org/10.1039/c2ee21892e													WOS:000305530900017
J	Sheikh, HR; Sabir, MF; Bovik, AC				Sheikh, Hamid Rahim; Sabir, Muhammad Farooq; Bovik, Alan Conrad			A statistical evaluation of recent full reference image quality assessment algorithms	IEEE TRANSACTIONS ON IMAGE PROCESSING												Measurement of visual quality is of fundamental importance for numerous image and video processing applications, where the goal of quality assessment (QA) algorithms is to automatically assess the quality of images or videos in agreement with human quality judgments. Over the years, many researchers have taken different approaches to the problem and have contributed significant research in this area and claim to have made progress in their respective domains. It is important to evaluate the performance of these algorithms in a comparative setting and analyze the strengths and weaknesses of these methods. In this paper, we present results of an extensive subjective quality assessment study in which a total of 779 distorted images were evaluated by about two dozen human subjects. The "ground truth" image quality data obtained from about 25 000 individual human quality judgments is used to evaluate the performance of several prominent full-reference image quality assessment algorithms. To the best of our knowledge, apart from video quality studies conducted by the Video Quality Experts Group, the study presented in this paper is the largest subjective image quality study in the literature in terms of number of images, distortion types, and number of human judgments per image. Moreover, we have made the data from the study freely available to the research community [1]. This would allow other researchers to easily report comparative results in the future.					Bovik, Alan/B-6717-2012	Bovik, Alan/0000-0001-6067-710X													1057-7149	1941-0042				NOV	2006	15	11					3440	3451		10.1109/TIP.2006.881959	http://dx.doi.org/10.1109/TIP.2006.881959								17076403					WOS:000241391100017
J	Dai, LL; Wang, BC; Yuan, YF; Han, SF; Chih-Lin, ; Wang, ZC				Dai, Linglong; Wang, Bichai; Yuan, Yifei; Han, Shuangfeng; Chih-Lin, I; Wang, Zhaocheng			Non-Orthogonal Multiple Access for 5G: Solutions, Challenges, Opportunities, and Future Research Trends	IEEE COMMUNICATIONS MAGAZINE												The increasing demand of mobile Internet and the Internet of Things poses challenging requirements for 5G wireless communications, such as high spectral efficiency and massive connectivity. In this article, a promising technology, non-orthogonal multiple access (NOMA), is discussed, which can address some of these challenges for 5G. Different from conventional orthogonal multiple access technologies, NOMA can accommodate much more users via non-orthogonal resource allocation. We divide existing dominant NOMA schemes into two categories: power-domain multiplexing and code-domain multiplexing, and the corresponding schemes include power-domain NOMA, multiple access with low-density spreading, sparse code multiple access, multi-user shared access, pattern division multiple access, and so on. We discuss their principles, key features, and pros/cons, and then provide a comprehensive comparison of these solutions from the perspective of spectral efficiency, system performance, receiver complexity, and so on. In addition, challenges, opportunities, and future research trends for NOMA design are highlighted to provide some insight on the potential future work for researchers in this field. Finally, to leverage different multiple access schemes including both conventional OMA and new NOMA, we propose the concept of software defined multiple access (SoDeMA), which enables adaptive configuration of available multiple access schemes to support diverse services and applications in future 5G networks.					Wang, Zhaocheng/AAA-6192-2019; Han, ShuangFeng/ABB-8755-2020; Dai, Linglong/D-3023-2016	Dai, Linglong/0000-0002-4250-7315													0163-6804	1558-1896				SEP	2015	53	9					74	81		10.1109/mcom.2015.7263349	http://dx.doi.org/10.1109/mcom.2015.7263349													WOS:000361676900011
J	Noel, NK; Stranks, SD; Abate, A; Wehrenfennig, C; Guarnera, S; Haghighirad, AA; Sadhanala, A; Eperon, GE; Pathak, SK; Johnston, MB; Petrozza, A; Herz, LM; Snaith, HJ				Noel, Nakita K.; Stranks, Samuel D.; Abate, Antonio; Wehrenfennig, Christian; Guarnera, Simone; Haghighirad, Amir-Abbas; Sadhanala, Aditya; Eperon, Giles E.; Pathak, Sandeep K.; Johnston, Michael B.; Petrozza, Annamaria; Herz, Laura M.; Snaith, Henry J.			Lead-free organic-inorganic tin halide perovskites for photovoltaic applications	ENERGY & ENVIRONMENTAL SCIENCE												Already exhibiting solar to electrical power conversion efficiencies of over 17%, organic-inorganic lead halide perovskite solar cells are one of the most promising emerging contenders in the drive to provide a cheap and clean source of energy. One concern however, is the potential toxicology issue of lead, a key component in the archetypical material. The most likely substitute is tin, which like lead, is also a group 14 metal. While organic-inorganic tin halide perovskites have shown good semiconducting behaviour, the instability of tin in its 2+ oxidation state has thus far proved to be an overwhelming challenge. Here, we report the first completely lead-free, CH3NH3SnI3 perovskite solar cell processed on a mesoporous TiO2 scaffold, reaching efficiencies of over 6% under 1 sun illumination. Remarkably, we achieve open circuit voltages over 0.88 V from a material which has a 1.23 eV band gap.					Haghighirad, Amir-Abbas/ABE-6071-2020; Noel, Nakita/F-3990-2014; Sadhanala, Aditya/JSE-2039-2023; Petrozza, Annamaria/A-1065-2014; Noel, Nakita K./U-1313-2018; Eperon, Giles/J-2316-2015; Johnston, Michael/B-9813-2008; Snaith, Henry/A-7367-2016; Stranks, Sam/M-7837-2015; Abate, Antonio/F-2419-2010; Herz, Laura/B-9789-2008; Sadhanala, Aditya/J-1212-2017	Africa, Josephine/0000-0002-8117-9211; Noel, Nakita K./0000-0002-8570-479X; Eperon, Giles/0000-0001-9600-4847; Johnston, Michael/0000-0002-0301-8033; Snaith, Henry/0000-0001-8511-790X; Stranks, Sam/0000-0002-8303-7292; Abate, Antonio/0000-0002-3012-3541; Petrozza, Annamaria/0000-0001-6914-4537; Herz, Laura/0000-0001-9621-334X; Sadhanala, Aditya/0000-0003-2832-4894													1754-5692	1754-5706				SEP	2014	7	9					3061	3068		10.1039/c4ee01076k	http://dx.doi.org/10.1039/c4ee01076k													WOS:000340450100024
J	Lai, LF; Potts, JR; Zhan, D; Wang, L; Poh, CK; Tang, CH; Gong, H; Shen, ZX; Jianyi, LY; Ruoff, RS				Lai, Linfei; Potts, Jeffrey R.; Zhan, Da; Wang, Liang; Poh, Chee Kok; Tang, Chunhua; Gong, Hao; Shen, Zexiang; Lin, Jianyi; Ruoff, Rodney S.			Exploration of the active center structure of nitrogen-doped graphene-based catalysts for oxygen reduction reaction	ENERGY & ENVIRONMENTAL SCIENCE												We present two different ways to fabricate nitrogen-doped graphene (N-graphene) and demonstrate its use as a metal-free catalyst to study the catalytic active center for the oxygen reduction reaction (ORR). N-graphene was produced by annealing of graphene oxide (G-O) under ammonia or by annealing of a N-containing polymer/reduced graphene oxide (RG-O) composite (polyaniline/RG-O or polypyrrole/RG-O). The effects of the N precursors and annealing temperature on the performance of the catalyst were investigated. The bonding state of the N atom was found to have a significant effect on the selectivity and catalytic activity for ORR. Annealing of G-O with ammonia preferentially formed graphitic N and pyridinic N centers, while annealing of polyaniline/RG-O and polypyrrole/RG-O tended to generate pyridinic and pyrrolic N moieties, respectively. Most importantly, the electrocatalytic activity of the catalyst was found to be dependent on the graphitic N content which determined the limiting current density, while the pyridinic N content improved the onset potential for ORR. However, the total N content in the graphene-based non-precious metal catalyst does not play an important role in the ORR process.					Ruoff, Rodney/B-7605-2009; Shen, Zexiang/B-6988-2011; Lai, Linfei/J-7129-2017; Gong, Hao/N-5746-2017; Poh, Chee Kok/E-8965-2011	Yang, Shuman/0000-0002-9638-0890; Shen, Zexiang/0000-0001-7432-7936; Lai, Linfei/0000-0002-3421-6710; Gong, Hao/0000-0002-0410-5147; Poh, Chee Kok/0000-0002-3175-8493													1754-5692					JUL	2012	5	7					7936	7942		10.1039/c2ee21802j	http://dx.doi.org/10.1039/c2ee21802j													WOS:000305530900033
J	Vincent, E; Gribonval, R; Févotte, C				Vincent, Emmanuel; Gribonval, Remi; Févotte, Cedric			Performance measurement in blind audio source separation	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING												In this paper, we discuss the evaluation of blind audio source separation (BASS) algorithms. Depending on the exact application, different distortions can be allowed between an estimated source and the wanted true source. We consider four different sets of such allowed distortions, from time-invariant gains to time-varying filters. In each case, we decompose the estimated source into a true source part plus error terms corresponding to interferences, additive noise, and algorithmic artifacts. Then, we derive a global performance measure using an energy ratio, plus a separate performance,measure for each error term. These measures are computed and discussed on the results of several BASS problems with various difficulty levels.																			1558-7916	1558-7924				JUL	2006	14	4					1462	1469		10.1109/TSA.2005.858005	http://dx.doi.org/10.1109/TSA.2005.858005													WOS:000238709200034
J	Chen, YS; Jiang, HL; Li, CY; Jia, XP; Ghamisi, P				Chen, Yushi; Jiang, Hanlu; Li, Chunyang; Jia, Xiuping; Ghamisi, Pedram			Deep Feature Extraction and Classification of Hyperspectral Images Based on Convolutional Neural Networks	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING												Due to the advantages of deep learning, in this paper, a regularized deep feature extraction (FE) method is presented for hyperspectral image (HSI) classification using a convolutional neural network (CNN). The proposed approach employs several convolutional and pooling layers to extract deep features from HSIs, which are nonlinear, discriminant, and invariant. These features are useful for image classification and target detection. Furthermore, in order to address the common issue of imbalance between high dimensionality and limited availability of training samples for the classification of HSI, a few strategies such as L2 regularization and dropout are investigated to avoid overfitting in class data modeling. More importantly, we propose a 3-D CNN-based FE model with combined regularization to extract effective spectral-spatial features of hyperspectral imagery. Finally, in order to further improve the performance, a virtual sample enhanced method is proposed. The proposed approaches are carried out on three widely used hyperspectral data sets: Indian Pines, University of Pavia, and Kennedy Space Center. The obtained results reveal that the proposed models with sparse constraints provide competitive results to state-of-the-art methods. In addition, the proposed deep FE opens a new window for further research.					Chen, Yushi/ACI-9252-2022; WANG, JIAXUAN/JMP-8599-2023; Ghamisi, Pedram/ABD-5419-2021	Chen, Yushi/0000-0003-2421-0996; Jia, Xiuping/0000-0001-9916-6382													0196-2892	1558-0644				OCT	2016	54	10					6232	6251		10.1109/TGRS.2016.2584107	http://dx.doi.org/10.1109/TGRS.2016.2584107													WOS:000385178700043
J	Li, WJ; Laurencin, CT; Caterson, EJ; Tuan, RS; Ko, FK				Li, WJ; Laurencin, CT; Caterson, EJ; Tuan, RS; Ko, FK			Electrospun nanofibrous structure: A novel scaffold for tissue engineering	JOURNAL OF BIOMEDICAL MATERIALS RESEARCH												The architecture of an engineered tissue substitute plays an important role in modulating tissue growth. A novel poly(D,L-lactide-co-glycolide) (PLGA) structure with a unique architecture produced by an electrospinning process has been developed for tissue-engineering applications. Electrospinning is a process whereby ultra-fine fibers are formed in a high-voltage electrostatic field. The electrospun structure, composed of PLGA fibers ranging from 500 to 800 rim in diameter, features a morphologic similarity to the extracellular matrix (ECM) of natural tissue, which is characterized by a wide range of pore diameter distribution, high porosity, and effective mechanical properties. Such a structure meets the essential design criteria of an ideal engineered scaffold. The favorable cell-matrix interaction within the cellular construct supports the active biocompatibility of the structure. The electrospun nanofibrous structure is capable of supporting cell attachment and proliferation. Cells seeded on this structure tend to maintain phenotypic shape and guided growth according to nanofiber orientation. This novel biodegradable scaffold has potential applications for tissue engineering based upon its unique architecture, which acts to support and guide cell growth. (C) 2002 Wiley Periodicals, Inc.					Li, Wan-Ju/B-4911-2011	Li, Wan-Ju/0000-0002-6579-8063; Caterson, Edward/0000-0003-4024-650X													0021-9304					JUN 15	2002	60	4					613	621		10.1002/jbm.10167	http://dx.doi.org/10.1002/jbm.10167								11948520					WOS:000175367500012
J	Fu, JW; Xu, QL; Low, JX; Jiang, CJ; Yu, JG				Fu, Junwei; Xu, Quanlong; Low, Jingxiang; Jiang, Chuanjia; Yu, Jiaguo			Ultrathin 2D/2D WO<sub>3</sub>/g-C<sub>3</sub>N<sub>4</sub> step-scheme H<sub>2</sub>-production photocatalyst	APPLIED CATALYSIS B-ENVIRONMENTAL												The appropriate interfacial contact of heterojunction photocatalysts plays a critical role in transfer/separation of interfacial charge carriers. Design of two-dimensional (2D)/2D surface-to-surface heterojunction is an effective method for improving photocatalytic activity since greater contact area can enhance interfacial charge transfer rate. Herein, ultrathin 2D/2D WO3/g-C3N4 step-like composite heterojunction photocatalysts were fabricated by electrostatic self-assembly of ultrathin tungsten trioxide (WO3) and graphitic carbon nitride (g-C3N4) nanosheets. The ultrathin WO3 and g-C3N4 nanosheets were obtained by electrostatic-assisted ultrasonic exfoliation of bulk WO3 and a two-step thermal-etching of bulk g-C3N4, respectively. The thickness of ultrathin WO3 and g-C3N4 nanosheets are 2.5-3.5 nm, which is equivalent to 5-8 atomic or molecular layer thickness. This ultrathin layered heterojunction structure can enhance surface photocatalytic rate because photogenerated electrons and holes at heterogeneous interface more easily transfer to surface of photocatalysts. Therefore, the obtained ultrathin 2D/2D WO3/g-C3N4 step-scheme (S-scheme) heterojunction photocatalysts exhibited better Hz-production activity than pure g-C3N4 and WO3 with the same loading amount of Pt as cocatalyst. The mechanism and driving force of charge transfer and separation in S-scheme heterojunction photocatalysts are investigated and discussed. This investigation will provide new insight about designing and constructing novel S-scheme heterojunction photocatalysts.					Xu, Quanlong/O-9295-2019; Jiang, Chuanjia/C-9398-2014; Yu, Jiaguo/G-4317-2010; Low, Jingxiang/N-2381-2014	Xu, Quanlong/0000-0003-3347-9065; Jiang, Chuanjia/0000-0003-2637-5508; Yu, Jiaguo/0000-0002-0612-8633; Low, Jingxiang/0000-0002-2486-6357													0926-3373	1873-3883				APR	2019	243						556	565		10.1016/j.apcatb.2018.11.011	http://dx.doi.org/10.1016/j.apcatb.2018.11.011													WOS:000453616800057
J	Witte, F; Kaese, V; Haferkamp, H; Switzer, E; Meyer-Lindenberg, A; Wirth, CJ; Windhagen, H				Witte, F; Kaese, V; Haferkamp, H; Switzer, E; Meyer-Lindenberg, A; Wirth, CJ; Windhagen, H			In vivo corrosion of four magnesium alloys and the associated bone response	BIOMATERIALS												Degrading metal alloys are a new class of implant materials suitable for bone surgery. The aim of this study was to investigate the degradation mechanism at the bone-implant interface of different degrading magnesium alloys in bone and to determine their effect on the surrounding bone. Sample rods of four different magnesium alloys and a degradable polymer as a control were implanted intramedullary into the femora of guinea pigs. After 6 and 18 weeks, uncalcified sections were generated for histomorphologic analysis. The bone-implant interface was characterized in uncalcified sections by scanning electron microscopy (SEM), element mapping and X-ray diffraction. Results showed that metallic implants made of magnesium alloys degrade in vivo depending on the composition of the alloying elements. While the corrosion layer of all magnesium alloys accumulated with biological calcium phosphates, the corrosion layer was in direct contact with the surrounding bone. The results further showed high mineral apposition rates and an increased bone mass around the magnesium rods, while no bone was induced in the surrounding soft tissue. From the results of this study, there is a strong rationale that in this research model, high magnesium ion concentration could lead to bone cell activation. (C) 2004 Elsevier Ltd. All rights reserved.					Meyer-Lindenberg, Andreas/H-1076-2011; Witte, Frank/AFK-1556-2022; Witte, Frank/D-9294-2014	Meyer-Lindenberg, Andrea/0000-0001-6137-3773; Witte, Frank/0000-0001-9154-6217													0142-9612					JUN	2005	26	17					3557	3563		10.1016/j.biomaterials.2004.09.049	http://dx.doi.org/10.1016/j.biomaterials.2004.09.049								15621246					WOS:000226968200021
J	Chandrasekhar, V; Andrews, JG; Gatherer, A				Chandrasekhar, Vikram; Andrews, Jeffrey G.; Gatherer, Alan			Femtocell Networks: A Survey	IEEE COMMUNICATIONS MAGAZINE												The surest way to increase the system capacity of a wireless link is by getting the transmitter and receiver closer to each other, which creates the dual benefits of higher-quality links and more spatial reuse. In a network with nomadic users, this inevitably involves deploying more infrastructure, typically in the form of microcells, hot spots, distributed antennas, or relays. A less expensive alternative is the recent concept of femtocells - also called home base stations which are data access points installed by home users to get better indoor voice and data coverage. In this article we overview the technical and business arguments for femtocells and describe the state of the art on each front. We also describe the technical challenges facing femtocell networks and give some preliminary ideas for how to overcome them.					Andrews, Jeffrey/ADW-5995-2022														0163-6804					SEP	2008	46	9					59	67		10.1109/MCOM.2008.4623708	http://dx.doi.org/10.1109/MCOM.2008.4623708													WOS:000260867400009
J	Nascimento, JMP; Dias, JMB				Nascimento, JMP; Dias, JMB			Vertex component analysis: A fast algorithm to unmix hyperspectral data	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING												Given a set of mixed spectral (multispectral or hyperspectral) vectors, linear spectral mixture analysis, or linear unmixing, aims at estimating the number of reference substances, also called endmembers, their spectral signatures, and their abundance fractions. This paper presents a new method for unsupervised endmember extraction from hyperspectral data, termed vertex component analysis (VCA). The algorithm exploits two facts: 1) the endmembers are the vertices of a simplex and 2) the affine transformation of a simplex is also a simplex. In a series of experiments using simulated and real data, the VCA algorithm competes with state-of-the-art methods, with a computational complexity between one and two orders of magnitude lower than the best available method.					Bioucas-Dias, Jose/C-5479-2009; Nascimento, Jose/E-6212-2015	Bioucas-Dias, Jose/0000-0002-0166-5149; Nascimento, Jose/0000-0002-5291-6147													0196-2892	1558-0644				APR	2005	43	4					898	910		10.1109/TGRS.2005.844293	http://dx.doi.org/10.1109/TGRS.2005.844293													WOS:000227882500023
J	Likas, A; Vlassis, N; Verbeek, JJ				Likas, A; Vlassis, N; Verbeek, JJ			The global <i>k</i>-means clustering algorithm	PATTERN RECOGNITION												We present the global k-means algorithm which is an incremental approach to clustering that dynamically adds one cluster center at a time through a deterministic global search procedure consisting of N (with N being the size of the data set) executions of the k-means algorithm from suitable initial positions. We also propose modifications of the method to reduce the computational load without significantly affecting solution quality. The proposed clustering methods are tested on well-known data sets and they compare favorably to the k-means algorithm with random restarts. (C) 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.																			0031-3203	1873-5142				FEB	2003	36	2					451	461	PII S0031-3203(02)00060-2															WOS:000179225600015
J	Fischer, D; Li, YX; Ahlemeyer, B; Krieglstein, J; Kissel, T				Fischer, D; Li, YX; Ahlemeyer, B; Krieglstein, J; Kissel, T			In vitro cytotoxicity testing of polycations: influence of polymer structure on cell viability and hemolysis.	BIOMATERIALS												A comparative in vitro cytotoxicity study with different water-soluble, cationic macromolecules which have been described as gene delivery systems was performed. Cytotoxicity in L929 mouse fibroblasts was monitored using the MTT assay and the release of the cytosolic enzyme lactate dehydrogenase (LDH). Microscopic observations were carried out as indicators for cell viability. Furthermore, hemolysis of erythrocytes was quantified spectrophotometrically. To determine the nature of cell death induced by the polycations, the nuclear morphology after DAPI staining and the inhibition of the toxic effects by the caspase inhibitor zVAD.fmk were investigated. All assays yielded comparable results and allowed the following ranking of the polymers with regard to cytotoxicity: Poly(ethylenimine) = poly(L-lysine) > poly(diallyl-dimethyl-ammonium chloride) > diethylaminoethyl-dextran > poly (vinyl pyridinium bromide) > Starburst dendrimer > cationized albumin > native albumin. The magnitude of the cytotoxic effects of all polymers were found to be time- and concentration dependent. The molecular weight as well as the cationic charge density of the polycations were confirmed as key parameters for the interaction with the cell membranes and consequently, the cell damage. Evaluating the nature of cell death induced by poly(ethylenimine), we did not detect any indication for apoptosis suggesting that the polymer induced a necrotic cell reaction. Cell nuclei retained their size, chromatin was homogenously distributed and cell membranes lost their integrity very rapidly at an early stage. Furthermore, the broad spectrum caspase inhibitor zVAD.fmk did not inhibit poly(ethylenimine)-induced cell damage. Insights into the structure-toxicity relationship are necessary to optimize the cytotoxicity and biocompatibility of non-viral gene delivery systems. (C) 2002 Elsevier Science Ltd. All rights reserved.																			0142-9612					MAR	2003	24	7					1121	1131	PII S0142-9612(02)00445-3	10.1016/S0142-9612(02)00445-3	http://dx.doi.org/10.1016/S0142-9612(02)00445-3								12527253					WOS:000180603900001
J	Roh, W; Seol, JY; Park, J; Lee, B; Lee, J; Kim, Y; Cho, J; Cheun, K; Aryanfar, F				Roh, Wonil; Seol, Ji-Yun; Park, JeongHo; Lee, Byunghwan; Lee, Jaekon; Kim, Yungsoo; Cho, Jaeweon; Cheun, Kyungwhoon; Aryanfar, Farshid			Millimeter-Wave Beamforming as an Enabling Technology for 5G Cellular Communications: Theoretical Feasibility and Prototype Results	IEEE COMMUNICATIONS MAGAZINE												The ever growing traffic explosion in mobile communications has recently drawn increased attention to the large amount of underutilized spectrum in the millimeter-wave frequency bands as a potentially viable solution for achieving tens to hundreds of times more capacity compared to current 4G cellular networks. Historically, mmWave bands were ruled out for cellular usage mainly due to concerns regarding short-range and non-line-of-sight coverage issues. In this article, we present recent results from channel measurement campaigns and the development of advanced algorithms and a prototype, which clearly demonstrate that the mmWave band may indeed be a worthy candidate for next generation (5G) cellular systems. The results of channel measurements carried out in both the United States and Korea are summarized along with the actual free space propagation measurements in an anechoic chamber. Then a novel hybrid beamforming scheme and its link-and system-level simulation results are presented. Finally, recent results from our mmWave prototyping efforts along with indoor and outdoor test results are described to assert the feasibility of mmWave bands for cellular usage.						Cheun, Kyungwhoon/0000-0001-7206-5258													0163-6804	1558-1896				FEB	2014	52	2					106	113		10.1109/MCOM.2014.6736750	http://dx.doi.org/10.1109/MCOM.2014.6736750													WOS:000331904900013
J	Arulkumaran, K; Deisenroth, MP; Brundage, M; Bharath, AA				Arulkumaran, Kai; Deisenroth, Marc Peter; Brundage, Miles; Bharath, Anil Anthony			Deep Reinforcement Learning <i>A brief survey</i>	IEEE SIGNAL PROCESSING MAGAZINE												Deep reinforcement learning (DRL) is poised to revolutionize the field of artificial intelligence (AI) and represents a step toward building autonomous systems with a higher-level understanding of the visual world. Currently, deep learning is enabling reinforcement learning (RL) to scale to problems that were previously intractable, such as learning to play video games directly from pixels. DRL algorithms are also applied to robotics, allowing control policies for robots to be learned directly from camera inputs in the real world. In this survey, we begin with an introduction to the general field of RL, then progress to the main streams of value-based and policy-based methods. Our survey will cover central algorithms in deep RL, including the deep Q-network (DQN), trust region policy optimization (TRPO), and asynchronous advantage actor critic. In parallel, we highlight the unique advantages of deep neural networks, focusing on visual understanding via RL. To conclude, we describe several current areas of research within the field.					Deisenroth, Marc/G-8947-2013	Arulkumaran, Kai/0000-0003-0459-892X													1053-5888	1558-0792				NOV	2017	34	6					26	38		10.1109/MSP.2017.2743240	http://dx.doi.org/10.1109/MSP.2017.2743240													WOS:000415188500006
J	Tian, J				Tian, J			Reversible data embedding using a difference expansion	IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY												Reversible data embedding has drawn lots of interest recently. Being reversible, the original digital content can be completely restored. In this paper, we present a novel reversible data-embedding method for digital images. We explore the redundancy in digital images to achieve very high embedding capacity, and keep y the distortion low.																			1051-8215	1558-2205				AUG	2003	13	8					890	896		10.1109/TCSVT.2003.815962	http://dx.doi.org/10.1109/TCSVT.2003.815962													WOS:000185154500015
J	Lv, YS; Duan, YJ; Kang, WW; Li, ZX; Wang, FY				Lv, Yisheng; Duan, Yanjie; Kang, Wenwen; Li, Zhengxi; Wang, Fei-Yue			Traffic Flow Prediction With Big Data: A Deep Learning Approach	IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS												Accurate and timely traffic flow information is important for the successful deployment of intelligent transportation systems. Over the last few years, traffic data have been exploding, and we have truly entered the era of big data for transportation. Existing traffic flow prediction methods mainly use shallow traffic prediction models and are still unsatisfying for many real-world applications. This situation inspires us to rethink the traffic flow prediction problem based on deep architecture models with big traffic data. In this paper, a novel deep-learning-based traffic flow prediction method is proposed, which considers the spatial and temporal correlations inherently. A stacked autoencoder model is used to learn generic traffic flow features, and it is trained in a greedy layerwise fashion. To the best of our knowledge, this is the first time that a deep architecture model is applied using autoencoders as building blocks to represent traffic flow features for prediction. Moreover, experiments demonstrate that the proposed method for traffic flow prediction has superior performance.					Li, Zhengxi/IWE-2213-2023; Lv, Yisheng/N-3426-2015	lu, yi sheng/0000-0002-0508-1298													1524-9050	1558-0016				APR	2015	16	2					865	873		10.1109/TITS.2014.2345663	http://dx.doi.org/10.1109/TITS.2014.2345663													WOS:000352282500029
J	He, CB; Hu, YP; Yin, LC; Tang, C; Yin, CH				He, Chunbai; Hu, Yiping; Yin, Lichen; Tang, Cui; Yin, Chunhua			Effects of particle size and surface charge on cellular uptake and biodistribution of polymeric nanoparticles	BIOMATERIALS												To elucidate the effects of particle size and surface charge on cellular uptake and biodistribution of polymeric nanoparticles (NPs), rhodamine B (RhB) labeled carboxymethyl chitosan grafted NPs (RhB-CMCNP) and chitosan hydrochloride grafted NPs (RhB-CHNP) were developed as the model negatively and positively charged polymeric NPs, respectively. These NPs owned well defined particle sizes (150-500 nm) and Zeta potentials (-40 mV - +35 mV). FITC labeled protamine sulfate (FITC-PS) loaded RhB-CMCNP and camptothecin (CPT) loaded RhB-CHNP with high encapsulation efficiency were prepared. The fluorescence stability in plasma and towards I was investigated, and the result indicated it was sufficient for qualitative and quantitative analysis. NPs with high surface charge and large particle size were phagocytized more efficiently by murine macrophage. Slight particle size and surface charge differences and different cell lines had significant implications in the cellular uptake of NPs, and various mechanisms were involved in the uptake process. In vivo biodistribution suggested that NPs with slight negative charges and particle size of 150 nm were tended to accumulate in tumor more efficiently. These results could serve as a guideline in the rational design of drug nanocarriers with maximized therapeutic efficacy and predictable in vivo properties, in which the control of particle size and surface charge was of significance. (C) 2010 Elsevier Ltd. All rights reserved.																			0142-9612	1878-5905				MAY	2010	31	13					3657	3666		10.1016/j.biomaterials.2010.01.065	http://dx.doi.org/10.1016/j.biomaterials.2010.01.065								20138662					WOS:000276254100027
J	Chen, WH; Yang, J; Guo, L; Li, SH				Chen, Wen-Hua; Yang, Jun; Guo, Lei; Li, Shihua			Disturbance-Observer-Based Control and Related Methods-An Overview	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS												Disturbance-observer-based control (DOBC) and related methods have been researched and applied in various industrial sectors in the last four decades. This survey, at first time, gives a systematic and comprehensive tutorial and summary on the existing disturbance/uncertainty estimation and attenuation techniques, most notably, DOBC, active disturbance rejection control, disturbance accommodation control, and composite hierarchical antidisturbance control. In all of these methods, disturbance and uncertainty are, in general, lumped together, and an observation mechanism is employed to estimate the total disturbance. This paper first reviews a number of widely used linear and nonlinear disturbance/uncertainty estimation techniques and then discusses and compares various compensation techniques and the procedures of integrating disturbance/uncertainty compensation with a (predesigned) linear/nonlinear controller. It also provides concise tutorials of the main methods in this area with clear descriptions of their features. The application of this group ofmethods in various industrial sections is reviewed, with emphasis on the commercialization of some algorithms. The survey is ended with the discussion of future directions.					Yang, Jun/N-8514-2014; Li, Shihua/B-2561-2012; Chen, Wen-Hua/C-5993-2009	Li, Shihua/0000-0001-9044-7137; Yang, Jun/0000-0002-4290-9568; Chen, Wen-Hua/0000-0003-3356-2889; Guo, Lei/0000-0002-3061-2337													0278-0046	1557-9948				FEB	2016	63	2					1083	1095		10.1109/TIE.2015.2478397	http://dx.doi.org/10.1109/TIE.2015.2478397													WOS:000369990300039
J	Das, SK; Putra, N; Thiesen, P; Roetzel, W				Das, SK; Putra, N; Thiesen, P; Roetzel, W			Temperature dependence of thermal conductivity enhancement for nanofluids	JOURNAL OF HEAT TRANSFER-TRANSACTIONS OF THE ASME												Usual heat transfer fluids with suspended ultra fine particles of nanometer size are named as nanofluids, which have opened a new dimension in heat transfer processes. The recent investigations confirm the potential of nanofluids in enhancing heat transfer required for present age technology The present investigation goes detailed into investigating the increase of thermal conductivity with temperature for nano fluids with water as base fluid and particles of Al2O3 or CuO as suspension material. A temperature oscillation technique is utilized,for the measurement of thermal diffusivity and thermal conductivity is calculated from it. The results indicate an increase of enhancement characteristics with temperature, which makes the nanofluids even more attractive for applications with high energy density than usual room temperature measurements reported earlier.					Putra, Nandy/L-4412-2019; Thiesen, Peter H./CAI-8857-2022	Putra, Nandy/0000-0003-3010-599X; Thiesen, Peter H./0000-0003-4766-8393													0022-1481	1528-8943				AUG	2003	125	4					567	574		10.1115/1.1571080	http://dx.doi.org/10.1115/1.1571080													WOS:000184610500010
J	Richardson, TJ; Urbanke, RL				Richardson, TJ; Urbanke, RL			The capacity of low-density parity-check codes under message-passing decoding	IEEE TRANSACTIONS ON INFORMATION THEORY												In this paper, we present a general method for determining the capacity of low-density parity-check (LDPC) codes under message-passing decoding when used over any binary-input memoryless channel with discrete or continuous output alphabets, Transmitting at rates below this capacity, a randomly chosen element of the given ensemble will achieve an arbitrarily small target probability of error with a probability that approaches one exponentially fast in the length of the code. (By concatenating with an appropriate outer code one can achieve a probability of error that approaches zero exponentially fast in the length of the code with arbitrarily small loss in rate.) Conversely, transmitting at rates above this capacity the probability of error is bounded away from zero by a strictly positive constant which is independent of the length of the code and of the number of iterations performed. Our results are based on the observation that the concentration of the performance of the decoder around its average performance, as observed by Luby et al. [1] in the case of a binary-symmetric channel and a binary message-passing algorithm, is a general phenomenon, For the particularly important case of belief-propagation decoders, we provide an effective algorithm to deter-mine the corresponding capacity to any desired degree of accuracy, The ideas presented in this paper are broadly applicable and extensions of the general method to low-density parity-check codes over larger alphabets, turbo codes, and other concatenated coding schemes are outlined.					Urbanke, Ruediger/K-6310-2016	Urbanke, Ruediger/0000-0002-4839-821X													0018-9448					FEB	2001	47	2					599	618		10.1109/18.910577	http://dx.doi.org/10.1109/18.910577													WOS:000167491700007
J	Beckmann, CF; Smith, SA				Beckmann, CF; Smith, SA			Probabilistic independent component analysis for functional magnetic resonance imaging	IEEE TRANSACTIONS ON MEDICAL IMAGING												We present an integrated approach to probabilistic independent component analysis (ICA) for functional MRI (FMRI) data that allows for nonsquare mixing in the presence of Gaussian noise. In order to avoid overfitting, we employ objective estimation of the amount of Gaussian noise through Bayesian analysis of the true dimensionality of the data, i.e., the number of activation and non-Gaussian noise sources. This enables us to carry out probabilistic modeling and achieves an asymptotically unique decomposition of the data. It reduces problems of interpretation, as each final independent component is now much more likely to be due to only one physical or physiological process. We also describe other improvements to standard ICA, such as temporal prewhitening and variance normalization of timeseries, the latter being particularly useful in the context of dimensionality reduction when weak activation is present. We discuss the use of prior information about the spatiotemporal nature of the source processes, and an alternative-hypothesis testing approach for inference, using Gaussian mixture models. The performance of our approach is illustrated and evaluated on real and artificial FMRI data, and compared to the spatio-temporal accuracy of results obtained from classical ICA and GLM analyses.					Beckmann, Christian F./E-6374-2012	Beckmann, Christian F./0000-0002-3373-3193; Smith, Stephen/0000-0001-8166-069X													0278-0062	1558-254X				FEB	2004	23	2					137	152		10.1109/TMI.2003.822821	http://dx.doi.org/10.1109/TMI.2003.822821								14964560					WOS:000188858300001
J	Huang, GB; Chen, L; Siew, CK				Huang, Guang-Bin; Chen, Lei; Siew, Chee-Kheong			Universal approximation using incremental constructive feedforward networks with random hidden nodes	IEEE TRANSACTIONS ON NEURAL NETWORKS												According to conventional neural network theories, single-hidden-layer feedforward networks (SLFNs) with additive or radial basis function (RBF) hidden nodes are universal approximators when all the parameters of the networks are allowed adjustable. However, as observed in most neural network implementations, tuning all the parameters of the networks may cause learning complicated and inefficient, and it may be difficult to train networks with nondifferential activation functions such as threshold networks. Unlike conventional neural network theories, this paper proves in an incremental constructive method that in order to let SLFNs work as universal approximators, one may simply randomly choose hidden nodes and then only need to adjust the output weights linking the hidden layer and the output layer. In such SLFNs implementations, the activation functions for additive nodes can be any bounded nonconstant piecewise continuous functions g : R -> R and the activation functions for RBF nodes can be any integrable piecewise continuous functions g : R -> Rand f(R) g(x)dx not equal 0. The proposed incremental method is efficient not only for SFLNs with continuous (including nondifferentiable) activation functions but also for SLFNs with piecewise continuous (such as threshold) activation functions. Compared to other popular methods such a new network is fully automatic and users need not intervene the learning process by manually tuning control parameters.					Huang, Guang-Bin/A-5035-2011; Siew, CK/A-5082-2011; Huang, Guang-Bin/JZE-2974-2024	Huang, Guang-Bin/0000-0002-2480-4965													1045-9227	1941-0093				JUL	2006	17	4					879	892		10.1109/TNN.2006.875977	http://dx.doi.org/10.1109/TNN.2006.875977								16856652					WOS:000238865200004
J	Olivares, DE; Mehrizi-Sani, A; Etemadi, AH; Cañizares, CA; Iravani, R; Kazerani, M; Hajimiragha, AH; Gomis-Bellmunt, O; Saeedifard, M; Palma-Behnke, R; Jiménez-Estévez, GA; Hatziargyriou, ND				Olivares, Daniel E.; Mehrizi-Sani, Ali; Etemadi, Amir H.; Canizares, Claudio A.; Iravani, Reza; Kazerani, Mehrdad; Hajimiragha, Amir H.; Gomis-Bellmunt, Oriol; Saeedifard, Maryam; Palma-Behnke, Rodrigo; Jimenez-Estevez, Guillermo A.; Hatziargyriou, Nikos D.			Trends in Microgrid Control	IEEE TRANSACTIONS ON SMART GRID												The increasing interest in integrating intermittent renewable energy sources into microgrids presents major challenges from the viewpoints of reliable operation and control. In this paper, the major issues and challenges in microgrid control are discussed, and a review of state-of-the-art control strategies and trends is presented; a general overview of the main control principles (e.g., droop control, model predictive control, multi-agent systems) is also included. The paper classifies microgrid control strategies into three levels: primary, secondary, and tertiary, where primary and secondary levels are associated with the operation of the microgrid itself, and tertiary level pertains to the coordinated operation of the microgrid and the host grid. Each control level is discussed in detail in view of the relevant existing technical literature.					Palma-Behnke, Rodrigo/A-1849-2012; Olivares, Daniel/G-2760-2015; Hatziargyriou, Nikos/AAA-3899-2021; Jimenez, Guillermo/C-4085-2015; Gomis-Bellmunt, Oriol/I-3557-2014	Olivares, Daniel/0000-0002-9314-602X; Gomis-Bellmunt, Oriol/0000-0002-9507-8278; Palma-Behnke, Rodrigo/0000-0002-7508-0944; Kazerani, Mehrdad/0000-0002-9200-2139; Jimenez-Estevez, Guillermo/0000-0002-8044-0713; Mehrizi-Sani, Ali/0000-0001-9072-4819													1949-3053	1949-3061				JUL	2014	5	4					1905	1919		10.1109/TSG.2013.2295514	http://dx.doi.org/10.1109/TSG.2013.2295514													WOS:000338191200037
J	Li, ZK; Duan, ZS; Chen, GR; Huang, L				Li, Zhongkui; Duan, Zhisheng; Chen, Guanrong; Huang, Lin			Consensus of Multiagent Systems and Synchronization of Complex Networks: A Unified Viewpoint	IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS												This paper addresses the consensus problem of multiagent systems with a time-invariant communication topology consisting of general linear node dynamics. A distributed observer-type consensus protocol based on relative output measurements is proposed. A new framework is introduced to address in a unified way the consensus of multiagent systems and the synchronization of complex networks. Under this framework, the consensus of multiagent systems with a communication topology having a spanning tree can be cast into the stability of a set of matrices of the same low dimension. The notion of consensus region is then introduced and analyzed. It is shown that there exists an observer-type protocol solving the consensus problem and meanwhile yielding an unbounded consensus region if and only if each agent is both stabilizable and detectable. A multistep consensus protocol design procedure is further presented. The consensus with respect to a time-varying state and the robustness of the consensus protocol to external disturbances are finally discussed. The effectiveness of the theoretical results is demonstrated through numerical simulations, with an application to low-Earth-orbit satellite formation flying.					Li, Zhongkui/G-3639-2010; Duan, Zhisheng/B-4158-2012; Chen, Guanrong/F-6000-2011														1549-8328	1558-0806				JAN	2010	57	1					213	224		10.1109/TCSI.2009.2023937	http://dx.doi.org/10.1109/TCSI.2009.2023937													WOS:000274152300001
J	Yager, RR				Yager, Ronald R.			Pythagorean Membership Grades in Multicriteria Decision Making	IEEE TRANSACTIONS ON FUZZY SYSTEMS												We first look at some nonstandard fuzzy sets, intuitionistic, and interval-valued fuzzy sets. We note both these allow a degree of commitment of less then one in assigning membership. We look at the formulation of the negation for these sets and show its expression in terms of the standard complement with respect to the degree of commitment. We then consider the complement operation. We describe its properties and look at alternative definitions of complement operations. We then focus on the Pythagorean complement. Using this complement, we introduce a class of nonstandard Pythagorean fuzzy subsets whose membership grades are pairs, (a, b) satisfying the requirement a(2) + b(2) <= 1. We introduce a variety of aggregation operations for these Pythagorean fuzzy subsets. We then look at multicriteria decision making in the case where the criteria satisfaction are expressed using Pythagorean membership grades. The issue of having to choose a best alternative in multicriteria decision making leads us to consider the problem of comparing Pythagorean membership grades.					Yager, Ronald/L-1429-2017														1063-6706	1941-0034				AUG	2014	22	4					958	965		10.1109/TFUZZ.2013.2278989	http://dx.doi.org/10.1109/TFUZZ.2013.2278989													WOS:000344661600020
J	Moreau, L				Moreau, L			Stability of multiagent systems with time-dependent communication links	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												We study a simple but compelling model of network of agents interacting via time-dependent communication links. The model finds application in a variety of fields including synchronization, swarming and distributed decision making. In the model, each agent updates his current state based upon the current information received from neighboring agents. Necessary and/or sufficient conditions for the convergence of the individual agents' states to a common value are presented, thereby extending recent results reported in the literature.. The stability analysis is based upon a blend of graph-theoretic and system-theoretic tools with the notion of convexity playing a central role. The analysis is integrated within a formal framework of set-valued Lyapunov theory, which may be of independent interest. Among others, it is observed that more communication does not necessarily lead to faster convergence and may eventually even lead to a loss of convergence, even for the simple models discussed in the present paper.					Moreau, Luc/C-9061-2011														0018-9286	1558-2523				FEB	2005	50	2					169	182		10.1109/TAC.2004.841888	http://dx.doi.org/10.1109/TAC.2004.841888													WOS:000226909700003
J	Tiwari, RK; Das, MK				Tiwari, Raj Kamal; Das, Manab Kumar			Heat transfer augmentation in a two-sided lid-driven differentially heated square cavity utilizing nanofluids	INTERNATIONAL JOURNAL OF HEAT AND MASS TRANSFER												The behaviour of nanofluids is investigated numerically inside a two-sided lid-driven differentially heated square cavity to gain insight into convective recirculation and flow processes induced by a nanofluid. A model is developed to analyze the behaviour of nanofluids taking into account the solid volume fraction Z. The transport equations are solved numerically with finite volume approach using SIMPLE algorithm. Comparisons with previously published work on the basis of special cases are performed and found to be in excellent agreement. The left and the right moving walls are maintained at different constant temperatures while the upper and the bottom walls are thermally insulated. Three case were considered depending on the direction of the moving walls. Governing parameters were 0.01 < Ri < 100 but due to space constraints only the results for 0. 1 < Ri < 10 are presented. It is found that both the Richardson number and the direction of the moving walls affect the fluid flow and heat transfer in the cavity. Copper-Water nanofluid is used with Pr = 6.2 and solid volume fraction Z is varied as 0.0%, 8%, 16% and 20%. Detailed results are presented for flow pattern and heat transfer curves. (c) 2006 Elsevier Ltd. All rights reserved.																			0017-9310	1879-2189				MAY	2007	50	9-10					2002	2018		10.1016/j.ijheatmasstransfer.2006.09.034	http://dx.doi.org/10.1016/j.ijheatmasstransfer.2006.09.034													WOS:000245502100035
J	Kolmogorov, V; Zabih, R				Kolmogorov, V; Zabih, R			What energy functions can be minimized via graph cuts?	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												In the last few years, several new algorithms based on graph cuts have been developed to solve energy minimization problems in computer vision. Each of these techniques constructs a graph such that the minimum cut on the graph also minimizes the energy. Yet, because these graph constructions are complex and highly specific to a particular energy function, graph cuts have seen limited application to date. In this paper, we give a characterization of the energy functions that can be minimized by graph cuts. Our results are restricted to functions of binary variables. However, our work generalizes many previous constructions and is easily applicable to vision problems that involve large numbers of labels, such as stereo, motion, image restoration, and scene reconstruction. We give a precise characterization of what energy functions can be minimized using graph cuts, among the energy functions that can be written as a sum of terms containing three or fewer binary variables. We also provide a general-purpose construction to minimize such an energy function. Finally, we give a necessary condition for any energy function of binary variables to be minimized by graph cuts. Researchers who are considering the use of graph cuts to optimize a particular energy function can use our results to determine if this is possible and then follow our construction to create the appropriate graph. A software implementation is freely available.						Zabih, Ramin/0000-0001-8769-5666													0162-8828	1939-3539				FEB	2004	26	2					147	159		10.1109/TPAMI.2004.1262177	http://dx.doi.org/10.1109/TPAMI.2004.1262177								15376891					WOS:000187954300002
J	Creswell, A; White, T; Dumoulin, V; Arulkumaran, K; Sengupta, B; Bharath, AA				Creswell, Antonia; White, Tom; Dumoulin, Vincent; Arulkumaran, Kai; Sengupta, Biswa; Bharath, Anil A.			Generative Adversarial Networks <i>An overview</i>	IEEE SIGNAL PROCESSING MAGAZINE																		Bharath, Anil/0000-0001-8808-2714; Arulkumaran, Kai/0000-0003-0459-892X													1053-5888	1558-0792				JAN	2018	35	1					53	65		10.1109/MSP.2017.2765202	http://dx.doi.org/10.1109/MSP.2017.2765202													WOS:000422751500008
J	Chen, YS; Lin, ZH; Zhao, X; Wang, G; Gu, YF				Chen, Yushi; Lin, Zhouhan; Zhao, Xing; Wang, Gang; Gu, Yanfeng			Deep Learning-Based Classification of Hyperspectral Data	IEEE JOURNAL OF SELECTED TOPICS IN APPLIED EARTH OBSERVATIONS AND REMOTE SENSING												Classification is one of the most popular topics in hyperspectral remote sensing. In the last two decades, a huge number of methods were proposed to deal with the hyperspectral data classification problem. However, most of them do not hierarchically extract deep features. In this paper, the concept of deep learning is introduced into hyperspectral data classification for the first time. First, we verify the eligibility of stacked autoencoders by following classical spectral information-based classification. Second, a new way of classifying with spatial-dominated information is proposed. We then propose a novel deep learning framework to merge the two features, from which we can get the highest classification accuracy. The framework is a hybrid of principle component analysis (PCA), deep learning architecture, and logistic regression. Specifically, as a deep learning architecture, stacked autoencoders are aimed to get useful high-level features. Experimental results with widely-used hyperspectral data indicate that classifiers built in this deep learning-based framework provide competitive performance. In addition, the proposed joint spectral-spatial deep neural network opens a new window for future research, showcasing the deep learning-based methods' huge potential for accurate hyperspectral data classification.					Wang, Gang/B-7027-2013; Chen, Yushi/ACI-9252-2022; Gu, Yanfeng/F-7781-2015														1939-1404	2151-1535				JUN	2014	7	6			SI		2094	2107		10.1109/JSTARS.2014.2329330	http://dx.doi.org/10.1109/JSTARS.2014.2329330													WOS:000340621200022
J	Dahl, GE; Yu, D; Deng, L; Acero, A				Dahl, George E.; Yu, Dong; Deng, Li; Acero, Alex			Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING												We propose a novel context-dependent (CD) model for large-vocabulary speech recognition (LVSR) that leverages recent advances in using deep belief networks for phone recognition. We describe a pre-trained deep neural network hidden Markov model (DNN-HMM) hybrid architecture that trains the DNN to produce a distribution over senones (tied triphone states) as its output. The deep belief network pre-training algorithm is a robust and often helpful way to initialize deep neural networks generatively that can aid in optimization and reduce generalization error. We illustrate the key components of our model, describe the procedure for applying CD-DNN-HMMs to LVSR, and analyze the effects of various modeling choices on performance. Experiments on a challenging business search dataset demonstrate that CD-DNN-HMMs can significantly outperform the conventional context-dependent Gaussian mixture model (GMM)-HMMs, with an absolute sentence accuracy improvement of 5.8% and 9.2% (or relative error reduction of 16.0% and 23.2%) over the CD-GMM-HMMs trained using the minimum phone error rate (MPE) and maximum-likelihood (ML) criteria, respectively.					yu, dong/KRO-7922-2024														1558-7916	1558-7924				JAN	2012	20	1					30	42		10.1109/TASL.2011.2134090	http://dx.doi.org/10.1109/TASL.2011.2134090													WOS:000298325600007
J	Matas, J; Chum, O; Urban, M; Pajdla, T				Matas, J; Chum, O; Urban, M; Pajdla, T			Robust wide-baseline stereo from maximally stable extremal regions	IMAGE AND VISION COMPUTING												The wide-baseline stereo problem, i.e. the problem of establishing correspondences between a pair of images taken from different viewpoints is studied. A new set of image elements that are put into correspondence, the so called extremal regions, is introduced. Extremal regions possess highly desirable properties: the set is closed under (1) continuous (and thus projective) transformation of image coordinates and (2) monotonic transformation of image intensities. An efficient (near linear complexity) and practically fast detection algorithm (near frame rate) is presented for an affinely invariant stable subset of extremal regions, the maximally stable extremal regions (MSER). A new robust similarity measure for establishing tentative correspondences is proposed. The robustness ensures that invariants from multiple measurement regions (regions obtained by invariant constructions from extremal re ions), some that are significantly larger (and hence discriminative) than the MSERs, may be used to establish tentative correspondences. The high utility of MSERs, multiple measurement regions and the robust metric is demonstrated in wide-baseline experiments on image pairs from both indoor and outdoor scenes. Significant change of scale (3.5 X), illumination conditions, out-of-plane rotation, occlusion, locally anisotropic scale change and 3D translation of the viewpoint are all present in the test problems. Good estimates of epipolar geometry (average distance from corresponding points to the epipolar line below 0.09 of the inter-pixel distance) are obtained. (C) 2004 Elsevier B.V. All rights reserved.					Chum, Ondrej/F-5262-2015; , Matas/AAW-3282-2020; Pajdla, Tomas/K-7954-2013; Urban, Mark/Y-2430-2019	Matas, Jiri/0000-0003-0863-4844; Pajdla, Tomas/0000-0001-6325-0072; Chum, Ondrej/0000-0001-7042-1810													0262-8856	1872-8138				SEP 1	2004	22	10					761	767		10.1016/j.imavis.2004.02.006	http://dx.doi.org/10.1016/j.imavis.2004.02.006													WOS:000222889300003
J	Bulusu, N; Heidemann, J; Estrin, D				Bulusu, N; Heidemann, J; Estrin, D			GPS-less low-cost outdoor localization for very small devices	IEEE PERSONAL COMMUNICATIONS												Instrumenting the physical world through large networks of wireless sensor nodes, particularly for applications like environmental monitoring of water and soil, requires that these nodes be very small, lightweight, untethered, and unobtrusive. The problem of localization, that is, determining where a given node is physically located in a network, is a challenging one, and yet extremely crucial for many of these applications. Practical considerations such as the small size, form factor, cost and power constraints of nodes preclude the reliance on GPS of all nodes in these networks. In this article we review localization techniques and evaluate the effectiveness of a very simple connectivity metric method for localization in outdoor environments that makes use of the inherent RF communications capabilities of these devices. A fixed number of reference points in the network with overlapping regions of coverage transmit periodic beacon signals. Nodes use a simple connectivity metric, which is more robust to environmental vagaries, to infer proximity to a given subset of these reference points. Nodes localize themselves to the centroid of their proximate reference points. The accuracy of localization is then dependent on the separation distance between two adjacent reference points and the transmission range of these reference points. Initial experimental results show that the accuracy for 90 percent of our data points is within one-third of the separation distance. However, future work is needed to extend the technique to more cluttered environments.						Heidemann, John/0000-0002-1225-7562													1070-9916					OCT	2000	7	5					28	34		10.1109/98.878533	http://dx.doi.org/10.1109/98.878533													WOS:000089992500006
J	Middleton, JC; Tipton, AJ				Middleton, JC; Tipton, AJ			Synthetic biodegradable polymers as orthopedic devices	BIOMATERIALS												Polymer scientists, working closely with those in the device and medical fields, have made tremendous advances over the past 30 years in the use of synthetic materials in the body. In this article we will focus on properties of biodegradable polymers which make them ideally suited for orthopedic applications where a permanent implant is not desired. The materials with the greatest history of use are the poly(lactides) and poly(glycolides), and these will be covered in specific detail. The chemistry of the polymers, including synthesis and degradation, the tailoring of properties by proper synthetic controls such as copolymer composition, special requirements for processing and handling, and mechanisms of biodegradation will be covered. An overview of biocompatibility and approved devices of particular interest in orthopedics are also covered. (C) 2000 Elsevier Science Ltd. All rights reserved.																			0142-9612	1878-5905				DEC	2000	21	23			SI		2335	2346		10.1016/S0142-9612(00)00101-0	http://dx.doi.org/10.1016/S0142-9612(00)00101-0								11055281					WOS:000089679000002
J	Mohsenian-Rad, AH; Wong, VWS; Jatskevich, J; Schober, R; Leon-Garcia, A				Mohsenian-Rad, Amir-Hamed; Wong, Vincent W. S.; Jatskevich, Juri; Schober, Robert; Leon-Garcia, Alberto			Autonomous Demand-Side Management Based on Game-Theoretic Energy Consumption Scheduling for the Future Smart Grid	IEEE TRANSACTIONS ON SMART GRID												Most of the existing demand-side management programs focus primarily on the interactions between a utility company and its customers/users. In this paper, we present an autonomous and distributed demand-side energy management system among users that takes advantage of a two-way digital communication infrastructure which is envisioned in the future smart grid. We use game theory and formulate an energy consumption scheduling game, where the players are the users and their strategies are the daily schedules of their household appliances and loads. It is assumed that the utility company can adopt adequate pricing tariffs that differentiate the energy usage in time and level. We show that for a common scenario, with a single utility company serving multiple customers, the global optimal performance in terms of minimizing the energy costs is achieved at the Nash equilibrium of the formulated energy consumption scheduling game. The proposed distributed demand-side energy management strategy requires each user to simply apply its best response strategy to the current total load and tariffs in the power distribution system. The users can maintain privacy and do not need to reveal the details on their energy consumption schedules to other users. We also show that users will have the incentives to participate in the energy consumption scheduling game and subscribing to such services. Simulation results confirm that the proposed approach can reduce the peak-to-average ratio of the total energy demand, the total energy costs, as well as each user's individual daily electricity charges.					Schober, Robert/ABC-9480-2020; Wong, Vincent/O-6120-2019	Wong, Vincent/0000-0003-3821-4365													1949-3053	1949-3061				DEC	2010	1	3					320	331		10.1109/TSG.2010.2089069	http://dx.doi.org/10.1109/TSG.2010.2089069													WOS:000208787300012
J	Chen, X; Jiao, L; Li, WZ; Fu, XM				Chen, Xu; Jiao, Lei; Li, Wenzhong; Fu, Xiaoming			Efficient Multi-User Computation Offloading for Mobile-Edge Cloud Computing	IEEE-ACM TRANSACTIONS ON NETWORKING												Mobile-edge cloud computing is a new paradigm to provide cloud computing capabilities at the edge of pervasive radio access networks in close proximity to mobile users. In this paper, we first study the multi-user computation offloading problem for mobile-edge cloud computing in a multi-channel wireless interference environment. We show that it is NP-hard to compute a centralized optimal solution, and hence adopt a game theoretic approach for achieving efficient computation offloading in a distributed manner. We formulate the distributed computation offloading decision making problem among mobile device users as a multi-user computation offloading game. We analyze the structural property of the game and show that the game admits a Nash equilibrium and possesses the finite improvement property. We then design a distributed computation offloading algorithm that can achieve a Nash equilibrium, derive the upper bound of the convergence time, and quantify its efficiency ratio over the centralized optimal solutions in terms of two important performance metrics. We further extend our study to the scenario of multi-user computation offloading in the multi-channel wireless contention environment. Numerical results corroborate that the proposed algorithm can achieve superior computation offloading performance and scale well as the user size increases.					Chen, Xu/GXW-3072-2022; Jiao, Lei/GWR-2528-2022; Fu, Xiaoming/B-7208-2016	Jiao, Lei/0000-0002-3964-3172; Fu, Xiaoming/0000-0002-8012-4753													1063-6692	1558-2566				OCT	2016	24	5					2827	2840		10.1109/TNET.2015.2487344	http://dx.doi.org/10.1109/TNET.2015.2487344													WOS:000386238600019
J	Palensky, P; Dietrich, D				Palensky, Peter; Dietrich, Dietmar			Demand Side Management: Demand Response, Intelligent Energy Systems, and Smart Loads	IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS												Energy management means to optimize one of the most complex and important technical creations that we know: the energy system. While there is plenty of experience in optimizing energy generation and distribution, it is the demand side that receives increasing attention by research and industry. Demand Side Management (DSM) is a portfolio of measures to improve the energy system at the side of consumption. It ranges from improving energy efficiency by using better materials, over smart energy tariffs with incentives for certain consumption patterns, up to sophisticated real-time control of distributed energy resources. This paper gives an overview and a taxonomy for DSM, analyzes the various types of DSM, and gives an outlook on the latest demonstration projects in this domain.					Palensky, Peter/J-7238-2013														1551-3203	1941-0050				AUG	2011	7	3					381	388		10.1109/TII.2011.2158841	http://dx.doi.org/10.1109/TII.2011.2158841													WOS:000293753600001
J	Steffen, W; Crutzen, PJ; McNeill, JR				Steffen, Will; Crutzen, Paul J.; McNeill, John R.			The Anthropocene: Are humans now overwhelming the great forces of nature	AMBIO												We explore the development of the Anthropocene, the current epoch in which humans and our societies have become a global geophysical force. The Anthropocene began around 1800 with the onset of industrialization, the central feature of which was the enormous expansion in the use of fossil fuels. We use atmospheric carbon dioxide concentration as a single, simple indicator to track the progression of the Anthropocene. From a preindustrial value of 270-275 ppm, atmospheric carbon dioxide had risen to about 310 ppm by 1950. Since then the human enterprise has experienced a remarkable explosion, the Great Acceleration, with significant consequences for Earth System functioning. Atmospheric CO2 concentration has risen from 310 to 380 ppm since 1950, with about half of the total rise since the preindustrial era occurring in just the last 30 years. The Great Acceleration is reaching criticality. Whatever unfolds, the next few decades will surely be a tipping point in the evolution of the Anthropocene.					Crutzen, Paul/F-6044-2012; Steffen, Will/C-7651-2011														0044-7447	1654-7209				DEC	2007	36	8					614	621		10.1579/0044-7447(2007)36[614:TAAHNO]2.0.CO;2	http://dx.doi.org/10.1579/0044-7447(2007)36[614:TAAHNO]2.0.CO;2								18240674					WOS:000251979900001
J	Keblinski, P; Phillpot, SR; Choi, SUS; Eastman, JA				Keblinski, P; Phillpot, SR; Choi, SUS; Eastman, JA			Mechanisms of heat flow in suspensions of nano-sized particles (nanofluids)	INTERNATIONAL JOURNAL OF HEAT AND MASS TRANSFER												Recent measurements on nanofluids have demonstrated that the thermal conductivity increases with decreasing grain size. However, Such increases cannot be explained by existing theories. We explore four possible explanations for this anomalous increase: Brownian motion of the particles, molecular-level layering of the liquid at the liquid/particle interface, the nature of heat transport in the nanoparticles. and the effects of nanoparticle clustering. We show that the key factors in understanding thermal properties of nanofluids are the ballistic, rather than diffusive, nature of heat transport in the nanoparticles, combined with direct or fluid-mediated clustering effects that provide paths for rapid heat transport. (C) 2001 Elsevier Science Ltd. All rights reserved.					Phillpot, Simon/J-9117-2012; Eastman, Jeffrey/E-4380-2011	Phillpot, Simon/0000-0002-7774-6535; Eastman, Jeffrey/0000-0002-0847-4265													0017-9310	1879-2189				FEB	2002	45	4					855	863		10.1016/S0017-9310(01)00175-2	http://dx.doi.org/10.1016/S0017-9310(01)00175-2													WOS:000172960800016
J	Gottschalk, F; Sonderer, T; Scholz, RW; Nowack, B				Gottschalk, Fadri; Sonderer, Tobias; Scholz, Roland W.; Nowack, Bernd			Modeled Environmental Concentrations of Engineered Nanomaterials (TiO<sub>2</sub>, ZnO, Ag, CNT, Fullerenes) for Different Regions	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Engineered nanomaterials (ENM) are already used in many products and consequently released into environmental compartments. In this study, we calculated predicted environmental concentrations (PEC) based on a probabilistic material flow analysis from a life-cycle perspective of ENM-containing products. We modeled namo-TiO2, namo-ZnO, nano-Ag, carbon nanotubes (CNT), and fullerenes for the U.S., Europe and Switzerland. The environmental concentrations were calculated as probabilistic density functions and were compared to data from ecotoxicological studies. The simulated modes (most frequent values) range from 0.003 ng L-1 (fullerenes) to 21 ng L-1 (namo-TiO2) for surface waters and from 4 ng L-1 (fullerenes) to 4 mu g L-1 (nano-TiO2) for sewage treatment effluents. For Europe and the U.S., the annual increase of ENMs on sludge-treated soil ranges from 1 ng kg(-1) for fullerenes to 89 mu g kg(-1) for namo-TiO2. The results of this study indicate that risks to aquatic organisms may currently emanate from nano-Ag, namo-TiO2, and namo-ZnO in sewage treatment effluents for all considered regions and for nano-Ag in surface waters. For the other environmental compartments for which ecotoxicological data were available, no risks to organisms are presently expected.					Scholz, Roland/B-2076-2008; Nowack, Bernd/B-6425-2008	Scholz, Roland/0000-0003-2506-3254; Nowack, Bernd/0000-0002-5676-112X													0013-936X	1520-5851				DEC 15	2009	43	24					9216	9222		10.1021/es9015553	http://dx.doi.org/10.1021/es9015553								20000512					WOS:000272462500030
J	Gilbert, TL				Gilbert, TL			A phenomenological theory of damping in ferromagnetic materials	IEEE TRANSACTIONS ON MAGNETICS												In 1955, a phenomenological theory of ferromagnetism was well established and had been corroborated by a considerable amount of experimental data. However, there were problems in the phenomenological theory of the dynamics of the magnetization field. The Landau-Lifshitz equation for damping of the motion of the magnetization field could not account for the large noneddy-current damping in thin Permalloy sheets. The problem undertaken herein is a reformulation of the theory in a way that is more consistent with the theory of damping in other physical systems in order to be able to take large damping into account.																			0018-9464	1941-0069				NOV	2004	40	6					3443	3449		10.1109/TMAG.2004.836740	http://dx.doi.org/10.1109/TMAG.2004.836740													WOS:000225053600005
J	Swaroop, D; Hedrick, JK; Yip, PP; Gerdes, JC				Swaroop, D; Hedrick, JK; Yip, PP; Gerdes, JC			Dynamic surface control for a class of nonlinear systems	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												A new method is proposed for designing controllers with arbitrarily small tracking error for uncertain, mismatched nonlinear systems in the strict feedback form. This method is another "synthetic input technique," similar to backstepping and multiple surface control methods, but with an important addition, r - 1 low pass filters are included in the design where r is the relative degree of the output to be controlled. It is shown that these low pass filters allo rv a design where the model is not differentiated, thus ending the complexity arising due to the "explosion of terms" that has made other methods difficult to implement in practice. The backstepping approach, while suffering from the problem of "explosion of terms" guarantees boundedness of tracking errors globally; however, the proposed approach, while being simpler to implement, can only guarantee boundedness of tracking error semiglobally, when the nonlinearities in the system are non-Lipschitz.					Darbha, Swaroop/W-8667-2018														0018-9286					OCT	2000	45	10					1893	1899		10.1109/TAC.2000.880994	http://dx.doi.org/10.1109/TAC.2000.880994													WOS:000165173400013
J	Al-Hourani, A; Kandeepan, S; Lardner, S				Al-Hourani, Akram; Kandeepan, Sithamparanathan; Lardner, Simon			Optimal LAP Altitude for Maximum Coverage	IEEE WIRELESS COMMUNICATIONS LETTERS												Low-altitude aerial platforms (LAPs) have recently gained significant popularity as key enablers for rapid deployable relief networks where coverage is provided by onboard radio heads. These platforms are capable of delivering essential wireless communication for public safety agencies in remote areas or during the aftermath of natural disasters. In this letter, we present an analytical approach to optimizing the altitude of such platforms to provide maximum radio coverage on the ground. Our analysis shows that the optimal altitude is a function of the maximum allowed pathloss and of the statistical parameters of the urban environment, as defined by the International Telecommunication Union. Furthermore, we present a closed-form formula for predicting the probability of the geometrical line of sight between a LAP and a ground receiver.					Al-Hourani, Akram/AAC-1330-2020; Al-Hourani, Akram/I-6907-2016	Al-Hourani, Akram/0000-0003-0652-8626; Sithamparanathan, Kandeepan/0000-0002-9388-9173													2162-2337	2162-2345				DEC	2014	3	6					569	572		10.1109/LWC.2014.2342736	http://dx.doi.org/10.1109/LWC.2014.2342736													WOS:000209681700006
J	Femia, N; Petrone, G; Spagnuolo, G; Vitelli, M				Femia, N; Petrone, G; Spagnuolo, G; Vitelli, M			Optimization of perturb and observe maximum power point tracking method	IEEE TRANSACTIONS ON POWER ELECTRONICS												Maximum power point tracking (MPPT) techniques are used in photovoltaic (PV) systems to maximize the PV array output power by tracking continuously the maximum power point (MPP) which depends on panels temperature and on irradiance conditions. The issue of MPPT has been addressed in different ways in the literature but, especially for low-cost implementations, the perturb and observe (P&O) maximum power point tracking algorithm is the most commonly used method due to its ease of implementation. A drawback of P&O is that, at steady state, the operating point oscillates around the MPP giving rise to the waste of some amount of available energy; moreover, it is well known that the P&O algorithm can be confused during those time intervals characterized by rapidly changing atmospheric conditions. In this paper it is shown that, in order to limit the negative effects associated to the above drawbacks, the P&O MPPT parameters must be customized to the dynamic behavior of the specific converter adopted. A theoretical analysis allowing the optimal choice of such parameters is also carried out. Results of experimental measurements are in agreement with the predictions of theoretical analysis.					Vitelli, Massimo/AAI-2073-2019; Petrone, Giovanni/J-1802-2019; Spagnuolo, Giovanni/G-5398-2012	FEMIA, Nicola/0000-0003-0313-1869; PETRONE, GIOVANNI/0000-0003-0163-9546; Spagnuolo, Giovanni/0000-0002-4817-1138; Vitelli, Massimo/0000-0003-0315-0891													0885-8993	1941-0107				JUL	2005	20	4					963	973		10.1109/TPEL.2005.850975	http://dx.doi.org/10.1109/TPEL.2005.850975													WOS:000230420800029
J	Dimarogonas, DV; Frazzoli, E; Johansson, KH				Dimarogonas, Dimos V.; Frazzoli, Emilio; Johansson, Karl H.			Distributed Event-Triggered Control for Multi-Agent Systems	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												Event-driven strategies for multi-agent systems are motivated by the future use of embedded microprocessors with limited resources that will gather information and actuate the individual agent controller updates. The controller updates considered here are event-driven, depending on the ratio of a certain measurement error with respect to the norm of a function of the state, and are applied to a first order agreement problem. A centralized formulation is considered first and then its distributed counterpart, in which agents require knowledge only of their neighbors' states for the controller implementation. The results are then extended to a self-triggered setup, where each agent computes its next update time at the previous one, without having to keep track of the state error that triggers the actuation between two consecutive update instants. The results are illustrated through simulation examples.					Johansson, Karl H./E-1724-2013	Johansson, Karl H./0000-0001-9940-5929; /0000-0002-0505-1400													0018-9286	1558-2523				MAY	2012	57	5					1291	1297		10.1109/TAC.2011.2174666	http://dx.doi.org/10.1109/TAC.2011.2174666													WOS:000303325100022
J	Cai, BL; Xu, XM; Jia, K; Qing, CM; Tao, DC				Cai, Bolun; Xu, Xiangmin; Jia, Kui; Qing, Chunmei; Tao, Dacheng			DehazeNet: An End-to-End System for Single Image Haze Removal	IEEE TRANSACTIONS ON IMAGE PROCESSING												Single image haze removal is a challenging ill-posed problem. Existing methods use various constraints/priors to get plausible dehazing solutions. The key to achieve haze removal is to estimate a medium transmission map for an input hazy image. In this paper, we propose a trainable end-to-end system called DehazeNet, for medium transmission estimation. DehazeNet takes a hazy image as input, and outputs its medium transmission map that is subsequently used to recover a haze-free image via atmospheric scattering model. DehazeNet adopts convolutional neural network-based deep architecture, whose layers are specially designed to embody the established assumptions/priors in image dehazing. Specifically, the layers of Maxout units are used for feature extraction, which can generate almost all haze-relevant features. We also propose a novel nonlinear activation function in DehazeNet, called bilateral rectified linear unit, which is able to improve the quality of recovered haze-free image. We establish connections between the components of the proposed DehazeNet and those used in existing methods. Experiments on benchmark images show that DehazeNet achieves superior performance over existing methods, yet keeps efficient and easy to use.					Tao, Dacheng/A-5449-2012	Cai, Bolun/0000-0002-9394-7820													1057-7149	1941-0042				NOV	2016	25	11					5187	5198		10.1109/TIP.2016.2598681	http://dx.doi.org/10.1109/TIP.2016.2598681								28873058					WOS:000386148400015
J	Nosratinia, A; Hunter, TE; Hedayat, A				Nosratinia, A; Hunter, TE; Hedayat, A			Cooperative communication in wireless networks	IEEE COMMUNICATIONS MAGAZINE												Transmit diversity generally requires more than one antenna at the transmitter. However, many wireless devices are limited by size or hardware complexity to one antenna. Recently, a new class of methods called cooperative communication has been proposed that enables single-antenna mobiles in a multi-user environment to share their antennas and generate a virtual multiple-antenna transmitter that allows them to achieve transmit diversity. This article presents an overview of the developments in this burgeoning field.					Nosratinia, Aria/B-2753-2013	Nosratinia, Aria/0000-0002-3751-0165													0163-6804	1558-1896				OCT	2004	42	10					74	80		10.1109/MCOM.2004.1341264	http://dx.doi.org/10.1109/MCOM.2004.1341264													WOS:000224331000009
J	Yilmaz, M; Krein, PT				Yilmaz, Murat; Krein, Philip T.			Review of Battery Charger Topologies, Charging Power Levels, and Infrastructure for Plug-In Electric and Hybrid Vehicles	IEEE TRANSACTIONS ON POWER ELECTRONICS												This paper reviews the current status and implementation of battery chargers, charging power levels, and infrastructure for plug-in electric vehicles and hybrids. Charger systems are categorized into off-board and on-board types with unidirectional or bidirectional power flow. Unidirectional charging limits hardware requirements and simplifies interconnection issues. Bidirectional charging supports battery energy injection back to the grid. Typical on-board chargers restrict power because of weight, space, and cost constraints. They can be integrated with the electric drive to avoid these problems. The availability of charging infrastructure reduces on-board energy storage requirements and costs. On-board charger systems can be conductive or inductive. An off-board charger can be designed for high charging rates and is less constrained by size and weight. Level 1 (convenience), Level 2 (primary), and Level 3 (fast) power levels are discussed. Future aspects such as roadbed charging are presented. Various power level chargers and infrastructure configurations are presented, compared, and evaluated based on amount of power, charging time and location, cost, equipment, and other factors.					Krein, Philip/R-3113-2019; Yilmaz, Murat/A-6867-2018	Yilmaz, Murat/0000-0003-1584-1788													0885-8993	1941-0107				MAY	2013	28	5					2151	2169		10.1109/TPEL.2012.2212917	http://dx.doi.org/10.1109/TPEL.2012.2212917													WOS:000314699700006
J	Khan, WA; Pop, I				Khan, W. A.; Pop, I.			Boundary-layer flow of a nanofluid past a stretching sheet	INTERNATIONAL JOURNAL OF HEAT AND MASS TRANSFER												The problem of laminar fluid flow which results from the stretching of a flat surface in a nanofluid has been investigated numerically. This is the first paper on stretching sheet in nanofluids. The model used for the nanofluid incorporates the effects of Brownian motion and thermophoresis. A similarity solution is presented which depends on the Prandtl number Pr, Lewis number Le, Brownian motion number Nb and thermophoresis number Nt. The variation of the reduced Nusselt and reduced Sherwood numbers with Nb and Nt for various values of Pr and Le is presented in tabular and graphical forms. It was found that the reduced Nusselt number is a decreasing function of each dimensionless number, while the reduced Sherwood number is an increasing function of higher Pr and a decreasing function of lower Pr number for each Le, Nb and Nt numbers. (C) 2010 Elsevier Ltd. All rights reserved.					Pop, Ioan/ABE-6678-2020; Khan, Waqar/H-3886-2013	Khan, Waqar/0000-0002-8328-850X													0017-9310	1879-2189				MAY	2010	53	11-12					2477	2483		10.1016/j.ijheatmasstransfer.2010.01.032	http://dx.doi.org/10.1016/j.ijheatmasstransfer.2010.01.032													WOS:000276428800016
J	Sinopoli, B; Schenato, L; Franceschetti, M; Poolla, K; Jordan, MI; Sastry, SS				Sinopoli, B; Schenato, L; Franceschetti, M; Poolla, K; Jordan, MI; Sastry, SS			Kalman filtering with intermittent observations	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												Motivated by navigation and tracking applications within sensor networks, we consider the problem of performing Kalman filtering with intermittent observations. When data travel along unreliable communication channels in a large, wireless, multihop sensor network, the effect of communication delays and loss of information in the control loop cannot be neglected. We address this problem starting from the discrete Kalman filtering formulation, and modeling the arrival of the observation as a random process. We study the statistical convergence properties of the estimation error covariance, showing the existence of a critical value for the arrival rate of the observations, beyond which a transition to an unbounded state error covariance occurs. We also give upper and lower bounds on this expected state error covariance.					schenato, luca/E-6736-2012; Jordan, Michael/C-5253-2013	SCHENATO, LUCA/0000-0003-2544-2553													0018-9286	1558-2523				SEP	2004	49	9					1453	1464		10.1109/TAC.2004.834121	http://dx.doi.org/10.1109/TAC.2004.834121													WOS:000223851800004
J	Myronenko, A; Song, XB				Myronenko, Andriy; Song, Xubo			Point Set Registration: Coherent Point Drift	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Point set registration is a key component in many computer vision tasks. The goal of point set registration is to assign correspondences between two sets of points and to recover the transformation that maps one point set to the other. Multiple factors, including an unknown nonrigid spatial transformation, large dimensionality of point set, noise, and outliers, make the point set registration a challenging problem. We introduce a probabilistic method, called the Coherent Point Drift (CPD) algorithm, for both rigid and nonrigid point set registration. We consider the alignment of two point sets as a probability density estimation problem. We fit the Gaussian mixture model (GMM) centroids (representing the first point set) to the data (the second point set) by maximizing the likelihood. We force the GMM centroids to move coherently as a group to preserve the topological structure of the point sets. In the rigid case, we impose the coherence constraint by reparameterization of GMM centroid locations with rigid parameters and derive a closed form solution of the maximization step of the EM algorithm in arbitrary dimensions. In the nonrigid case, we impose the coherence constraint by regularizing the displacement field and using the variational calculus to derive the optimal transformation. We also introduce a fast algorithm that reduces the method computation complexity to linear. We test the CPD algorithm for both rigid and nonrigid transformations in the presence of noise, outliers, and missing points, where CPD shows accurate results and outperforms current state-of-the-art methods.						Myronenko, Andriy/0000-0001-8713-7031													0162-8828	1939-3539				DEC	2010	32	12					2262	2275		10.1109/TPAMI.2010.46	http://dx.doi.org/10.1109/TPAMI.2010.46								20975122					WOS:000283558700011
J	Rodríguez, RM; Martínez, L; Herrera, F				Rodriguez, Rosa M.; Martinez, Luis; Herrera, Francisco			Hesitant Fuzzy Linguistic Term Sets for Decision Making	IEEE TRANSACTIONS ON FUZZY SYSTEMS												Dealing with uncertainty is always a challenging problem, and different tools have been proposed to deal with it. Recently, a new model that is based on hesitant fuzzy sets has been presented to manage situations in which experts hesitate between several values to assess an indicator, alternative, variable, etc. Hesitant fuzzy sets suit the modeling of quantitative settings; however, similar situations may occur in qualitative settings so that experts think of several possible linguistic values or richer expressions than a single term for an indicator, alternative, variable, etc. In this paper, the concept of a hesitant fuzzy linguistic term set is introduced to provide a linguistic and computational basis to increase the richness of linguistic elicitation based on the fuzzy linguistic approach and the use of context-free grammars by using comparative terms. Then, a multicriteria linguistic decision-makingmodel is presented in which experts provide their assessments by eliciting linguistic expressions. This decision model manages such linguistic expressions by means of its representation using hesitant fuzzy linguistic term sets.					Herrera, Francisco/K-9019-2017; Martinez, Luis/A-1746-2009; Rodriguez, Rosa Maria/B-9618-2011	Herrera, Francisco/0000-0002-7283-312X; Martinez, Luis/0000-0003-4245-8813; Rodriguez, Rosa Maria/0000-0002-1736-8915													1063-6706	1941-0034				FEB	2012	20	1					109	119		10.1109/TFUZZ.2011.2170076	http://dx.doi.org/10.1109/TFUZZ.2011.2170076													WOS:000300080700010
J	Schalk, G; McFarland, DJ; Hinterberger, T; Birbaumer, N; Wolpaw, JR				Schalk, G; McFarland, DJ; Hinterberger, T; Birbaumer, N; Wolpaw, JR			BCI2000: A general-purpose, brain-computer interface (BCI) system	IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING												Many laboratories have begun to develop brain-computer interface (BCI) systems that provide communication and control capabilities to people with severe motor disabilities. Further progress and realization of practical applications depends on systematic evaluations and comparisons of different brain signals, recording methods, processing algorithms, output formats, and operating protocols. However, the typical BCI system is designed specifically for one particular BCI method and is, therefore, not suited to the systematic studies that are essential for continued progress. In response to this problem, we have developed a documented general-purpose BCI research and development platform called BCI2000. BCI2000 can incorporate alone or in combination any brain signals, signal processing methods, output devices, and operating protocols. This report is intended to describe to investigators, biomedical engineers, and computer scientists the concepts that the BCI2000 system is based upon and gives examples of successful BCI implementations using this system. To date, we have used BCI2000 to create BCI systems for a variety of brain signals, processing methods, and applications. The data show that these systems function well in online operation and that BCI2000 satisfies the stringent real-time requirements of BCI systems. By substantially reducing labor and cost, BCI2000 facilitates the implementation of different BCI systems and other psychophysiological experiments. It is available with full documentation and free of charge for research or educational purposes and is currently being used in a variety of studies by many research groups.						Schalk, Gerwin/0000-0003-3443-9487; Wolpaw, Jonathan/0000-0003-0805-1315; Birbaumer, Niels/0000-0002-6786-5127													0018-9294	1558-2531				JUN	2004	51	6					1034	1043		10.1109/TBME.2004.827072	http://dx.doi.org/10.1109/TBME.2004.827072								15188875					WOS:000221578000023
J	Zettler, ER; Mincer, TJ; Amaral-Zettler, LA				Zettler, Erik R.; Mincer, Tracy J.; Amaral-Zettler, Linda A.			Life in the "Plastisphere": Microbial Communities on Plastic Marine Debris	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Plastics are the most abundant form of marine debris, with global production rising and documented impacts in some marine environments, but the influence of plastic on open ocean ecosystems is poorly understood, particularly for microbial communities. Plastic marine debris (PMD) collected at multiple locations in the North Atlantic was analyzed with scanning electron microscopy (SEM) and next generation sequencing to characterize the attached microbial communities. We unveiled a diverse microbial community of heterotrophs, autotrophs, predators, and symbionts, a community we refer to as the "Plastisphere". Pits visualized in the PMD surface conformed to bacterial shapes suggesting active hydrolysis of the hydrocarbon polymer. Small-subunit rRNA gene surveys identified several hydrocarbon degrading bacteria, supporting the possibility that microbes play a role in degrading PMD. Some Plastisphere members may be opportunistic pathogens (the authors, unpublished data) such as specific members of the genus Vibrio that dominated one of our plastic samples. Plastisphere communities are distinct from surrounding surface water, implying that plastic serves as a novel ecological habitat in the open ocean. Plastic has a longer half-life than most natural floating marine substrates, and a hydrophobic surface that promotes microbial colonization and biofilm formation, differing from autochthonous substrates in the upper layers of the ocean.						Zettler, Erik/0000-0002-9266-1142; Mincer, Tracy/0000-0002-4644-5609													0013-936X	1520-5851				JUL 2	2013	47	13					7137	7146		10.1021/es401288x	http://dx.doi.org/10.1021/es401288x								23745679					WOS:000321521400052
J	Xu, ZS; Yager, RR				Xu, Zeshui; Yager, Ronald R.			Some geometric aggregation operators based on intuitionistic fuzzy sets	INTERNATIONAL JOURNAL OF GENERAL SYSTEMS												The weighted geometric (WG) operator and the ordered weighted geometric (OWG) operator are two common aggregation operators in the field of information fusion. But these two aggregation operators are usually used in situations where the given arguments are expressed as crisp numbers or linguistic values. In this paper, we develop some new geometric aggregation operators, such as the intuitionistic fuzzy weighted geometric (IFWG) operator, the intuitionistic fuzzy ordered weighted geometric (IFOWG) operator, and the intuitionistic fuzzy hybrid geometric (IFHG) operator, which extend the WG and OWG operators to accommodate the environment in which the given arguments are intuitionistic fuzzy sets which are characterized by a membership function and a non-membership function. Some numerical examples are given to illustrate the developed operators. Finally, we give an application of the IFHG operator to multiple attribute decision making based on intuitionistic fuzzy sets.					Xu, Zeshui/N-8908-2013; Yager, Ronald/A-2960-2013	Xu, Zeshui/0000-0003-3547-2908													0308-1079	1563-5104				AUG	2006	35	4					417	433		10.1080/03081070600574353	http://dx.doi.org/10.1080/03081070600574353													WOS:000239153200003
J	Bercoff, J; Tanter, M; Fink, M				Bercoff, J; Tanter, M; Fink, M			Supersonic shear imaging: A new technique for soft tissue elasticity mapping	IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL												Supersonic shear imaging (SSI) is a new ultrasound-based technique for real-time visualization of soft tissue viscoelastic properties. Using ultrasonic focused beams, it is possible to remotely generate mechanical vibration sources radiating low-frequency, shear waves inside tissues. Relying on this concept, SSI proposes to create such a source and make it move at a supersonic speed. In analogy with the "sonic boom" created by a supersonic aircraft, the resulting shear waves will interfere constructively along a Mach cone, creating two intense plane shear waves. These waves propagate through the medium and are progressively distorted by tissue heterogeneities. An ultrafast scanner prototype is able to both generate this supersonic source and image (5000 frames/s) the propagation of the resulting shear waves. Using inversion algorithms, the shear elasticity of medium can be mapped quantitatively from this propagation movie. The SSI enables tissue elasticity mapping in less than 20 ins, even in strongly viscous medium like breast. Modalities such as shear compounding are im-plementable by tilting shear waves in different directions and improving the elasticity estimation. Results validating SSI in heterogeneous phantoms are presented. The first in vivo investigations made on healthy volunteers emphasize the potential clinical applicability of SSI for breast cancer detection.					Fink, Mathias/M-9437-2016; Tanter, Mickael/H-4657-2012	Fink, Mathias/0000-0002-8494-7562; Tanter, Mickael/0000-0001-7739-8051													0885-3010	1525-8955				APR	2004	51	4					396	409		10.1109/TUFFC.2004.1295425	http://dx.doi.org/10.1109/TUFFC.2004.1295425								15139541					WOS:000221047300003
J	Zhong, QC; Weiss, G				Zhong, Qing-Chang; Weiss, George			Synchronverters: Inverters That Mimic Synchronous Generators	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS												In this paper, the idea of operating an inverter to mimic a synchronous generator (SG) is motivated and developed. We call the inverters that are operated in this way synchronverters. Using synchronverters, the well-established theory/algorithms used to control SGs can still be used in power systems where a significant proportion of the generating capacity is inverter-based. We describe the dynamics, implementation, and operation of synchronverters. The real and reactive power delivered by synchronverters connected in parallel and operated as generators can be automatically shared using the well-known frequency- and voltage-drooping mechanisms. Synchronverters can be easily operated also in island mode, and hence, they provide an ideal solution for microgrids or smart grids. Both simulation and experimental results are given to verify the idea.					Weiss, George/A-4442-2012	Weiss, George/0000-0002-9524-2795													0278-0046	1557-9948				APR	2011	58	4					1259	1267		10.1109/TIE.2010.2048839	http://dx.doi.org/10.1109/TIE.2010.2048839													WOS:000288334300018
J	Chang, SG; Yu, B; Vetterli, M				Chang, SG; Yu, B; Vetterli, M			Adaptive wavelet thresholding for image denoising and compression	IEEE TRANSACTIONS ON IMAGE PROCESSING					International Conference on Image Processing	OCT 26-29, 1997	SANTA BARBARA, CALIFORNIA	IEEE Signal Proc Soc				The first part of this paper proposes an adaptive, data-driven threshold for image denoising via wavelet soft-thresholding, The threshold is derived in a Bayesian framework, and the prior used on the wavelet coefficients is the generalized Gaussian distribution (GGD) widely used in image processing applications, The proposed threshold is simple and closed-form, and it is adaptive to each subband because it depends on data-driven estimates of the parameters. Experimental results show that the proposed method, called BayesShrink, is typically within 5% of the MSE of the best soft-thresholding benchmark with the image assumed known, It also outperforms Donoho and Johnstone's SureShrink most of the time. The second part of the paper attempts to further validate recent claims that lossy compression can be used for denoising, The BayesShrink threshold can aid in the parameter selection of a coder designed with the intention of denoising, and thus achieving simultaneous denoising and compression. Specifically, the zero-zone in the quantization step of compression is analogous to the threshold value in the thresholding function. The remaining coder design parameters are chosen based on a criterion derived from Rissanen's minimum description length (MDL) principle, Experiments show that this compression method does indeed remove noise significantly, especially for large noise power, However, it introduces quantization noise and should he used only if bitrate were an additional concern to denoising.					Vetterli, Martin/B-3612-2010	Vetterli, Martin/0000-0002-6122-1216													1057-7149					SEP	2000	9	9					1532	1546		10.1109/83.862633	http://dx.doi.org/10.1109/83.862633								18262991					WOS:000088914400007
J	Cai, D; He, XF; Han, JW; Huang, TS				Cai, Deng; He, Xiaofei; Han, Jiawei; Huang, Thomas S.			Graph Regularized Nonnegative Matrix Factorization for Data Representation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Matrix factorization techniques have been frequently applied in information retrieval, computer vision, and pattern recognition. Among them, Nonnegative Matrix Factorization (NMF) has received considerable attention due to its psychological and physiological interpretation of naturally occurring data whose representation may be parts based in the human brain. On the other hand, from the geometric perspective, the data is usually sampled from a low-dimensional manifold embedded in a high-dimensional ambient space. One then hopes to find a compact representation, which uncovers the hidden semantics and simultaneously respects the intrinsic geometric structure. In this paper, we propose a novel algorithm, called Graph Regularized Nonnegative Matrix Factorization (GNMF), for this purpose. In GNMF, an affinity graph is constructed to encode the geometrical information and we seek a matrix factorization, which respects the graph structure. Our empirical study shows encouraging results of the proposed algorithm in comparison to the state-of-the-art algorithms on real-world problems.					han, jiawei/GVT-3012-2022	Yan, Shuicheng/0000-0001-8906-3777													0162-8828	1939-3539				AUG	2011	33	8					1548	1560		10.1109/TPAMI.2010.231	http://dx.doi.org/10.1109/TPAMI.2010.231								21173440					WOS:000291807200005
J	Farhangi, H				Farhangi, Hassan			The Path of the Smart Grid	IEEE POWER & ENERGY MAGAZINE																															1540-7977	1558-4216				JAN-FEB	2010	8	1					18	28		10.1109/MPE.2009.934876	http://dx.doi.org/10.1109/MPE.2009.934876													WOS:000273094800001
J	Tajbakhsh, N; Shin, JY; Gurudu, SR; Hurst, RT; Kendall, CB; Gotway, MB; Liang, JM				Tajbakhsh, Nima; Shin, Jae Y.; Gurudu, Suryakanth R.; Hurst, R. Todd; Kendall, Christopher B.; Gotway, Michael B.; Liang, Jianming			Convolutional Neural Networks for Medical Image Analysis: Full Training or Fine Tuning?	IEEE TRANSACTIONS ON MEDICAL IMAGING												Training a deep convolutional neural network (CNN) from scratch is difficult because it requires a large amount of labeled training data and a great deal of expertise to ensure proper convergence. A promising alternative is to fine-tune a CNN that has been pre-trained using, for instance, a large set of labeled natural images. However, the substantial differences between natural and medical images may advise against such knowledge transfer. In this paper, we seek to answer the following central question in the context of medical image analysis: Can the use of pre-trained deep CNNs with sufficient fine-tuning eliminate the need for training a deep CNN from scratch? To address this question, we considered four distinct medical imaging applications in three specialties (radiology, cardiology, and gastroenterology) involving classification, detection, and segmentation from three different imaging modalities, and investigated how the performance of deep CNNs trained from scratch compared with the pre-trained CNNs fine-tuned in a layer-wise manner. Our experiments consistently demonstrated that 1) the use of a pre-trained CNN with adequate fine-tuning outperformed or, in the worst case, performed as well as a CNN trained from scratch; 2) fine-tuned CNNs were more robust to the size of training sets than CNNs trained from scratch; 3) neither shallow tuning nor deep tuning was the optimal choice for a particular application; and 4) our layer-wise fine-tuning scheme could offer a practical way to reach the best performance for the application at hand based on the amount of available data.					Liang, Jianming/X-8241-2019; Tajbakhsh, Nima/AAC-1354-2019	Liang, Jianming/0000-0001-5486-1613; Liang, Jianming/0000-0002-3029-341X													0278-0062	1558-254X				MAY	2016	35	5			SI		1299	1312		10.1109/TMI.2016.2535302	http://dx.doi.org/10.1109/TMI.2016.2535302								26978662					WOS:000375550500014
J	Hench, LL				Hench, Larry L.			The story of Bioglass®	JOURNAL OF MATERIALS SCIENCE-MATERIALS IN MEDICINE					1985 ANNUAL CONVENTION OF THE AMERICAN PSYCHOLOGICAL ASSOC	1985	LOS ANGELES, CA	AMER PSYCHOL ASSOC				Historically the function of biomaterials has been to replace diseased or damaged tissues. First generation biomaterials were selected to be as bio-inert as possible and thereby minimize formation of scar tissue at the interface with host tissues. Bioactive glasses were discovered in 1969 and provided for the first time an alternative; second generation, interfacial bonding of an implant with host tissues. Tissue regeneration and repair using the gene activation properties of Bioglass(R) provide a third generation of biomaterials. This article reviews the 40 year history of the development of bioactive glasses, with emphasis on the first composition, 45S5 Bioglass(R), that has been in clinical use since 1985. The steps of discovery, characterization, in vivo and in vitro evaluation, clinical studies and product development are summarized along with the technology transfer processes.																			0957-4530	1573-4838				NOV	2006	17	11					967	978		10.1007/s10856-006-0432-z	http://dx.doi.org/10.1007/s10856-006-0432-z								17122907					WOS:000242295900003
J	Zhao, GY; Pietikäinen, M				Zhao, Guoying; Pietikainen, Matti			Dynamic texture recognition using local binary patterns with an application to facial expressions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Dynamic texture (DT) is an extension of texture to the temporal domain. Description and recognition of DTs have attracted growing attention. In this paper, a novel approach for recognizing DTs is proposed and its simplifications and extensions to facial image analysis are also considered. First, the textures are modeled with volume local binary patterns (VLBP), which are an extension of the LBP operator widely used in ordinary texture analysis, combining motion and appearance. To make the approach computationally simple and easy to extend, only the co-occurrences of the local binary patterns on three orthogonal planes (LBP-TOP) are then considered. A block-based method is also proposed to deal with specific dynamic events such as facial expressions in which local information and its spatial locations should also be taken into account. In experiments with two DT databases, DynTex and Massachusetts Institute of Technology (MIT), both the VLBP and LBP-TOP clearly outperformed the earlier approaches. The proposed block-based method was evaluated with the Cohn-Kanade facial expression database with excellent results. The advantages of our approach include local processing, robustness to monotonic gray-scale changes, and simple computation.					Zhao, Guoying/ABE-7716-2020	Zhao, Guoying/0000-0003-3694-206X													0162-8828	1939-3539				JUN	2007	29	6					915	928		10.1109/TPAMI.2007.1110	http://dx.doi.org/10.1109/TPAMI.2007.1110								17431293					WOS:000245600800001
J	Dixit, S; Hering, JG				Dixit, S; Hering, JG			Comparison of arsenic(V) and arsenic(III) sorption onto iron oxide minerals: Implications for arsenic mobility	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Arsenic derived from natural sources occurs in groundwater in many countries, affecting the health of millions of people. The combined effects of As(V) reduction and diagenesis of iron oxide minerals on arsenic mobility are investigated in this study by comparing As(V) and As(III) sorption onto amorphous iron oxide (HFO), goethite, and magnetite at varying solution compositions. Experimental data are modeled with a diffuse double layer surface complexation model, and the extracted model parameters are used to examine the consistency of our results with those previously reported. Sorption of As(V) onto HFO and goethite is more favorable than that of As(III) below pH 5-6, whereas, above pH 7-8, As(III) has a higher affinity for the solids. The pH at which As(V) and As(III) are equally sorbed depends on the solid-to-solution ratio and type and specific surface area of the minerals and is shifted to lower pH values in the presence of phosphate, which competes for sorption sites. The sorption data indicate that, under most of the chemical conditions investigated in this study, reduction of As(V) in the presence of HFO or goethite would have only minor effects on or even decrease its mobility in the environment at near-neutral pH conditions. As(V) and As(III) sorption isotherms indicate similar surface site densities on the three oxides. Intrinsic surface complexation constants for As(V) are higher for goethite than HFO, whereas As(III) binding is similar for both of these oxides and also for magnetite. However, decrease in specific surface area and hence sorption site density that accompanies transformation of amorphous iron oxides to more crystalline phases could increase arsenic mobility.																			0013-936X					SEP 15	2003	37	18					4182	4189		10.1021/es030309t	http://dx.doi.org/10.1021/es030309t								14524451					WOS:000185326700022
J	Malioutov, D; Çetin, M; Willsky, AS				Malioutov, D; Çetin, M; Willsky, AS			A sparse signal reconstruction perspective for source localization with sensor arrays	IEEE TRANSACTIONS ON SIGNAL PROCESSING												We present a source localization method based on a sparse representation of sensor measurements with an overcomplete basis composed of samples from the array manifold. We enforce sparsity by imposing penalties based on the l(1)-norm. A number of recent theoretical results on sparsifying properties of l(1) penalties justify this choice. Explicitly enforcing the sparsity of the representation is motivated by a desire to obtain a sharp estimate of the spatial spectrum that exhibits super-resolution. We propose to use the singular value decomposition (SVD) of the data matrix to summarize multiple time or frequency samples. Our formulation leads to an optimization problem, which we solve efficiently in a second-order cone (SOC) programming framework by an interior point implementation. We propose a grid refinement method to mitigate the effects of limiting estimates to a grid of spatial locations and introduce an automatic selection criterion for the regularization parameter involved in our approach. We demonstrate the effectiveness of the method on simulated data by plots of spatial spectra and by comparing the estimator variance to the Cramar-Rao bound (CRB). We observe that our approach has a number of advantages over other source localization techniques, including increased resolution, improved robustness to noise, limitations in data quantity, and correlation of the sources, as well as not requiring an accurate initialization.						Cetin, Mujdat/0000-0002-9824-1229													1053-587X	1941-0476				AUG	2005	53	8	2				3010	3022		10.1109/TSP.2005.850882	http://dx.doi.org/10.1109/TSP.2005.850882													WOS:000230652900005
J	Schaap, MG; Leij, FJ; van Genuchten, MT				Schaap, MG; Leij, FJ; van Genuchten, MT			ROSETTA: a computer program for estimating soil hydraulic parameters with hierarchical pedotransfer functions	JOURNAL OF HYDROLOGY												Soil hydraulic properties are necessary for many studies of water and solute transport but often cannot be measured because of practical and/or financial constraints. We describe a computer program, ROSETTA, which implements five hierarchical pedotransfer functions (PTFs) for the estimation of water retention, and the saturated and unsaturated hydraulic conductivity. The hierarchy in PTFs allows the estimation of van Genuchten water retention parameters and the saturated hydraulic conductivity using limited (textural classes only) to more extended (texture, bulk density, and one or two water retention points) input data. ROSETTA is based on neural network analyses combined with the bootstrap method, thus allowing the program to provide uncertainty estimates of the predicted hydraulic parameters. The general performance Of ROSETTA was characterized with coefficients of determination, and root mean square errors (RMSEs). The RMSE values decreased from 0.078 to 0.044 cm(3) cm(-3) for water retention when more predictors were used. The RMSE for the saturated conductivity similarly decreased from 0.739 to 0.647 (dimensionless log(10) units). The RMSE values for unsaturated conductivity ranged between 0.79 and 1.06, depending on whether measured or estimated retention parameters were used as predictors. Calculated mean errors showed that the PTFs underestimated water retention and the unsaturated hydraulic conductivity at relatively high suctions. ROSETTA's uncertainty estimates can be used as an indication of model reliability when no hydraulic data are available. The ROSETTA program comes with a graphical user interface that allows user-friendly access to the PTFs, and can be downloaded from the US Salinity Laboratory website: http://www.ussl.ars.usda.gov/. (C) 2001 Elsevier Science B.V. All rights reserved.					Schaap, Marcel/AAF-3775-2019; van Genuchten, Martinus/K-6892-2013	van Genuchten, Martinus/0000-0003-1654-8858													0022-1694					OCT 1	2001	251	3-4					163	176		10.1016/S0022-1694(01)00466-8	http://dx.doi.org/10.1016/S0022-1694(01)00466-8													WOS:000170823900004
J	Pollock, TM; Tin, S				Pollock, TM; Tin, S			Nickel-based superalloys for advanced turbine engines: Chemistry, microstructure, and properties	JOURNAL OF PROPULSION AND POWER												The chemical, physical, and mechanical characteristics of nickel-based superalloys are reviewed with emphasis on the use of this class of materials within turbine engines. The role of major and minor alloying additions in multicomponent commercial cast and wrought superalloys is discussed. Microstructural stability and phases observed during processing and in subsequent elevated-temperature service are summarized. Processing paths and recent advances in processing are addressed. Mechanical properties and deformation mechanisms are reviewed, including tensile properties, creep, fatigue, and cyclic crack growth.					Tin, Sammy/G-2869-2012	Tin, Sammy/0000-0002-0283-4426													0748-4658	1533-3876				MAR-APR	2006	22	2					361	374		10.2514/1.18239	http://dx.doi.org/10.2514/1.18239													WOS:000236087000009
J	Havaei, M; Davy, A; Warde-Farley, D; Biard, A; Courville, A; Bengio, Y; Pal, C; Jodoin, PM; Larochelle, H				Havaei, Mohammad; Davy, Axel; Warde-Farley, David; Biard, Antoine; Courville, Aaron; Bengio, Yoshua; Pal, Chris; Jodoin, Pierre-Marc; Larochelle, Hugo			Brain tumor segmentation with Deep Neural Networks	MEDICAL IMAGE ANALYSIS												In this paper, we present a fully automatic brain tumor segmentation method based on Deep Neural Networks (DNNs). The proposed networks are tailored to glioblastomas (both low and high grade) pictured in MR images. By their very nature, these tumors can appear anywhere in the brain and have almost any kind of shape, size, and contrast. These reasons motivate our exploration of a machine learning solution that exploits a flexible, high capacity DNN while being extremely efficient. Here, we give a description of different model choices that we've found to be necessary for obtaining competitive performance. We explore in particular different architectures based on Convolutional Neural Networks (CNN), i.e. DNNs specifically adapted to image data. We present a novel CNN architecture which differs from those traditionally used in computer vision. Our CNN exploits both local features as well as more global contextual features simultaneously. Also, different from most traditional uses of CNNs, our networks use a final layer that is a convolutional implementation of a fully connected layer which allows a 40 fold speed up. We also describe a 2-phase training procedure that allows us to tackle difficulties related to the imbalance of tumor labels. Finally, we explore a cascade architecture in which the output of a basic CNN is treated as an additional source of information for a subsequent CNN. Results reported on the 2013 BRATS test data-set reveal that our architecture improves over the currently published state-of-the-art while being over 30 times faster. (C) 2016 Elsevier B.V. All rights reserved.					Davy, Axel/X-3798-2019														1361-8415	1361-8423				JAN	2017	35						18	31		10.1016/j.media.2016.05.004	http://dx.doi.org/10.1016/j.media.2016.05.004								27310171					WOS:000388248300002
J	Clement-Nyns, K; Haesen, E; Driesen, J				Clement-Nyns, Kristien; Haesen, Edwin; Driesen, Johan			The Impact of Charging Plug-In Hybrid Electric Vehicles on a Residential Distribution Grid	IEEE TRANSACTIONS ON POWER SYSTEMS												Alternative vehicles, such as plug-in hybrid electric vehicles, are becoming more popular. The batteries of these plug-in hybrid electric vehicles are to be charged at home from a standard outlet or on a corporate car park. These extra electrical loads have an impact on the distribution grid which is analyzed in terms of power losses and voltage deviations. Without coordination of the charging, the vehicles are charged instantaneously when they are plugged in or after a fixed start delay. This uncoordinated power consumption on a local scale can lead to grid problems. Therefore, coordinated charging is proposed to minimize the power losses and to maximize the main grid load factor. The optimal charging profile of the plug-in hybrid electric vehicles is computed by minimizing the power losses. As the exact forecasting of household loads is not possible, stochastic programming is introduced. Two main techniques are analyzed: quadratic and dynamic programming.					Driesen, Johan/C-2506-2014	Driesen, Johan/0000-0002-1025-0949													0885-8950	1558-0679				FEB	2010	25	1					371	380		10.1109/TPWRS.2009.2036481	http://dx.doi.org/10.1109/TPWRS.2009.2036481													WOS:000273930800039
J	Gao, ZW; Cecati, C; Ding, SX				Gao, Zhiwei; Cecati, Carlo; Ding, Steven X.			A Survey of Fault Diagnosis and Fault-Tolerant Techniques-Part I: Fault Diagnosis With Model-Based and Signal-Based Approaches	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS												With the continuous increase in complexity and expense of industrial systems, there is less tolerance for performance degradation, productivity decrease, and safety hazards, which greatly necessitates to detect and identify any kinds of potential abnormalities and faults as early as possible and implement real-time fault-tolerant operation for minimizing performance degradation and avoiding dangerous situations. During the last four decades, fruitful results have been reported about fault diagnosis and fault-tolerant control methods and their applications in a variety of engineering systems. The three-part survey paper aims to give a comprehensive review of real-time fault diagnosis and fault-tolerant control, with particular attention on the results reported in the last decade. In this paper, fault diagnosis approaches and their applications are comprehensively reviewed from model-and signal-based perspectives, respectively.					Gao, Zhiwei/AAP-2252-2021; Ding, Steven/ABF-2356-2020; Cecati, Carlo/E-1535-2018	Cecati, Carlo/0000-0001-9228-7886; Gao, Zhiwei/0000-0001-5464-3288													0278-0046	1557-9948				JUN	2015	62	6					3757	3767		10.1109/TIE.2015.2417501	http://dx.doi.org/10.1109/TIE.2015.2417501													WOS:000354453600045
J	Gao, ZW; Cecati, C; Ding, SX				Gao, Zhiwei; Cecati, Carlo; Ding, Steven X.			A Survey of Fault Diagnosis and Fault-Tolerant Techniques-Part II: Fault Diagnosis With Knowledge-Based and Hybrid/Active Approaches	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS												This is the second-part paper of the survey on fault diagnosis and fault-tolerant techniques, where fault diagnosis methods and applications are overviewed, respectively, from the knowledge-based and hybrid/active viewpoints. With the aid of the first-part survey paper, the second-part review paper completes a whole overview on fault diagnosis techniques and their applications. Comments on the advantages and constraints of various diagnosis techniques, including model-based, signal-based, knowledge-based, and hybrid/active diagnosis techniques, are also given. An overlook on the future development of fault diagnosis is presented.					Gao, Zhiwei/AAP-2252-2021; Ding, Steven/ABF-2356-2020; Cecati, Carlo/E-1535-2018	Cecati, Carlo/0000-0001-9228-7886; Gao, Zhiwei/0000-0001-5464-3288													0278-0046	1557-9948				JUN	2015	62	6					3768	3774		10.1109/TIE.2015.2419013	http://dx.doi.org/10.1109/TIE.2015.2419013													WOS:000354453600046
J	Robertson, J				Robertson, J			Band offsets of wide-band-gap oxides and implications for future electronic devices	JOURNAL OF VACUUM SCIENCE & TECHNOLOGY B					International Conference on Silicon Dielectric Interfaces (ICSDI)	FEB 25-27, 2000	RALEIGH, NC	Coll Phys & Math Sci, North Carolina State Univ, Phys Dept				Wide-band-gap oxides such as SrTiO3 are shown to be critical tests of theories of Schottky barrier heights based on metal-induced gap states and charge neutrality levels. This theory is reviewed and used to calculate the Schottky barrier heights and band offsets for many important high dielectric constant oxides on Pt and Si. Good agreement with experiment is found for barrier heights. The band offsets fur electrons on Si are found to be small for many key oxides such as SrTiO3 and Ta2O5 which limit their utility as Sate oxides in future silicon field effect transistors. The calculations are extended to screen other proposed oxides such as BaZrO3. ZrO2, HfO2, La2O3, Y2O3, HfSiO4, and ZrSiO4. Predictions are also given for barrier heights of the ferroelectric oxides Pb1-xZrxTiO3 and SrBi2Ta2O9 which are used in nonvolatile memories. (C) 2000 American Vacuum Society.																			1071-1023					MAY-JUN	2000	18	3					1785	1791		10.1116/1.591472	http://dx.doi.org/10.1116/1.591472													WOS:000087654200135
J	Oztop, HF; Abu-Nada, E				Oztop, Hakan F.; Abu-Nada, Eiyad			Numerical study of natural convection in partially heated rectangular enclosures filled with nanofluids	INTERNATIONAL JOURNAL OF HEAT AND FLUID FLOW												Heat transfer and fluid flow due to buoyancy forces in a partially heated enclosure using nanofluids is carried out using different types of nanoparticles. The flush mounted heater is located to the left vertical wall with a finite length. The temperature of the right vertical wall is lower than that of heater while other walls are insulated. The finite volume technique is used to solve the governing equations. Calculations were performed for Rayleigh number (10(3) <= Ra <= 5 x 10(5)), height of heater (0.1 <= h <= 0.75), location of heater (0.25 <= y(p) <= 0.75), aspect ratio (0.5 <= A <= 2) and volume fraction of nanoparticles (0 <= phi <= 0.2). Different types of nanoparticles were tested. An increase in mean Nusselt number was found with the volume fraction of nanoparticles for the whole range of Rayleigh number. Heat transfer also increases with increasing of height of heater. It was found that the heater location affects the flow and temperature fields when using nanofluids. It was found that the heat transfer enhancement, using nanofluids, is more pronounced at low aspect ratio than at high aspect ratio. (C) 2008 Elsevier Inc. All rights reserved.					Oztop, Hakan/D-5115-2014; , Eiyad/N-2868-2016	, Eiyad/0000-0002-1223-0706													0142-727X	1879-2278				OCT	2008	29	5					1326	1336		10.1016/j.ijheatfluidflow.2008.04.009	http://dx.doi.org/10.1016/j.ijheatfluidflow.2008.04.009													WOS:000260645600009
J	Haklay, M; Weber, P				Haklay, Mordechai (Muki); Weber, Patrick			OpenStreetMap: User-Generated Street Maps	IEEE PERVASIVE COMPUTING																	Haklay, Mordechai/AAN-6892-2021	Haklay, Mordechai/0000-0001-6117-3026; Newman, Gregory/0000-0003-0503-5782													1536-1268					OCT-DEC	2008	7	4					12	18		10.1109/MPRV.2008.80	http://dx.doi.org/10.1109/MPRV.2008.80													WOS:000260046400004
J	Channiwala, SA; Parikh, PP				Channiwala, SA; Parikh, PP			A unified correlation for estimating HHV of solid, liquid and gaseous fuels	FUEL												A unified correlation for computation of higher heating value (HHV) from elemental analysis of fuels is proposed in this paper. This correlation has been derived using 225 data points and validated for additional 50 data points. The entire spectrum of fuels ranging from gaseous, liquid, coals, biomass material, char to residue-derived fuels has been considered in derivation of present correlation. The validity of this correlation has been established for fuels having wide range of elemental composition, i.e. C - 0.00-92.25%, H - 0.43-2,5.15%, 0 - 0.00-50.00%, N - 0.00-5.60%, S - 0.00-94.08% and Ash - 0.00-71.4%. The correlation offers an average absolute error of 1.45% and bias error as 0.00% and thereby establishes its versatility. Complete details of few salient data points, the methodology used for derivation of the correlation and the base assumptions made for derivation are the important constituents of this work. A summary of published correlations along with their basis also forms an important component of present work. (C) 2001 Published by Elsevier Science Ltd.																			0016-2361					MAY	2002	81	8					1051	1063	PII S0016-2361(01)001631-4	10.1016/S0016-2361(01)00131-4	http://dx.doi.org/10.1016/S0016-2361(01)00131-4													WOS:000175523200010
J	Mesleh, RY; Haas, H; Sinanovic, S; Ahn, CW; Yun, S				Mesleh, Raed Y.; Haas, Harald; Sinanovic, Sinan; Ahn, Chang Wook; Yun, Sangboh			Spatial modulation	IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY												Spatial modulation (SM) is a recently developed transmission technique that uses multiple antennas. The basic idea is to map a block of information bits to two information carrying units: 1) a symbol that was chosen from a constellation diagram and 2) a unique transmit antenna number that was chosen from a set of transmit antennas. The use of the transmit antenna number as an information-bearing unit increases the overall spectral efficiency by the base-two logarithm of the number of transmit antennas. At the receiver, a maximum receive ratio combining algorithm is used to retrieve the transmitted block of information bits. Here, we apply SM to orthogonal frequency division multiplexing (OFDM) transmission. We develop an analytical approach for symbol error ratio (SER) analysis of the SM algorithm in independent identically distributed (i.i.d.) Rayleigh channels. The analytical and simulation results closely match. The performance and the receiver complexity of the SM-OFDM technique are compared to those of the vertical Bell Labs layered space-time (V-BLAST-OFDM) and Alamouti-OFDM algorithms. V-BLAST uses minimum mean square error (MMSE) detection with ordered successive interference cancellation. The combined effect of spatial correlation, mutual antenna coupling, and Rician fading on both coded and uncoded systems are presented. It is shown that, for the same spectral efficiency, SM results in a reduction of around 90% in receiver complexity as compared to V-BLAST and nearly the same receiver complexity as Alamouti. In addition, we show that SM achieves better performance in all studied channel conditions, as compared with other techniques. It is also shown to efficiently work for any configuration of transmit and receive antennas, even for the case of fewer receive antennas than transmit antennas.					Haas, Harald/AAD-1660-2019; Mesleh, Raed/A-4533-2013	Mesleh, Raed/0000-0001-6838-2816; Sinanovic, Sinan/0000-0002-2221-3467; Ahn, Chang Wook/0000-0002-9902-5966; Haas, Harald/0000-0001-9705-2701													0018-9545	1939-9359				JUL	2008	57	4					2228	2241		10.1109/TVT.2007.912136	http://dx.doi.org/10.1109/TVT.2007.912136													WOS:000257950400021
J	Seuret, A; Gouaisbaut, F				Seuret, A.; Gouaisbaut, F.			Wirtinger-based integral inequality: Application to time-delay systems	AUTOMATICA					10th IFAC Workshop on Time-Delay Systems	JUN 22-24, 2012	Boston, MA	IFAC				In the last decade, the Jensen inequality has been intensively used in the context of time-delay or sampled-data systems since it is an appropriate tool to derive tractable stability conditions expressed in terms of linear matrix inequalities (LMIs). However, it is also well-known that this inequality introduces an undesirable conservatism in the stability conditions and looking at the literature, reducing this gap is a relevant issue and always an open problem. In this paper, we propose an alternative inequality based on the Fourier Theory, more precisely on the Wirtinger inequalities. It is shown that this resulting inequality encompasses the Jensen one and also leads to tractable LMI conditions. In order to illustrate the potential gain of employing this new inequality with respect to the Jensen one, two applications on time-delay and sampled-data stability analysis are provided. (C) 2013 Elsevier Ltd. All rights reserved.					Seuret, Alexandre/AAU-3251-2021	Seuret, Alexandre/0000-0003-1434-7614													0005-1098	1873-2836				SEP	2013	49	9					2860	2866		10.1016/j.automatica.2013.05.030	http://dx.doi.org/10.1016/j.automatica.2013.05.030													WOS:000323594200032
J	Farabet, C; Couprie, C; Najman, L; LeCun, Y				Farabet, Clement; Couprie, Camille; Najman, Laurent; LeCun, Yann			Learning Hierarchical Features for Scene Labeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Scene labeling consists of labeling each pixel in an image with the category of the object it belongs to. We propose a method that uses a multiscale convolutional network trained from raw pixels to extract dense feature vectors that encode regions of multiple sizes centered on each pixel. The method alleviates the need for engineered features, and produces a powerful representation that captures texture, shape, and contextual information. We report results using multiple postprocessing methods to produce the final labeling. Among those, we propose a technique to automatically retrieve, from a pool of segmentation components, an optimal set of components that best explain the scene; these components are arbitrary, for example, they can be taken from a segmentation tree or from any family of oversegmentations. The system yields record accuracies on the SIFT Flow dataset (33 classes) and the Barcelona dataset (170 classes) and near-record accuracy on Stanford background dataset (eight classes), while being an order of magnitude faster than competing approaches, producing a 320 x 240 image labeling in less than a second, including feature extraction.					couprie, camille/H-4092-2014; Najman, Laurent/AAB-4212-2020; Liu, Yixin/ABC-7725-2021	Najman, Laurent/0000-0002-6190-0235													0162-8828	1939-3539				AUG	2013	35	8					1915	1929		10.1109/TPAMI.2012.231	http://dx.doi.org/10.1109/TPAMI.2012.231								23787344					WOS:000320381400008
J	Jégou, H; Douze, M; Schmid, C				Jegou, Herve; Douze, Matthijs; Schmid, Cordelia			Product Quantization for Nearest Neighbor Search	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												This paper introduces a product quantization-based approach for approximate nearest neighbor search. The idea is to decompose the space into a Cartesian product of low-dimensional subspaces and to quantize each subspace separately. A vector is represented by a short code composed of its subspace quantization indices. The euclidean distance between two vectors can be efficiently estimated from their codes. An asymmetric version increases precision, as it computes the approximate distance between a vector and a code. Experimental results show that our approach searches for nearest neighbors efficiently, in particular in combination with an inverted file system. Results for SIFT and GIST image descriptors show excellent search accuracy, outperforming three state-of-the-art approaches. The scalability of our approach is validated on a data set of two billion vectors.																			0162-8828	1939-3539				JAN	2011	33	1					117	128		10.1109/TPAMI.2010.57	http://dx.doi.org/10.1109/TPAMI.2010.57								21088323					WOS:000284277600009
J	Heath, RW; González-Prelcic, N; Rangan, S; Roh, W; Sayeed, AM				Heath, Robert W., Jr.; Gonzalez-Prelcic, Nuria; Rangan, Sundeep; Roh, Wonil; Sayeed, Akbar M.			An Overview of Signal Processing Techniques for Millimeter Wave MIMO Systems	IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING												Communication at millimeter wave (mmWave) frequencies is defining a new era of wireless communication. The mmWave band offers higher bandwidth communication channels versus those presently used in commercial wireless systems. The applications of mmWave are immense: wireless local and personal area networks in the unlicensed band, 5G cellular systems, not to mention vehicular area networks, ad hoc networks, and wearables. Signal processing is critical for enabling the next generation of mmWave communication. Due to the use of large antenna arrays at the transmitter and receiver, combined with radio frequency and mixed signal power constraints, new multiple-input multiple-output (MIMO) communication signal processing techniques are needed. Because of the wide bandwidths, low complexity transceiver algorithms become important. There are opportunities to exploit techniques like compressed sensing for channel estimation and beamforming. This article provides an overview of signal processing challenges in mmWave wireless systems, with an emphasis on those faced by using MIMO communication at higher carrier frequencies.					Rangan, Sundeep/AAH-2526-2020; Heath, Robert/AAY-4148-2020; González-Prelcic, Nuria/G-1680-2016; Heath, Robert/A-5366-2010	Gonzalez-Prelcic, Nuria/0000-0002-0828-8454; Heath, Robert/0000-0002-4666-5628													1932-4553	1941-0484				APR	2016	10	3					436	453		10.1109/JSTSP.2016.2523924	http://dx.doi.org/10.1109/JSTSP.2016.2523924													WOS:000375114900002
J	Flandrin, P; Rilling, G; Gonçalvés, P				Flandrin, P; Rilling, G; Gonçalvés, P			Empirical mode decomposition as a filter bank	IEEE SIGNAL PROCESSING LETTERS												Empirical mode decomposition (EMD) has recently been pioneered by Huang et al. for adaptively representing nonstationary signals as sums of zero-mean amplitude modulation frequency modulation components. In-order to better understand the way EMD behaves in stochastic situations involving broadband noise, we report here on numerical experiments based on fractional Gaussian noise. In such a case, it turns out that EMD acts essentially as a dyadic filter bank resembling those involved in wavelet decompositions. It is also pointed out that the hierarchy of the extracted modes may be similarly exploited for getting access to the Hurst exponent.																			1070-9908					FEB	2004	11	2	1				112	114		10.1109/LSP.2003.821662	http://dx.doi.org/10.1109/LSP.2003.821662													WOS:000188369600014
J	Ionescu, C; Papava, D; Olaru, V; Sminchisescu, C				Ionescu, Catalin; Papava, Dragos; Olaru, Vlad; Sminchisescu, Cristian			Human3.6M: Large Scale Datasets and Predictive Methods for 3D Human Sensing in Natural Environments	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												We introduce a new dataset, Human3.6M, of 3.6 Million accurate 3D Human poses, acquired by recording the performance of 5 female and 6 male subjects, under 4 different viewpoints, for training realistic human sensing systems and for evaluating the next generation of human pose estimation models and algorithms. Besides increasing the size of the datasets in the current state-of-the-art by several orders of magnitude, we also aim to complement such datasets with a diverse set of motions and poses encountered as part of typical human activities (taking photos, talking on the phone, posing, greeting, eating, etc.), with additional synchronized image, human motion capture, and time of flight (depth) data, and with accurate 3D body scans of all the subject actors involved. We also provide controlled mixed reality evaluation scenarios where 3D human models are animated using motion capture and inserted using correct 3D geometry, in complex real environments, viewed with moving cameras, and under occlusion. Finally, we provide a set of large-scale statistical models and detailed evaluation baselines for the dataset illustrating its diversity and the scope for improvement by future work in the research community. Our experiments show that our best large-scale model can leverage our full training set to obtain a 20% improvement in performance compared to a training set of the scale of the largest existing public dataset for this problem. Yet the potential for improvement by leveraging higher capacity, more complex models with our large dataset, is substantially vaster and should stimulate future research. The dataset together with code for the associated large-scale learning models, features, visualization tools, as well as the evaluation server, is available online at http://vision.imar.ro/human3.6m.																			0162-8828	1939-3539				JUL	2014	36	7					1325	1339		10.1109/TPAMI.2013.248	http://dx.doi.org/10.1109/TPAMI.2013.248								26353306					WOS:000338209900004
J	Saremi, S; Mirjalili, S; Lewis, A				Saremi, Shahrzad; Mirjalili, Seyedali; Lewis, Andrew			Grasshopper Optimisation Algorithm: Theory and application	ADVANCES IN ENGINEERING SOFTWARE												This paper proposes an optimisation algorithm called Grasshopper Optimisation Algorithm (GOA) and applies it to challenging problems in structural optimisation. The proposed algorithm mathematically models and mimics the behaviour of grasshopper swarms in nature for solving optimisation problems. The GOA algorithm is first benchmarked on a set of test problems including CEC2005 to test and verify its performance qualitatively and quantitatively. It is then employed to find the optimal shape for a 52-bar truss, 3-bar truss, and cantilever beam to demonstrate its applicability. The results show that the proposed algorithm is able to provide superior results compared to well-knowri and recent algorithms in the literature. The results of the real applications also prove the merits of GOA in solving real problems with unknown search spaces. (C) 2017 Elsevier Ltd. All rights reserved.					Saremi, Shahrzad/AAA-7696-2019; Mirjalili, Seyedali/P-1372-2018	Mirjalili, Seyedali/0000-0002-1443-9458													0965-9978	1873-5339				MAR	2017	105						30	47		10.1016/j.advengsoft.2017.01.004	http://dx.doi.org/10.1016/j.advengsoft.2017.01.004													WOS:000394077800004
J	Daugman, J				Daugman, J			How iris recognition works	IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY												Algorithms developed by the author for recognizing persons by their iris patterns have now been tested in many field and laboratory trials, producing no false matches in several million comparison tests. The recognition principle is the failure of a test of statistical independence on iris phase structure encoded by multi-scale quadrature wavelets. The combinatorial complexity of this phase information across different persons spans about 249 degrees of freedom and generates a discrimination entropy of about 3.2 b/mm(2) over the, iris, enabling real-time decisions about personal identity with extremely high confidence. The high confidence levels are important because they allow very large databases to be searched exhaustively (one-to-many "identification mode") without making false matches, despite so many chances. Biometrics that lack this property can only survive one-to-one ("verification") or few comparisons. This paper explains the iris recognition algorithms and presents results of 9.1 million comparisons among eye images from trials in Britain, the USA, Japan, and Korea.																			1051-8215					JAN	2004	14	1					21	30		10.1109/TCSVT.2003.818350	http://dx.doi.org/10.1109/TCSVT.2003.818350													WOS:000188198000003
J	Diethelm, K; Ford, NJ; Freed, AD				Diethelm, K; Ford, NJ; Freed, AD			A predictor-corrector approach for the numerical solution of fractional differential equations	NONLINEAR DYNAMICS												We discuss an Adams-type predictor-corrector method for the numerical solution of fractional differential equations. The method may be used both for linear and for nonlinear problems, and it may be extended to multi-term equations (involving more than one differential operator) too.					Ford, Neville/C-7039-2009; Diethelm, Kai/I-1214-2019; Diethelm, Kai/I-3731-2013	Ford, Neville/0000-0002-9446-437X; Freed, Alan/0000-0002-3492-0628; Diethelm, Kai/0000-0002-7276-454X													0924-090X	1573-269X				JUL-SEP	2002	29	1-4					3	22		10.1023/A:1016592219341	http://dx.doi.org/10.1023/A:1016592219341													WOS:000177142500002
J	Pi, ZY; Khan, F				Pi, Zhouyue; Khan, Farooq			An Introduction to Millimeter-Wave Mobile Broadband Systems	IEEE COMMUNICATIONS MAGAZINE												Almost all mobile communication systems today use spectrum in the range of 300 MHz-3 GHz. In this article, we reason why the wireless community should start looking at the 3-300 GHz spectrum for mobile broadband applications. We discuss propagation and device technology challenges associated with this band as well as its unique advantages for mobile communication. We introduce a millimeter-wave mobile broadband (MMB) system as a candidate next-generation mobile communication system. We demonstrate the feasibility for MMB to achieve gigabit-per-second data rates at a distance up to 1 km in an urban mobile environment. A few key concepts in MMB network architecture such as the MMB base station grid, MMB inter-BS backhaul link, and a hybrid MMB + 4G system are described. We also discuss beamforming techniques and the frame structure of the MMB air interface.																			0163-6804	1558-1896				JUN	2011	49	6					101	107		10.1109/MCOM.2011.5783993	http://dx.doi.org/10.1109/MCOM.2011.5783993													WOS:000291404200014
J	Zhao, Q; Sadler, BM				Zhao, Qing; Sadler, Brian M.			A survey of dynamic spectrum access	IEEE SIGNAL PROCESSING MAGAZINE																	Sadler, Brian/AAR-6018-2021	Sadler, Brian/0000-0002-9564-3812													1053-5888	1558-0792				MAY	2007	24	3					79	89		10.1109/MSP.2007.361604	http://dx.doi.org/10.1109/MSP.2007.361604													WOS:000246422800010
J	Tan, XY; Triggs, B				Tan, Xiaoyang; Triggs, Bill			Enhanced Local Texture Feature Sets for Face Recognition Under Difficult Lighting Conditions	IEEE TRANSACTIONS ON IMAGE PROCESSING												Making recognition more reliable under uncontrolled lighting conditions is one of the most important challenges for practical face recognition systems. We tackle this by combining the strengths of robust illumination normalization, local texture-based face representations, distance transform based matching, kernel-based feature extraction and multiple feature fusion. Specifically, we make three main contributions: 1) we present a simple and efficient preprocessing chain that eliminates most of the effects of changing illumination while still preserving the essential appearance details that are needed for recognition; 2) we introduce local ternary patterns (LTP), a generalization of the local binary pattern (LBP) local texture descriptor that is more discriminant and less sensitive to noise in uniform regions, and we show that replacing comparisons based on local spatial histograms with a distance transform based similarity metric further improves the performance of LBP/LTP based face recognition; and 3) we further improve robustness by adding Kernel principal component analysis (PCA) feature extraction and incorporating rich local appearance cues from two complementary sources-Gabor wavelets and LBP-showing that the combination is considerably more accurate than either feature set alone. The resulting method provides state-of-the-art performance on three data sets that are widely used for testing recognition under difficult illumination conditions: Extended Yale-B, CAS-PEAL-R1, and Face Recognition Grand Challenge version 2 experiment 4 (FRGC-204). For example, on the challenging FRGC-204 data set it halves the error rate relative to previously published methods, achieving a face verification rate of 88.1% at 0.1% false accept rate. Further experiments show that our preprocessing method outperforms several existing preprocessors for a range of feature sets, data sets and lighting conditions.					tan, xiao/GZL-0264-2022														1057-7149	1941-0042				JUN	2010	19	6					1635	1650		10.1109/TIP.2010.2042645	http://dx.doi.org/10.1109/TIP.2010.2042645								20172829					WOS:000277773200021
J	Liu, H; Yu, L				Liu, H; Yu, L			Toward integrating feature selection algorithms for classification and clustering	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING												This paper introduces concepts and algorithms of feature selection, surveys existing feature selection algorithms for classification and clustering, groups and compares different algorithms with a categorizing framework based on search strategies, evaluation criteria, and data mining tasks, reveals unattempted combinations, and provides guidelines in selecting feature selection algorithms. With the categorizing framework, we continue our efforts toward building an integrated system for intelligent feature selection. A unifying platform is proposed as an intermediate step. An illustrative example is presented to show how existing feature selection algorithms can be integrated into a meta algorithm that can take advantage of individual algorithms. An added advantage of doing so is to help a user employ a suitable algorithm without knowing details of each algorithm. Some real-world applications are included to demonstrate the use of feature selection in data mining. We conclude this work by identifying trends and challenges of feature selection research and development.																			1041-4347	1558-2191				APR	2005	17	4					491	502		10.1109/TKDE.2005.66	http://dx.doi.org/10.1109/TKDE.2005.66													WOS:000226996100004
J	Minami, T				Minami, T			Transparent conducting oxide semiconductors for transparent electrodes	SEMICONDUCTOR SCIENCE AND TECHNOLOGY												The present status and prospects for further development of polycrystalline or amorphous transparent conducting oxide (TCO) semiconductors used for practical thin-film transparent electrode applications are presented in this paper. The important TCO semiconductors are impurity-doped ZnO, In2O3 and SnO2 as well as multicomponent oxides consisting of combinations of ZnO, In2O3 and SnO2, including some ternary compounds existing in their systems. Development of these and other TCO semiconductors is important because the expanding need for transparent electrodes for optoelectronic device applications is jeopardizing the availability of indium-tin-oxide (ITO), whose main constituent, indium, is a very expensive and scarce material. Al- and Ga-doped ZnO (AZO and GZO) semiconductors are promising as alternatives to ITO for thin-film transparent electrode applications. In particular, AZO thin films, with a low resistivity of the order of 10(-5) Omega cm and source materials that are inexpensive and non-toxic, are the best candidates. However, further development of the deposition techniques, such as magnetron sputtering or vacuum arc plasma evaporation, as well as of the targets is required to enable the preparation of AZO and GZO films on large area substrates with a high deposition rate.																			0268-1242	1361-6641				APR	2005	20	4					S35	S44		10.1088/0268-1242/20/4/004	http://dx.doi.org/10.1088/0268-1242/20/4/004													WOS:000228840900005
J	Mendel, JM; John, RI				Mendel, JM; John, RI			Type-2 fuzzy sets made simple	IEEE TRANSACTIONS ON FUZZY SYSTEMS												Type-2 fuzzy sets let us model and minimize the effects of uncertainties in rule-base fuzzy logic systems. However, they are difficult to understand for a variety of reasons which we enunciate. In this paper, we strive to overcome the difficulties by: 1) establishing a small set of terms that let us easily communicate about type-2 fuzzy sets and also let us define such sets very precisely, 2) presenting a new representation for type-2 fuzzy sets, and 3) using this new representation to derive formulas for union, intersection and complement of type-2 fuzzy sets without having to use the Extension Principle.					John, Robert/A-4073-2009	John, Robert/0000-0002-2341-9993													1063-6706	1941-0034				APR	2002	10	2					117	127	PII S1063-6706(02)02960-0	10.1109/91.995115	http://dx.doi.org/10.1109/91.995115													WOS:000174814000001
J	Nichol, JW; Koshy, ST; Bae, H; Hwang, CM; Yamanlar, S; Khademhosseini, A				Nichol, Jason W.; Koshy, Sandeep T.; Bae, Hojae; Hwang, Chang M.; Yamanlar, Seda; Khademhosseini, Ali			Cell-laden microengineered gelatin methacrylate hydrogels	BIOMATERIALS												The cellular microenvironment plays an integral role in improving the function of microengineered tissues. Control of the microarchitecture in engineered tissues can be achieved through photopatterning of cell-laden hydrogels. However, despite high pattern fidelity of photopolymerizable hydrogels, many such materials are not cell-responsive and have limited biodegradability. Here, we demonstrate gelatin methacrylate (GelMA) as an inexpensive, cell-responsive hydrogel platform for creating cell-laden microtissues and microfluidic devices. Cells readily bound to, proliferated, elongated, and migrated both when seeded on micropatterned GelMA substrates as well as when encapsulated in microfabricated GelMA hydrogels. The hydration and mechanical properties of GelMA were demonstrated to be tunable for various applications through modification of the methacrylation degree and gel concentration. The pattern fidelity and resolution of GelMA were high and it could be patterned to create perfusable microfluidic channels. Furthermore, GelMA micropatterns could be used to create cellular micropatterns for in vitro cell studies or 3D microtissue fabrication. These data suggest that GelMA hydrogels could be useful for creating complex, cell-responsive microtissues, such as endothelialized microvasculature, or for other applications that require cell-responsive microengineered hydrogels. (c) 2010 Elsevier Ltd. All rights reserved.					Khademhosseini, Ali/A-9435-2010	Koshy, Sandeep/0000-0003-2836-5813; bae, hojae/0000-0003-3057-4999; Khademhosseini, Ali/0000-0001-6322-8852; Khademhosseini, Ali/0000-0002-2692-1524													0142-9612					JUL	2010	31	21					5536	5544		10.1016/j.biomaterials.2010.03.064	http://dx.doi.org/10.1016/j.biomaterials.2010.03.064								20417964					WOS:000279092600006
J	Shokrollahi, A				Shokrollahi, Amin			Raptor codes	IEEE TRANSACTIONS ON INFORMATION THEORY												LT-codes are a new class of codes introduced by Luby for the purpose of scalable and fault-tolerant distribution of data over computer networks. In this paper, we introduce Raptor codes, an extension of LT-codes with linear time encoding and decoding. We will exhibit a class of universal Raptor codes: for a given integer k and any real epsilon > 0, Raptor codes in this class produce a potentially infinite stream of symbols such that any subset of symbols of size k(1 + epsilon) is sufficient to recover the original k symbols with high probability. Each output symbol is generated using 0(log(1/epsilon)) operations, and the original symbols are recovered from the collected ones with 0(k log(1/epsilon)) operations. We will also introduce novel techniques for the analysis of the error probability of the decoder for finite length Raptor codes. Moreover, we will introduce and analyze systematic versions of Raptor codes, i.e., versions in which the first output elements of the coding system coincide with the original k elements.																			0018-9448	1557-9654				JUN	2006	52	6					2551	2567		10.1109/TIT.2006.874390	http://dx.doi.org/10.1109/TIT.2006.874390													WOS:000238319400018
J	Ni, ZC; Shi, YQ; Ansari, N; Su, W				Ni, ZC; Shi, YQ; Ansari, N; Su, W			Reversible data hiding	IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY												A novel reversible data hiding algorithm, which can recover the original image without any distortion from the marked image after the hidden data have been extracted, is presented in this paper. This algorithm utilizes the zero or the minimum points of the histogram of an image and slightly modifies the pixel grayscale values to embed data into the image. It can embed more data than many of the existing reversible data hiding algorithms. It is proved analytically and shown experimentally that the peak signal-to-noise ratio (PSNR) of the marked image generated by this method versus the original image is guaranteed to be above 48 dB. This lower bound of PSNR is much higher than that of all reversible data hiding techniques reported in the literature. The computational complexity of our proposed technique is low and the execution time is short. The algorithm has been successfully applied to a wide range of images, including commonly used images, medical images, texture images, aerial images and all of the 1096 images in CorelDraw database. Experimental results and performance comparison with other reversible data hiding schemes are presented to demonstrate the validity of the proposed algorithm.					Ansari, Nirwan/N-1264-2019	Ansari, Nirwan/0000-0001-8541-3565													1051-8215	1558-2205				MAR	2006	16	3					354	362		10.1109/TCSVT.2006.869964	http://dx.doi.org/10.1109/TCSVT.2006.869964													WOS:000236474700003
J	Tarvainen, MP; Niskanen, JP; Lipponen, JA; Ranta-aho, PO; Karjalainen, PA				Tarvainen, Mika P.; Niskanen, Juha-Pekka; Lipponen, Jukka A.; Ranta-aho, Perttu O.; Karjalainen, Pasi A.			Kubios HRV - Heart rate variability analysis software	COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE												Kubios HRV is an advanced and easy to use software for heart rate variability (HRV) analysis. The software supports several input data formats for electrocardiogram (ECG) data and beat-to-beat RR interval data. It includes an adaptive QRS detection algorithm and tools for artifact correction, trend removal and analysis sample selection. The software computes all the commonly used time-domain and frequency-domain HRV parameters and several nonlinear parameters. There are several adjustable analysis settings through which the analysis methods can be optimized for different data. The ECG derived respiratory frequency is also computed, which is important for reliable interpretation of the analysis results. The analysis results can be saved as an ASCII text file (easy to import into MS Excel or SPSS), Matlab MAT-file, or as a PDF report. The software is easy to use through its compact graphical user interface. The software is available free of charge for Windows and Linux operating systems at http://kubios.uerfi. (C) 2013 Elsevier Ireland Ltd. All rights reserved.					Karjalainen, Pasi/G-4043-2016; Tarvainen, Mika/B-1290-2009	Karjalainen, Pasi/0000-0002-1267-493X; Lipponen, Jukka/0000-0002-4182-1994; Tarvainen, Mika/0000-0001-8686-5395													0169-2607	1872-7565				JAN	2014	113	1					210	220		10.1016/j.cmpb.2013.07.024	http://dx.doi.org/10.1016/j.cmpb.2013.07.024								24054542					WOS:000327180900019
J	Williams, DF				Williams, David F.			On the mechanisms of biocompatibility	BIOMATERIALS					Ratner Symposium 2006	2006	Maui, HI					The manner in which a mutually acceptable co-existence of biomaterials and tissues is developed and sustained has been the focus of attention in biomaterials science for many years, and forms the foundation of the subject of biocompatibility. There are many ways in which materials and tissues can be brought into contact such that this co-existence may be compromised, and the search for biomaterials that are able to provide for the best performance in devices has been based upon the understanding of all the interactions within biocompatibility phenomena. Our understanding of the mechanisms of biocompatibility has been restricted whilst the focus of attention has been long-term implantable devices. In this paper, over 50 years of experience with such devices is analysed and it is shown that, in the vast majority of circumstances, the sole requirement for biocompatibility in a medical device intended for long-term contact with the tissues of the human body is that the material shall do no harm to those tissues, achieved through chemical and biological inertness. Rarely has an attempt to introduce biological activity into a biomaterial been clinically successful in these applications. This essay then turns its attention to the use of biomaterials in tissue engineering, sophisticated cell, drug and gene delivery systems and applications in biotechnology, and shows that here the need for specific and direct interactions between biomaterials and tissue components has become necessary, and with this a new paradigm for biocompatibility has emerged. It is believed that once the need for this change is recognised, so our understanding of the mechanisms of biocompatibility will markedly improve. (C) 2008 Elsevier Ltd. All rights reserved.																			0142-9612	1878-5905				JUL	2008	29	20					2941	2953		10.1016/j.biomaterials.2008.04.023	http://dx.doi.org/10.1016/j.biomaterials.2008.04.023								18440630					WOS:000256655100001
J	Cao, YC; Yu, WW; Ren, W; Chen, GR				Cao, Yongcan; Yu, Wenwu; Ren, Wei; Chen, Guanrong			An Overview of Recent Progress in the Study of Distributed Multi-Agent Coordination	IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS												This paper reviews some main results and progress in distributed multi-agent coordination, focusing on papers published in major control systems and robotics journals since 2006. Distributed coordination of multiple vehicles, including unmanned aerial vehicles, unmanned ground vehicles, and unmanned underwater vehicles, has been a very active research subject studied extensively by the systems and control community. The recent results in this area are categorized into several directions, such as consensus, formation control, optimization, and estimation. After the review, a short discussion section is included to summarize the existing research and to propose several promising research directions along with some open problems that are deemed important for further investigations.					Cao, Yongcan/B-3881-2010; Chen, Guanrong/F-6000-2011; Ren, Wei/G-7369-2011; Yu, Wenwu/G-5496-2012	Cao, Yongcan/0000-0003-3383-0185; Chen, Guanrong/0000-0003-1381-7418													1551-3203	1941-0050				FEB	2013	9	1					427	438		10.1109/TII.2012.2219061	http://dx.doi.org/10.1109/TII.2012.2219061													WOS:000312839600045
J	Ferretti, A; Prati, C; Rocca, F				Ferretti, A; Prati, C; Rocca, F			Nonlinear subsidence rate estimation using permanent scatterers in differential SAR interferometry	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING					International Geoscience and Remote Sensing Symposium (IGARSS 99)	JUN 28-JUL 02, 1999	HAMBURG, GERMANY					Discrete and temporarily stable natural reflectors or permanent scatterers (PS) can be identified from long temporal series of interferometric SAR images even with baselines larger than the so-called critical baseline. This subset of image pixels can be exploited successfully for high accuracy differential measurements. We discuss the use of PS in urban areas, like Pomona, CA, showing subsidence and absidence effects. A new approach to the estimation of the atmospheric phase contributions, and the local displacement field is proposed based on simple statistical assumptions. New solutions are presented in order to cope with nonlinear motion of the targets.					Ferretti, Alessandro/K-3811-2019	Ferretti, Alessandro/0000-0002-7802-5019; Rocca, Fabio/0000-0002-2266-6212													0196-2892	1558-0644				SEP	2000	38	5	1				2202	2212		10.1109/36.868878	http://dx.doi.org/10.1109/36.868878													WOS:000089510300013
J	Lee, KC; Ho, J; Kriegman, DJ				Lee, KC; Ho, J; Kriegman, DJ			Acquiring linear subspaces for face recognition under variable lighting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Previous work has demonstrated that the image variation of many objects ( human faces in particular) under variable lighting can be effectively modeled by low-dimensional linear spaces, even when there are multiple light sources and shadowing. Basis images spanning this space are usually obtained in one of three ways: A large set of images of the object under different lighting conditions is acquired, and principal component analysis (PCA) is used to estimate a subspace. Alternatively, synthetic images are rendered from a 3D model ( perhaps reconstructed from images) under point sources and, again, PCA is used to estimate a subspace. Finally, images rendered from a 3D model under diffuse lighting based on spherical harmonics are directly used as basis images. In this paper, we show how to arrange physical lighting so that the acquired images of each object can be directly used as the basis vectors of a low-dimensional linear space and that this subspace is close to those acquired by the other methods. More specifically, there exist configurations of k point light source directions, with k typically ranging from 5 to 9, such that, by taking k images of an object under these single sources, the resulting subspace is an effective representation for recognition under a wide range of lighting conditions. Since the subspace is generated directly from real images, potentially complex and/or brittle intermediate steps such as 3D reconstruction can be completely avoided; nor is it necessary to acquire large numbers of training images or to physically construct complex diffuse ( harmonic) light fields. We validate the use of subspaces constructed in this fashion within the context of face recognition.																			0162-8828	1939-3539				MAY	2005	27	5					684	698		10.1109/TPAMI.2005.92	http://dx.doi.org/10.1109/TPAMI.2005.92								15875791					WOS:000227569300003
J	Furukawa, Y; Ponce, J				Furukawa, Yasutaka; Ponce, Jean			Accurate, Dense, and Robust Multiview Stereopsis	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												This paper proposes a novel algorithm for multiview stereopsis that outputs a dense set of small rectangular patches covering the surfaces visible in the images. Stereopsis is implemented as a match, expand, and filter procedure, starting from a sparse set of matched keypoints, and repeatedly expanding these before using visibility constraints to filter away false matches. The keys to the performance of the proposed algorithm are effective techniques for enforcing local photometric consistency and global visibility constraints. Simple but effective methods are also proposed to turn the resulting patch model into a mesh which can be further refined by an algorithm that enforces both photometric consistency and regularization constraints. The proposed approach automatically detects and discards outliers and obstacles and does not require any initialization in the form of a visual hull, a bounding box, or valid depth ranges. We have tested our algorithm on various data sets including objects with fine surface details, deep concavities, and thin structures, outdoor scenes observed from a restricted set of viewpoints, and "crowded" scenes where moving obstacles appear in front of a static structure of interest. A quantitative evaluation on the Middlebury benchmark [1] shows that the proposed method outperforms all others submitted so far for four out of the six data sets.																			0162-8828	1939-3539				AUG	2010	32	8					1362	1376		10.1109/TPAMI.2009.161	http://dx.doi.org/10.1109/TPAMI.2009.161								20558871					WOS:000278858600002
J	Li, FF; Fergus, R; Perona, P				Li Fei-Fei; Fergus, Rob; Perona, Pietro			Learning generative visual models from few training examples: An incremental Bayesian approach tested on 101 object categories	COMPUTER VISION AND IMAGE UNDERSTANDING					2nd International Workshop on Generative-Model Based Vision	2005	Washington, DC					Current computational approaches to learning visual object categories require thousands of training images, are slow, cannot learn in an incremental manner and cannot incorporate prior information into the learning process. In addition, no algorithm presented in the literature has been tested on more than a handful of object categories. We present all method for learning object categories from just a few training images. It is quick and it uses prior information in a principled way. We test it on a dataset composed of images of objects belonging to 101 widely varied categories. Our proposed method is based on making use of prior information, assembled from (unrelated) object categories which were previously learnt. A generative probabilistic model is used, which represents the shape and appearance of a constellation of features belonging to the object. The parameters of the model are learnt incrementally in a Bayesian manner. Our incremental algorithm is compared experimentally to an earlier batch Bayesian algorithm, as well as to one based on maximum likelihood. The incremental and batch versions have comparable classification performance on small training sets, but incremental learning is significantly faster, making real-time learning feasible. Both Bayesian methods outperform maximum likelihood on small training sets. (C) 2006 Elsevier Inc. All rights reserved.					Li, Feifei/JTT-8011-2023														1077-3142	1090-235X				APR	2007	106	1					59	70		10.1016/j.cviu.2005.09.012	http://dx.doi.org/10.1016/j.cviu.2005.09.012													WOS:000245874900006
J	Miehe, C; Hofacker, M; Welschinger, F				Miehe, Christian; Hofacker, Martina; Welschinger, Fabian			A phase field model for rate-independent crack propagation: Robust algorithmic implementation based on operator splits	COMPUTER METHODS IN APPLIED MECHANICS AND ENGINEERING												The computational modeling of failure mechanisms in solids due to fracture based on sharp crack discontinuities suffers in situations with complex crack topologies. This can be overcome by a diffusive crack modeling based on the introduction of a crack phase field. Following our recent work [C. Miehe, F. Welschinger, M. Hofacker, Thermodynamically-consistent phase field models of fracture: Variational principles and multi-field fe implementations, International Journal for Numerical Methods in Engineering DOI:10.1002/nme.2861] on phase-field-type fracture, we propose in this paper a new variational framework for rate-independent diffusive fracture that bases on the introduction of a local history field. It contains a maximum reference energy obtained in the deformation history, which may be considered as a measure for the maximum tensile strain obtained in history. It is shown that this local variable drives the evolution of the crack phase field. The introduction of the history field provides a very transparent representation of the balance equation that governs the diffusive crack topology. In particular, it allows for the construction of a new algorithmic treatment of diffusive fracture. Here, we propose an extremely robust operator split scheme that successively updates in a typical time step the history field, the crack phase field and finally the displacement field. A regularization based on a viscous crack resistance that even enhances the robustness of the algorithm may easily be added. The proposed algorithm is considered to be the canonically simple scheme for the treatment of diffusive fracture in elastic solids. We demonstrate the performance of the phase field formulation of fracture by means of representative numerical examples. (C) 2010 Elsevier By. All rights reserved.						Welschinger, Fabian/0000-0003-0238-6237													0045-7825	1879-2138					2010	199	45-48					2765	2778		10.1016/j.cma.2010.04.011	http://dx.doi.org/10.1016/j.cma.2010.04.011													WOS:000285431900002
J	Li, FF; Fergus, R; Perona, P				Li, FF; Fergus, R; Perona, P			One-shot learning of object categories	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Learning visual models of object categories notoriously requires hundreds or thousands of training examples. We show that it is possible to learn much information about a category from just one, or a handful, of images. The key insight is that, rather than learning from scratch, one can take advantage of knowledge coming from previously learned categories, no matter how different these categories might be. We explore a Bayesian implementation of this idea. Object categories are represented by probabilistic models. Prior knowledge is represented as a probability density function on the parameters of these models. The posterior model for an object category is obtained by updating the prior in the light of one or more observations. We test a simple implementation of our algorithm on a database of 101 diverse object categories. We compare category models learned by an implementation of our Bayesian approach to models learned from by Maximum Likelihood (ML) and Maximum A Posteriori (MAP) methods. We find that on a database of more than 100 categories, the Bayesian approach produces informative models when the number of training examples is too small for other methods to operate successfully.					Li, Feifei/JTT-8011-2023	Fergus, Rob/0009-0005-3077-2495													0162-8828	1939-3539				APR	2006	28	4					594	611		10.1109/TPAMI.2006.79	http://dx.doi.org/10.1109/TPAMI.2006.79								16566508					WOS:000235253300009
J	Alkhateeb, A; El Ayach, O; Leus, G; Heath, RW				Alkhateeb, Ahmed; El Ayach, Omar; Leus, Geert; Heath, Robert W., Jr.			Channel Estimation and Hybrid Precoding for Millimeter Wave Cellular Systems	IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING												Millimeter wave (mmWave) cellular systems will enable gigabit-per-second data rates thanks to the large bandwidth available at mmWave frequencies. To realize sufficient link margin, mmWave systems will employ directional beamforming with large antenna arrays at both the transmitter and receiver. Due to the high cost and power consumption of gigasample mixed-signal devices, mmWave precoding will likely be divided among the analog and digital domains. The large number of antennas and the presence of analog beamforming requires the development of mmWave-specific channel estimation and precoding algorithms. This paper develops an adaptive algorithm to estimate the mmWave channel parameters that exploits the poor scattering nature of the channel. To enable the efficient operation of this algorithm, a novel hierarchical multi-resolution codebook is designed to construct training beamforming vectors with different beamwidths. For single-path channels, an upper bound on the estimation error probability using the proposed algorithm is derived, and some insights into the efficient allocation of the training power among the adaptive stages of the algorithm are obtained. The adaptive channel estimation algorithm is then extended to the multi-path case relying on the sparse nature of the channel. Using the estimated channel, this paper proposes a new hybrid analog/ digital precoding algorithm that overcomes the hardware constraints on the analog-only beamforming, and approaches the performance of digital solutions. Simulation results show that the proposed low-complexity channel estimation algorithm achieves comparable precoding gains compared to exhaustive channel training algorithms. The results illustrate that the proposed channel estimation and precoding algorithms can approach the coverage probability achieved by perfect channel knowledge even in the presence of interference.					Heath, Robert/AAY-4148-2020; Alkhateeb, Ahmed/I-8485-2015; Heath, Robert/A-5366-2010	Leus, Geert/0000-0001-8288-867X; Heath, Robert/0000-0002-4666-5628													1932-4553	1941-0484				OCT	2014	8	5					831	846		10.1109/JSTSP.2014.2334278	http://dx.doi.org/10.1109/JSTSP.2014.2334278													WOS:000342283600008
J	Bobick, AF; Davis, JW				Bobick, AF; Davis, JW			The recognition of human movement using temporal templates	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												A new view-based approach to the representation and recognition of human movement is presented. The basis of the representation is a temporal template-a static vector-image where the vector value at each point is a function of the motion properties at the corresponding spatial location in an image sequence. Using aerobics exercises as a test domain, we explore the representational power of a simple, two component version of the templates: The first value is a binary value indicating the presence of motion and the second value is a function of the recency of motion in a sequence. We then develop a recognition method matching temporal templates against stored instances of Views of known actions. The method automatically performs temporal segmentation, is invariant to linear changes in speed, and runs in real-time on standard platforms.					Davis, James/D-4314-2012														0162-8828	1939-3539				MAR	2001	23	3					257	267		10.1109/34.910878	http://dx.doi.org/10.1109/34.910878													WOS:000167276200002
J	Basar, E; Di Renzo, M; De Rosny, J; Debbah, M; Alouini, MS; Zhang, R				Basar, Ertugrul; Di Renzo, Marco; De Rosny, Julien; Debbah, Merouane; Alouini, Mohamed-Slim; Zhang, Rui			Wireless Communications Through Reconfigurable Intelligent Surfaces	IEEE ACCESS												The future of mobile communications looks exciting with the potential new use cases and challenging requirements of future 6th generation (6G) and beyond wireless networks. Since the beginning of the modern era of wireless communications, the propagation medium has been perceived as a randomly behaving entity between the transmitter and the receiver, which degrades the quality of the received signal due to the uncontrollable interactions of the transmitted radio waves with the surrounding objects. The recent advent of reconfigurable intelligent surfaces in wireless communications enables, on the other hand, network operators to control the scattering, refiection, and refraction characteristics of the radio waves, by overcoming the negative effects of natural wireless propagation. Recent results have revealed that reconfigurable intelligent surfaces can effectively control the wavefront, e.g., the phase, amplitude, frequency, and even polarization, of the impinging signals without the need of complex decoding, encoding, and radio frequency processing operations. Motivated by the potential of this emerging technology, the present article is aimed to provide the readers with a detailed overview and historical perspective on state-of-the-art solutions, and to elaborate on the fundamental differences with other technologies, the most important open research issues to tackle, and the reasons why the use of reconfigurable intelligent surfaces necessitates to rethink the communication-theoretic models currently employed in wireless networks. This article also explores theoretical performance limits of reconfigurable intelligent surface-assisted communication systems using mathematical techniques and elaborates on the potential use cases of intelligent surfaces in 6G and beyond wireless networks.					Yang, Zhaohui/T-5687-2019; Basar, Ertugrul/AAR-9977-2020; Zhang, Rui/GXN-3801-2022; Alouini, Mohamed-Slim/I-2658-2018	Alouini, Mohamed-Slim/0000-0003-4827-1793; Basar, Ertugrul/0000-0001-5566-2392; Debbah, Merouane/0000-0001-8941-8080													2169-3536						2019	7						116753	116773		10.1109/ACCESS.2019.2935192	http://dx.doi.org/10.1109/ACCESS.2019.2935192													WOS:000484235600019
J	Ji, SH; Xue, Y; Carin, L				Ji, Shihao; Xue, Ya; Carin, Lawrence			Bayesian compressive sensing	IEEE TRANSACTIONS ON SIGNAL PROCESSING												The data of interest are assumed to be represented as N-dimensional real vectors, and these vectors are compressible in some linear basis B, implying that the signal can be reconstructed accurately using only a small number M << N of basis-function coefficients associated with B. Compressive sensing is a framework whereby one does not measure one of the aforementioned N-dimensional signals directly, but rather a set of related measurements, with the new measurements a linear combination of the original underlying N-dimensional signal. The number of required compressive-sensing measurements is typically much smaller than N, offering the potential to simplify the sensing system. Let f denote the unknown underlying N-dimensional signal, and g a vector of compressive-sensing measurements, then one may approximate f accurately by utilizing knowledge of the (under-determined) linear relationship between f and g, in addition to knowledge of the fact that f is compressible in B. In this paper we employ a Bayesian formalism for estimating the underlying signal f based on compressive-sensing measurements g. The proposed framework has the following properties: i) in addition to estimating the underlying signal f, "error bars" are also estimated, these giving a measure of confidence in the inverted signal; ii) using knowledge of the error bars, a principled means is provided for determining when a sufficient number of compressive-sensing measurements have been performed; iii) this setting lends itself naturally to a framework whereby the compressive sensing measurements are optimized adaptively and hence not determined randomly; and iv) the framework accounts for additive noise in the compressive-sensing measurements and provides an estimate of the noise variance. In this paper we present the underlying theory, an associated algorithm, example results, and provide comparisons to other compressive-sensing inversion algorithms in the literature.						Carin, Lawrence/0000-0001-6277-7948; Ji, Shihao/0000-0002-3573-5379													1053-587X	1941-0476				JUN	2008	56	6					2346	2356		10.1109/TSP.2007.914345	http://dx.doi.org/10.1109/TSP.2007.914345													WOS:000256153800016
J	Song, CS				Song, CS			An overview of new approaches to deep desulfurization for ultra-clean gasoline, diesel fuel and jet fuel	CATALYSIS TODAY					International Symposium on Ultra-Clean Transportation Fuels held at the National Meeting of the American-Chemical-Society	AUG 18-22, 2002	BOSTON, MA	Amer Chem Soc				This review discusses the problems of sulfur reduction in highway and non-road fuels and presents an overview of new approaches and emerging technologies for ultra-deep desulfurization of refinery streams for ultra-clean (ultra-low-sulfur) gasoline, diesel fuels and jet fuels. The issues of gasoline and diesel deep desulfurization are becoming more serious because the crude oils refined in the US are getting higher in sulfur contents and heavier in density, while the regulated sulfur limits are becoming lower and lower. Current gasoline desulfurization problem is dominated by the issues of sulfur removal from FCC naphtha, which contributes about 35% of gasoline pool but over 90% of sulfur in gasoline. Deep reduction of gasoline sulfur (from 330 to 30 ppm) must be made without decreasing octane number or losing gasoline yield. The problem is complicated by the high olefins contents of FCC naphtha which contributes to octane number enhancement but can be saturated under HDS conditions. Deep reduction of diesel sulfur (from 500 to < 15 ppm sulfur) is dictated largely by 4,6-dimethyldibenzothiophene, which represents the least reactive sulfur compounds that have substitutions on both 4- and 6-positions. The deep HDS problem of diesel streams is exacerbated by the inhibiting effects of co-existing polyaromatics and nitrogen compounds in the feed as well as H2S in the product. The approaches to deep desulfurization include catalysts and process developments for hydrodesulfurization (HDS), and adsorbents or reagents and methods for non-HDS-type processing schemes. The needs for dearomatization of diesel and jet fuels are also discussed along with some approaches. Overall, new and more effective approaches and continuing catalysis and processing research are needed for producing affordable ultra-clean (ultra-low-sulfur and low-aromatics) transportation fuels and non-road fuels, because meeting the new government sulfur regulations in 2006-2010 (15 ppm sulfur in highway diesel fuels by 2006 and non-road diesel fuels by 20 10; 30 ppm sulfur in gasoline by 2006) is only a milestone. Desulfurization research should also take into consideration of the fuel-cell fuel processing needs, which will have a more stringent requirement on desulfurization (e.g., < 1 ppm sulfur) than IC engines. The society at large is stepping on the road to zero sulfur fuel, so researchers should begin with the end in mind and try to develop long-term solutions. (C) 2003 Elsevier B.V. All rights reserved.					Song, Chunshan/B-3524-2008	Song, Chunshan/0000-0003-2344-9911													0920-5861	1873-4308				NOV 1	2003	86	1-4					211	263		10.1016/S0920-5861(03)00412-7	http://dx.doi.org/10.1016/S0920-5861(03)00412-7													WOS:000186414400015
J	Essiambre, RJ; Kramer, G; Winzer, PJ; Foschini, GJ; Goebel, B				Essiambre, Rene-Jean; Kramer, Gerhard; Winzer, Peter J.; Foschini, Gerard J.; Goebel, Bernhard			Capacity Limits of Optical Fiber Networks	JOURNAL OF LIGHTWAVE TECHNOLOGY												We describe a method to estimate the capacity limit of fiber-optic communication systems (or "fiber channels") based on information theory. This paper is divided into two parts. Part 1 reviews fundamental concepts of digital communications and information theory. We treat digitization and modulation followed by information theory for channels both without and with memory. We provide explicit relationships between the commonly used signal-to-noise ratio and the optical signal-to-noise ratio. We further evaluate the performance of modulation constellations such as quadrature-amplitude modulation, combinations of amplitude-shift keying and phase-shift keying, exotic constellations, and concentric rings for an additive white Gaussian noise channel using coherent detection. Part 2 is devoted specifically to the "fiber channel." We review the physical phenomena present in transmission over optical fiber networks, including sources of noise, the need for optical filtering in optically-routed networks, and, most critically, the presence of fiber Kerr nonlinearity. We describe various transmission scenarios and impairment mitigation techniques, and define a fiber channel deemed to be the most relevant for communication over optically-routed networks. We proceed to evaluate a capacity limit estimate for this fiber channel using ring constellations. Several scenarios are considered, including uniform and optimized ring constellations, different fiber dispersion maps, and varying transmission distances. We further present evidences that point to the physical origin of the fiber capacity limitations and provide a comparison of recent record experiments with our capacity limit estimation.					Winzer, Peter/AFW-0783-2022; Kramer, Gerhard/M-4270-2014	Kramer, Gerhard/0000-0002-3904-9181													0733-8724	1558-2213				FEB 15	2010	28	4					662	701		10.1109/JLT.2009.2039464	http://dx.doi.org/10.1109/JLT.2009.2039464													WOS:000275710300001
J	Grady, L				Grady, Leo			Random walks for image segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												A novel method is proposed for performing multilabel, interactive image segmentation. Given a small number of pixels with user-defined (or predefined) labels, one can analytically and quickly determine the probability that a random walker starting at each unlabeled pixel will first reach one of the prelabeled pixels. By assigning each pixel to the label for which the greatest probability is calculated, a high-quality image segmentation may be obtained. Theoretical properties of this algorithm are developed along with the corresponding connections to discrete potential theory and electrical circuits. This algorithm is formulated in discrete space (i.e., on a graph) using combinatorial analogues of standard operators and principles from continuous potential theory, allowing it to be applied in arbitrary dimension on arbitrary graphs.																			0162-8828	1939-3539				NOV	2006	28	11					1768	1783		10.1109/TPAMI.2006.233	http://dx.doi.org/10.1109/TPAMI.2006.233								17063682					WOS:000240443400005
J	Viswanath, P; Tse, DNC; Laroia, R				Viswanath, P; Tse, DNC; Laroia, R			Opportunistic beamforming using dumb antennas	IEEE TRANSACTIONS ON INFORMATION THEORY					IEEE Comunication Theory Workshop	MAR, 2001	ANZA BORREGO, CALIFORNIA	IEEE				Multiuser diversity is a form of diversity inherent in a wireless network, provided by independent time-varying channels across the different users. The diversity benefit is exploited by tracking the channel fluctuations of the users and scheduling tran missions to users when their instantaneous channel quality is near the peak. The diversity gain increases with the dynamic range of the fluctuations and is thus limited in environments with little scattering and/or slow fading. In such environments, we propose the use of multiple transmit antennas to induce large and fast channel fluctuations so that multiuser diversity can still be exploited. The scheme can be interpreted as opportunistic beamforming and we show that true beamforming gains can be achieved when there are sufficient users, even though very limited channel feedback is needed. Furthermore, in a cellular system, the scheme plays an additional role of opportunistic nulling of the interference created on users of adjacent cells. We discuss the design implications of implementing this scheme in a complete wireless system.																			0018-9448					JUN	2002	48	6					1277	1294	PII S0018-9448(02)04009-9	10.1109/tit.2002.1003822	http://dx.doi.org/10.1109/tit.2002.1003822													WOS:000175821500005
J	Rangan, S; Rappaport, TS; Erkip, E				Rangan, Sundeep; Rappaport, Theodore S.; Erkip, Elza			Millimeter-Wave Cellular Wireless Networks: Potentials and Challenges	PROCEEDINGS OF THE IEEE												Millimeter-wave (mmW) frequencies between 30 and 300 GHz are a new frontier for cellular communication that offers the promise of orders of magnitude greater bandwidths combined with further gains via beamforming and spatial multiplexing from multielement antenna arrays. This paper surveys measurements and capacity studies to assess this technology with a focus on small cell deployments in urban environments. The conclusions are extremely encouraging; measurements in New York City at 28 and 73 GHz demonstrate that, even in an urban canyon environment, significant non-line-of-sight (NLOS) outdoor, street-level coverage is possible up to approximately 200 m from a potential low-power microcell or picocell base station. In addition, based on statistical channel models from these measurements, it is shown that mmW systems can offer more than an order of magnitude increase in capacity over current state-of-the-art 4G cellular networks at current cell densities. Cellular systems, however, will need to be significantly redesigned to fully achieve these gains. Specifically, the requirement of highly directional and adaptive transmissions, directional isolation between links, and significant possibilities of outage have strong implications on multiple access, channel structure, synchronization, and receiver design. To address these challenges, the paper discusses how various technologies including adaptive beamforming, multihop relaying, heterogeneous network architectures, and carrier aggregation can be lever-aged in the mmW context.					Erkip, Elza/A-2992-2012; Rangan, Sundeep/AAH-2526-2020	Erkip, Elza/0000-0001-8718-8648; Rappaport, Theodore (Ted)/0000-0001-7449-9957													0018-9219	1558-2256				MAR	2014	102	3			SI		366	385		10.1109/JPROC.2014.2299397	http://dx.doi.org/10.1109/JPROC.2014.2299397													WOS:000331973300011
J	Cole, M; Lindeque, P; Fileman, E; Halsband, C; Goodhead, R; Moger, J; Galloway, TS				Cole, Matthew; Lindeque, Pennie; Fileman, Elaine; Halsband, Claudia; Goodhead, Rhys; Moger, Julian; Galloway, Tamara S.			Microplastic Ingestion by Zooplankton	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Small plastic detritus, termed "microplastics", are a widespread and ubiquitous contaminant of marine ecosystems across the globe. Ingestion of microplastics by marine biota, including mussels, worms, fish, and seabirds, has been widely reported, but despite their vital ecological role in marine food-webs, the impact of microplastics on zooplankton remains under-researched. Here, we show that microplastics are ingested by, and may impact upon, zooplankton. We used bioimaging techniques to document ingestion, egestion, and adherence of microplastics in a range of zooplankton common to the northeast Atlantic, and employed feeding rate studies to determine the impact of plastic detritus on algal ingestion rates in copepods. Using fluorescence and coherent anti-Stokes Raman scattering (CARS) microscopy we identified that thirteen zooplankton taxa had the capacity to ingest 1.7-30.6 mu m polystyrene beads, with uptake varying by taxa, life-stage and bead-size. Post-ingestion, copepods egested faecal pellets laden with microplastics. We further observed microplastics adhered to the external carapace and appendages of exposed zooplankton. Exposure of the copepod Centropages typicus to natural assemblages of algae with and without microplastics showed that 7.3 mu m microplastics (>4000 mL(-1)) significantly decreased algal feeding. Our findings imply that marine microplastic debris can negatively impact upon zooplankton function and health.					Lindeque, Penelope/AAE-9193-2019; Fileman, Elaine/AAB-5002-2022; Cole, Matthew/KHZ-6806-2024; Galloway, Tamara/C-1662-2009; Halsband, Claudia/B-7770-2008	moger, julian/0000-0001-6208-7840; Fileman, Elaine/0000-0002-7795-7535; Galloway, Tamara/0000-0002-7466-6775; Lindeque, Penelope/0000-0003-1789-7515; Halsband, Claudia/0000-0002-8570-9056; Cole, Matthew/0000-0001-5910-1189													0013-936X	1520-5851				JUN 18	2013	47	12					6646	6655		10.1021/es400663f	http://dx.doi.org/10.1021/es400663f								23692270					WOS:000320749000071
J	Garcia, R; Calantone, R				Garcia, R; Calantone, R			A critical look at technological innovation typology and innovativeness terminology: a literature review	JOURNAL OF PRODUCT INNOVATION MANAGEMENT					PDMA Research Conference	1999	MARCO ISL, FL					A plethora of definitions for innovation types has resulted in an ambiguity in the way the terms 'innovation' and 'innovativeness' are p operationalized and utilized in the new product development literature. The terms radical, really-new, incremental and discontinuous are used ubiquitously to identify innovations. One must question, what is the difference between these different classifications? To date consistent definitions for these innovation types have not emerged from the new product research community. A review of the literature from the marketing, engineering, and new product development disciplines attempts to put some clarity and continuity to the use of these terms. This review shows that it is important to consider both a marketing and technological perspective as well as a macrolevel and microlevel perspective when identifying innovations. Additionally, it is shown when strict classifications from the extant literature are applied, a significant shortfall appears in empirical work directed toward radical and really new innovations. A method for classifying innovations is suggested so that practitioners and academies can talk with a common understanding of how a specific innovation type is identified and how the innovation process may be unique for that particular innovation type. A recommended list of measures based on extant literature is provided for future empirical research concerning technological innovations and innovativeness. (C) 2002 PDMA. All rights reserved.					Garcia, Rosanna/A-4329-2010	Garcia, Rosanna/0000-0002-8319-2655													0737-6782	1540-5885				MAR	2002	19	2					110	132	PII S0737-6782(01)00132-1	10.1111/1540-5885.1920110	http://dx.doi.org/10.1111/1540-5885.1920110													WOS:000175021300002
J	Win, MZ; Scholtz, RA				Win, MZ; Scholtz, RA			Ultra-wide bandwidth time-hopping spread-spectrum impulse radio for wireless multiple-access communications	IEEE TRANSACTIONS ON COMMUNICATIONS					IEEE International Conference on Communications	JUN 08-12, 1997	MONTREAL, CANADA	IEEE				Attractive features of time-hopping spread-spectrum multiple-access systems employing impulse signal technology are outlined, and emerging design issues are described. Performance of such communications systems in terms of achievable transmission rate and multiple-access capability are estimated for both analog and digital data modulation formats under ideal multiple-access channel conditions.					Win, Moe/A-3960-2009	Win, Moe/0000-0002-8573-0488													0090-6778					APR	2000	48	4					679	691		10.1109/26.843135	http://dx.doi.org/10.1109/26.843135													WOS:000087081200020
J	Akdeniz, MR; Liu, YP; Samimi, MK; Sun, S; Rangan, S; Rappaport, TS; Erkip, E				Akdeniz, Mustafa Riza; Liu, Yuanpeng; Samimi, Mathew K.; Sun, Shu; Rangan, Sundeep; Rappaport, Theodore S.; Erkip, Elza			Millimeter Wave Channel Modeling and Cellular Capacity Evaluation	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS												With the severe spectrum shortage in conventional cellular bands, millimeter wave (mmW) frequencies between 30 and 300 GHz have been attracting growing attention as a possible candidate for next-generation micro-and picocellular wireless networks. The mmW bands offer orders of magnitude greater spectrum than current cellular allocations and enable very high-dimensional antenna arrays for further gains via beamforming and spatial multiplexing. This paper uses recent real-world measurements at 28 and 73 GHz in New York, NY, USA, to derive detailed spatial statistical models of the channels and uses these models to provide a realistic assessment of mmW micro-and picocellular networks in a dense urban deployment. Statistical models are derived for key channel parameters, including the path loss, number of spatial clusters, angular dispersion, and outage. It is found that, even in highly non-line-of-sight environments, strong signals can be detected 100-200 m from potential cell sites, potentially with multiple clusters to support spatial multiplexing. Moreover, a system simulation based on the models predicts that mmW systems can offer an order of magnitude increase in capacity over current state-of-the-art 4G cellular networks with no increase in cell density from current urban deployments.					Sun, Shu/AAH-1270-2021; Erkip, Elza/A-2992-2012; Rangan, Sundeep/AAH-2526-2020	Erkip, Elza/0000-0001-8718-8648; Rappaport, Theodore (Ted)/0000-0001-7449-9957													0733-8716	1558-0008				JUN	2014	32	6					1164	1179		10.1109/JSAC.2014.2328154	http://dx.doi.org/10.1109/JSAC.2014.2328154													WOS:000340748600008
J	Chong, CY; Kumar, SP				Chong, CY; Kumar, SP			Sensor networks: Evolution, opportunities, and challenges	PROCEEDINGS OF THE IEEE												Wireless microsensor networks have been identified as one of the most important technologies for the 21st century. This paper traces the history of research in sensor networks over the past three decades, including two important programs of the Defense Advanced Research Projects Agency (DARPA) spanning this period: the Distributed Sensor Networks (DSN) and the Sensor Information Technology (SensIT) programs. Technology trends that impact the development of sensor networks are reviewed, and new applications such as infrastructure security. habitat monitoring, and traffic control are presented. Technical challenges in sensor network development include network discovery, control and routing, collaborative signal and information processing, tasking and querying, and security. The paper concludes by presenting some recent research results in sensor network algorithms, including localized algorithms and directed diffusion, distributed tracking in wireless ad hoc networks, and distributed classification using local agents.																			0018-9219	1558-2256				AUG	2003	91	8					1247	1256		10.1109/JPROC.2003.814918	http://dx.doi.org/10.1109/JPROC.2003.814918													WOS:000184655000010
J	Sigmund, O				Sigmund, O			A 99 line topology optimization code written in Matlab	STRUCTURAL AND MULTIDISCIPLINARY OPTIMIZATION												The paper presents a compact Matlab implementation of a topology optimization code for compliance minimization of statically loaded structures. The total number of Matlab input lines is 99 including optimizer and Finite Element subroutine. The 99 lines are divided into 36 lines for the main program, 12 lines for the Optimality Criteria based optimizer, 16 lines for a mesh-independency filter and 35 lines for the finite element code. In fact, excluding comment lines and lines associated with output and finite element analysis, it is shown that only 49 Matlab input lines are required for solving a well-posed topology optimization problem. By adding three additional lines, the program can solve problems with multiple load cases. The code is intended for educational purposes. The complete Matlab code is given in the Appendix and can be down-loaded from the web-site http://www.topopt.dtu.dk.					Sigmund, Ole/A-5354-2008	Sigmund, Ole/0000-0003-0344-7249													1615-147X					APR	2001	21	2					120	127		10.1007/s001580050176	http://dx.doi.org/10.1007/s001580050176													WOS:000168915400004
J	Hair, J; Hollingsworth, CL; Randolph, AB; Chong, AYL				Hair, Joe; Hollingsworth, Carole L.; Randolph, Adriane B.; Chong, Alain Yee Loong			An updated and expanded assessment of PLS-SEM in information systems research	INDUSTRIAL MANAGEMENT & DATA SYSTEMS												Purpose - Following the call for awareness of accepted reporting practices by Ringle, Sarstedt, and Straub in 2012, the purpose of this paper is to review and analyze the use of partial least squares structural equation modeling (PLS-SEM) in Industrial Management & Data Systems (IMDS) and extend MIS Quarterly (MISQ) applications to include the period 2012-2014. Design/methodology/approach - Review of PLS-SEM applications in information systems (IS) studies published in IMDS and MISQ for the period 2010-2014 identifying a total of 57 articles reporting the use of or commenting on PLS-SEM. Findings - The results indicate an increased maturity of the IS field in using PLS-SEM for model complexity and formative measures and not just small sample sizes and non-normal data. Research limitations/implications - Findings demonstrate the continued use and acceptance of PLS-SEM as an accepted research method within IS. PLS-SEM is discussed as the preferred SEM method when the research objective is prediction. Practical implications - This update on PLS-SEM use and recent developments will help authors to better understand and apply the method. Researchers are encouraged to engage in complete reporting procedures. Originality/value - Applications of PLS-SEM for exploratory research and theory development are increasing. IS scholars should continue to exercise sound practice by reporting reasons for using PLS-SEM and recognizing its wider applicability for research. Recommended reporting guidelines following Ringle et al. (2012) and Gefen et al. (2011) are included. Several important methodological updates are included as well.					Randolph, Adriane/AAO-2821-2020; Chong, Alain/ABD-6916-2021; Hair, Joseph/AEY-0477-2022	Chong, Alain/0000-0002-0881-1612													0263-5577	1758-5783					2017	117	3					442	458		10.1108/IMDS-04-2016-0130	http://dx.doi.org/10.1108/IMDS-04-2016-0130													WOS:000401033700001
J	Xuan, YM; Li, Q				Xuan, YM; Li, Q			Investigation on convective heat transfer and flow features of nanofluids	JOURNAL OF HEAT TRANSFER-TRANSACTIONS OF THE ASME												An experimental system was built to investigate convective heat trouser and flow features of the nanofluid in a tube. Both the convective heat transfer coefficient and friction factor of the sample nanofluids for the turbulent flow are measured, respectively. The effects of such factors as the volume fraction of suspended nanoparticles and the Reynolds number on the heat transfer and flow features are discussed in detail. A new type of convective heat transfer correlation is proposed to correlate experimental data of heat transfer for nanofluids.																			0022-1481					FEB	2003	125	1					151	155		10.1115/1.1532008	http://dx.doi.org/10.1115/1.1532008													WOS:000180915100019
J	Baltrusaitis, T; Ahuja, C; Morency, LP				Baltrusaitis, Tadas; Ahuja, Chaitanya; Morency, Louis-Philippe			Multimodal Machine Learning: A Survey and Taxonomy	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Our experience of the world is multimodal - we see objects, hear sounds, feel texture, smell odors, and taste flavors. Modality refers to the way in which something happens or is experienced and a research problem is characterized as multimodal when it includes multiple such modalities. In order for Artificial Intelligence to make progress in understanding the world around us, it needs to be able to interpret such multimodal signals together. Multimodal machine learning aims to build models that can process and relate information from multiple modalities. It is a vibrant multi-disciplinary field of increasing importance and with extraordinary potential. Instead of focusing on specific multimodal applications, this paper surveys the recent advances in multimodal machine learning itself and presents them in a common taxonomy. We go beyond the typical early and late fusion categorization and identify broader challenges that are faced by multimodal machine learning, namely: representation, translation, alignment, fusion, and co-learning. This new taxonomy will enable researchers to better understand the state of the field and identify directions for future research.					Morency, Louis-Philippe/B-2006-2008	Baltrusaitis, Tadas/0000-0001-7923-8780													0162-8828	1939-3539				FEB	2019	41	2					423	443		10.1109/TPAMI.2018.2798607	http://dx.doi.org/10.1109/TPAMI.2018.2798607								29994351					WOS:000456150600012
J	Cortés, J; Martínez, S; Karatas, T; Bullo, F				Cortés, J; Martínez, S; Karatas, T; Bullo, F			Coverage control for mobile sensing networks	IEEE TRANSACTIONS ON ROBOTICS AND AUTOMATION					10th IEEE Mediterranean Conference on Control and Automation	JUL, 2002	Lisbon, PORTUGAL	IEEE				This paper presents control and coordination algorithms for groups of vehicles. The focus is on autonomous vehicle networks performing distributed sensing tasks, where each vehicle plays the role of a mobile tunable sensor. The paper proposes gradient descent algorithms for a class of utility functions which encode optimal coverage and sensing policies. The resulting closed-loop behavior is adaptive, distributed, asynchronous, and verifiably correct.					; Cortes, Jorge/H-9135-2012	Bullo, Francesco/0000-0002-4785-2118; Cortes, Jorge/0000-0001-9582-5184													1042-296X					APR	2004	20	2					243	255		10.1109/TRA.2004.824698	http://dx.doi.org/10.1109/TRA.2004.824698													WOS:000220706700008
J	Yoshimoto, H; Shin, YM; Terai, H; Vacanti, JP				Yoshimoto, H; Shin, YM; Terai, H; Vacanti, JP			A biodegradable nanofiber scaffold by electrospinning and its potential for bone tissue engineering	BIOMATERIALS												Microporous, non-woven poly(epsilon-caprolactone) (PCL) scaffolds were made by electrostatic fiber spinning. In this process, polymer fibers with diameters down to the nanometer range, or nanofibers, are formed by subjecting a fluid jet to a high electric field. Mesenchymal stem cells (MSCs) derived from the bone marrow of neonatal rats were cultured, expanded and seeded oil electrospun PCL scaffolds. The cell-polymer constructs were cultured with osteogenic supplements under dynamic culture conditions for up to 4 weeks. The cell-polymer constructs maintained the size and shape of the original scaffolds. Scanning electron microscopy (SEM), histological and immunohistochemical examinations were performed. Penetration of cells and abundant extracellular matrix were observed in the cell-polymer constructs after 1 week. SEM showed that the surfaces of the cell-polymer constructs were covered with cell multilayers at 4 weeks. In addition, mineralization and type I collagen were observed at 4 weeks. This suggests that electrospun PCL is a potential candidate scaffold for bone tissue engineering. (C) 2003 Elsevier Science Ltd. All rights reserved.					Terai, Hidetomi/AAB-9953-2021	Terai, Hidetomi/0000-0001-9183-3363													0142-9612	1878-5905				MAY	2003	24	12					2077	2082		10.1016/S0142-9612(02)00635-X	http://dx.doi.org/10.1016/S0142-9612(02)00635-X								12628828					WOS:000181758200010
J	Ramoser, H; Müller-Gerking, J; Pfurtscheller, G				Ramoser, H; Müller-Gerking, J; Pfurtscheller, G			Optimal spatial filtering of single trial EEG during imagined hand movement	IEEE TRANSACTIONS ON REHABILITATION ENGINEERING												The development of an electroencephalograph (EEG)-based brain-computer interface (BCI) requires rapid and reliable discrimination of EEG patterns, e.g., associated with imaginary movement. One-sided hand movement imagination results in EEG changes located at contra- and ipsilateral central areas, We demonstrate that spatial filters for multichannel EEG effectively extract discriminatory information from two populations of single-trial EEG, recorded during left- and right-hand movement imagery. The best classification results for three subjects are 90.8%, 92.7%, and 99.7%. The spatial filters are estimated from a set of data by the method of common spatial patterns and reflect the specific activation of cortical areas, The method performs a weighting of the electrodes according to their importance for the classification task. The high recognition rates and computational simplicity make it a promising method for an EEG-based brain-computer interface.																			1063-6528					DEC	2000	8	4					441	446		10.1109/86.895946	http://dx.doi.org/10.1109/86.895946								11204034					WOS:000166570900002
J	Jan, S; Santin, G; Strul, D; Staelens, S; Assié, K; Autret, D; Avner, S; Barbier, R; Bardiès, M; Bloomfield, PM; Brasse, D; Breton, V; Bruyndonckx, P; Buvat, I; Chatziioannou, AF; Choi, Y; Chung, YH; Comtat, C; Donnarieix, D; Ferrer, L; Glick, SJ; Groiselle, CJ; Guez, D; Honore, PF; Kerhoas-Cavata, S; Kirov, AS; Kohli, V; Koole, M; Krieguer, M; van der Laan, DJ; Lamare, F; Largeron, G; Lartizien, C; Lazaro, D; Maas, MC; Maigne, L; Mayet, F; Melot, F; Merheb, C; Pennacchio, E; Perez, J; Pietrzyk, U; Rannou, FR; Rey, M; Schaart, DR; Schmidtlein, CR; Simon, L; Song, TY; Vieira, JM; Visvikis, D; Van de Walle, R; Wieërs, E; Morel, C				Jan, S; Santin, G; Strul, D; Staelens, S; Assié, K; Autret, D; Avner, S; Barbier, R; Bardiès, M; Bloomfield, PM; Brasse, D; Breton, V; Bruyndonckx, P; Buvat, I; Chatziioannou, AF; Choi, Y; Chung, YH; Comtat, C; Donnarieix, D; Ferrer, L; Glick, SJ; Groiselle, CJ; Guez, D; Honore, PF; Kerhoas-Cavata, S; Kirov, AS; Kohli, V; Koole, M; Krieguer, M; van der Laan, DJ; Lamare, F; Largeron, G; Lartizien, C; Lazaro, D; Maas, MC; Maigne, L; Mayet, F; Melot, F; Merheb, C; Pennacchio, E; Perez, J; Pietrzyk, U; Rannou, FR; Rey, M; Schaart, DR; Schmidtlein, CR; Simon, L; Song, TY; Vieira, JM; Visvikis, D; Van de Walle, R; Wieërs, E; Morel, C			GATE:: a simulation toolkit for PET and SPECT	PHYSICS IN MEDICINE AND BIOLOGY												Monte Carlo simulation is an essential tool in emission tomography that can assist in the design of new medical imaging devices, the optimization of acquisition protocols and the development or assessment of image reconstruction algorithms and correction techniques. GATE, the Geant4 Application for Tomographic Emission, encapsulates the Geant4 libraries to achieve a modular, versatile, scripted simulation toolkit adapted to the field of nuclear medicine. In particular, GATE allows the description of time-dependent phenomena such as source or detector movement, and source decay kinetics. This feature makes it possible to simulate time curves under realistic acquisition conditions and to test dynamic reconstruction algorithms. This paper gives a detailed description of the design and development of GATE by the OpenGATE collaboration, whose continuing objective is to improve, document and validate GATE by simulating commercially available imaging systems for PET and SPECT. Large effort is also invested in the ability and the flexibility to model novel detection systems or systems still under design. A public release of GATE licensed under the GNU Lesser General Public License can be downloaded at http:/www-lphe.epfl.ch/GATE/. Two benchmarks developed for PET and SPECT to test the installation of GATE and to serve as a tutorial for the users are presented. Extensive validation of the GATE simulation platform has been started, comparing simulations and measurements on commercially available acquisition systems. References to those results are listed. The future prospects towards the gridification of GATE and its extension to other domains such as dosimetry are also discussed.					Kirov, Assen/HGA-8103-2022; Maas, Marnix/J-5101-2014; BUVAT, Irene/U-8447-2018; Ferrer, Ludovic/M-2945-2015; Schmidtlein, C. Ross/IAN-6642-2023; Brasse, David/AAU-3671-2020; VISVIKIS, Dimitris/H-4277-2014; Rannou, Fernando/G-5749-2019; Lartizien, Carole/H-4447-2014; Maigne, Lydia/H-3137-2018; Schaart, Dennis/C-7136-2014; MOREL, Christian/C-2184-2018; SIMON, Luc/O-5114-2014; BARDIES, Manuel/L-3136-2014; Pietrzyk, Uwe/H-5786-2013; Staelens, Steven/D-8385-2017	Schmidtlein, Charles/0000-0003-0485-3601; Buvat, Irene/0000-0002-7053-6471; Maigne, Lydia/0000-0002-0414-8462; Schaart, Dennis/0000-0002-3199-5608; Lamare, Frederic/0000-0003-1289-7655; Rannou, Fernando/0000-0002-3244-1893; guez, david/0000-0002-9143-2575; Kirov, Assen/0000-0001-6521-3582; MOREL, Christian/0000-0001-5359-6504; Breton, Vincent/0000-0001-8197-7080; SIMON, Luc/0000-0002-0148-4217; Koole, Michel/0000-0001-5862-640X; BARDIES, Manuel/0000-0002-1766-727X; Avner, Stephane/0000-0001-7413-1327; Pietrzyk, Uwe/0000-0002-2791-8765; Ferrer, Ludovic/0000-0002-5166-1998; Santin, Giovanni/0000-0003-4330-9449; Mayet, Frederic/0000-0001-9995-4792; Staelens, Steven/0000-0003-3376-0519													0031-9155	1361-6560				OCT 7	2004	49	19					4543	4561	PII S0031-9155(04)80763-2	10.1088/0031-9155/49/19/007	http://dx.doi.org/10.1088/0031-9155/49/19/007								15552416					WOS:000224663300007
J	Crawley, DB; Lawrie, LK; Winkelmann, FC; Buhl, WF; Huang, YJ; Pedersen, CO; Strand, RK; Liesen, RJ; Fisher, DE; Witte, MJ; Glazer, J				Crawley, DB; Lawrie, LK; Winkelmann, FC; Buhl, WF; Huang, YJ; Pedersen, CO; Strand, RK; Liesen, RJ; Fisher, DE; Witte, MJ; Glazer, J			EnergyPlus: creating a new-generation building energy simulation program	ENERGY AND BUILDINGS					6th International IBPSA Conference	SEP 13-15, 1999	KYOTO, JAPAN					Many of the popular building energy simulation programs around the world are reaching maturity - some use simulation methods land even code) that originated in the 1960s. For more than two decades, the US government supported development of two hourly building energy simulation programs, BLAST and DOE-2. Designed in the days of mainframe computers, expanding their capabilities further has become difficult, time-consuming, and expensive. At the same time, the 30 years have seen significant advances in analysis and computational methods and power - providing an opportunity for significant improvement in these tools. In 1996, a US federal agency began developing a new building energy simulation tool, EnergyPlus, building on development experience with two existing programs: DOE-2 and BLAST. EnergyPlus includes a number of innovative simulation features - such as variable time steps, user-configurable modular systems that are integrated with a heat and mass balance-based zone simulation - and input and output data structures tailored to facilitate third party module and interface development. Other planned simulation capabilities include multizone airflow, and electric power and solar thermal and photovoltaic simulation. Beta testing of EnergyPlus began in late 1999 and the first release is scheduled for early 2001. (C) 2001 Elsevier Science B.V. All rights reserved.					Crawley, Drury/I-6523-2019														0378-7788					APR	2001	33	4			SI		319	331		10.1016/S0378-7788(00)00114-6	http://dx.doi.org/10.1016/S0378-7788(00)00114-6													WOS:000167272000005
J	Hoydis, J; ten Brink, S; Debbah, M				Hoydis, Jakob; ten Brink, Stephan; Debbah, Merouane			Massive MIMO in the UL/DL of Cellular Networks: How Many Antennas Do We Need?	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS												We consider the uplink (UL) and downlink (DL) of non-cooperative multi-cellular time-division duplexing (TDD) systems, assuming that the number N of antennas per base station (BS) and the number K of user terminals (UTs) per cell are large. Our system model accounts for channel estimation, pilot contamination, and an arbitrary path loss and antenna correlation for each link. We derive approximations of achievable rates with several linear precoders and detectors which are proven to be asymptotically tight, but accurate for realistic system dimensions, as shown by simulations. It is known from previous work assuming uncorrelated channels, that as N -> infinity while K is fixed, the system performance is limited by pilot contamination, the simplest precoders/detectors, i.e., eigenbeamforming (BF) and matched filter (MF), are optimal, and the transmit power can be made arbitrarily small. We analyze to which extent these conclusions hold in the more realistic setting where N is not extremely large compared to K. In particular, we derive how many antennas per UT are needed to achieve eta% of the ultimate performance limit with infinitely many antennas and how many more antennas are needed with MF and BF to achieve the performance of minimum mean-square error (MMSE) detection and regularized zero-forcing (RZF), respectively.					Debbah, Merouane/B-6261-2011; Hoydis, Jakob/AAG-6646-2020	Debbah, Merouane/0000-0001-8941-8080													0733-8716	1558-0008				FEB	2013	31	2					160	171		10.1109/JSAC.2013.130205	http://dx.doi.org/10.1109/JSAC.2013.130205													WOS:000313966200005
J	Winker, DM; Vaughan, MA; Omar, A; Hu, YX; Powell, KA; Liu, ZY; Hunt, WH; Young, SA				Winker, David M.; Vaughan, Mark A.; Omar, Ali; Hu, Yongxiang; Powell, Kathleen A.; Liu, Zhaoyan; Hunt, William H.; Young, Stuart A.			Overview of the CALIPSO Mission and CALIOP Data Processing Algorithms	JOURNAL OF ATMOSPHERIC AND OCEANIC TECHNOLOGY												The Cloud-Aerosol Lidar with Orthogonal Polarization (CALIOP) is a two-wavelength polarization lidar performs global profiling of aerosols and clouds in the troposphere and lower stratosphere. CALIOP is the primary instrument on the Cloud-Aerosol Lidar and Infrared Pathfinder Satellite Observations (CALIPSO) satellite, which has flown in formation with the NASA A-train constellation of satellites since May 2006. The global, multiyear dataset obtained from CALIOP provides a new view of the earth's atmosphere and will lead to an improved understanding of the role of aerosols and clouds in the climate system. A suite of algorithms has been developed to identify aerosol and cloud layers and to retrieve a variety of optical and microphysical properties. CALIOP represents a significant advance over previous space lidars, and the algorithms that have been developed have many innovative aspects to take advantage of its capabilities. This paper provides a brief overview of the CALIPSO mission, the CALIOP instrument and data products, and an overview of the algorithms used to produce these data products.					Liu, Zhaoyan/B-1783-2010; Vaughan, Mark/IVH-3495-2023; Omar, Ali/AAE-3845-2019; Hu, Yongxiang/K-4426-2012; Young, Stuart/A-8641-2011	Liu, Zhaoyan/0000-0003-4996-5738; Hu, Yongxiang/0000-0001-8526-108X; Young, Stuart/0000-0001-6434-9816													0739-0572	1520-0426				NOV	2009	26	11					2310	2323		10.1175/2009JTECHA1281.1	http://dx.doi.org/10.1175/2009JTECHA1281.1													WOS:000271904500003
J	Kramer, G; Gastpar, M; Gupta, P				Kramer, G; Gastpar, M; Gupta, P			Cooperative strategies and capacity theorems for relay networks	IEEE TRANSACTIONS ON INFORMATION THEORY					IEEE International Zurich Seminar on Communications	FEB 18-20, 2004	ETH, Zurich, SWITZERLAND	IEEE Switzerland Chapter Digital Commun, ASCOM, Nokia, IBM, Elektrobit, Philips, Swisscom	ETH			Coding strategies that exploit node cooperation are developed for relay networks. Two basic schemes are studied: the relays decode-and-forward the source message to the destination, or they compress-and-forward their channel outputs to the destination. The decode-and-forward scheme is a variant of multihopping, but in addition to having the relays successively decode the message, the transmitters cooperate and each receiver uses several or all of its past channel output blocks to decode. For the compress-and-forward scheme, the relays take advantage of the statistical dependence between their channel outputs and the destination's channel output. The strategies are applied to wireless channels, and it is shown that decode-and-forward achieves the ergodic capacity with phase fading if phase information is available only locally, and if the relays are near the source node. The ergodic capacity coincides with the rate of a distributed antenna array with full cooperation even though the transmitting antennas are not colocated. The capacity results generalize broadly, including to multiantenna transmission with Rayleigh fading, single-bounce fading, certain quasi-static fading problems, cases where partial channel knowledge is available at the transmitters, and cases where local user cooperation is permitted. The results further extend to multisource and multidestination networks such as multiaccess and broadcast relay channels.					Gastpar, Michael/A-2088-2011; Kramer, Gerhard/M-4270-2014	Kramer, Gerhard/0000-0002-3904-9181; Gastpar, Michael/0000-0002-5499-5336													0018-9448	1557-9654				SEP	2005	51	9					3037	3063		10.1109/TIT.2005.853304	http://dx.doi.org/10.1109/TIT.2005.853304													WOS:000231392900003
J	Shiu, DS; Foschini, GJ; Gans, MJ; Kahn, JM				Shiu, DS; Foschini, GJ; Gans, MJ; Kahn, JM			Fading correlation and its effect on the capacity of multielement antenna systems	IEEE TRANSACTIONS ON COMMUNICATIONS												We investigate the effects of fading correlations in multielement antenna (MEA) communication systems, Pioneering studies show-ed that if the fades connecting pairs of transmit and receive antenna elements are independently, identically distributed, MEA's offer a large increase in capacity compared to single-antenna systems. An MEA system can be described in terms of spatial eigenmodes, which are single-input single-output subchannels. The channel capacity of an MEA is the sum of capacities of these subchannels. We will show that the fading correlation affects the MEA capacity by modifying the distributions of the gains of these subchannels. The fading correlation depends on the physical parameters of MEA and the scatterer characteristics. in this paper, to characterize the fading correlation, we employ an abstract model, which is appropriate for modeling narrow-band Rayleigh fading in filed wireless systems.																			0090-6778	1558-0857				MAR	2000	48	3					502	513		10.1109/26.837052	http://dx.doi.org/10.1109/26.837052													WOS:000086290100019
J	Boutell, MR; Luo, JB; Shen, XP; Brown, CM				Boutell, MR; Luo, JB; Shen, XP; Brown, CM			Learning multi-label scene classification	PATTERN RECOGNITION												In classic pattern recognition problems, classes are mutually exclusive by definition. Classification errors occur when the classes overlap in the feature space. We examine a different situation, occurring when the classes are, by definition, not mutually exclusive. Such problems arise in semantic scene and document classification and in medical diagnosis. We present a framework to handle such problems and apply it to the problem of semantic scene classification, where a natural scene may contain multiple objects such that the scene can be described by multiple class labels (e.g., a field scene with a mountain in the background). Such a problem poses challenges to the classic pattern recognition paradigm and demands a different treatment. We discuss approaches for training and testing in this scenario and introduce new metrics for evaluating individual examples, class recall and precision, and overall accuracy. Experiments show that our methods are suitable for scene classification; furthermore, our work appears to generalize to other classification problems of the same nature. (C) 2004 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.					Luo, Jiebo/AAI-7549-2020	Shen, Xipeng/0000-0003-3599-8010; Luo, Jiebo/0000-0002-4516-9729													0031-3203	1873-5142				SEP	2004	37	9					1757	1771		10.1016/j.patcog.2004.03.009	http://dx.doi.org/10.1016/j.patcog.2004.03.009													WOS:000222701700001
J	Perrig, A; Szewczyk, R; Tygar, JD; Wen, V; Culler, DE				Perrig, A; Szewczyk, R; Tygar, JD; Wen, V; Culler, DE			SPINS: Security protocols for sensor networks	WIRELESS NETWORKS												Wireless sensor networks will be widely deployed in the near future. While much research has focused on making these networks feasible and useful, security has received little attention. We present a suite of security protocols optimized for sensor networks: SPINS. SPINS has two secure building blocks: SNEP and muTESLA. SNEP includes: data confidentiality, two-party data authentication, and evidence of data freshness. muTESLA provides authenticated broadcast for severely resource-constrained environments. We implemented the above protocols, and show that they are practical even on minimal hardware: the performance of the protocol suite easily matches the data rate of our network. Additionally, we demonstrate that the suite can be used for building higher level protocols.						Perrig, Adrian/0000-0002-5280-5412													1022-0038	1572-8196				SEP	2002	8	5					521	534		10.1023/A:1016598314198	http://dx.doi.org/10.1023/A:1016598314198													WOS:000177140900009
J	Donoho, DL; Elad, M; Temlyakov, VN				Donoho, DL; Elad, M; Temlyakov, VN			Stable recovery of sparse overcomplete representations in the presence of noise	IEEE TRANSACTIONS ON INFORMATION THEORY												Overcomplete representations are attracting interest in signal processing theory, particularly due to their potential to generate sparse representations of signals. However, in general, the problem of finding sparse representations must be unstable in the presence of noise. This paper establishes the possibility of stable recovery under a combination of sufficient sparsity and favorable structure of the overcomplete system. Considering an ideal underlying signal that has a sufficiently sparse representation, it is assumed that only a noisy version of it can be observed. Assuming further that the overcomplete system is incoherent, it is shown that the optimally sparse approximation to the noisy data differs from the optimally sparse decomposition of the ideal noiseless signal by at most a constant multiple of the noise level. As this optimal-sparsity method requires heavy (combinatorial) computational effort, approximation algorithms are considered. It is shown that similar stability is also available using the basis and the matching pursuit algorithms. Furthermore, it is shown that these methods result in sparse approximation of the noisy data that contains only terms also appearing in the unique sparsest representation of the ideal noiseless sparse signal.					, Miki/AAH-4640-2019; Temlyakov, Vladimir/I-2872-2017														0018-9448	1557-9654				JAN	2006	52	1					6	18		10.1109/TIT.2005.860430	http://dx.doi.org/10.1109/TIT.2005.860430													WOS:000234412500001
J	Abbas, N; Zhang, Y; Taherkordi, A; Skeie, T				Abbas, Nasir; Zhang, Yan; Taherkordi, Amir; Skeie, Tor			Mobile Edge Computing: A Survey	IEEE INTERNET OF THINGS JOURNAL												Mobile edge computing (MEC) is an emergent architecture where cloud computing services are extended to the edge of networks leveraging mobile base stations. As a promising edge technology, it can be applied to mobile, wireless, and wire-line scenarios, using software and hardware platforms, located at the network edge in the vicinity of end-users. MEC provides seamless integration of multiple application service providers and vendors toward mobile subscribers, enterprises, and other vertical segments. It is an important component in the 5G architecture which supports variety of innovative applications and services where ultralow latency is required. This paper is aimed to present a comprehensive survey of relevant research and technological developments in the area of MEC. It provides the definition of MEC, its advantages, architectures, and application areas; where we in particular highlight related research and future directions. Finally, security and privacy issues and related existing solutions are also discussed.					Zhang, Yan/AFK-8566-2022	Zhang, Yan/0000-0002-8561-5092													2327-4662					FEB	2018	5	1					450	465		10.1109/JIOT.2017.2750180	http://dx.doi.org/10.1109/JIOT.2017.2750180													WOS:000425170000035
J	Miehe, C; Welschinger, F; Hofacker, M				Miehe, C.; Welschinger, F.; Hofacker, M.			Thermodynamically consistent phase-field models of fracture: Variational principles and multi-field FE implementations	INTERNATIONAL JOURNAL FOR NUMERICAL METHODS IN ENGINEERING												The computational modeling of failure mechanisms in solids due to fracture based on sharp crack discontinuities suffers in situations with complex crack topologies. This can be overcome by a diffusive crack modeling based on the introduction of a crack phase-field. In this paper, we outline a thermodynamically consistent framework for phase-field models of crack propagation in elastic solids, develop incremental variational principles and consider their numerical implementations by multi-field finite element methods. We start our investigation with an intuitive and descriptive derivation of a regularized crack surface functional that Gamma-converges for vanishing length-scale parameter to a sharp crack topology functional. This functional provides the basis for the definition of suitable convex dissipation functions that govern the evolution of the crack phase-field. Here, we propose alternative rate-independent and viscous over-force models that ensure the local growth of the phase-field. Next, we define an energy storage function whose positive tensile part degrades with increasing phase-field. With these constitutive functionals at hand, we derive the coupled balances of quasi-static stress equilibrium and gradient-type phase-field evolution in the solid from the argument of virtual power. Here, we consider a canonical two-field setting for rate-independent response and a time-regularized three-field formulation with viscous over-force response. It is then shown that these balances follow as the Euler equations of incremental variational principles that govern the multi-field problems. These principles make the proposed formulation extremely compact and provide a perfect base for the finite element implementation, including features such as the symmetry of the monolithic tangent matrices. We demonstrate the performance of the proposed phase-field formulations of fracture by means of representative numerical examples. Copyright (C) 2010 John Wiley & Sons, Ltd.						Welschinger, Fabian/0000-0003-0238-6237													0029-5981	1097-0207				SEP 3	2010	83	10					1273	1311		10.1002/nme.2861	http://dx.doi.org/10.1002/nme.2861													WOS:000282160900001
J	Dry, ME				Dry, ME			The Fischer-Tropsch process: 1950-2000	CATALYSIS TODAY					Conference on Fischer-Tropsch on the Eve of XXI Century	NOV, 2000	SOUTH AFRICA	Catalysis Soc South Africa (CATSA)				The decision to build a Fischer-Tropsch (FT) plant is still fraught with risk because it has to be based on the perceived future price and availability of petroleum crude oil and on local politics. The most expensive section of an FT complex is the production of purified syngas and so its composition should match the overall usage ratio of the FT reactions, which in turn depends on the product selectivity. The kinetics, reactor requirements, control of selectivity and the life of cobalt and iron catalysts are discussed and compared. Control of the FT conditions coupled with appropriate downstream processes results in high yields of gasoline, excellent quality diesel fuel or high value linear alpha-olefins. The history of the various FT options and of the improvements in FT reactor technologies over the last 50 years is reviewed. It appears that "new" technologies are re-discovered in cycles of 15-30 years and it often takes the same time for the implementation of new concepts. (C) 2002 EIsevier Science B.V. All rights reserved.																			0920-5861					JAN 15	2002	71	3-4					227	241	PII S0920-5861(01)00453-9	10.1016/S0920-5861(01)00453-9	http://dx.doi.org/10.1016/S0920-5861(01)00453-9													WOS:000174156700002
J	Zeng, LZ; Benatallah, B; Ngu, AHH; Dumas, M; Kalagnanam, J; Chang, H				Zeng, LZ; Benatallah, B; Ngu, AHH; Dumas, M; Kalagnanam, J; Chang, H			QoS-aware middleware for Web Services Composition	IEEE TRANSACTIONS ON SOFTWARE ENGINEERING												The paradigmatic shift from a Web of manual interactions to a Web of programmatic interactions driven by Web services is creating unprecedented opportunities for the formation of online Business-to-Business (B2B) collaborations. In particular, the creation of value-added services by composition of existing ones is gaining a significant momentum. Since many available Web services provide overlapping or identical functionality, albeit with different Quality of Service (QoS), a choice needs to be made to determine which services are to participate in a given composite service. This paper presents a middleware platform which addresses the issue of selecting Web services for the purpose of their composition in a way that maximizes user satisfaction expressed as utility functions over QoS attributes, while satisfying the constraints set by the user and by the structure of the composite service. Two selection approaches are described and compared: one based on local (task-level) selection of services and the other based on global allocation of tasks to services using integer programming.					kalagnanam, jayant/AAD-6069-2019; Dumas, Marlon/H-2757-2015	Dumas, Marlon/0000-0002-9247-7476													0098-5589	1939-3520				MAY	2004	30	5					311	327		10.1109/TSE.2004.11	http://dx.doi.org/10.1109/TSE.2004.11													WOS:000220904000003
J	ten Brink, S				ten Brink, S			Convergence behavior of iteratively decoded parallel concatenated codes	IEEE TRANSACTIONS ON COMMUNICATIONS					3rd ITG Conference on Source and Channel Coding	JAN, 2000	MUNICH, GERMANY	German Informat Techn Gesell				Mutual information transfer characteristics of soft in/soft out decoders are proposed as a tool to better understand the convergence behavior of iterative decoding schemes. The exchange of extrinsic information is visualized as a decoding trajectory in the extrinsic information transfer chart (EXIT chart). This allows the prediction of turbo cliff position and bit error rate after an arbitrary number of iterations. The influence of code memory, code polynomials as well as different constituent codes on the convergence behavior is studied for parallel concatenated codes. A code search based on the EXIT chart technique has been performed yielding new recursive systematic convolutional constituent codes exhibiting turbo cliffs at lower signal-to-noise ratios than attainable by previously known constituent codes.																			0090-6778	1558-0857				OCT	2001	49	10					1727	1737		10.1109/26.957394	http://dx.doi.org/10.1109/26.957394													WOS:000171610100008
J	Izhikevich, EM				Izhikevich, EM			Which model to use for cortical spiking neurons?	IEEE TRANSACTIONS ON NEURAL NETWORKS												We discuss the biological plausibility and computational efficiency of some of the most useful models of spiking and bursting neurons. We compare their applicability to large-scale simulations of cortical neural networks.																			1045-9227					SEP	2004	15	5					1063	1070		10.1109/TNN.2004.832719	http://dx.doi.org/10.1109/TNN.2004.832719								15484883					WOS:000223798400013
J	Blaabjerg, F; Chen, Z; Kjaer, SB				Blaabjerg, F; Chen, Z; Kjaer, SB			Power electronics as efficient interface in dispersed power generation systems	IEEE TRANSACTIONS ON POWER ELECTRONICS												The global electrical energy consumption is rising and there is a steady increase of the demand on the power capacity, efficient production, distribution and utilization of energy. The traditional power systems are changing globally, a large number of dispersed generation (DG) units, including both renewable and nonrenewable energy sources such as wind turbines, photovoltaic (PV) generators, fuel cells, small hydro, wave generators, and gas/steam powered combined heat and power stations, are being integrated into power systems at distribution level. Power electronic, the technology of efficiently processing electric power, plays an essential part in the integration of the dispersed generation units for good efficiency and high performance of the power systems. This paper reviews the applications of power electronics in the integration of DG units, in particularly, wind power, fuel cells and PV generators.					Chen, Zhe/KMA-1659-2024; Blaabjerg, Frede/A-5008-2008	Blaabjerg, Frede/0000-0001-8311-7412; Chen, Zhe/0000-0002-2919-4481													0885-8993	1941-0107				SEP	2004	19	5					1184	1194		10.1109/TPEL.2004.833453	http://dx.doi.org/10.1109/TPEL.2004.833453													WOS:000223723900006
J	Krames, MR; Shchekin, OB; Mueller-Mach, R; Mueller, GO; Zhou, L; Harbers, G; Craford, MG				Krames, Michael R.; Shchekin, Oleg B.; Mueller-Mach, Regina; Mueller, Gerd O.; Zhou, Ling; Harbers, Gerard; Craford, M. George			Status and future of high-power light-emitting diodes for solid-state lighting	JOURNAL OF DISPLAY TECHNOLOGY												Status and future outlook of III-V compound semiconductor visible-spectrum light-emitting diodes (LEDs) are presented. Light extraction techniques are reviewed and extraction efficiencies are quantified in the 60%+ (AlGaInP) and similar to 80% (InGaN) regimes for state-of-the-art devices. The phosphor-based white LED concept is reviewed and recent performance discussed, showing that high-power white LEDs now approach the 100-lm/W regime. Devices employing multiple phosphors for "warm" white color temperatures (similar to 3000-4000 K) and high color rendering (CRI > 80), which provide properties critical for many illumination applications, are discussed. Recent developments in chip design, packaging, and high current performance lead to very high luminance devices (similar to 50 Mcd/m(2) white at 1 A forward current in 1 x 1 mm(2) chip) that are suitable for application to automotive forward lighting. A prognosis for future LED performance levels is considered given further improvements in internal quantum efficiency, which to date lag achievements in light extraction efficiency for InGaN LEDs.					wang, yan/JBJ-7462-2023	Krames, Michael/0000-0001-8545-851X													1551-319X	1558-9323				JUN	2007	3	2					160	175		10.1109/JDT.2007.895339	http://dx.doi.org/10.1109/JDT.2007.895339													WOS:000259064300010
J	Dai, W; Milenkovic, O				Dai, Wei; Milenkovic, Olgica			Subspace Pursuit for Compressive Sensing Signal Reconstruction	IEEE TRANSACTIONS ON INFORMATION THEORY												We propose a new method for reconstruction of sparse signals with and without noisy perturbations, termed the subspace pursuit algorithm. The algorithm has two important characteristics: low computational complexity, comparable to that of orthogonal matching pursuit techniques when applied to very sparse signals, and reconstruction accuracy of the same order as that of linear programming (LP) optimization methods. The presented analysis shows that in the noiseless setting, the proposed algorithm can exactly reconstruct arbitrary sparse signals provided that the sensing matrix satisfies the restricted isometry property with a constant parameter. In the noisy setting and in the case that the signal is not exactly sparse, it can be shown that the mean-squared error of the reconstruction is upper-bounded by constant multiples of the measurement and signal perturbation energies.																			0018-9448	1557-9654				MAY	2009	55	5					2230	2249		10.1109/TIT.2009.2016006	http://dx.doi.org/10.1109/TIT.2009.2016006													WOS:000265713000022
J	Kannan, N; Sundaram, MM				Kannan, N; Sundaram, MM			Kinetics and mechanism of removal of methylene blue by adsorption on various carbons - a comparative study	DYES AND PIGMENTS												The kinetics and mechanism of methylene blue adsorption on commercial activated carbon (CAC) and indigenously prepared activated carbons from bamboo dust, coconut shell, groundnut shell, rice husk, and straw, have been studied. The effects of various experimental parameters have been investigated using a batch adsorption technique to obtain information on treating effluents from the dye industry. The extent of dye removal increased with decrease in the initial concentration of the dye and particle size of the adsorbent and also increased with increase in contact time, amount of adsorbent used and the initial pH of the solution. Adsorption data were modeled using the Freundlich and Langmuir adsorption isotherms and first order kinetic equations. The kinetics of adsorption were found to be first order with regard to intra-particle diffusion rate. The adsorption capacities of indigenous activated carbons have been compared with that of the commercial activated carbon. The results indicate that such carbons could be employed as low cost alternatives to commercial activated carbon in wastewater treatment for the removal of colour and dyes. (C) 2001 Published by Elsevier Science Ltd. All rights reserved.					Mariappan, Meenakshisundaram/AAI-8846-2020														0143-7208					OCT	2001	51	1					25	40		10.1016/S0143-7208(01)00056-0	http://dx.doi.org/10.1016/S0143-7208(01)00056-0													WOS:000172113400004
J	Hong, YG; Hu, JP; Gao, LX				Hong, Yiguang; Hu, Jiangping; Gao, Linxin			Tracking control for multi-agent consensus with an active leader and variable topology	AUTOMATICA												In this paper, we consider a multi-agent consensus problem with an active leader and variable interconnection topology. The state of the considered leader not only keeps changing but also may not be measured. To track such a leader, a neighbor-based local controller together with a neighbor-based state-estimation rule is given for each autonomous agent. Then we prove that, with the proposed control scheme, each agent can follow the leader if the (acceleration) input of the active leader is known, and the tracking error is estimated if the input of the leader is unknown. (c) 2006 Elsevier Ltd. All rights reserved.					Li, Xiaomin/A-4674-2015; Hu, Jiangping/G-6897-2011	Gao, Lixin/0000-0002-6691-7992; Hu, Jiangping/0000-0002-7559-8604													0005-1098	1873-2836				JUL	2006	42	7					1177	1182		10.1016/j.automatica.2006.02.013	http://dx.doi.org/10.1016/j.automatica.2006.02.013													WOS:000238829700010
J	Güngör, VC; Sahin, D; Kocak, T; Ergüt, S; Buccella, C; Cecati, C; Hancke, GP				Gungor, Vehbi C.; Sahin, Dilan; Kocak, Taskin; Ergut, Salih; Buccella, Concettina; Cecati, Carlo; Hancke, Gerhard P.			Smart Grid Technologies: Communication Technologies and Standards	IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS												For 100 years, there has been no change in the basic structure of the electrical power grid. Experiences have shown that the hierarchical, centrally controlled grid of the 20th Century is ill-suited to the needs of the 21st Century. To address the challenges of the existing power grid, the new concept of smart grid has emerged. The smart grid can be considered as a modern electric power grid infrastructure for enhanced efficiency and reliability through automated control, high-power converters, modern communications infrastructure, sensing and metering technologies, and modern energy management techniques based on the optimization of demand, energy and network availability, and so on. While current power systems are based on a solid information and communication infrastructure, the new smart grid needs a different and much more complex one, as its dimension is much larger. This paper addresses critical issues on smart grid technologies primarily in terms of information and communication technology (ICT) issues and opportunities. The main objective of this paper is to provide a contemporary look at the current state of the art in smart grid communications as well as to discuss the still-open research issues in this field. It is expected that this paper will provide a better understanding of the technologies, potential advantages and research challenges of the smart grid and provoke interest among the research community to further explore this promising research area.					Buccella, Concettina/ABA-5776-2020; Hancke, Gerhard/AAB-7256-2020; Cecati, Carlo/E-1535-2018	buccella, concettina/0000-0002-2221-403X; Hancke, Gerhard/0000-0002-4026-687X; Cecati, Carlo/0000-0001-9228-7886; Ergut, Salih/0000-0003-3820-4087													1551-3203	1941-0050				NOV	2011	7	4					529	539		10.1109/TII.2011.2166794	http://dx.doi.org/10.1109/TII.2011.2166794													WOS:000296728600001
J	Girshick, R; Donahue, J; Darrell, T; Malik, J				Girshick, Ross; Donahue, Jeff; Darrell, Trevor; Malik, Jitendra			Region-Based Convolutional Networks for Accurate Object Detection and Segmentation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Object detection performance, as measured on the canonical PASCAL VOC Challenge datasets, plateaued in the final years of the competition. The best-performing methods were complex ensemble systems that typically combined multiple low-level image features with high-level context. In this paper, we propose a simple and scalable detection algorithm that improves mean average precision (mAP) by more than 50 percent relative to the previous best result on VOC 2012-achieving a mAP of 62.4 percent. Our approach combines two ideas: (1) one can apply high-capacity convolutional networks (CNNs) to bottom-up region proposals in order to localize and segment objects and (2) when labeled training data are scarce, supervised pre-training for an auxiliary task, followed by domain-specific fine-tuning, boosts performance significantly. Since we combine region proposals with CNNs, we call the resulting model an R-CNN or Region-based Convolutional Network. Source code for the complete system is available at http://www.cs.berkeley.edu/similar to rbg/rcnn.																			0162-8828	1939-3539				JAN	2016	38	1					142	158		10.1109/TPAMI.2015.2437384	http://dx.doi.org/10.1109/TPAMI.2015.2437384								26656583					WOS:000366669200011
J	Beven, K				Beven, K			A manifesto for the equifinality thesis	JOURNAL OF HYDROLOGY					3rd MOPEX Workshop	JUL, 2003	Sapporo, JAPAN	MOPEX				This essay discusses some of the issues involved in the identification and predictions of hydrological models given some calibration data. The reasons for the incompleteness of traditional calibration methods are discussed. The argument is made that the potential for multiple acceptable models as representations of hydrological and other environmental systems (the equifinality thesis) should be given more serious consideration than hitherto. It proposes some techniques for an extended GLUE methodology to make it more rigorous and outlines some of the research issues still to be resolved. (c) 2005 Elsevier Ltd All rights reserved.					Beven, Keith/F-8707-2011														0022-1694	1879-2707				MAR 30	2006	320	1-2			SI		18	36		10.1016/j.jhydrol.2005.07.007	http://dx.doi.org/10.1016/j.jhydrol.2005.07.007													WOS:000236448000003
J	Mahler, RPS				Mahler, RPS			Multitarget Bayes filtering via first-order multitarget moments	IEEE TRANSACTIONS ON AEROSPACE AND ELECTRONIC SYSTEMS												The theoretically optimal approach to multisensor-multitarget detection, tracking, and identification is a suitable generalization of the recursive Bayes nonlinear filter. Even in single-target problems, this optimal filter is so computationally challenging that it must usually be approximated. Consequently, multitarget Bayes filtering will never be of practical interest without the development of drastic but principled approximation strategies. In single-target problems, the computationally fastest approximate filtering approach is the constant-gain Kalman filter. This filter propagates a first-order statistical moment-the posterior expectation-in the place of the posterior distribution. The purpose of this paper is to propose an analogous strategy for multitarget systems: propagation of a first-order statistical moment of the multitarget posterior. This moment, the probability hypothesis density (PHD), is the function whose integral in any region of state space is the expected number of targets in that region. We derive recursive Bayes filter equations for the PHD that account for multiple sensors, nonconstant probability of detection, Poisson false alarms, and appearance, spawning, and disappearance of targets. We also show that the PHD is a best-fit approximation of the multitarget posterior in an information-theoretic sense.																			0018-9251	1557-9603				OCT	2003	39	4					1152	1178		10.1109/TAES.2003.1261119	http://dx.doi.org/10.1109/TAES.2003.1261119													WOS:000188511200004
J	Vesanto, J; Alhoniemi, E				Vesanto, J; Alhoniemi, E			Clustering of the self-organizing map	IEEE TRANSACTIONS ON NEURAL NETWORKS												The self-organizing map (SOM) is an excellent tool in exploratory phase of data mining. It projects input space on prototypes of a low-dimensional regular grid that can be effectively utilized to visualize and explore properties of the data. When the number of SOM units is large, to facilitate quantitative analysis of the map and the data, similar units need to be grouped, i.e., clustered. In this paper, different approaches to clustering of the SOM are considered, In particular, the use of hierarchical agglomerative clustering and partitive clustering using Ic-means are investigated. The two-stage procedure-first using SOM to produce the prototypes that are then clustered in the second stage-is found to perform well when compared with direct clustering of the data and to reduce the computation time.																			1045-9227	1941-0093				MAY	2000	11	3					586	600		10.1109/72.846731	http://dx.doi.org/10.1109/72.846731								18249787					WOS:000087732100005
J	Folke, C; Carpenter, S; Elmqvist, T; Gunderson, L; Holling, CS; Walker, B				Folke, C; Carpenter, S; Elmqvist, T; Gunderson, L; Holling, CS; Walker, B			Resilience and sustainable development: Building adaptive capacity in a world of transformations	AMBIO												Emerging recognition of two fundamental errors underpinning past polices for natural resource issues heralds awareness of the need for a worldwide fundamental change in thinking and in practice of environmental management. The first error has been an implicit assumption that ecosystem responses to human use are linear predictable and controllable. The second has been an assumption that human and natural systems can be treated independently. However, evidence that has been accumulating in diverse regions all over the world suggests that natural and social systems behave in nonlinear ways, exhibit marked thresholds in their dynamics, and that social-ecological systems act as strongly coupled, complex and evolving integrated systems. This article is a summary of a report prepared on behalf of the Environmental Advisory Council to the Swedish Government, as input to the process of the World Summit on Sustainable Development (WSSD) in Johannesburg, South Africa in 26 August 4 September 2002. We use the concept of resilience-the capacity to buffer change, learn and develop-as a framework for understanding how to sustain and enhance adaptive capacity in a complex world of rapid transformations. Two useful tools for resilience-building in social-ecological systems are structured scenarios and active adaptive management. These tools require and facilitate a social context with flexible and open institutions and multi-level governance systems that allow for learning and increase adaptive capacity without foreclosing future development options.					Folke, Carl/Z-1545-2019; Walker, Brian/F-2386-2011; Carpenter, Stephen/AAQ-6404-2020; Elmqvist, Thomas/AAY-6344-2021	Folke, Carl/0000-0002-4050-3281; Elmqvist, Thomas/0000-0002-4617-6197													0044-7447	1654-7209				AUG	2002	31	5					437	440		10.1639/0044-7447(2002)031[0437:RASDBA]2.0.CO;2	http://dx.doi.org/10.1639/0044-7447(2002)031[0437:RASDBA]2.0.CO;2								12374053					WOS:000178085900008
J	Rodríguez, J; Bernet, S; Wu, B; Pontt, JO; Kouro, S				Rodriguez, Jose; Bernet, Steffen; Wu, Bin; Pontt, Jorge O.; Kouro, Samir			Multilevel voltage-source-converter topologies for industrial medium-voltage drives	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS												This paper presents a technology review of voltage-source-converter topologies for industrial medium-voltage drives. In this highly active area, different converter topologies and circuits have found their application in the market. This paper covers the high-power voltage-source inverter and the most used multilevel-inverter topologies, including the neutral-point-clamped, cascaded, H-bridge, and flying-capacitor converters. This paper presents the operating principle of each topology and a review of the most relevant modulation methods, focused mainly on those used by industry. In addition, the latest advances and future trends of the technology are discussed. It is concluded that the topology and modulation-method selection are closely related to each particular application, leaving a space on the market for all the different solutions, depending on their unique features and limitations like power or voltage level, dynamic performance, reliability, costs, and other technical specifications.					Bernet, Steffen/B-4609-2010; Kouro, Samir/E-9167-2012; Rodriguez, Jose/A-2534-2013	Kouro, Samir/0000-0002-1690-4624; Rodriguez, Jose/0000-0002-1410-4121													0278-0046	1557-9948				DEC	2007	54	6					2930	2945		10.1109/TIE.2007.907044	http://dx.doi.org/10.1109/TIE.2007.907044													WOS:000251457600002
J	Holloway, CL; Kuester, EF; Gordon, JA; O'Hara, J; Booth, J; Smith, DR				Holloway, Christopher L.; Kuester, Edward F.; Gordon, Joshua A.; O'Hara, John; Booth, Jim; Smith, David R.			An Overview of the Theory and Applications of Metasurfaces: The Two-Dimensional Equivalents of Metamaterials	IEEE ANTENNAS AND PROPAGATION MAGAZINE												Metamaterials are typically engineered by arranging a set of small scatterers or apertures in a regular array throughout a region of space, thus obtaining some desirable bulk electromagnetic behavior. The desired property is often one that is not normally found naturally (negative refractive index, near-zero index, etc.). Over the past ten years, metamaterials have moved from being simply a theoretical concept to a field with developed and marketed applications. Three-dimensional metamaterials can be extended by arranging electrically small scatterers or holes into a two-dimensional pattern at a surface or interface. This surface version of a metamaterial has been given the name metasurface (the term metafilm has also been employed for certain structures). For many applications, metasurfaces can be used in place of metamaterials. Metasurfaces have the advantage of taking up less physical space than do full three-dimensional metamaterial structures; consequently, metasurfaces offer the possibility of less-lossy structures. In this overview paper, we discuss the theoretical basis by which metasurfaces should be characterized, and discuss their various applications. We will see how metasurfaces are distinguished from conventional frequency-selective surfaces. Metasurfaces have a wide range of potential applications in electromagnetics (ranging from low microwave to optical frequencies), including: (1) controllable "smart" surfaces, (2) miniaturized cavity resonators, (3) novel wave-guiding structures, (4) angular-independent surfaces, (5) absorbers, (6) biomedical devices, (7) terahertz switches, and (8) fluid-tunable frequency-agile materials, to name only a few. In this review, we will see that the development in recent years of such materials and/or surfaces is bringing us closer to realizing the exciting speculations made over one hundred years ago by the work of Lamb, Schuster, and Pocklington, and later by Mandel'shtam and Veselago.					Gordon, Joshua/E-6778-2012; Smith, David/E-4710-2012; O'Hara, John/A-5067-2018	O'Hara, John/0000-0001-8193-1867													1045-9243	1558-4143				APR	2012	54	2					10	35		10.1109/MAP.2012.6230714	http://dx.doi.org/10.1109/MAP.2012.6230714													WOS:000309409800002
J	Bergmann, G; Deuretzbacher, G; Heller, M; Graichen, F; Rohlmann, A; Strauss, J; Duda, GN				Bergmann, G; Deuretzbacher, G; Heller, M; Graichen, F; Rohlmann, A; Strauss, J; Duda, GN			Hip contact forces and gait patterns from routine activities	JOURNAL OF BIOMECHANICS												In vivo loads acting at the hip joint have so F;rr only been measured in few patients and without detailed documentation of gait data. Such information is required to test and improve wear, strength and fixation stability of hip implants. Measurements of hip contact forces with instrumented implants and synchronous analysts of gait patterns and ground reaction forces were performed in four patients during the most frequent activities of daily living. From the individual data sets an average was calculated. The paper focuses on the loading of the femoral implant component but complete data are additionally stored on an associated compact disc. It contains complete gait and hip contact force data as well as calculated muscle activities during walking and stair climbing and the frequencies of daily activities observed in hip patients. The mechanical loading and function of the hip joint and proximal femur is thereby completely documented. The average patient loaded his hip joint with 238% BW (percent of body weight) when walking at about 4 km/h and with slightly less when standing on one leg. This is below the levels previously reported for two other patients (Bergmann et al., Clinical Biomechanics 26 (1993) 969-990). When climbing upstairs the joint contact force is 251% BW which is less than 260% BW when going downstairs. Inwards torsion of the implant is probably critical For the stem fixation. On average it is 23% larger when going upstairs than during normal level walking. The inter- and intra-individual variations during stair climbing are large and the highest torque values are 83% larger than during normal walking. Because the hip joint loading: during all other common activities of most hip patients are comparably small (except during stumbling), implants should mainly; be tested with loading conditions that mimic walking and stair climbing. (C) 2001 Elsevier Science Ltd. All rights reserved.					Rohlmann, Antonius/E-4778-2011; Heller, Markus/F-8437-2010; Duda, Georg/H-2085-2016	Rohlmann, Antonius/0000-0002-0083-2793; Heller, Markus/0000-0002-7879-1135; Duda, Georg/0000-0001-7605-3908													0021-9290					JUL	2001	34	7					859	871		10.1016/S0021-9290(01)00040-9	http://dx.doi.org/10.1016/S0021-9290(01)00040-9								11410170					WOS:000169800500004
J	Bechlioulis, CP; Rovithakis, GA				Bechlioulis, Charalampos P.; Rovithakis, George A.			Robust Adaptive Control of Feedback Linearizable MIMO Nonlinear Systems With Prescribed Performance	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												A novel robust adaptive controller for multi-input multi-output (MIMO) feedback linearizable nonlinear systems possessing unknown nonlinearities, capable of guaranteeing a prescribed performance, is developed in this paper. By prescribed performance we mean that the tracking error should converge to an arbitrarily small residual set, with convergence rate no less than a prespecified value, exhibiting a maximum overshoot less than a sufficiently small prespecified constant. Visualizing the prescribed performance characteristics as tracking error constraints, the key idea is to transform the "constrained" system into an equivalent "unconstrained" one, via an appropriately defined output error transformation. It is shown that stabilization of the "unconstrained" system is sufficient to solve the stated problem. Besides guaranteeing a uniform ultimate boundedness property for the transformed output error and the uniform boundedness for all other signals in the closed loop, the proposed robust adaptive controller is smooth with easily selected parameter values and successfully bypasses the loss of controllability issue. Simulation results on a two-link robot, clarify and verify the approach.					Bechlioulis, Charalampos/O-3892-2017	Bechlioulis, Charalampos/0000-0001-9850-2540													0018-9286	1558-2523				OCT	2008	53	9					2090	2099		10.1109/TAC.2008.929402	http://dx.doi.org/10.1109/TAC.2008.929402													WOS:000260220000009
J	Hoover, A; Kouznetsova, V; Goldbaum, M				Hoover, A; Kouznetsova, V; Goldbaum, M			Locating blood vessels in retinal images by piecewise threshold probing of a matched filter response	IEEE TRANSACTIONS ON MEDICAL IMAGING												We describe an automated method to locate and outline blood vessels in images of the ocular fundus, Such a tool should prove useful to eye care specialists for purposes of patient screening, treatment evaluation, and clinical study. Our method differs from previously known methods in that it uses local and global vessel features cooperatively to segment the vessel network. We evaluate our method using hand-labeled ground truth segmentations of 20 images. A plot of the operating characteristic shows that our method reduces false positives by as much as 15 times over basic thresholding of a matched filter response (MFR), at up to a 75% true positive rate. For a baseline, we also compared the ground truth against a second hand-labeling, yielding a 90% true positive and a 4% false positive detection rate, on average. These numbers suggest there is still room for a 15% true positive rate improvement, with the same false positive rate, over our method. We are making all our images and hand labelings publicly available for interested researchers to use in evaluating related methods.					Goldbaum, Michael/AAG-4258-2020														0278-0062	1558-254X				MAR	2000	19	3					203	210		10.1109/42.845178	http://dx.doi.org/10.1109/42.845178								10875704					WOS:000087569300005
J	Sabharwal, A; Schniter, P; Guo, DN; Bliss, DW; Rangarajan, S; Wichman, R				Sabharwal, Ashutosh; Schniter, Philip; Guo, Dongning; Bliss, Daniel W.; Rangarajan, Sampath; Wichman, Risto			In-Band Full-Duplex Wireless: Challenges and Opportunities	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS												In-band full-duplex (IBFD) operation has emerged as an attractive solution for increasing the throughput of wireless communication systems and networks. With IBFD, a wireless terminal is allowed to transmit and receive simultaneously in the same frequency band. This tutorial paper reviews the main concepts of IBFD wireless. One of the biggest practical impediments to IBFD operation is the presence of self-interference, i.e., the interference that the modem's transmitter causes to its own receiver. This tutorial surveys a wide range of IBFD self-interference mitigation techniques. Also discussed are numerous other research challenges and opportunities in the design and analysis of IBFD wireless systems.					Wichman, Risto/G-2469-2013; Guo, Dongning/B-7160-2009; Schniter, Philip/X-3346-2019	Schniter, Philip/0000-0003-0939-7545; Wichman, Risto/0000-0002-5261-5037													0733-8716	1558-0008				SEP	2014	32	9					1637	1652		10.1109/JSAC.2014.2330193	http://dx.doi.org/10.1109/JSAC.2014.2330193													WOS:000346043400002
J	Sun, J				Sun, Jian			Impedance-Based Stability Criterion for Grid-Connected Inverters	IEEE TRANSACTIONS ON POWER ELECTRONICS												Grid-connected inverters are known to become unstable when the grid impedance is high. Existing approaches to analyzing such instability are based on inverter control models that account for the grid impedance and the coupling with other grid-connected inverters. A new method to determine inverter-grid system stability using only the inverter output impedance and the grid impedance is developed in this paper. It will be shown that a grid-connected inverter will remain stable if the ratio between the grid impedance and the inverter output impedance satisfies the Nyquist stability criterion. This new impedance-based stability criterion is a generalization to the existing stability criterion for voltage-source systems, and can be applied to all current-source systems. A single-phase solar inverter is studied to demonstrate the application of the proposed method.																			0885-8993	1941-0107				NOV	2011	26	11					3075	3078		10.1109/TPEL.2011.2136439	http://dx.doi.org/10.1109/TPEL.2011.2136439													WOS:000297355900001
J	Varcoe, JR; Atanassov, P; Dekel, DR; Herring, AM; Hickner, MA; Kohl, PA; Kucernak, AR; Mustain, WE; Nijmeijer, K; Scott, K; Xu, TW; Zhuang, L				Varcoe, John R.; Atanassov, Plamen; Dekel, Dario R.; Herring, Andrew M.; Hickner, Michael A.; Kohl, Paul. A.; Kucernak, Anthony R.; Mustain, William E.; Nijmeijer, Kitty; Scott, Keith; Xu, Tongwen; Zhuang, Lin			Anion-exchange membranes in electrochemical energy systems	ENERGY & ENVIRONMENTAL SCIENCE												This article provides an up-to-date perspective on the use of anion-exchange membranes in fuel cells, electrolysers, redox flow batteries, reverse electrodialysis cells, and bioelectrochemical systems (e.g. microbial fuel cells). The aim is to highlight key concepts, misconceptions, the current state-of-the-art, technological and scientific limitations, and the future challenges (research priorities) related to the use of anion-exchange membranes in these energy technologies. All the references that the authors deemed relevant, and were available on the web by the manuscript submission date (30th April 2014), are included.					Varcoe, John/E-5754-2011; Herring, Andy/E-7088-2010; Zhuang, Lin/G-1053-2012; kucernak, anthony/D-1647-2009; Atanassov, Plamen/AAI-4242-2020; Hickner, Michael/S-9735-2017; xu, Tongwen/F-6000-2010	Hickner, Michael/0000-0002-2252-7626; Varcoe, John/0000-0001-9898-0235; Mustain, William/0000-0001-7804-6410; xu, Tongwen/0000-0002-9221-5126; Herring, Andrew/0000-0001-7318-5999													1754-5692	1754-5706				OCT	2014	7	10					3135	3191		10.1039/c4ee01303d	http://dx.doi.org/10.1039/c4ee01303d													WOS:000342884300003
J	Bocken, NMP; de Pauw, I; Bakker, C; van der Grinten, B				Bocken, Nancy M. P.; de Pauw, Ingrid; Bakker, Conny; van der Grinten, Bram			Product design and business model strategies for a circular economy	JOURNAL OF INDUSTRIAL AND PRODUCTION ENGINEERING												The transition within business from a linear to a circular economy brings with it a range of practical challenges for companies. The following question is addressed: What are the product design and business model strategies for companies that want to move to a circular economy model? This paper develops a framework of strategies to guide designers and business strategists in the move from a linear to a circular economy. Building on Stahel, the terminology of slowing, closing, and narrowing resource loops is introduced. A list of product design strategies, business model strategies, and examples for key decision-makers in businesses is introduced, to facilitate the move to a circular economy. This framework also opens up a future research agenda for the circular economy.					Bakker, Conny/F-2426-2012	Bocken, Nancy/0000-0003-0137-4074; Bakker, Conny/0000-0001-9982-8788													2168-1015	2168-1023					2016	33	5			SI		308	320		10.1080/21681015.2016.1172124	http://dx.doi.org/10.1080/21681015.2016.1172124													WOS:000378222500003
J	Millán, J; Godignon, P; Perpiñà, X; Pérez-Tomás, A; Rebollo, J				Millan, Jose; Godignon, Philippe; Perpina, Xavier; Perez-Tomas, Amador; Rebollo, Jose			A Survey of Wide Bandgap Power Semiconductor Devices	IEEE TRANSACTIONS ON POWER ELECTRONICS												Wide bandgap semiconductors show superior material properties enabling potential power device operation at higher temperatures, voltages, and switching speeds than current Si technology. As a result, a new generation of power devices is being developed for power converter applications in which traditional Si power devices show limited operation. The use of these new power semiconductor devices will allow both an important improvement in the performance of existing power converters and the development of new power converters, accounting for an increase in the efficiency of the electric energy transformations and a more rational use of the electric energy. At present, SiC and GaN are the more promising semiconductor materials for these new power devices as a consequence of their outstanding properties, commercial availability of starting material, and maturity of their technological processes. This paper presents a review of recent progresses in the development of SiC- and GaN-based power semiconductor devices together with an overall view of the state of the art of this new device generation.					Perez-Tomas, Amador/B-5806-2017; Perpina, Xavier/C-4506-2015	Perez-Tomas, Amador/0000-0002-0551-3142; Godignon, Philippe/0000-0002-9273-9819; Rebollo, Jose/0000-0002-4833-737X; Perpina, Xavier/0000-0001-5946-5580													0885-8993	1941-0107				MAY	2014	29	5			SI		2155	2163		10.1109/TPEL.2013.2268900	http://dx.doi.org/10.1109/TPEL.2013.2268900													WOS:000329991500002
J	Mishra, UK; Parikh, P; Wu, YF				Mishra, UK; Parikh, P; Wu, YF			AlGaN/GaN HEMTs - An overview of device operation and applications	PROCEEDINGS OF THE IEEE												Wide bandgap, semiconductors are extremely attractive for the gamut of power electronics applications from power conditioning to microwave transmitters for communications and radar Of the various materials and device technologies, the AlGaN/GaN high-electron mobility transistor seems the most promising. This paper attempts to present the status of the technology and the market with a view of highlighting both the progress and the remaining problems.					Wu, Yifeng/AAD-7201-2020; Mishra, Upendra/ABF-9593-2021														0018-9219					JUN	2002	90	6					1022	1031	PII S0018-9219(02)05582-2	10.1109/JPROC.2002.1021567	http://dx.doi.org/10.1109/JPROC.2002.1021567													WOS:000177273000009
J	Knothe, G				Knothe, G			Dependence of biodiesel fuel properties on the structure of fatty acid alkyl esters	FUEL PROCESSING TECHNOLOGY												Biodiesel, defined as the mono-alkyl esters of vegetable oils or animal fats, is an "alternative" diesel fuel that is becoming accepted in a steadily growing number of countries around the world. Since the source of biodiesel varies with the location and other sources such as recycled oils are continuously gaining interest, it is important to possess data on how the various fatty acid profiles of the different sources can influence biodiesel fuel properties. The properties of the various individual fatty esters that comprise biodiesel determine the overall fuel properties of the biodiesel fuel. In turn, the properties of the various fatty esters are determined by the structural features of the fatty acid and the alcohol moieties that comprise a fatty ester. Structural features that influence the physical and fuel properties of a fatty ester molecule are chain length, degree of unsaturation, and branching of the chain. Important fuel properties of biodiesel that are influenced by the fatty acid profile and, in turn, by the structural features of the various fatty esters are cetane number and ultimately exhaust emissions, heat of combustion, cold flow, oxidative stability, viscosity, and lubricity. Published by Elsevier B.V.																			0378-3820	1873-7188				JUN 25	2005	86	10					1059	1070		10.1016/j.fuproc.2004.11.002	http://dx.doi.org/10.1016/j.fuproc.2004.11.002													WOS:000229403500002
J	Huynh-Thu, Q; Ghanbari, M				Huynh-Thu, Q.; Ghanbari, M.			Scope of validity of PSNR in image/video quality assessment	ELECTRONICS LETTERS												Experimental data are presented that clearly demonstrate the scope of application of peak signal-to-noise ratio (PSNR) as a video quality metric. It is shown that as long as the video content and the codec type are not changed, PSNR is a valid quality measure. However, when the content is changed, correlation between subjective quality and PSNR is highly reduced. Hence PSNR cannot be a reliable method for assessing the video quality across different video contents.					Ghanbari, Mohammad/L-4053-2019	Ghanbari, Mohammad/0000-0002-5482-8378													0013-5194					JUN 19	2008	44	13					800	U35		10.1049/el:20080522	http://dx.doi.org/10.1049/el:20080522													WOS:000257785600014
J	Wu, XD; Zhu, XQ; Wu, GQ; Ding, W				Wu, Xindong; Zhu, Xingquan; Wu, Gong-Qing; Ding, Wei			Data Mining with Big Data	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING												Big Data concern large-volume, complex, growing data sets with multiple, autonomous sources. With the fast development of networking, data storage, and the data collection capacity, Big Data are now rapidly expanding in all science and engineering domains, including physical, biological and biomedical sciences. This paper presents a HACE theorem that characterizes the features of the Big Data revolution, and proposes a Big Data processing model, from the data mining perspective. This data-driven model involves demand-driven aggregation of information sources, mining and analysis, user interest modeling, and security and privacy considerations. We analyze the challenging issues in the data-driven model and also in the Big Data revolution.					Wu, Xindong/AAB-6713-2022; ZOU, Fengcai/ABE-4598-2021; Wu, Gongqing/D-3442-2016	Zhu, Xingquan/0000-0003-4129-9611; Ding, Wei/0000-0002-3383-551X													1041-4347	1558-2191				JAN	2014	26	1					97	107		10.1109/TKDE.2013.109	http://dx.doi.org/10.1109/TKDE.2013.109													WOS:000327656800009
J	Torr, PHS; Zisserman, A				Torr, PHS; Zisserman, A			MLESAC: A new robust estimator with application to estimating image geometry	COMPUTER VISION AND IMAGE UNDERSTANDING												A new method is presented for robustly estimating multiple view relations from point correspondences. The method comprises two parts. The first is a new robust estimator MLESAC which is a generalization of the RANSAC estimator. It adopts the same sampling strategy as RANSAC to generate putative solutions, but chooses the solution that maximizes the likelihood rather than just the number of inliers. The second part of the algorithm is a general purpose method for automatically parameterizing these relations, using the output of MLESAC. A difficulty with multiview image relations is that there are often nonlinear constraints between the parameters, making optimization a difficult task. The parameterization method overcomes the difficulty of nonlinear constraints and conducts a constrained optimization. The method is general and its use is illustrated for the estimation of fundamental matrices, image-image homographies, and quadratic transformations. Results are given for both synthetic and real images. It is demonstrated that the method gives results equal or superior to those of previous approaches, (C) 2000 Academic Press.																			1077-3142	1090-235X				APR	2000	78	1					138	156		10.1006/cviu.1999.0832	http://dx.doi.org/10.1006/cviu.1999.0832													WOS:000086473800009
J	Liserre, M; Blaabjerg, F; Hansen, S				Liserre, M; Blaabjerg, F; Hansen, S			Design and control of an <i>LCL-</i>filter-based three-phase active rectifier	IEEE TRANSACTIONS ON INDUSTRY APPLICATIONS					Annual Meeting of the Industry-Applications-Society	SEP 30-OCT 05, 2001	CHICAGO, IL	Ind Applicat Soc				This paper proposes a step-by-step procedure for designing the LCL filter of a front-end three-phase active rectifier. The primary goal is to reduce the switching frequency ripple at a reasonable cost, while at the same time achieving a high-performance front-end rectifier (as characterized by a rapid dynamic response and good stability margin). An example LCL filter design is reported and a filter has been built and tested using the values obtained from this design. The experimental results demonstrate the performance of the design procedure both for the LCL filter and for the rectifier controller. The system is stable and the grid current harmonic content is low both in the low- and high-frequency ranges. Moreover, the good agreement that was obtained between simulation and experimental results validates the proposed approach. Hence, the design procedure and the simulation model provide a powerful tool to design an LCL-filter based active rectifier while avoiding trial-and-error procedures that can result in having to build several filter prototypes.					Liserre, Marco/C-2857-2011; Blaabjerg, Frede/A-5008-2008	Blaabjerg, Frede/0000-0001-8311-7412													0093-9994	1939-9367				SEP-OCT	2005	41	5					1281	1291		10.1109/TIA.2005.853373	http://dx.doi.org/10.1109/TIA.2005.853373													WOS:000232012000017
J	Mendel, JM; John, RI; Liu, FL				Mendel, Jerry M.; John, Robert I.; Liu, Feilong			Interval type-2 fuzzy logic systems made simple	IEEE TRANSACTIONS ON FUZZY SYSTEMS												To date, because of the computational complexity of using a general type-2 fuzzy set (T2 FS) in a T2 fuzzy logic system (FLS), most people only use an interval T2 FS, the result being an interval T2 FLS (IT2 FLS). Unfortunately, there is a heavy educational burden even to using an IT2 FLS. This burden has to do with first having to learn general T2 FS mathematics, and then specializing it to an IT2 FSs. In retrospect, we believe that requiring a person to use T2 FS mathematics represents a barrier to the use of an IT2 FLS. In this paper, we demonstrate that it is unnecessary to take the route from general T2 FS to IT2 FS, and that all of the results that are needed to implement an IT2 FLS can be obtained using T1 FS mathematics. As such, this paper is a novel tutorial that makes an IT2 FLS much more accessible to all readers of this journal. We can now develop an IT2 FLS in a much more straightforward way.					John, Robert/A-4073-2009	John, Robert/0000-0002-2341-9993													1063-6706	1941-0034				DEC	2006	14	6					808	821		10.1109/TFUZZ.2006.879986	http://dx.doi.org/10.1109/TFUZZ.2006.879986													WOS:000243892000009
J	Boyd, S; Ghosh, A; Prabhakar, B; Shah, D				Boyd, Stephen; Ghosh, Arpita; Prabhakar, Balaji; Shah, Devavrat			Randomized gossip algorithms	IEEE TRANSACTIONS ON INFORMATION THEORY												Motivated by applications to sensor, peer-to-peer, and ad hoc networks, we study distributed algorithms, also known as gossip algorithms, for exchanging information and for computing in an arbitrarily connected network of nodes. The topology of such networks changes continuously as new nodes join and old nodes leave the network. Algorithms for such networks need to be robust against changes in topology. Additionally, nodes in sensor networks operate under limited computational, communication, and energy resources. These constraints have motivated the design of "gossip" algorithms: schemes which distribute the computational burden and in which a node communicates with a randomly chosen neighbor. We analyze the averaging problem under the gossip constraint for an arbitrary network graph, and find that the averaging time of a gossip algorithm depends on the second largest eigenvalue of a doubly stochastic matrix characterizing the algorithm. Designing the fastest gossip algorithm corresponds to minimizing this eigenvalue, which is a semidefinite program (SDP). In general, SDPs cannot be solved in a distributed fashion; however, exploiting problem structure, we propose a distributed subgradient method that solves the optimization problem over the network. The relation of averaging time to the second largest eigenvalue naturally relates it to the mixing time of a random walk with transition probabilities derived from the gossip algorithm. We use this connection to study the performance and scaling of gossip algorithms on two popular networks: Wireless Sensor Networks, which are modeled as Geometric Random Graphs, and the Internet graph under the so-called Preferential Connectivity (PC) model.																			0018-9448	1557-9654				JUN	2006	52	6					2508	2530		10.1109/TIT.2006.874516	http://dx.doi.org/10.1109/TIT.2006.874516													WOS:000238319400016
J	Turpin, BJ; Lim, HJ				Turpin, BJ; Lim, HJ			Species contributions to PM2.5 mass concentrations: Revisiting common assumptions for estimating organic mass	AEROSOL SCIENCE AND TECHNOLOGY												In virtually all published literature wherein closure between gravimetric and chemical measurements is tested, the concentration of particulate organics is estimated by multiplying the measured concentration of organic carbon (micrograms carbon/cubic meter air) by a factor of 1.2-1.4. This factor, which is an estimate of the average molecular weight per carbon weight for the organic aerosol, stems from very limited theoretical and laboratory studies conducted during the 1970s. This investigation suggests that 1.4 is the lowest reasonable estimate for the organic molecular weight per carbon weight for an urban aerosol and that 1.4 does not accurately represent the average organic molecular weight per carbon weight for a nonurban aerosol. Based on the current evaluation, ratios of 1.6 +/- 0.2 for urban aerosols and 2.1 +/- 0.2 for nonurban aerosols appear to be more accurate. Measurements are recommended. Literature values also suggest that 1.2 g/cm(3) is a reasonable estimate for the organic aerosol density. This quantity is needed to convert between geometric and aerodynamic size distributions (e.g., to predict aerosol optical properties and understand cloud nucleating properties).					Turpin, Barbara/D-8346-2012	Turpin, Barbara/0000-0003-4513-4187													0278-6826					JUL	2001	35	1					602	610		10.1080/02786820119445	http://dx.doi.org/10.1080/02786820119445													WOS:000169797800007
J	Ang, KH; Chong, G; Li, Y				Ang, KH; Chong, G; Li, Y			PID control system analysis, design, and technology	IEEE TRANSACTIONS ON CONTROL SYSTEMS TECHNOLOGY												Designing and tuning a proportional-integral-derivative (PID) controller appears to be conceptually intuitive, but can be hard in practice, if multiple (and often conflicting) objectives such as short transient and high stability are to be achieved. Usually, initial designs obtained by all means need to be adjusted repeatedly through computer simulations until the closed-loop system performs or compromises as desired. This stimulates the development of "intelligent" tools that can assist engineers to achieve the best overall PID control for the entire operating envelope. This development has further led to the incorporation of some advanced tuning algorithms into PID hardware modules. Corresponding to these developments, this paper presents a modern overview of functionalities and tuning methods in patents, software packages and commercial hardware modules. It is seen that many PID variants have been developed in order to improve transient performance, but standardising and modularising PID control are desired, although challenging. The inclusion of system identification and "intelligent" techniques in software based PID systems helps automate the entire design and tuning process to a useful degree. This should also assist future development of "plug-and-play" PID controllers that are widely applicable and can be set up easily and operate optimally for enhanced productivity, improved quality and reduced maintenance requirements.					Li, Yun/C-6411-2009	Li, Yun/0000-0002-6575-1839													1063-6536	1558-0865				JUL	2005	13	4					559	576		10.1109/TCST.2005.847331	http://dx.doi.org/10.1109/TCST.2005.847331													WOS:000229865400006
J	Au, SK; Beck, JL				Au, SK; Beck, JL			Estimation of small failure probabilities in high dimensions by subset simulation	PROBABILISTIC ENGINEERING MECHANICS					Conference on Monte Carlo Simulation	JUN 18-21, 2000	MONTE CARLO, MONACO					A new simulation approach, called 'subset simulation', is proposed to compute small failure probabilities encountered in reliability analysis of engineering systems. The basic idea is to express the failure probability as a product of larger conditional failure probabilities by introducing intermediate failure events. With a proper choice of the conditional events, the conditional failure probabilities can be made sufficiently large so that they can be estimated by means of simulation with a small number of samples. The original problem of calculating a small failure probability, which is computationally demanding, is reduced to calculating a sequence of conditional probabilities, which can be readily and efficiently estimated by means of simulation. The conditional probabilities cannot be estimated efficiently by a standard Monte Carlo procedure, however, and so a Markov chain Monte Carlo simulation (MCS) technique based on the Metropolis algorithm is presented for their estimation. The proposed method is robust to the number of uncertain parameters and efficient in computing small probabilities. The efficiency of the method is demonstrated by calculating the first-excursion probabilities for a linear oscillator subjected to white noise excitation and for a five-story nonlinear hysteretic shear building under uncertain seismic excitation. (C) 2001 Elsevier Science Ltd. All rights reserved.					Au, Siu-Kui/A-2947-2011	Au, Siu-Kui/0000-0002-0228-1796													0266-8920					OCT	2001	16	4					263	277		10.1016/S0266-8920(01)00019-4	http://dx.doi.org/10.1016/S0266-8920(01)00019-4													WOS:000172053600002
J	Ding, ZG; Lei, XF; Karagiannidis, GK; Schober, R; Yuan, JH; Bhargava, VK				Ding, Zhiguo; Lei, Xianfu; Karagiannidis, George K.; Schober, Robert; Yuan, Jinhong; Bhargava, Vijay K.			A Survey on Non-Orthogonal Multiple Access for 5G Networks: Research Challenges and Future Trends	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS												Non-orthogonal multiple access (NOMA) is an essential enabling technology for the fifth-generation (5G) wireless networks to meet the heterogeneous demands on low latency, high reliability, massive connectivity, improved fairness, and high throughput. The key idea behind NOMA is to serve multiple users in the same resource block, such as a time slot, subcarrier, or spreading code. The NOMA principle is a general framework, and several recently proposed 5G multiple access schemes can be viewed as special cases. This survey provides an overview of the latest NOMA research and innovations as well as their applications. Thereby, the papers published in this special issue are put into the context of the existing literature. Future research challenges regarding NOMA in 5G and beyond are also discussed.					Yuan, Jinhong/AAF-7715-2019; Schober, Robert/ABC-9480-2020; Ding, Zhiguo/B-9805-2017; Karagiannidis, George K./A-5190-2014	Yuan, Jinhong/0000-0002-5794-493X; Karagiannidis, George K./0000-0001-8810-0345													0733-8716	1558-0008				OCT	2017	35	10					2181	2195		10.1109/JSAC.2017.2725519	http://dx.doi.org/10.1109/JSAC.2017.2725519													WOS:000410646800001
J	Zhang, Y; Wu, JX; Cai, JF				Zhang, Yu; Wu, Jianxin; Cai, Jianfei			Compact Representation of High-Dimensional Feature Vectors for Large-Scale Image Recognition and Retrieval	IEEE TRANSACTIONS ON IMAGE PROCESSING												In large-scale visual recognition and image retrieval tasks, feature vectors, such as Fisher vector (FV) or the vector of locally aggregated descriptors (VLAD), have achieved state-of-the-art results. However, the combination of the large numbers of examples and high-dimensional vectors necessitates dimensionality reduction, in order to reduce its storage and CPU costs to a reasonable range. In spite of the popularity of various feature compression methods, this paper shows that the feature (dimension) selection is a better choice for high-dimensional FV/VLAD than the feature (dimension) compression methods, e.g., product quantization. We show that strong correlation among the feature dimensions in the FV and the VLAD may not exist, which renders feature selection a natural choice. We also show that, many dimensions in FV/VLAD are noise. Throwing them away using feature selection is better than compressing them and useful dimensions altogether using feature compression methods. To choose features, we propose an efficient importance sorting algorithm considering both the supervised and unsupervised cases, for visual recognition and image retrieval, respectively. Combining with the 1-bit quantization, feature selection has achieved both higher accuracy and less computational cost than feature compression methods, such as product quantization, on the FV and the VLAD image representations.					Wu, Jianxin/A-3700-2011; Cai, Jianfei/A-3691-2011	Cai, Jianfei/0000-0002-9444-3763													1057-7149	1941-0042				MAY	2016	25	5							2407	10.1109/TIP.2016.2549360	http://dx.doi.org/10.1109/TIP.2016.2549360								27046897					WOS:000374889800001
J	Tominaga, Y; Mochida, A; Yoshie, R; Kataoka, H; Nozu, T; Yoshikawa, M; Shirasawa, T				Tominaga, Yoshihide; Mochida, Akashi; Yoshie, Ryuichiro; Kataoka, Hiroto; Nozu, Tsuyoshi; Yoshikawa, Masaru; Shirasawa, Taichi			AIJ guidelines for practical applications of CFD to pedestrian wind environment around buildings	JOURNAL OF WIND ENGINEERING AND INDUSTRIAL AERODYNAMICS					4th International Symposium on Computational Wind Engineering (CWE 2006)	JUL 16-19, 2006	Yokohama, JAPAN	Japan Assoc Wind Engn, Tokyo Polytech Univ, 21st Cent COE Program, Int Assoc Wind Engn, Architectural Inst Japan, Japan Soc Nat Disaster Sci, Japan Soc Snow Engn, Japan Soc Civil Engineers, Japan Soc Fluid Mech, Japan Structural Consultants Assoc, Japan Wind Energy Assoc, Meteorol Soc Japan, Soc Hearing, Air Condit & Sanitary Engineers Japan, Visualizat Soc Japan Steel Bridge Engn Assoc, City Yokohama				Significant improvements of computer facilities and computational fluid dynamics (CFD) software in recent years have enabled prediction and assessment of the pedestrian wind environment around buildings in the design stage. Therefore, guidelines are required that summarize important points in using the CFD technique for this purpose. This paper describes guidelines proposed by the Working Group of the Architectural Institute of Japan (AIJ). The feature of these guidelines is that they are based on cross-comparison between CFD predictions, wind tunnel test results and field measurements for seven test cases used to investigate the influence of many kinds of computational conditions for various flow fields. (c) 2008 Elsevier Ltd. All rights reserved.					Mochida, Akashi/T-6076-2019; Kataoka, Hiroto/HPG-6848-2023; Tominaga, Yoshihide/P-4104-2014	Mochida, Akashi/0000-0002-4216-2361; Tominaga, Yoshihide/0000-0002-4329-0787													0167-6105	1872-8197				OCT-NOV	2008	96	10-11			SI		1749	1761		10.1016/j.jweia.2008.02.058	http://dx.doi.org/10.1016/j.jweia.2008.02.058													WOS:000259340500020
J	Bas, D; Boyaci, IH				Bas, Deniz; Boyaci, Ismail H.			Modeling and optimization I: Usability of response surface methodology	JOURNAL OF FOOD ENGINEERING												Response surface methodology (RSM) is the most popular optimization method used in recent years. There are so many works based on the application of RSM in chemical and biochemical process. On the other hand, few articles were published about the limitation and usability of it. In this paper, we looked at some of the RSM articles published during the last few years. We tried to identify common mistakes made in the application and the limitations of RSM. We asked ourselves two important questions. These questions are "Can RSM be used for optimization of all chemical and biochemical processes without any limitation?" and "Is RSM usable for other purposes (determination of reaction kinetics, stability or evaluation of kinetic constants etc.) in addition to optimization?". We were able to answer these questions based on the observations obtained from reviewed articles. We believe that the answers will be helpful for researchers, who will use RSM in their future studies. (c) 2005 Elsevier Ltd. All rights reserved.					BOYACI, Ismail/A-5255-2013; BAS, Deniz/AAR-7028-2020	BAS, Deniz/0000-0003-1494-681X													0260-8774	1873-5770				FEB	2007	78	3					836	845		10.1016/j.jfoodeng.2005.11.024	http://dx.doi.org/10.1016/j.jfoodeng.2005.11.024													WOS:000241073500012
J	Oh, KK; Park, MC; Ahn, HS				Oh, Kwang-Kyo; Park, Myoung-Chul; Ahn, Hyo-Sung			A survey of multi-agent formation control	AUTOMATICA												We present a survey of formation control of multi-agent systems. Focusing on the sensing capability and the interaction topology of agents, we categorize the existing results into position-, displacement-, and distance-based control. We then summarize problem formulations, discuss distinctions, and review recent results of the formation control schemes. Further we review some other results that do not fit into the categorization. (C) 2014 Elsevier Ltd. All rights reserved.					; Ahn, Hyo-Sung/G-9060-2015	Park, Myoung-Chul/0000-0002-9725-2719; Ahn, Hyo-Sung/0000-0002-7939-0093													0005-1098	1873-2836				MAR	2015	53						424	440		10.1016/j.automatica.2014.10.022	http://dx.doi.org/10.1016/j.automatica.2014.10.022													WOS:000351961900054
J	Feng, Y; Yu, XH; Man, ZH				Feng, Y; Yu, XH; Man, ZH			Non-singular terminal sliding mode control of rigid manipulators	AUTOMATICA												This paper presents a global non-singular terminal sliding mode controller for rigid manipulators. A new terminal sliding mode manifold is first proposed for the second-order system to enable the elimination of the singularity problem associated with conventional terminal sliding mode control. The time taken to reach the equilibrium point from any initial state is guaranteed to be finite time. The proposed terminal sliding mode controller is then applied to the control of n-link rigid manipulators. Simulation results are presented to validate the analysis. (C) 2002 Elsevier Science Ltd. All rights reserved.					Man, Zhihong/AAH-7200-2020; Feng, Yong/AAC-2465-2019														0005-1098	1873-2836				DEC	2002	38	12					2159	2167	PII S0005-1098(02)00147-4	10.1016/S0005-1098(02)00147-4	http://dx.doi.org/10.1016/S0005-1098(02)00147-4													WOS:000179364100014
J	Haritaoglu, I; Harwood, D; Davis, LS				Haritaoglu, I; Harwood, D; Davis, LS			<i>W</i><SUP>4</SUP>:: Real-time surveillance of people and their activities	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												W-4 is a real time visual surveillance system for detecting and tracking multiple people and monitoring their activities in an outdoor environment. It operates on monocular gray-scale video imagery, or on video imagery from an infrared camera. W-4 employs a combination of shape analysis and tracking to locate people and their parts (head, hands, feet, torso) and to create models of people's appearance so that they can be tracked through interactions such as occlusions. It can determine whether a foreground region contains multiple people and can segment the region into its constituent people and track them. W-4 can also determine whether people are carrying objects, and can segment objects from their silhouettes, and construct appearance models for them so they can be identified in subsequent frames. W-4 can recognize events between people and objects, such as depositing an object, exchanging bags, or removing an object. It runs at 25 Hz for 320x240 resolution images on a 400 Mhz dual-Pentium II PC.																			0162-8828	1939-3539				AUG	2000	22	8					809	830		10.1109/34.868683	http://dx.doi.org/10.1109/34.868683													WOS:000089321500008
J	Ahn, SH; Montero, M; Odell, D; Roundy, S; Wright, PK				Ahn, SH; Montero, M; Odell, D; Roundy, S; Wright, PK			Anisotropic material properties of fused deposition modeling ABS	RAPID PROTOTYPING JOURNAL												Rapid Prototyping (RP) technologies provide the ability to fabricate initial prototypes from various model materials. Stratasys Fused Deposition Modeling (FDM) is a typical RP process that can fabricate prototypes out of ABS plastic. To predict the mechanical behavior of FDM parts, it is critical to understand the material properties of the raw FDM process material, and the effect that FDM build parameters have on anisotropic material properties. This paper characterizes the properties of ABS parts fabricated by the FDM 1650. Using a Design of Experiment (DOE) approach, the process parameters of FDM, such as raster orientation, air gap, bead width, color, and model temperature were examined. Tensile strengths and compressive strengths of directionally fabricated specimens were measured and compared with injection molded FDM ABS P400 material, For the FDM parts made with a 0.003 inch overlap between roads, the typical tensile strength ranged between 65 and 72 percent of the strength of injection molded ABS P400. The compressive strength ranged from 80 to 90 percent of the injection molded FDM ABS. Several build rules for designing FDM parts were formulated based on experimental results.					Ahn, Sung-Hoon/GLS-7239-2022	Ahn, Sung-Hoon/0000-0002-1548-2394; Roundy, Shad/0000-0002-5256-628X													1355-2546						2002	8	4					248	257		10.1108/13552540210441166	http://dx.doi.org/10.1108/13552540210441166													WOS:000178077300006
J	Xu, LD; Xu, EL; Li, L				Xu, Li Da; Xu, Eric L.; Li, Ling			Industry 4.0: state of the art and future trends	INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH												Rapid advances in industrialisation and informatisation methods have spurred tremendous progress in developing the next generation of manufacturing technology. Today, we are on the cusp of the Fourth Industrial Revolution. In 2013, amongst one of 10 Future Projects' identified by the German government as part of its High-Tech Strategy 2020 Action Plan, the Industry 4.0 project is considered to be a major endeavour for Germany to establish itself as a leader of integrated industry. In 2014, China's State Council unveiled their ten-year national plan, Made-in-China 2025, which was designed to transform China from the world's workshop into a world manufacturing power. Made-in-China 2025 is an initiative to comprehensively upgrade China's industry including the manufacturing sector. In Industry 4.0 and Made-in-China 2025, many applications require a combination of recently emerging new technologies, which is giving rise to the emergence of Industry 4.0. Such technologies originate from different disciplines including cyber-physical Systems, IoT, cloud computing, Industrial Integration, Enterprise Architecture, SOA, Business Process Management, Industrial Information Integration and others. At this present moment, the lack of powerful tools still poses a major obstacle for exploiting the full potential of Industry 4.0. In particular, formal methods and systems methods are crucial for realising Industry 4.0, which poses unique challenges. In this paper, we briefly survey the state of the art in the area of Industry 4.0 as it relates to industries.						LAPA, ANTONIO/0000-0002-5954-5115													0020-7543	1366-588X					2018	56	8					2941	2962		10.1080/00207543.2018.1444806	http://dx.doi.org/10.1080/00207543.2018.1444806													WOS:000433972400014
J	Bell, IH; Wronski, J; Quoilin, S; Lemort, V				Bell, Ian H.; Wronski, Jorrit; Quoilin, Sylvain; Lemort, Vincent			Pure and Pseudo-pure Fluid Thermophysical Property Evaluation and the Open-Source Thermophysical Property Library CoolProp	INDUSTRIAL & ENGINEERING CHEMISTRY RESEARCH												Over the last few decades, researchers have developed a number of empirical and theoretical models for the correlation and prediction of the thermophysical properties of pure fluids and mixtures treated as pseudo-pure fluids. In this paper, a survey of all the state-of-the-art formulations of thermophysical properties is presented. The most-accurate thermodynamic properties are obtained from multiparameter Helmholtz-energy-explicit-type formulations. For the transport properties, a wider range of methods has been employed, including the extended corresponding states method. All of the thermophysical property correlations described here have been implemented into CoolProp, an open-source thermophysical property library. This library is written in C++, with wrappers available for the majority of programming languages and platforms of technical interest. As of publication, 110 pure and pseudo-pure fluids are included in the library, as well as properties of 40 incompressible fluids and humid air. The source code for the CoolProp library is included as an electronic annex.					Lemort, Vincent/AAE-7059-2019; Quoilin, Sylvain/AAE-7477-2019; Wronski, Jorrit/G-1858-2014	Wronski, Jorrit/0000-0001-8216-4153; Quoilin, Sylvain/0000-0002-2064-209X; Lemort, Vincent/0000-0002-0654-8435													0888-5885					FEB 12	2014	53	6					2498	2508		10.1021/ie4033999	http://dx.doi.org/10.1021/ie4033999								24623957					WOS:000331343600045
J	Mohanty, AK; Misra, M; Drzal, LT				Mohanty, AK; Misra, M; Drzal, LT			Sustainable bio-composites from renewable resources: Opportunities and challenges in the green materials world	JOURNAL OF POLYMERS AND THE ENVIRONMENT												Sustainability, industrial ecology, eco-efficiency, and green chemistry are guiding the development of the next generation of materials, products, and processes. Biodegradable plastics and bio-based polymer products based on annually renewable agricultural and biomass feedstock can form the basis for a portfolio of sustainable, eco-efficient products that can compete and capture markets currently dominated by products based exclusively on petroleum feedstock. Natural/Biofiber composites (Bio-Composites) are emerging as a viable alternative to glass fiber reinforced composites especially in automotive and building product applications. The combination of biofibers such as kenaf, hemp, flax, jute, henequen, pineapple leaf fiber, and sisal with polymer matrices from both nonrenewable and renewable resources to produce composite materials that are competitive with synthetic composites requires special attention, i.e., biofiber-matrix interface and novel processing. Natural fiber-reinforced polypropylene composites have attained commercial attraction in automotive industries. Natural fiber-polypropylene or natural fiber-polyester composites are not sufficiently eco-friendly because of the petroleum-based source and the nonbiodegradable nature of the polymer matrix. Using natural fibers with polymers based on renewable resources will allow many environmental issues to be solved. By embedding biofibers with renewable resource-based biopolymers such as cellulosic plastics; polylactides; starch plastics; polyhydroxyalkanoates (bacterial polyesters); and soy-based plastics, the so-called green bio-composites are continuously being developed.					Drzal, Lawrence/G-1494-2012														1566-2543	1572-8919				APR	2002	10	1-2					19	26		10.1023/A:1021013921916	http://dx.doi.org/10.1023/A:1021013921916													WOS:000179201800004
J	Kokubo, T; Kim, HM; Kawashita, M				Kokubo, T; Kim, HM; Kawashita, M			Novel bioactive materials with different mechanical properties	BIOMATERIALS												Some ceramics, such as Bioglass((R)), sintered hydroxyapatite, and glass-ceramic A-W, spontaneously bond to living bone. They are called bioactive materials and are already clinically used as important bone substitutes. However, compared with human cortical bone, they have lower fracture toughness and higher elastic moduli. Therefore, it is desirable to develop bioactive materials with improved mechanical properties. All the bioactive materials mentioned above form a bone-like apatite layer on their surfaces in the living body, and bond to bone through this apatite layer. The formation of bone-like apatite on artificial material is induced by functional groups, such as Si-OH, Ti-OH, Zr-OH, Nb-OH, Ta-OH, -COOH, and PO4H2. These groups have specific structures revealing negatively charge, and induce apatite formation via formations of an amorphous calcium compound, e.g., calcium silicate, calcium titanate, and amorphous calcium phosphate. These fundamental findings provide methods for preparing new bioactive materials with different mechanical properties. Tough bioactive materials can be prepared by the chemical treatment of metals and ceramics that have high fracture toughness, e.g., by the NaOH and heat treatments of titanium metal, titanium alloys, and tantalum metal, and by H3PO4 treatment of tetragonal zirconia. Soft bioactive materials can be synthesized by the sol-gel process, in which the bioactive silica or titania is polymerized with a flexible polymer, such as polydimethylsiloxane or polytetramethyloxide, at the molecular level to form an inorganic-organic nano-hybrid. The biomimetic process has been used to deposit nano-sized bone-like apatite on fine polymer fibers, which were textured into a three-dimensional knit framework. This strategy is expected to ultimately lead to bioactive composites that have a bone-like structure and, hence, bone-like mechanical properties. (C) 2003 Elsevier Science Ltd. All rights reserved.					Kawashita, Masakazu/E-6632-2016	Kawashita, Masakazu/0000-0002-4329-9001													0142-9612	1878-5905				JUN	2003	24	13					2161	2175		10.1016/S0142-9612(03)00044-9	http://dx.doi.org/10.1016/S0142-9612(03)00044-9								12699652					WOS:000182280400005
J	Saberi, S; Kouhizadeh, M; Sarkis, J; Shen, LJ				Saberi, Sara; Kouhizadeh, Mahtab; Sarkis, Joseph; Shen, Lejia			Blockchain technology and its relationships to sustainable supply chain management	INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH												Globalisation of supply chains makes their management and control more difficult. Blockchain technology, as a distributed digital ledger technology which ensures transparency, traceability, and security, is showing promise for easing some global supply chain management problems. In this paper, blockchain technology and smart contracts are critically examined with potential application to supply chain management. Local and global government, community, and consumer pressures to meet sustainability goals prompt us to further investigate how blockchain can address and aid supply chain sustainability. Part of this critical examination is how blockchains, a potentially disruptive technology that is early in its evolution, can overcome many potential barriers. Four blockchain technology adoption barriers categories are introduced; inter-organisational, intra-organisational, technical, and external barriers. True blockchain-led transformation of business and supply chain is still in progress and in its early stages; we propose future research propositions and directions that can provide insights into overcoming barriers and adoption of blockchain technology for supply chain management.					Kouhizadeh, Mahtab/AAV-6880-2020; Saberi, Sara/IQV-2051-2023; Sarkis, Joseph/F-4508-2014	Sarkis, Joseph/0000-0003-0143-804X													0020-7543	1366-588X				APR 3	2019	57	7					2117	2135		10.1080/00207543.2018.1533261	http://dx.doi.org/10.1080/00207543.2018.1533261													WOS:000463617000010
J	Caire, G; Shamai, S				Caire, G; Shamai, S			On the achievable throughput of a multiantenna Gaussian broadcast channel	IEEE TRANSACTIONS ON INFORMATION THEORY					IEEE International Symposium on Information Theory	JUN 24-29, 2001	WASHINGTON, DC	IEEE				A Gaussian broadcast channel (GBC) with r single-antenna receivers and t antennas at the transmitter is considered. Both transmitter and receivers have perfect knowledge of the channel. Despite its apparent simplicity, this model is, in general, a nondegraded broadcast channel (BC), for-which the capacity region is not fully known. For the two-user case, we find a special case of Marton's region that achieves optimal sum-rate (throughput). In brief, the transmitter decomposes the channel into two interference channels, where interference is caused by the other user signal. Users are successively encoded, such that encoding of the second user is based on the noncausal knowledge of the interference caused by the first user. The crosstalk parameters are optimized such that the overall throughput is maximum and, surprisingly, this is shown to be optimal over all possible strategies (not only with respect to Marton's achievable region). For the case of r > 2 users, we find a somewhat simpler choice of Marton's region based on ordering and successively encoding the users. For each user i in the given ordering, the interference caused by users j > i is eliminated by zero forcing at the transmitter, while interference caused by users j < i is taken into account by coding for noncausally known interference. Under certain mild conditions, this scheme is found to be throughput-wise. asympmtotically optimal for both high and low signal-to-noise ratio (SNR). We conclude by providing some numerical results for the ergodic throughput of the simplified zero-forcing scheme in independent Rayleigh fading.					Caire, Giuseppe/Q-7275-2018														0018-9448	1557-9654				JUL	2003	49	7					1691	1706		10.1109/TIT.2003.813523	http://dx.doi.org/10.1109/TIT.2003.813523													WOS:000183766000007
J	Debnath, S; Qin, JC; Bahrani, B; Saeedifard, M; Barbosa, P				Debnath, Suman; Qin, Jiangchao; Bahrani, Behrooz; Saeedifard, Maryam; Barbosa, Peter			Operation, Control, and Applications of the Modular Multilevel Converter: A Review	IEEE TRANSACTIONS ON POWER ELECTRONICS												The modular multilevel converter (MMC) has been a subject of increasing importance for medium/high-power energy conversion systems. Over the past few years, significant research has been done to address the technical challenges associated with the operation and control of the MMC. In this paper, a general overview of the basics of operation of the MMC along with its control challenges are discussed, and a review of state-of-the-art control strategies and trends is presented. Finally, the applications of the MMC and their challenges are highlighted.					Barbosa, Peter/T-4828-2019	Bahrani, Behrooz/0000-0002-9482-2990; barbosa, peter/0000-0001-6018-7522; Debnath, Suman/0000-0001-9451-7294													0885-8993	1941-0107				JAN	2015	30	1			SI		37	53		10.1109/TPEL.2014.2309937	http://dx.doi.org/10.1109/TPEL.2014.2309937													WOS:000341624200004
J	Babenko, B; Yang, MH; Belongie, S				Babenko, Boris; Yang, Ming-Hsuan; Belongie, Serge			Robust Object Tracking with Online Multiple Instance Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												In this paper, we address the problem of tracking an object in a video given its location in the first frame and no other information. Recently, a class of tracking techniques called "tracking by detection" has been shown to give promising results at real-time speeds. These methods train a discriminative classifier in an online manner to separate the object from the background. This classifier bootstraps itself by using the current tracker state to extract positive and negative examples from the current frame. Slight inaccuracies in the tracker can therefore lead to incorrectly labeled training examples, which degrade the classifier and can cause drift. In this paper, we show that using Multiple Instance Learning (MIL) instead of traditional supervised learning avoids these problems and can therefore lead to a more robust tracker with fewer parameter tweaks. We propose a novel online MIL algorithm for object tracking that achieves superior results with real-time performance. We present thorough experimental results (both qualitative and quantitative) on a number of challenging video clips.					Yang, Ming-Hsuan/T-9533-2019	Belongie, Serge/0000-0002-0388-5217													0162-8828	1939-3539				AUG	2011	33	8					1619	1632		10.1109/TPAMI.2010.226	http://dx.doi.org/10.1109/TPAMI.2010.226								21173445					WOS:000291807200010
J	Martin, DR; Fowlkes, CC; Malik, J				Martin, DR; Fowlkes, CC; Malik, J			Learning to detect natural image boundaries using local brightness, color, and texture cues	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												The goal of this work is to accurately detect and localize boundaries in natural scenes using local image measurements. We formulate features that respond to characteristic changes in brightness, color, and texture associated with natural boundaries. In order to combine the information from these features in an optimal way, we train a classifier using human labeled images as ground truth. The output of this classifier provides the posterior probability of a boundary at each image location and orientation. We present precision-recall curves showing that the resulting detector significantly outperforms existing approaches. Our two main results are 1) that cue combination can be performed adequately with a simple linear model and 2) that a proper, explicit treatment of texture is required to detect boundaries in natural images.																			0162-8828	1939-3539				MAY	2004	26	5					530	549		10.1109/TPAMI.2004.1273918	http://dx.doi.org/10.1109/TPAMI.2004.1273918								15460277					WOS:000220756400001
J	Portilla, J; Strela, V; Wainwright, MJ; Simoncelli, EP				Portilla, J; Strela, V; Wainwright, MJ; Simoncelli, EP			Image denoising using scale mixtures of Gaussians in the wavelet domain	IEEE TRANSACTIONS ON IMAGE PROCESSING												We describe a method for removing noise from digital images, based on a statistical model of the coefficients of an over-complete multiscale oriented basis. Neighborhoods of coefficients at adjacent positions and scales are modeled as the product of two independent random variables: a Gaussian vector and a hidden positive scalar multiplier. The latter modulates the local variance of the coefficients in the neighborhood, and is thus able to account for the empirically observed correlation between the coefficient amplitudes. Under this model, the Bayesian least squares estimate of each coefficient reduces to a weighted average of the local linear estimates over all possible values of the hidden multiplier variable. We demonstrate through simulations with images contaminated by additive white Gaussian noise that the performance of this method substantially surpasses that of previously published methods, both visually and in terms of mean squared error.					; Portilla, Javier/H-3483-2015	Simoncelli, Eero/0000-0002-1206-527X; Wainwright, Martin J./0000-0002-8760-2236; Portilla, Javier/0000-0002-0147-2769													1057-7149	1941-0042				NOV	2003	12	11					1338	1351		10.1109/TIP.2003.818640	http://dx.doi.org/10.1109/TIP.2003.818640								18244692					WOS:000186221800004
J	Gadelmawla, ES; Koura, MM; Maksoud, TMA; Elewa, IM; Soliman, HH				Gadelmawla, ES; Koura, MM; Maksoud, TMA; Elewa, IM; Soliman, HH			Roughness parameters	JOURNAL OF MATERIALS PROCESSING TECHNOLOGY												Surface roughness evaluation is very important for many fundamental problems such as friction, contact deformation, heat and electric current conduction, tightness of contact joints and positional accuracy. For this reason surface roughness has been the subject of experimental and theoretical investigations for many decades. The real surface geometry is so complicated that a finite number of parameters cannot provide a full description. If the number of parameters used is increased, a more accurate description can be obtained. This is one of the reasons for introducing new parameters for surface evaluation. Surface roughness parameters are normally categorised into three groups according to its functionality. These groups are defined as amplitude parameters, spacing parameters, and hybrid parameters. This paper illustrates the definitions and the mathematical formulae for about 59 of the roughness parameters. This collection of surface roughness parameter was used in a new software computer vision package called Surf Vision developed by the authors. In the package, these definitions were extended to calculate the 3D surface topography of different specimens. (C) 2002 Elsevier Science B.V. All rights reserved.					Soliman, Hanan/D-1170-2019														0924-0136					APR 10	2002	123	1					133	145	PII S0924-0136(02)00060-2	10.1016/S0924-0136(02)00060-2	http://dx.doi.org/10.1016/S0924-0136(02)00060-2													WOS:000175343700022
J	Bernardin, K; Stiefelhagen, R				Bernardin, Keni; Stiefelhagen, Rainer			Evaluating Multiple Object Tracking Performance: The CLEAR MOT Metrics	EURASIP JOURNAL ON IMAGE AND VIDEO PROCESSING												Simultaneous tracking of multiple persons in real-world environments is an active research field and several approaches have been proposed, based on a variety of features and algorithms. Recently, there has been a growing interest in organizing systematic evaluations to compare the various techniques. Unfortunately, the lack of common metrics for measuring the performance of multiple object trackers still makes it hard to compare their results. In this work, we introduce two intuitive and general metrics to allow for objective comparison of tracker characteristics, focusing on their precision in estimating object locations, their accuracy in recognizing object configurations and their ability to consistently label objects over time. These metrics have been extensively used in two large-scale international evaluations, the 2006 and 2007 CLEAR evaluations, to measure and compare the performance of multiple object trackers for a wide variety of tracking tasks. Selected performance results are presented and the advantages and drawbacks of the presented metrics are discussed based on the experience gained during the evaluations. Copyright (C) 2008 K. Bernardin and R. Stiefelhagen.						Stiefelhagen, Rainer/0000-0001-8046-4945													1687-5176	1687-5281					2008									246309	10.1155/2008/246309	http://dx.doi.org/10.1155/2008/246309													WOS:000207760900001
J	Dissanayake, MWMG; Newman, P; Clark, S; Durrant-Whyte, HF; Csorba, M				Dissanayake, MWMG; Newman, P; Clark, S; Durrant-Whyte, HF; Csorba, M			A solution to the simultaneous localization and map building (SLAM) problem	IEEE TRANSACTIONS ON ROBOTICS AND AUTOMATION												The simultaneous localization and map building (SLAM) problem asks if it is possible for an autonomous vehicle to start in an unknown location in an unknown environment and then to incrementally build a map of this environment while simultaneously using this map to compute absolute vehicle location. Starting from the estimation-theoretic foundations of this problem developed in [1]-[3], this paper proves that a solution to the SLAM problem is indeed possible. The underlying structure of the SLAM problem is first elucidated. A proof that the estimated map converges monotonically to a relative map with zero uncertainty is then developed. It is then shown that the absolute accuracy of the map and the vehicle location reach a lower bound defined only by the initial vehicle uncertainty. Together, these results show that it is possible for an autonomous vehicle to start in an unknown location in an unknown environment and, using relative observations only, incrementally build a perfect map of the world and to compute simultaneously a bounded estimate of vehicle location. This paper also describes a substantial implementation of the SLAM algorithm on a vehicle operating in an outdoor environment using millimeter-wave (MMW) radar to provide relative map observations. This implementation is used to demonstrate how some key issues such as map management and data association can be handled in a practical environment. The results obtained are cross-compared with absolute locations of the map landmarks obtained by surveying. In conclusion, this paper discusses a number of key issues raised by the solution to the SLAM problem including suboptimal map-building algorithms and map management.					Newman, Paul/E-9190-2011; Dissanayake, Gamini/F-7361-2017	Dissanayake, Gamini/0000-0002-7992-0680													1042-296X					JUN	2001	17	3					229	241		10.1109/70.938381	http://dx.doi.org/10.1109/70.938381													WOS:000170307300001
J	Murphy, CM; Haugh, MG; O'Brien, FJ				Murphy, Ciaral M.; Haugh, Matthew G.; O'Brien, Fergal J.			The effect of mean pore size on cell attachment, proliferation and migration in collagen-glycosaminoglycan scaffolds for bone tissue engineering	BIOMATERIALS												In the literature there are conflicting reports on the optimal scaffold mean pore size required for successful bone tissue engineering. This study set out to investigate the effect of mean pore size, in a series of collagen-glycosaminoglycan (CG) scaffolds with mean pore sizes ranging from 85 mu m to 325 mu m, on osteoblast adhesion and early stage proliferation up to 7 days post-seeding. The results show that cell number was highest in scaffolds with the largest pore size of 325 mu m. However, an early additional peak in cell number was also seen in scaffolds with a mean pore size of 120 mu m at time points up to 48 h post-seeding. This is consistent with previous studies from our laboratory which suggest that scaffold specific surface area plays an important role on initial cell adhesion. This early peak disappears following cell proliferation indicating that while specific surface area may be important for initial cell adhesion, improved cell migration provided by scaffolds with pores above 300 mu m overcomes this effect. An added advantage of the larger pores is a reduction in cell aggregations that develop along the edges of the scaffolds. Ultimately scaffolds with a mean pore size of 325 mu m were deemed optimal for bone tissue engineering. (C) 2009 Elsevier Ltd. All rights reserved.					murphy, ciara/JKI-3456-2023; O'Brien, Fergal/F-9485-2011	O'Brien, Fergal/0000-0003-2030-8005; Murphy, Ciara/0000-0002-9653-5477; Haugh, Matthew/0000-0003-4904-3127													0142-9612	1878-5905				JAN	2010	31	3					461	466		10.1016/j.biomaterials.2009.09.063	http://dx.doi.org/10.1016/j.biomaterials.2009.09.063								19819008					WOS:000272739200010
J	Lopes, JAP; Moreira, CL; Madureira, AG				Lopes, JAP; Moreira, CL; Madureira, AG			Defining control strategies for microgrids islanded operation	IEEE TRANSACTIONS ON POWER SYSTEMS												This paper describes and evaluates the feasibility of control strategies to be adopted for the operation of a microgrid when it becomes isolated. Normally, the microgrid operates in interconnected mode with the medium voltage network; however, scheduled or forced isolation can take place. In such conditions, the microgrid must have the ability to operate stably and autonomously. An evaluation of the need of storage devices and load shedding strategies is included in this paper.					Moreira, Carlos/AAO-9057-2020; Lopes, J./AAH-4416-2019; Moreira, Carlos/K-2358-2015; Madureira, Andre/J-2660-2013	Moreira, Carlos/0000-0001-9108-4921; Pecas Lopes, Joao Abel/0000-0001-7638-1522; Madureira, Andre/0000-0003-1817-102X													0885-8950	1558-0679				MAY	2006	21	2					916	924		10.1109/TPWRS.2006.873018	http://dx.doi.org/10.1109/TPWRS.2006.873018													WOS:000237313000052
J	Haimovich, AM; Blum, RS; Cimini, LJ				Haimovich, Alexander M.; Blum, Rick S.; Cimini, Leonard J., Jr.			MIMO radar with widely separated antennas	IEEE SIGNAL PROCESSING MAGAZINE												MIMO (multiple-input multiple-output) radar refers to an architecture that employs multiple, spatially distributed transmitters and receivers. While, in a general sense, MIMO radar can be viewed as a type of multistatic radar, the separate nomenclature suggests unique features that set MIMO radar apart from the multistatic radar literature and that have a close relation to MIMO communications. This article reviews some recent work on MIMO radar with widely separated antennas. Widely separated transmit/receive antennas capture the spatial diversity of the target's radar cross section (RCS). Unique features of MIMO radar are explained and illustrated by examples. It is shown that with noncoherent processing, a target's RCS spatial variations can be exploited to obtain a diversity gain for target detection and for estimation of various parameters, such as angle of arrival and Doppler. For target location, it is shown that coherent processing can provide a resolution far exceeding that supported by the radar's waveform.						Blum, Rick S/0000-0002-1024-6771													1053-5888	1558-0792				JAN	2008	25	1					116	129		10.1109/MSP.2008.4408448	http://dx.doi.org/10.1109/MSP.2008.4408448													WOS:000251906900015
J	Soref, R				Soref, Richard			The past, present, and future of silicon photonics	IEEE JOURNAL OF SELECTED TOPICS IN QUANTUM ELECTRONICS												The pace of the development of silicon photonics has quickened since 2004 due to investment by industry and government. Commercial state-of-the-art CMOS silicon-on-insulator (SOI) foundries are now being utilized in a crucial test of 1.55-mu m monolithic optoelectronic (OE) integration, a test sponsored by the Defense Advanced Research Projects Agency (DARPA). The preliminary results indicate that the silicon photonics are truly CMOS compatible. R&D groups have now developed 10-100-Gb/s electro-optic modulators, ultrafast Ge-on-Si photodetectors, efficient fiber-to-waveguide couplers, and Si Raman lasers. Electrically pumped silicon lasers are under intense investigation, with several approaches being tried; however, lasing has not yet been attained. The new paradigm for the Si-based photonic and optoelectric integrated circuits is that these chip-scale networks, when suitably designed, will operate at a wavelength anywhere within the broad spectral range of 1.2-100 mu m, with cryocooling needed in some cases.						Soref, Richard/0000-0001-7303-7056													1077-260X	1558-4542				NOV-DEC	2006	12	6	2				1678	1687		10.1109/JSTQE.2006.883151	http://dx.doi.org/10.1109/JSTQE.2006.883151													WOS:000243013700046
J	Liao, TW				Liao, TW			Clustering of time series data - a survey	PATTERN RECOGNITION												Time series clustering has been shown effective in providing useful information in various domains. There seems to be an increased interest in time series clustering as part of the effort in temporal data mining research. To provide an overview, this paper surveys and summarizes previous works that investigated the clustering of time series data in various application domains. The basics of time series clustering are presented, including general-purpose clustering algorithms commonly used in time series clustering studies, the criteria for evaluating the performance of the clustering results, and the measures to determine the similarity/dissimilarity between two time series being compared, either in the forms of raw data, extracted features, or some model parameters. The past researchs are organized into three groups depending upon whether they work directly with the raw data either in the time or frequency domain, indirectly with features extracted from the raw data, or indirectly with models built from the raw data. The uniqueness and limitation of previous research are discussed and several possible topics for future research are identified. Moreover, the areas that time series clustering have been applied to are also summarized, including the sources of data used. It is hoped that this review will serve as the steppingstone for those interested in advancing this area of research. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.					Liao, Thunshun/B-2724-2009	Liao, Thunshun/0000-0001-5018-8898													0031-3203	1873-5142				NOV	2005	38	11					1857	1874		10.1016/j.patcog.2005.01.025	http://dx.doi.org/10.1016/j.patcog.2005.01.025													WOS:000232113000006
J	Engel, J; Koltun, V; Cremers, D				Engel, Jakob; Koltun, Vladlen; Cremers, Daniel			Direct Sparse Odometry	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Direct Sparse Odometry (DSO) is a visual odometry method based on a novel, highly accurate sparse and direct structure and motion formulation. It combines a fully direct probabilistic model (minimizing a photometric error) with consistent, joint optimization of all model parameters, including geometry-represented as inverse depth in a reference frame-and camera motion. This is achieved in real time by omitting the smoothness prior used in other direct methods and instead sampling pixels evenly throughout the images. Since our method does not depend on keypoint detectors or descriptors, it can naturally sample pixels from across all image regions that have intensity gradient, including edges or smooth intensity variations on essentially featureless walls. The proposed model integrates a full photometric calibration, accounting for exposure time, lens vignetting, and non linear response functions. We thoroughly evaluate our method on three different datasets comprising several hours of video. The experiments show that the presented approach significantly outperforms state-of-the-art direct and indirect methods in a variety of real-world settings, both in terms of tracking accuracy and robustness.						Cremers, Daniel/0000-0002-3079-7984													0162-8828	1939-3539				MAR	2018	40	3					611	625		10.1109/TPAMI.2017.2658577	http://dx.doi.org/10.1109/TPAMI.2017.2658577								28422651					WOS:000424465900008
J	Ragaert, K; Delva, L; Van Geem, K				Ragaert, Kim; Delva, Laurens; Van Geem, Kevin			Mechanical and chemical recycling of solid plastic waste	WASTE MANAGEMENT												This review presents a comprehensive description of the current pathways for recycling of polymers, via both mechanical and chemical recycling. The principles of these recycling pathways are framed against current-day industrial reality, by discussing predominant industrial technologies, design strategies and recycling examples of specific waste streams. Starting with an overview on types of solid plastic waste (SPW) and their origins, the manuscript continues with a discussion on the different valorisation options for SPW. The section on mechanical recycling contains an overview of current sorting technologies, specific challenges for mechanical recycling such as thermo-mechanical or lifetime degradation and the immiscibility of polymer blends. It also includes some industrial examples such as polyethylene terephthalate (PET) recycling, and SPW from post-consumer packaging, end-of-life vehicles or electr(on)ic devices. A separate section is dedicated to the relationship between design and recycling, emphasizing the role of concepts such as Design from Recycling. The section on chemical recycling collects a state-of-the-art on techniques such as chemolysis, pyrolysis, fluid catalytic cracking, hydrogen techniques and gasification. Additionally, this review discusses the main challenges (and some potential remedies) to these recycling strategies and ground them in the relevant polymer science, thus providing an academic angle as well as an applied one. (C) 2017 Elsevier Ltd. All rights reserved.					; Van Geem, Kevin/J-3294-2014	Delva, Laurens/0000-0001-5845-066X; ragaert, kim/0000-0002-1498-6785; Van Geem, Kevin/0000-0003-4191-4960													0956-053X	1879-2456				NOV	2017	69						24	58		10.1016/j.wasman.2017.07.044	http://dx.doi.org/10.1016/j.wasman.2017.07.044								28823699					WOS:000414818000004
J	Robinson, J; Rahmat-Samii, Y				Robinson, J; Rahmat-Samii, Y			Particle swarm optimization in electromagnetics	IEEE TRANSACTIONS ON ANTENNAS AND PROPAGATION												The particle swarm optimization (PSO), new to the electromagnetics community, is a robust stochastic evolutionary computation technique based on the movement and intelligence of swarms. This paper introduces a conceptual overview and detailed explanation of the PSO algorithm, as well as how it can be used for electromagnetic optimizations. This paper also presents several results illustrating the swarm behavior in a PSO algorithm developed by the authors at UCLA specifically for engineering optimizations (UCLA-PSO). Also discussed is recent progress in the development of the PSO and the special considerations needed for engineering implementation including suggestions for the selection of parameter values. Additionally, a study of boundary conditions is presented indicating the invisible wall technique outperforms absorbing and reflecting wall techniques. These concepts are then integrated into a representative example of optimization of a profiled corrugated horn antenna.																			0018-926X	1558-2221				FEB	2004	52	2					397	407		10.1109/TAP.2004.823969	http://dx.doi.org/10.1109/TAP.2004.823969													WOS:000220615800005
J	Zhang, K; Zuo, WM; Zhang, L				Zhang, Kai; Zuo, Wangmeng; Zhang, Lei			FFDNet: Toward a Fast and Flexible Solution for CNN-Based Image Denoising	IEEE TRANSACTIONS ON IMAGE PROCESSING												Due to the fast inference and good performance, discriminative learning methods have been widely studied in image denoising. However, these methods mostly learn a specific model for each noise level, and require multiple models for denoising images with different noise levels. They also lack flexibility to deal with spatially variant noise, limiting their applications in practical denoising. To address these issues, we present a fast and flexible denoising convolutional neural network, namely FFDNet, with a tunable noise level map as the input. The proposed FFDNet works on downsampled sub-images, achieving a good trade-off between inference speed and denoising performance. In contrast to the existing discriminative denoisers, FFDNet enjoys several desirable properties, including: 1) the ability to handle a wide range of noise levels (i.e., [0, 75]) effectively with a single network; 2) the ability to remove spatially variant noise by specifying a non-uniform noise level map; and 3) faster speed than benchmark BM3D even on CPU without sacrificing denoising performance. Extensive experiments on synthetic and real noisy images are conducted to evaluate FFDNet in comparison with state-of-the-art denoisers. The results show that FFDNet is effective and efficient, making it highly attractive for practical denoising applications.					Zhang, Lei/P-8881-2014; Zhang, Kai/ABF-3950-2020; Zuo, Wangmeng/B-3701-2008	Zuo, Wangmeng/0000-0002-3330-783X; Zhang, Kai/0000-0002-6319-3722; Zhang, Lei/0000-0002-2078-4215													1057-7149	1941-0042				SEP	2018	27	9					4608	4622		10.1109/TIP.2018.2839891	http://dx.doi.org/10.1109/TIP.2018.2839891								29993717					WOS:000436462700001
J	Starck, JL; Candès, EJ; Donoho, DL				Starck, JL; Candès, EJ; Donoho, DL			The curvelet transform for image denoising	IEEE TRANSACTIONS ON IMAGE PROCESSING												We describe approximate digital implementations of two new mathematical transforms, namely. the ridgelet transform [2] and the curvelet transform [6], [5]. Our implementations offer exact reconstruction, stability against perturbations, ease of implementation, and low computational complexity. A central tool is Fourier-domain computation of an approximate digital Radon transform. We introduce a very simple interpolation in Fourier space which takes Cartesian samples and yields samples on a rectopolar grid, which is a pseudo-polar sampling set based on a concentric squares geometry. Despite the crudeness of our interpolation, the visual performance is surprisingly good. Our ridgelet transform applies to the Radon transform a special overcomplete wavelet pyramid whose wavelets have compact support in the frequency domain. Our curvelet transform uses our ridgelet transform as a component step, and implements curvelet subbands using a filter bank of a trous wavelet filters. Our philosophy throughout is that transforms should be overcomplete, rather than critically sampled. We apply these digital transforms to the denoising of some standard images embedded in white noise. In the tests reported here, simple thresholding of the curvelet coefficients is very competitive with "state of the art" techniques based on wavelets, including thresholding of decimated or undecimated wavelet transforms and also including tree-based Bayesian posterior mean methods. Moreover, the curvelet reconstructions exhibit higher perceptual quality than wavelet-based reconstructions, offering visually sharper images and, in particular, higher quality recovery of edges and of faint linear and curvilinear features. Existing theory for curvelet and ridgelet transforms suggests that these new approaches can outperform wavelet methods in certain image reconstruction problems. The empirical results reported here are in encouraging agreement.					Starck, Jean-Luc/D-9467-2011	Starck, Jean-Luc/0000-0003-2177-7794													1057-7149					JUN	2002	11	6					670	684	PII S1057-7149(02)01734-7	10.1109/TIP.2002.1014998	http://dx.doi.org/10.1109/TIP.2002.1014998								18244665					WOS:000176533400009
J	Li, XY; Yang, SF				Li, X. Y.; Yang, S. F.			Influence of loosely bound extracellular polymeric substances (EPS) on the flocculation, sedimentation and dewaterability of activated sludge	WATER RESEARCH												Laboratory experiments on the activated sludge (AS) process were carried out to investigate the influence of microbial extracellular polymeric substances (EPS), including loosely bound EPS (LB-EPS) and tightly bound EPS (TB-EPS), on biomass flocculation, sludge settlement and dewaterability. The heat EPS extraction method was modified to include a mild step and a harsh step for extracting the LB-EPS and TB-EPS, respectively, from the sludge suspension. Six lab-scale AS reactors were used to grow AS with different carbon sources of glucose and sodium acetate, and different sludge retention times (SRTs) of 5, 10 and 20 days. The variation in the bioreactor condition produced sludge with different abundances of EPS and different flocculation and separation characteristics. The sludge that was fed on glucose had more EPS than the sludge that was fed on acetate. For any of the feeding substrates, the sludge had a nearly consistent TB-EPS value regardless of the SRT, and an LB-EPS content that decreased with the SRT. The acetate-fed sludge performed better than the glucose-fed sludge in terms of bioflocculation, sludge sedimentation and compression, and sludge dewaterability. The sludge flocculation and separation improved considerably as the SRT lengthened. The results demonstrate that the LB-EPS had a negative effect on bioflocculation and sludge-water separation. The parameters for the performance of sludge-water separation were much more closely correlated with the amount of LB-EPS than with the amount of TB-EPS. It is argued that although EPS is essential to sludge floc formation, excessive EPS in the form of LB-EPS could weaken cell attachment and the floc structure, resulting in poor bioflocculation, greater cell erosion and retarded sludge-water separation. (C) 2006 Elsevier Ltd. All rights reserved.					Li, Xiao-yan/C-1808-2009														0043-1354					MAR	2007	41	5					1022	1030		10.1016/j.watres.2006.06.037	http://dx.doi.org/10.1016/j.watres.2006.06.037								16952388					WOS:000246465400009
J	Potoff, JJ; Siepmann, JI				Potoff, JJ; Siepmann, JI			Vapor-liquid equilibria of mixtures containing alkanes, carbon dioxide, and nitrogen	AICHE JOURNAL												New force fields for carbon dioxide and nitrogen are introduced that quantitatively reproduce the vapor - liquid equilibria (VLE) of the neat systems and their mixtures with alkanes. In addition to the usual VLE calculations for pure CO2 and N-2, calculations of the binary mixtures with propane were used in the force-field development to achieve a good balance between dispersive and electrostatic (qundrupole- quadrupole) interactions. The transfer ability of the force fields was then assessed from calculations of the VLE for the binary mixtures with n-hexane, the binary mixture of CO2/N-2, and the ternary mixture of CO2/N-2/propane. The VLE calculations were carried out using configurational-bias Monte Carlo simulations in either the grand canonical ensemble with histogram-reweighting or in the Gibbs ensemble.					Potoff, Jeffrey/AAX-3660-2020	Potoff, Jeffrey/0000-0002-4421-8787													0001-1541	1547-5905				JUL	2001	47	7					1676	1682		10.1002/aic.690470719	http://dx.doi.org/10.1002/aic.690470719													WOS:000169952500018
J	Weir, A; Westerhoff, P; Fabricius, L; Hristovski, K; von Goetz, N				Weir, Alex; Westerhoff, Paul; Fabricius, Lars; Hristovski, Kiril; von Goetz, Natalie			Titanium Dioxide Nanoparticles in Food and Personal Care Products	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Titanium dioxide is a common additive in many food, personal care, and other consumer products used by people, which after use can enter the sewage system and, subsequently, enter the environment as treated effluent discharged to surface waters or biosolids applied to agricultural land, incinerated wastes, or landfill solids. This study quantifies the amount of titanium in common food products, derives estimates of human exposure to dietary (nano-) TiO2, and discusses the impact of the nanoscale fraction of TiO2 entering the environment. The foods with the highest content of TiO2 included candies, sweets, and chewing gums. Among personal care products, toothpastes and select sunscreens contained 1% to >10% titanium by weight. While some other cremes contained titanium, despite being colored white, most shampoos, deodorants, and shaving creams contained the lowest levels of titanium (<0.01 mu g/mg). For several high-consumption pharmaceuticals, the titanium content ranged from below the instrument detection limit (0.0001 mu g Ti/mg) to a high of 0.014 mu g Ti/mg. Electron microscopy and stability testing of food-grade TiO2 (E171) suggests that approximately 36% of the particles are less than 100 nm in at least one dimension and that it readily disperses in water as fairly stable colloids. However, filtration of water solubilized consumer products and personal care products indicated that less than 5% of the titanium was able to pass through 0.45 or 0.7 mu m pores. Two white paints contained 110 mu g Ti/mg while three sealants (i.e., prime coat paint) contained less titanium (25 to 40 mu g Ti/mg). This research showed that, while many white-colored products contained titanium, it was not a prerequisite. Although several of these product classes contained low amounts of titanium, their widespread use and disposal down the drain and eventually to wastewater treatment plants (WWTPs) deserves attention. A Monte Carlo human exposure analysis to TiO2 through foods identified children as having the highest exposures because TiO2 content of sweets is higher than other food products and that a typical exposure for a US adult may be on the order of 1 mg Ti per kilogram body weight per day. Thus, because of the millions of tons of titanium-based white pigment used annually, testing should focus on food-grade TiO2 (E171) rather than that adopted in many environmental health and safety tests (i.e., P25), which is used in much lower amounts in products less likely to enter the environment (e.g., catalyst supports, photocatalytic coatings).					Hristovski, Kiril/A-6758-2010; von Goetz, Natalie/AAC-8960-2022; Westerhoff, Paul/AAF-1850-2019														0013-936X					FEB 21	2012	46	4					2242	2250		10.1021/es204168d	http://dx.doi.org/10.1021/es204168d								22260395					WOS:000300465900037
J	Silling, SA; Askari, E				Silling, SA; Askari, E			A meshfree method based on the peridynamic model of solid mechanics	COMPUTERS & STRUCTURES					2nd MIT Conference on Computational Fluid and Solid Mechanics	JUN 17-20, 2003	MIT, CAMBRIDGE, MA	GM, HP, Compaq, Daimler Chrysler, Hyundai, Ford, MSC Software, Sgi, ESI Grp, Boeing, CINI, Texas Instruments, Fluent Inc, CFX, CFD Soc Canada, SIAM, Michelin, IACMAG, Adinan, Mecalog, Star CD, ALCAN, ANSYS Inc	MIT			An alternative theory of solid mechanics, known as the peridynamic theory, formulates problems in terms of integral equations rather than partial differential equations. This theory assumes that particles in a continuum interact with each other across a finite distance, as in molecular dynamics. Damage is incorporated in the theory at the level of these two-particle interactions, so localization and fracture occur as a natural outgrowth of the equation of motion and constitutive models. A numerical method for solving dynamic problems within the peridynamic theory is described. Accuracy and numerical stability are discussed. Examples illustrate the properties of the method for modeling brittle dynamic crack growth. (c) 2005 Elsevier Ltd. All rights reserved.																			0045-7949	1879-2243				JUN	2005	83	17-18					1526	1535		10.1016/j.compstruc.2004.11.026	http://dx.doi.org/10.1016/j.compstruc.2004.11.026													WOS:000230160600013
J	Joshi, SV; Drzal, LT; Mohanty, AK; Arora, S				Joshi, SV; Drzal, LT; Mohanty, AK; Arora, S			Are natural fiber composites environmentally superior to glass fiber reinforced composites?	COMPOSITES PART A-APPLIED SCIENCE AND MANUFACTURING					Annual Meeting of the American-Institute-of-Chemical-Engineers	NOV 03-08, 2002	INDIANAPOLIS, IN	Amer Inst Chem Engn				Natural fibers are emerging as low cost, lightweight and apparently environmentally superior alternatives to glass fibers in composites. We review select comparative life cycle assessment studies of natural fiber and glass fiber composites, and identify key drivers of their relative environmental performance. Natural fiber composites are likely to be environmentally superior to glass fiber composites in most cases for the following reasons: (1) natural fiber production has lower environmental impacts compared to glass fiber production; (2) natural fiber composites have higher fiber content for equivalent performance, reducing more polluting base polymer content; (3) the light-weight natural fiber composites improve fuel efficiency and reduce emissions in the use phase of the component, especially in auto applications; and (4) end of life incineration of natural fibers results in recovered energy and carbon credits. (C) 2003 Elsevier Ltd. All rights reserved.					Drzal, Lawrence/G-1494-2012; Joshi, Satish/AAI-2470-2020	Joshi, Satish/0000-0003-3748-6940													1359-835X	1878-5840					2004	35	3					371	376		10.1016/j.compositesa.2003.09.016	http://dx.doi.org/10.1016/j.compositesa.2003.09.016													WOS:000189219000011
J	Hassibi, B; Hochwald, BM				Hassibi, B; Hochwald, BM			How much training is needed in multiple-antenna wireless links?	IEEE TRANSACTIONS ON INFORMATION THEORY												Multiple-antenna wireless communication links promise very high data rates with low error probabilities, especially when the wireless channel response is known at the receiver. In practice, knowledge of the channel is often obtained by sending known training symbols to the receiver. We show how training affects the capacity of a fading channel-too little training and the channel is improperly learned, too much training and there is no time left for data transmission before the channel changes. We compute a lower bound on the capacity of a channel that is learned by training, and maximize the, bound as a function of the received signal-to-noise ratio (SNR), fading coherence time, and number of transmitter antennas. When the training and data powers are allowed to vary, we show that the optimal number of training symbols is equal to the number of transmit antennas-this number is also the smallest training interval length that guarantees meaningful estimates of the channel matrix. When the training and data powers are instead required to be equal, the optimal number of symbols may be larger than the number of antennas. We show that training-based schemes can be optimal at high SNR, but suboptimal at low SNR.					Hassibi, Babak/A-1314-2007														0018-9448	1557-9654				APR	2003	49	4					951	963		10.1109/TIT.2003.809594	http://dx.doi.org/10.1109/TIT.2003.809594													WOS:000182169400014
J	Cheng, G; Han, JW; Lu, XQ				Cheng, Gong; Han, Junwei; Lu, Xiaoqiang			Remote Sensing Image Scene Classification: Benchmark and State of the Art	PROCEEDINGS OF THE IEEE												Remote sensing image scene classification plays an important role in a wide range of applications and hence has been receiving remarkable attention. During the past years, significant efforts have been made to develop various data sets or present a variety of approaches for scene classification from remote sensing images. However, a systematic review of the literature concerning data sets and methods for scene classification is still lacking. In addition, almost all existing data sets have a number of limitations, including the small scale of scene classes and the image numbers, the lack of image variations and diversity, and the saturation of accuracy. These limitations severely limit the development of new approaches especially deep learning-based methods. This paper first provides a comprehensive review of the recent progress. Then, we propose a large-scale data set, termed "NWPU-RESISC45," which is a publicly available benchmark for REmote Sensing Image Scene Classification (RESISC), created by Northwestern Polytechnical University (NWPU). This data set contains 31 500 images, covering 45 scene classes with 700 images in each class. The proposed NWPU-RESISC45 1) is large-scale on the scene classes and the total image number; 2) holds big variations in translation, spatial resolution, viewpoint, object pose, illumination, background, and occlusion; and 3) has high within-class diversity and between-class similarity. The creation of this data set will enable the community to develop and evaluate various data-driven algorithms. Finally, several representative methods are evaluated using the proposed data set, and the results are reported as a useful baseline for future research.					Han, Junwei/AEX-0831-2022; Cheng, Gong/I-9551-2019	Cheng, Gong/0000-0001-5030-0683; Lu, Xiaoqiang/0000-0002-7037-5188													0018-9219	1558-2256				OCT	2017	105	10			SI		1865	1883		10.1109/JPROC.2017.2675998	http://dx.doi.org/10.1109/JPROC.2017.2675998													WOS:000411273300004
J	Ordóñez, FJ; Roggen, D				Ordonez, Francisco Javier; Roggen, Daniel			Deep Convolutional and LSTM Recurrent Neural Networks for Multimodal Wearable Activity Recognition	SENSORS												Human activity recognition (HAR) tasks have traditionally been solved using engineered features obtained by heuristic processes. Current research suggests that deep convolutional neural networks are suited to automate feature extraction from raw sensor inputs. However, human activities are made of complex sequences of motor movements, and capturing this temporal dynamics is fundamental for successful HAR. Based on the recent success of recurrent neural networks for time series domains, we propose a generic deep framework for activity recognition based on convolutional and LSTM recurrent units, which: (i) is suitable for multimodal wearable sensors; (ii) can perform sensor fusion naturally; (iii) does not require expert knowledge in designing features; and (iv) explicitly models the temporal dynamics of feature activations. We evaluate our framework on two datasets, one of which has been used in a public activity recognition challenge. Our results show that our framework outperforms competing deep non-recurrent networks on the challenge dataset by 4% on average; outperforming some of the previous reported results by up to 9%. Our results show that the framework can be applied to homogeneous sensor modalities, but can also fuse multimodal sensors to improve performance. We characterise key architectural hyperparameters' influence on performance to provide insights about their optimisation.						Roggen, Daniel/0000-0001-8033-6417														1424-8220				JAN	2016	16	1							115	10.3390/s16010115	http://dx.doi.org/10.3390/s16010115								26797612					WOS:000370679800049
J	Reddy, JN				Reddy, J. N.			Nonlocal theories for bending, buckling and vibration of beams	INTERNATIONAL JOURNAL OF ENGINEERING SCIENCE												Various available beam theories, including the Euler-Bernoulli, Timoshenko, Reddy, and Levinson beam theories, are reformulated using the nonlocal differential constitutive relations of Eringen. The equations of motion of the nonlocal theories are derived, and variational statements in terms of the generalized displacements are presented. Analytical solutions of bending, vibration and buckling are presented using the nonlocal theories to bring out the effect of the nonlocal behavior on deflections, buckling loads, and natural frequencies. The theoretical development as well as numerical solutions presented herein should serve as references for nonlocal theories of beams, plates, and shells. (C) 2007 Elsevier Ltd. All rights reserved.					Reddy, Junuthula/D-7737-2013	Reddy, Junuthula/0000-0002-9739-1639													0020-7225	1879-2197				FEB-AUG	2007	45	2-8					288	307		10.1016/j.ijengsci.2007.04.004	http://dx.doi.org/10.1016/j.ijengsci.2007.04.004													WOS:000249109900008
J	Zhao, R; Yan, RQ; Chen, ZH; Mao, KZ; Wang, P; Gao, RX				Zhao, Rui; Yan, Ruqiang; Chen, Zhenghua; Mao, Kezhi; Wang, Peng; Gao, Robert X.			Deep learning and its applications to machine health monitoring	MECHANICAL SYSTEMS AND SIGNAL PROCESSING												Since 2006, deep learning (DL) has become a rapidly growing research direction, redefining state-of-the-art performances in a wide range of areas such as object recognition, image segmentation, speech recognition and machine translation. In modern manufacturing systems, data-driven machine health monitoring is gaining in popularity due to the widespread deployment of low-cost sensors and their connection to the Internet. Meanwhile, deep learning provides useful tools for processing and analyzing these big machinery data. The main purpose of this paper is to review and summarize the emerging research work of deep learning on machine health monitoring. After the brief introduction of deep learning techniques, the applications of deep learning in machine health monitoring systems are reviewed mainly from the following aspects: Auto-encoder (AE) and its variants, Restricted Boltzmann Machines and its variants including Deep Belief Network (DBN) and Deep Boltzmann Machines (DBM), Convolutional Neural Networks (CNN) and Recurrent Neural Networks (RNN). In addition, an experimental study on the performances of these approaches has been conducted, in which the data and code have been online. Finally, some new trends of DL-based machine health monitoring methods are discussed. (C) 2018 Elsevier Ltd. All rights reserved.					Gao, Robert/O-9339-2014; Mao, Kezhi/A-5025-2011; Chen, Zhenghua/I-1937-2018; Yan, Ruqiang/A-9776-2012; zhao, rui/AAD-1562-2020	Yan, Ruqiang/0000-0002-1250-4084; Mao, Kezhi/0000-0002-9191-8604													0888-3270	1096-1216				JAN 15	2019	115						213	237		10.1016/j.ymssp.2018.05.050	http://dx.doi.org/10.1016/j.ymssp.2018.05.050													WOS:000447085500015
J	Zhang, Y; Huo, MR; Zhou, JP; Xie, SF				Zhang, Yong; Huo, Meirong; Zhou, Jianping; Xie, Shaofei			PKSolver: An add-in program for pharmacokinetic and pharmacodynamic data analysis in Microsoft Excel	COMPUTER METHODS AND PROGRAMS IN BIOMEDICINE												This study presents PKSolver, a freely available menu-driven add-in program for Microsoft Excel written in Visual Basic for Applications (VBA), for solving basic problems in pharmacokinetic (PK) and pharmacodynamic (PD) data analysis. The program provides a range of modules for PK and PD analysis including noncompartmental analysis (NCA), compartmental analysis (CA), and pharmacodynamic modeling. Two special built-in modules, multiple absorption sites (MAS) and enterohepatic circulation (EHC), were developed for fitting the double-peak concentration-time profile based on the classical one-compartment model. In addition, twenty frequently used pharmacokinetic functions were encoded as a macro and can be directly accessed in an Excel spreadsheet. To evaluate the program, a detailed comparison of modeling PK data using PKSolver and professional PK/PD software package WinNonlin and Scientist was performed. The results showed that the parameters estimated with PKSolver were satisfactory. In conclusion, the PKSolver simplified the PK and PD data analysis process and its output could be generated in Microsoft Word in the form of an integrated report. The program provides pharmacokinetic researchers with a fast and easy-to-use tool for routine and basic PK and PD data analysis with a more user-friendly interface. (C) 2010 Elsevier Ireland Ltd. All rights reserved.																			0169-2607	1872-7565				SEP	2010	99	3					306	314		10.1016/j.cmpb.2010.01.007	http://dx.doi.org/10.1016/j.cmpb.2010.01.007								20176408					WOS:000281337700008
J	Liu, H; Logan, BE				Liu, H; Logan, BE			Electricity generation using an air-cathode single chamber microbial fuel cell in the presence and absence of a proton exchange membrane	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Microbial fuel cells (MFCs) are typically designed as a two-chamber system with the bacteria in the anode chamber separated from the cathode chamber by a polymeric proton exchange membrane (PEM). Most MFCs use aqueous cathodes where water is bubbled with air to provide dissolved oxygen to electrode. To increase energy output and reduce the cost of MFCs, we examined power generation in an air-cathode MFC containing carbon electrodes in the presence and absence of a polymeric proton exchange membrane (PEM). Bacteria present in domestic wastewater were used as the biocatalyst, and glucose and wastewater were tested as substrates. Power density was found to be much greater than typically reported for aqueous-cathode MFCs, reaching a maximum of 262 +/- 10 mW/m(2) (6.6 +/- 0.3 mW/L; liquid volume) using glucose. Removing the PEM increased the maximum power density to 494 +/- 21 mW/m(2) (12.5 +/- 0.5 mW/L). Coulombic efficiency was 40-55% with the PEM and 9-12% with the PEM removed, indicating substantial oxygen diffusion into the anode chamber in the absence of the PEM. Power output increased with glucose concentration according to saturation-type kinetics, with a half saturation constant of 79 mg/L with the PEM-MFC and 103 mg/L in the MFC without a PEM (1000 Omega resistor). Similar results on the effect of the PEM on power density were found using wastewater, where 28 +/- 3 mW/m(2) (0.7 +/- 0.1 mW/L) (28% Coulombic efficiency) was produced with the PEM, and 146 +/- 8 mW/m(2) (3.7 +/- 0.2 mW/L) (20% Coulombic efficiency) was produced when the PEM was removed. The increase in power output when a PEM was removed was attributed to a higher cathode potential as shown by an increase in the open circuit potential. An analysis based on available anode surface area and maximum bacterial growth rates suggests that mediatorless MFCs may have an upper order-of-magnitude limit in power density of 10(3) mW/m(2). A cost-effective approach to achieving power densities in this range will likely require systems that do not contain a polymeric PEM in the MFC and systems based on direct oxygen transfer to a carbon cathode.					Logan, Bruce/E-7063-2012; Liu, Hong/D-5012-2009														0013-936X	1520-5851				JUL 15	2004	38	14					4040	4046		10.1021/es0499344	http://dx.doi.org/10.1021/es0499344								15298217					WOS:000222670700039
J	Ho, T; Médard, M; Koetter, R; Karger, DR; Effros, M; Shi, J; Leong, B				Ho, Tracey; Medard, Muriel; Koetter, Ralf; Karger, David R.; Effros, Michelle; Shi, Jun; Leong, Ben			A random linear network coding approach to multicast	IEEE TRANSACTIONS ON INFORMATION THEORY												We present a distributed random linear network coding approach for transmission and compression of information in general multisource multicast networks. Network nodes independently and randomly select linear mappings from inputs onto output links over some field. We show that this achieves capacity with probability exponentially approaching I with the code length. We also demonstrate that random linear coding performs compression when necessary in a network, generalizing error exponents for linear Slepian-Wolf coding in a natural way. Benefits of this approach are decentralized operation and robustness to network changes or link failures. We show that this approach can take advantage of redundant network capacity for improved success probability and robustness. We illustrate some potential advantages of random linear network coding over routing in two examples of practical scenarios: distributed network operation and networks with dynamically varying connections. Our derivation of these results also yields a new bound on required field size for centralized network coding on general multicast networks.					Leong, Ben/M-9269-2019	Leong, Ben/0000-0003-1738-5958; Karger, David/0000-0002-0024-5847													0018-9448	1557-9654				OCT	2006	52	10					4413	4430		10.1109/TIT.2006.881746	http://dx.doi.org/10.1109/TIT.2006.881746													WOS:000240776500005
J	Beven, K; Freer, J				Beven, K; Freer, J			Equifinality, data assimilation, and uncertainty estimation in mechanistic modelling of complex environmental systems using the GLUE methodology	JOURNAL OF HYDROLOGY												It may be endemic to mechanistic modelling of complex environmental systems that there are many different model structures and many different parameter sets within a chosen model structure that may be behavioural or acceptable in reproducing the observed behaviour of that system. This has been called the equifinality concept. The generalised likelihood uncertainty estimation (GLUE) methodology for model identification allowing for equifinality is described. Prediction within this methodology is a process of ensemble forecasting using a sample of parameter sets from the behavioural model space, with each sample weighted according to its likelihood measure to estimate prediction quantiles. This allows that different models may contribute to the ensemble prediction interval at different time steps and that the distributional form of the predictions may change over time. Any effects of model nonlinearity, covariation of parameter values and errors in model structure, input data or observed variables, with which the simulations are compared, are handled implicitly within this procedure. GLUE involves a number of choices that must be made explicit and can be therefore subjected to scrutiny and discussion. These include ways of combining information from different types of model evaluation or from different periods in a data assimilation context. An example application to rainfall-runoff modelling is used to illustrate the methodology, including the updating of likelihood measures. (C) 2001 Elsevier Science B.V. All rights reserved.					Beven, Keith/F-8707-2011; Faybishenko, Boris/G-3363-2015; Freer, Jim/C-7335-2009	Faybishenko, Boris/0000-0003-0085-8499; Freer, Jim/0000-0001-6388-7890													0022-1694	1879-2707				AUG 1	2001	249	1-4					11	29		10.1016/S0022-1694(01)00421-8	http://dx.doi.org/10.1016/S0022-1694(01)00421-8													WOS:000170092400003
J	Cornell, CA; Jalayer, F; Hamburger, RO; Foutch, DA				Cornell, CA; Jalayer, F; Hamburger, RO; Foutch, DA			Probabilistic basis for 2000 SAC Federal Emergency Management Agency steel moment frame guidelines	JOURNAL OF STRUCTURAL ENGINEERING												This paper presents a formal probabilistic framework for seismic design and assessment of structures and its application to steel moment-resisting frame buildings. This is the probabilistic basis for the 2000 SAC Federal Emergency Management Agency (FEMA) steel moment frame guidelines. The framework is based on realizing a performance objective expressed as the probability of exceeding a specified performance level. Performance levels are quantified as expressions relating generic structural variables "demand" and "capacity" that are described by nonlinear, dynamic displacements of the structure. Common probabilistic analysis tools are used to convolve both the randomness and uncertainty characteristics of ground motion intensity, structural "demand," and structural system "capacity" in order to derive an expression for the probability of achieving the specified performance level. Stemming from this probabilistic framework, a safety-checking for-mat of the conventional "load and resistance factor" kind is developed with load and resistance terms being replaced by the more generic terms "demand" and "capacity," respectively. This framework also allows for a peformance objective being met. This format has been format based on quantitative confidence statements regarding the likelihood of the performance objective being met. This format has been adopted in the SAC/FEMA guidelines.					JALAYER, Fatemeh/A-9284-2012	JALAYER, Fatemeh/0000-0002-7580-8309													0733-9445	1943-541X				APR	2002	128	4					526	533		10.1061/(ASCE)0733-9445(2002)128:4(526)	http://dx.doi.org/10.1061/(ASCE)0733-9445(2002)128:4(526)													WOS:000174957100014
J	Malinowski, M; Gopakumar, K; Rodriguez, J; Pérez, MA				Malinowski, Mariusz; Gopakumar, K.; Rodriguez, Jose; Perez, Marcelo A.			A Survey on Cascaded Multilevel Inverters	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS												Cascaded multilevel inverters synthesize a medium-voltage output based on a series connection of power cells which use standard low-voltage component configurations. This characteristic allows one to achieve high-quality output voltages and input currents and also outstanding availability due to their intrinsic component redundancy. Due to these features, the cascaded multilevel inverter has been recognized as an important alternative in the medium-voltage inverter market. This paper presents a survey of different topologies, control strategies and modulation techniques used by these inverters. Regenerative and advanced topologies are also discussed. Applications where the mentioned features play a key role are shown. Finally, future developments are addressed.					Perez, Marcelo/E-9076-2012; Rodriguez, Jose/A-2534-2013; Malinowski, Mariusz/J-4260-2018	Perez, Marcelo/0000-0003-4166-448X; Rodriguez, Jose/0000-0002-1410-4121; Malinowski, Mariusz/0000-0002-4697-8261													0278-0046	1557-9948				JUL	2010	57	7					2197	2206		10.1109/TIE.2009.2030767	http://dx.doi.org/10.1109/TIE.2009.2030767													WOS:000278811000002
J	Bao, YB; Wierzbicki, T				Bao, YB; Wierzbicki, T			On fracture locus in the equivalent strain and stress triaxiality space	INTERNATIONAL JOURNAL OF MECHANICAL SCIENCES												The stress triaxiality is, besides the strain intensity, the most important factor that controls initiation of ductile fracture. In this study, a series of tests including upsetting tests, shear tests and tensile tests on 2024-T351 aluminum alloy providing clues to fracture ductility for a wide range of stress triaxiality was carried out. Numerical simulations of each test was performed using commercial finite element code ABAQUS. Good correlation of experiments and numerical simulations was achieved. Based on the experimental and numerical results, the relation between the equivalent strain to fracture versus the stress triaxiality was quantified and it was shown that there are three distinct branches of this function with possible slope discontinuities in the transition regime. For negative stress triaxialities, fracture is governed by shear mode. For large triaxialities void growth is the dominant failure mode, while at low stress triaxialities between above two regimes, fracture may develop as a combination of shear and void growth modes. (C) 2004 Elsevier Ltd. All rights reserved.																			0020-7403	1879-2162				JAN	2004	46	1					81	98		10.1016/j.ijmecsci.2004.02.006	http://dx.doi.org/10.1016/j.ijmecsci.2004.02.006													WOS:000221484200005
J	Zhao, FJ; Ma, YB; Zhu, YG; Tang, Z; McGrath, SP				Zhao, Fang-Jie; Ma, Yibing; Zhu, Yong-Guan; Tang, Zhong; McGrath, Steve P.			Soil Contamination in China: Current Status and Mitigation Strategies	ENVIRONMENTAL SCIENCE & TECHNOLOGY												China faces great challenges in protecting its soil from contamination caused by rapid industrialization and urbanization over the last three decades. Recent nationwide surveys show that 16% of the soil samples, 19% for the agricultural soils, are contaminated based on Chinas soil environmental quality limits, mainly with heavy metals and metalloids. Comparisons with other regions of the world show that the current status of soil contamination, based on the total contaminant concentrations, is not worse in China. However, the concentrations of some heavy metals in Chinese soils appear to be increasing at much greater rates. Exceedance of the contaminant limits in food crops is widespread in some areas, especially southern China, due to elevated inputs of contaminants, acidic nature of the soil and crop species or cultivars prone to heavy metal accumulation. Minimizing the transfer of contaminants from soil to the food chain is a top priority. A number of options are proposed, including identification of the sources of contaminants to agricultural systems, minimization of contaminant inputs, reduction of heavy metal phytoavailability in soil with liming or other immobilizing materials, selection and breeding of low accumulating crop cultivars, adoption of appropriate water and fertilizer management, bioremediation, and change of land use to grow nonfood crops. Implementation of these strategies requires not only technological advances, but also social-economic evaluation and effective enforcement of environmental protection law.					Zhu, Yong-Guan/A-1412-2009; Tang, Zhong/V-3737-2017; McGrath, Steve/B-5127-2008; Zhao, Fang-Jie/A-8339-2008	Tang, Zhong/0000-0002-1136-6687; Zhao, Fang-Jie/0000-0002-0164-169X; McGrath, Stephen/0000-0003-0952-8947; Zhu, Yong-Guan/0000-0003-3861-8482; Ma, Yibing/0000-0002-9340-8181													0013-936X	1520-5851				JAN 20	2015	49	2					750	759		10.1021/es5047099	http://dx.doi.org/10.1021/es5047099								25514502					WOS:000348332400008
J	Farsiu, S; Robinson, MD; Elad, M; Milanfar, P				Farsiu, S; Robinson, MD; Elad, M; Milanfar, P			Fast and robust multiframe super resolution	IEEE TRANSACTIONS ON IMAGE PROCESSING												Super-resolution reconstruction produces one or a set of high-resolution images from a set of low-resolution images. In the last two decades, a variety of super-resolution methods have been proposed. These methods are usually very sensitive to their assumed model of data and noise, which limits their utility. This paper reviews some of these methods and addresses their shortcomings. We propose an alternate approach using L-1 norm minimization and robust regularization based on a bilateral prior to deal with different data and noise models. This computationally inexpensive method is robust to errors in motion and blur estimation and results in images with sharp edges. Simulation results confirm the effectiveness of our method and demonstrate its superiority to other super-resolution methods.					, Miki/AAH-4640-2019; Milanfar, Peyman/B-2551-2009	Farsiu, Sina/0000-0003-4872-2902													1057-7149	1941-0042				OCT	2004	13	10					1327	1344		10.1109/TIP.2004.834669	http://dx.doi.org/10.1109/TIP.2004.834669								15462143					WOS:000223724500004
J	Liang, NY; Huang, GB; Saratchandran, P; Sundararajan, N				Liang, Nan-Ying; Huang, Guang-Bin; Saratchandran, P.; Sundararajan, N.			A fast and accurate online sequential learning algorithm for feedforward networks	IEEE TRANSACTIONS ON NEURAL NETWORKS												In this paper, we develop an online sequential learning algorithm for single hidden layer feedforward networks (SLFNs) with. additive or radial basis function (RBF) hidden nodes in a unified framework. The algorithm is referred to as online sequential extreme learning machine (OS-ELM) and can learn data one-by-one or chunk-by-chunk (a block of data) with fixed or varying chunk size. The activation functions for additive nodes in OS-ELM can be any bounded nonconstant piecewise continuous functions and the activation functions for RBF nodes can be any integrable piecewise continuous functions. In OS-ELM, the parameters of hidden nodes (the input weights and biases of additive nodes or the centers and impact factors of RBF nodes) are randomly selected and the output weights are analytically determined based on the sequentially arriving data. The algorithm uses the ideas of ELM of Huang et al. developed for batch learning which has been shown to be extremely fast with generalization performance better than other batch training methods. Apart from selecting the number of hidden nodes, no other control parameters have to be manually chosen. Detailed performance comparison of OS-ELM is done with other popular sequential learning algorithms on benchmark problems drawn from the regression, classification and time series prediction areas. The results show that the OS-ELM is faster than the other sequential algorithms and produces better generalization performance.					N, Sundararajan/O-7918-2018; Liang, Nanying/HGC-2099-2022; Huang, Guang-Bin/A-5035-2011; Huang, Guang-Bin/JZE-2974-2024	Huang, Guang-Bin/0000-0002-2480-4965; Liang, Nanying/0000-0003-1858-2582													1045-9227	1941-0093				NOV	2006	17	6					1411	1423		10.1109/TNN.2006.880583	http://dx.doi.org/10.1109/TNN.2006.880583								17131657					WOS:000241933100006
J	Qu, XL; Alvarez, PJJ; Li, QL				Qu, Xiaolei; Alvarez, Pedro J. J.; Li, Qilin			Applications of nanotechnology in water and wastewater treatment	WATER RESEARCH												Providing clean and affordable water to meet human needs is a grand challenge of the 21st century. Worldwide, water supply struggles to keep up with the fast growing demand, which is exacerbated by population growth, global climate change, and water quality deterioration. The need for technological innovation to enable integrated water management cannot be overstated. Nanotechnology holds great potential in advancing water and wastewater treatment to improve treatment efficiency as well as to augment water supply through safe use of unconventional water sources. Here we review recent development in nanotechnology for water and wastewater treatment. The discussion covers candidate nanomaterials, properties and mechanisms that enable the applications, advantages and limitations as compared to existing processes, and barriers and research needs for commercialization. By tracing these technological advances to the physicochemical properties of nanomaterials, the present review outlines the opportunities and limitations to further capitalize on these unique properties for sustainable water management. (C) 2013 Elsevier Ltd. All rights reserved.					Alvarez, Pedro/AAE-7216-2019; Li, Qilin/A-8970-2008	Alvarez, Pedro/0000-0002-6725-7199; Li, Qilin/0000-0001-5756-3873													0043-1354	1879-2448				AUG 1	2013	47	12			SI		3931	3946		10.1016/j.watres.2012.09.058	http://dx.doi.org/10.1016/j.watres.2012.09.058								23571110					WOS:000321084000008
J	Chen, M; Rincón-Mora, GA				Chen, Min; Rincon-Mora, Gabriel A.			Accurate electrical battery model capable of predicting, runtime and <i>I-V</i> performance	IEEE TRANSACTIONS ON ENERGY CONVERSION												Low power dissipation and maximum battery runtime are crucial in portable electronics. With accurate and efficient circuit and battery models in hand, circuit designers can predict and optimize battery runtime and circuit performance. In this paper, an accurate, intuitive, and comprehensive electrical battery model is proposed and implemented in a Cadence environment. This model accounts for all dynamic characteristics of the battery, from nonlinear open-circuit voltage, current-, temperature-, cycle number-, and storage time-dependent capacity to transient response. A simplified model neglecting the effects of self-discharge, cycle number, and temperature, which are nonconsequential in low-power Li-ion-supplied applications, is validated with experimental data on NiMH and polymer Li-ion batteries. Less than 0.4% runtime error and 30-mV maximum error voltage show that the proposed model predicts both the battery, runtime and I-V performance accurately. The model can also be easily extended to other battery and power sourcing technologies.																			0885-8969	1558-0059				JUN	2006	21	2					504	511		10.1109/TEC.2006.874229	http://dx.doi.org/10.1109/TEC.2006.874229													WOS:000237849800024
J	Featherman, MS; Pavlou, PA				Featherman, MS; Pavlou, PA			Predicting e-services adoption: a perceived risk facets perspective	INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES												Internet-delivered e-services are increasingly being made available to consumers; however, little is known about how consumers evaluate them for potential adoption. Past Technology Adoption Research has focused primarily on the positive utility gains attributable to system adoption. This research extends that approach to include measures of negative utility (potential losses) attributable to e-service adoption. Drawing from Perceived Risk Theory, specific risk facets were operationalized, integrated, and empirically tested within the Technology Acceptance Model resulting in a proposed e-services adoption model. Results indicated that e-services adoption is adversely affected primarily by performance-based risk perceptions, and perceived ease of use of the e-service reduced these risk concerns. Implications of integrating perceived risk into the proposed e-services adoption model are discussed. (C) 2003 Elsevier Ltd. All rights reserved.					Pavlou, Paul/D-3561-2014														1071-5819	1095-9300				OCT	2003	59	4					451	474		10.1016/S1071-5819(03)00111-3	http://dx.doi.org/10.1016/S1071-5819(03)00111-3													WOS:000185695700004
J	Falconer, D; Ariyavisitakul, SL; Benyamin-Seeyar, A; Eidson, B				Falconer, D; Ariyavisitakul, SL; Benyamin-Seeyar, A; Eidson, B			Frequency domain equalization for single-carrier broadband wireless systems	IEEE COMMUNICATIONS MAGAZINE												Broadband wireless access systems deployed in residential and business environments are likely to face hostile radio propagation environments, with multipath delay spread extending over tens or hundreds of bit intervals. Orthogonal frequency-division multiplex (OFDM) is a recognized multicarrier solution to combat the effects of such multipath conditions. This article surveys frequency domain equalization (FIDE) applied to single-carrier (SC) modulation solutions. SC radio modems with frequency domain equalization have similar performance, efficiency, and low signal processing complexity advantages as OFDM, and in addition are less sensitive than OFDM to RF impairments such as power amplifier nonlinearities. We discuss similarities and differences of SC and OFDM systems and coexistence possibilities, and present examples of SC-FDE performance capabilities.																			0163-6804					APR	2002	40	4					58	66		10.1109/35.995852	http://dx.doi.org/10.1109/35.995852													WOS:000174860600008
B	Lee, JS; Pottier, E	Lee, JS; Pottier, E			Lee, Jong-Sen; Pottier, Eric	Lee, JS; Pottier, E		Overview of Polarimetric Radar Imaging	POLARIMETRIC RADAR IMAGING: FROM BASICS TO APPLICATIONS	Optical Science and Engineering-CRC																																978-1-4200-5497-2				2009							1	30				10.1201/9781420054989												WOS:000267227600001
J	Lehner, B; Döll, P				Lehner, B; Döll, P			Development and validation of a global database of lakes, reservoirs and wetlands	JOURNAL OF HYDROLOGY												Drawing upon a variety of existing maps, data and information, a new Global Lakes and Wetlands Database (GLWD) has been created. The combination of best available sources for lakes and wetlands on a global scale (1: 1 to 1:3 million resolution), and the application of Geographic Information System (GIS) functionality enabled the generation of a database which focuses in three coordinated levels on (1) large lakes and reservoirs, (2) smaller water bodies, and (3) wetlands. Level 1 comprises the shoreline polygons of the 3067 largest lakes (surface area greater than or equal to50 km(2)) and 654 largest reservoirs (storage capacity greater than or equal to0.5 km(3)) worldwide, and offers extensive attribute data. Level 2 contains the shoreline polygons of approx. 250,000 smaller lakes, reservoirs and rivers (surface area; greater than or equal to0.1 km(2)), excluding all water bodies of level 1. Finally, level 3 represents lakes, reservoirs, rivers, and different wetland types in the form of a global raster map at 30-second resolution, including all water bodies of levels 1 and 2. In a validation against documented data, GLWD proved to represent a comprehensive database of global lakes 1 km(2) and to provide a good representation of the maximum global wetland extent. GLWD-1 and GLWD-2 establish two global polygon maps to which existing lake registers, compilations or remote sensing data can be linked in order to allow for further analyses in a GIS environment. GLWD-3 may serve as an estimate of wetland extents for global hydrology and climatology models, or to identify large-scale wetland distributions and important wetland complexes. (C) 2004 Elsevier B.V. All rights reserved.					Lehner, Bernhard/CAF-2153-2022; Doll, Petra/A-3784-2009	Doll, Petra/0000-0003-2238-4546; Lehner, Bernhard/0000-0003-3712-2581													0022-1694					AUG 20	2004	296	1-4					1	22		10.1016/j.jhydrol.2004.03.028	http://dx.doi.org/10.1016/j.jhydrol.2004.03.028													WOS:000223149300001
J	Tao, F; Zhan, H; Liu, A; Nee, AYC				Tao, Fei; Zhan, He; Liu, Ang; Nee, A. Y. C.			Digital Twin in Industry: State-of-the-Art	IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS												Digital twin (DT) is one of the most promising enabling technologies for realizing smart manufacturing and Industry 4.0. DTs are characterized by the seamless integration between the cyber and physical spaces. The importance of DTs is increasingly recognized by both academia and industry. It has been almost 15 years since the concept of the DT was initially proposed. To date, many DT applications have been successfully implemented in different industries, including product design, production, prognostics and health management, and some other fields. However, at present, no paper has focused on the review of DT applications in industry. In an effort to understand the development and application of DTs in industry, this paper thoroughly reviews the state-of-the-art of the DT research concerning the key components of DTs, the current development of DTs, and the major DT applications in industry. This paper also outlines the current challenges and some possible directions for future work.					Nee, Andrew, Y.C./C-9974-2009; Tao, Fei/F-8944-2012	Tao, Fei/0000-0002-9020-0633; Liu, Ang/0000-0001-9353-0948; Zhang, He/0000-0002-7630-2211; Nee, Andrew/0000-0002-1029-9988													1551-3203	1941-0050				APR	2019	15	4					2405	2415		10.1109/TII.2018.2873186	http://dx.doi.org/10.1109/TII.2018.2873186													WOS:000467095500054
J	Kenney, JB				Kenney, John B.			Dedicated Short-Range Communications (DSRC) Standards in the United States	PROCEEDINGS OF THE IEEE												Wireless vehicular communication has the potential to enable a host of new applications, the most important of which are a class of safety applications that can prevent collisions and save thousands of lives. The automotive industry is working to develop the dedicated short-range communication (DSRC) technology, for use in vehicle-to-vehicle and vehicle-to-roadside communication. The effectiveness of this technology is highly dependent on cooperative standards for interoperability. This paper explains the content and status of the DSRC standards being developed for deployment in the United States. Included in the discussion are the IEEE 802.11p amendment for wireless access in vehicular environments (WAVE), the IEEE 1609.2, 1609.3, and 1609.4 standards for Security, Network Services and Multi-Channel Operation, the SAE J2735 Message Set Dictionary, and the emerging SAE J2945.1 Communication Minimum Performance Requirements standard. The paper shows how these standards fit together to provide a comprehensive solution for DSRC. Most of the key standards are either recently published or expected to be completed in the coming year. A reader will gain a thorough understanding of DSRC technology for vehicular communication, including insights into why specific technical solutions are being adopted, and key challenges remaining for successful DSRC deployment. The U.S. Department of Transportation is planning to decide in 2013 whether to require DSRC equipment in new vehicles.																			0018-9219	1558-2256				JUL	2011	99	7					1162	1182		10.1109/JPROC.2011.2132790	http://dx.doi.org/10.1109/JPROC.2011.2132790													WOS:000291818900003
J	Browne, MA; Dissanayake, A; Galloway, TS; Lowe, DM; Thompson, RC				Browne, Mark A.; Dissanayake, Awantha; Galloway, Tamara S.; Lowe, David M.; Thompson, Richard C.			Ingested microscopic plastic translocates to the circulatory system of the mussel, <i>Mytilus edulis</i> (L.)	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Plastics debris is accumulating in the environment and is fragmenting into smaller pieces; as it does, the potential for ingestion by animals increases. The consequences of macroplastic debris for wildlife are well documented, however the impacts of microplastic (<1 mm) are poorly understood. The mussel, Mytilus edulis, was used to investigate ingestion, translocation, and accumulation of this debris. Initial experiments showed that upon ingestion, microplastic accumulated in the gut. Mussels were subsequently exposed to treatments containing seawater and microplastic (3.0 or 9.6 mu m). After transfer to clean microplastic was tracked in the hemolymph. Particles conditions, translocated from the gut to the circulatory system within 3 days and persisted for over 48 days. Abundance of microplastic was greatest after 12 days and declined thereafter. Smaller particles were more abundant than larger particles and our data indicate as plastic fragments into smaller particles, the potential for accumulation in the tissues of an organism increases. The short-term pulse exposure used here did not result in significant biological effects. However, plastics are exceedingly durable and so further work using a wider range of organisms, polymers, and periods of exposure will be required to establish the biological consequences of this debris.					Thompson, Richard/J-8879-2014; Dissanayake, Awantha/G-7017-2011; Galloway, Tamara/C-1662-2009	Galloway, Tamara/0000-0002-7466-6775; Dissanayake, Awantha/0000-0001-8758-8959; Thompson, Richard/0000-0003-2262-6621; Browne, Mark Anthony/0000-0002-7508-1015													0013-936X	1520-5851				JUL 1	2008	42	13					5026	5031		10.1021/es800249a	http://dx.doi.org/10.1021/es800249a								18678044					WOS:000257220600070
J	Wang, CX; Haider, F; Gao, XQ; You, XH; Yang, Y; Yuan, DF; Aggoune, HM; Haas, H; Fletcher, S; Hepsaydir, E				Wang, Cheng-Xiang; Haider, Fourat; Gao, Xiqi; You, Xiao-Hu; Yang, Yang; Yuan, Dongfeng; Aggoune, Hadi M.; Haas, Harald; Fletcher, Simon; Hepsaydir, Erol			Cellular Architecture and Key Technologies for 5G Wireless Communication Networks	IEEE COMMUNICATIONS MAGAZINE												The fourth generation wireless communication systems have been deployed or are soon to be deployed in many countries. However, with an explosion of wireless mobile devices and services, there are still some challenges that cannot be accommodated even by 4G, such as the spectrum crisis and high energy consumption. Wireless system designers have been facing the continuously increasing demand for high data rates and mobility required by new wireless applications and therefore have started research on fifth generation wireless systems that are expected to be deployed beyond 2020. In this article, we propose a potential cellular architecture that separates indoor and outdoor scenarios, and discuss various promising technologies for 5G wireless communication systems, such as massive MIMO, energy-efficient communications, cognitive radio networks, and visible light communications. Future challenges facing these potential technologies are also discussed.					Aggoune, Hadi/HRB-6520-2023; Yang, Yang/LRB-3113-2024; Haas, Harald/AAD-1660-2019; Gao, Xiqi/HZI-7015-2023; Wang, Cheng-Xiang/A-2233-2013; You, Xiaohu/ABH-3174-2021	Haas, Harald/0000-0001-9705-2701; Gao, Xiqi/0000-0001-9107-6593; Wang, Cheng-Xiang/0000-0002-9729-9592; You, Xiaohu/0000-0002-0809-8511													0163-6804	1558-1896				FEB	2014	52	2					122	130		10.1109/MCOM.2014.6736752	http://dx.doi.org/10.1109/MCOM.2014.6736752													WOS:000331904900015
J	Lawhern, VJ; Solon, AJ; Waytowich, NR; Gordon, SM; Hung, CP; Lance, BJ				Lawhern, Vernon J.; Solon, Amelia J.; Waytowich, Nicholas R.; Gordon, Stephen M.; Hung, Chou P.; Lance, Brent J.			EEGNet: a compact convolutional neural network for EEG-based brain-computer interfaces	JOURNAL OF NEURAL ENGINEERING												Objective. Brain-computer interfaces (BCI) enable direct communication with a computer, using neural activity as the control signal. This neural signal is generally chosen from a variety of well-studied electroencephalogram (EEG) signals. For a given BCI paradigm, feature extractors and classifiers are tailored to the distinct characteristics of its expected EEG control signal, limiting its application to that specific signal. Convolutional neural networks (CNNs), which have been used in computer vision and speech recognition to perform automatic feature extraction and classification, have successfully been applied to EEG-based BCIs; however, they have mainly been applied to single BCI paradigms and thus it remains unclear how these architectures generalize to other paradigms. Here, we ask if we can design a single CNN architecture to accurately classify EEG signals from different BCI paradigms, while simultaneously being as compact as possible. Approach. In this work we introduce EEGNet, a compact convolutional neural network for EEG-based BCIs. We introduce the use of depthwise and separable convolutions to construct an EEG-specific model which encapsulates well-known EEG feature extraction concepts for BCI. We compare EEGNet, both for within-subject and cross-subject classification, to current state-of-the-art approaches across four BCI paradigms: P300 visual-evoked potentials, error-related negativity responses (ERN), movement-related cortical potentials (MRCP), and sensory motor rhythms (SMR). Main results. We show that EEGNet generalizes across paradigms better than, and achieves comparably high performance to, the reference algorithms when only limited training data is available across all tested paradigms. In addition, we demonstrate three different approaches to visualize the contents of a trained EEGNet model to enable interpretation of the learned features. Significance. Our results suggest that EEGNet is robust enough to learn a wide variety of interpretable features over a range of BCI tasks. Our models can be found at: https://github.com/vlawhern/arl-eegmodels.																			1741-2560	1741-2552				OCT	2018	15	5							056013	10.1088/1741-2552/aace8c	http://dx.doi.org/10.1088/1741-2552/aace8c								29932424					WOS:000440075300003
J	Hopcroft, MA; Nix, WD; Kenny, TW				Hopcroft, Matthew A.; Nix, William D.; Kenny, Thomas W.			What is the Young's Modulus of Silicon?	JOURNAL OF MICROELECTROMECHANICAL SYSTEMS												The Young's modulus (E) of a material is a key parameter for mechanical engineering design. Silicon, the most common single material used in microelectromechanical systems (MEMS), is an anisotropic crystalline material whose material properties depend on orientation relative to the crystal lattice. This fact means that the correct value of E for analyzing two different designs in silicon may differ by up to 45%. However, perhaps, because of the perceived complexity of the subject, many researchers oversimplify silicon elastic behavior and use inaccurate values for design and analysis. This paper presents the best known elasticity data for silicon, both in depth and in a summary form, so that it may be readily accessible to MEMS designers. [2009-0054]						Hopcroft, Matthew/0000-0003-1340-930X													1057-7157	1941-0158				APR	2010	19	2					229	238		10.1109/JMEMS.2009.2039697	http://dx.doi.org/10.1109/JMEMS.2009.2039697													WOS:000276257700001
J	Silling, SA; Epton, M; Weckner, O; Xu, J; Askari, E				Silling, S. A.; Epton, M.; Weckner, O.; Xu, J.; Askari, E.			Peridynamic states and constitutive modeling	JOURNAL OF ELASTICITY												A generalization of the original peridynamic framework for solid mechanics is proposed. This generalization permits the response of a material at a point to depend collectively on the deformation of all bonds connected to the point. This extends the types of material response that can be reproduced by peridynamic theory to include an explicit dependence on such collectively determined quantities as volume change or shear angle. To accomplish this generalization, a mathematical object called a deformation state is defined, a function that maps any bond onto its image under the deformation. A similar object called a force state is defined, which contains the forces within bonds of all lengths and orientation. The relation between the deformation state and force state is the constitutive model for the material. In addition to providing a more general capability for reproducing material response, the new framework provides a means to incorporate a constitutive model from the conventional theory of solid mechanics directly into a peridynamic model. It also allows the condition of plastic incompressibility to be enforced in a peridynamic material model for permanent deformation analogous to conventional plasticity theory.																			0374-3535	1573-2681				AUG	2007	88	2					151	184		10.1007/s10659-007-9125-1	http://dx.doi.org/10.1007/s10659-007-9125-1													WOS:000248806300004
J	Grässel, O; Krüger, L; Frommeyer, G; Meyer, LW				Grässel, O; Krüger, L; Frommeyer, G; Meyer, LW			High strength Fe-Mn-(Al, Si) TRIP/TWIP steels development -: properties -: application	INTERNATIONAL JOURNAL OF PLASTICITY												Deformation twinning, martensitic phase transformation and mechanical properties of austenitic Fe-(15-30) wt.%Mn steels with additions of aluminium and silicon have been investigated. It is known that additions of aluminium increase the stacking fault energy gamma(fcc) and therefore strongly suppress the gamma --> epsilon transformation while silicon decrease gamma(fcc) and sustains the gamma --> epsilon transformation. The gamma --> epsilon phase transformation takes place in steels with gamma(fcc) less than or equal to 20 mJ/m(2). For steels with higher stacking fault energy twinning is the main deformation mechanism. Tensile tests were carried out at different strain rates and temperatures. The formation of twins, alpha- and epsilon- martensite during plastic deformation was analysed by optical microscopy, X-ray diffraction, scanning electron microscopy (SEM) and transmission electron microscopy (TEM). The developed light weight high manganese TRIP ("transformation induced plasticity") and TWIP ("twinning induced plasticity") steels exhibit high flow stress (600-1100 MPa) and extremely large elongation (60-95%) even at extremely high strain rates of about 10(3) s(-1). Recent trends in the automotive industry towards improved safely standards and a reduced weight as well as a more rational and cost effective manufacturing have led to great interest in these high strength and "super tough" steels. (C) 2000 Elsevier Science Ltd. All rights reserved.																			0749-6419	1879-2154					2000	16	10-11					1391	1409		10.1016/S0749-6419(00)00015-2	http://dx.doi.org/10.1016/S0749-6419(00)00015-2													WOS:000089253500013
J	Zhao, X; Wu, H; Guo, BL; Dong, RN; Qiu, YS; Ma, PX				Zhao, Xin; Wu, Hao; Guo, Baolin; Dong, Ruonan; Qiu, Yusheng; Ma, Peter X.			Antibacterial anti-oxidant electroactive injectable hydrogel as self-healing wound dressing with hemostasis and adhesiveness for cutaneous wound healing	BIOMATERIALS												Injectable self-healing hydrogel dressing with multifunctional properties including anti-infection, anti oxidative and conductivity promoting wound healing process will be highly desired in wound healing application and its design is still a challenge. We developed a series of injectable conductive self-healed hydrogels based on quaternized chitosan-g-polyaniline (QCSP) and benzaldehyde group functionalized poly(ethylene glycol)-co-poly(glycerol sebacate) (PEGS-FA) as antibacterial, anti-oxidant and electroactive dressing for cutaneous wound healing. These hydrogels presented good self-healing, electroactivity, free radical scavenging capacity, antibacterial activity, adhesiveness, conductivity, swelling ratio, and biocompatibility. Interestingly, the hydrogel with an optimal crosslinker concentration of 1.5 wt% PEGS-FA showed excellent in vivo blood clotting capacity, and it significantly enhanced in vivo wound healing process in a full-thickness skin defect model than quaternized chitosan/PEGS-FA hydrogel and commercial dressing (Tegaderm (TM) film) by upregulating the gene expression of growth factors including VEGF, EGF and TGF-beta and then promoting granulation tissue thickness and collagen deposition. Taken together, the antibacterial electroactive injectable hydrogel dressing prolonged the lifespan of dressing relying on self-healing ability and significantly promoted the in vivo wound healing process attributed to its multifunctional properties, meaning that they are excellent candidates for full-thickness skin wound healing. (C) 2017 Elsevier Ltd. All rights reserved.					X, Peter/E-4895-2011; Dong, Ruonan/KFB-4645-2024; Guo, Baolin/ISV-0506-2023; Guo, Baolin/A-1297-2011; Zhao, Xin/KGL-2713-2024	Dong, Ruonan/0000-0002-1536-5622; Guo, Baolin/0000-0001-6756-1441; Zhao, Xin/0000-0002-7190-423X													0142-9612	1878-5905				APR	2017	122						34	47		10.1016/j.biomaterials.2017.01.011	http://dx.doi.org/10.1016/j.biomaterials.2017.01.011								28107663					WOS:000394472500004
J	Pereira, S; Pinto, A; Alves, V; Silva, CA				Pereira, Sergio; Pinto, Adriano; Alves, Victor; Silva, Carlos A.			Brain Tumor Segmentation Using Convolutional Neural Networks in MRI Images	IEEE TRANSACTIONS ON MEDICAL IMAGING												Among brain tumors, gliomas are the most common and aggressive, leading to a very short life expectancy in their highest grade. Thus, treatment planning is a key stage to improve the quality of life of oncological patients. Magnetic resonance imaging (MRI) is a widely used imaging technique to assess these tumors, but the large amount of data produced by MRI prevents manual segmentation in a reasonable time, limiting the use of precise quantitative measurements in the clinical practice. So, automatic and reliable segmentation methods are required; however, the large spatial and structural variability among brain tumors make automatic segmentation a challenging problem. In this paper, we propose an automatic segmentation method based on Convolutional Neural Networks (CNN), exploring small 3 x 3 kernels. The use of small kernels allows designing a deeper architecture, besides having a positive effect against overfitting, given the fewer number of weights in the network. We also investigated the use of intensity normalization as a pre-processing step, which though not common in CNN-based segmentation methods, proved together with data augmentation to be very effective for brain tumor segmentation in MRI images. Our proposal was validated in the Brain Tumor Segmentation Challenge 2013 database (BRATS 2013), obtaining simultaneously the first position for the complete, core, and enhancing regions in Dice Similarity Coefficient metric (0.88, 0.83, 0.77) for the Challenge data set. Also, it obtained the overall first position by the online evaluation platform. We also participated in the on-site BRATS 2015 Challenge using the same model, obtaining the second place, with Dice Similarity Coefficient metric of 0.78, 0.65, and 0.75 for the complete, core, and enhancing regions, respectively.					Pereira, Sérgio/K-5591-2019; Alves, Victor/D-1319-2009; Silva, Carlos/J-1190-2014; Pereira, Sergio/N-9642-2015	Alves, Victor/0000-0003-1819-7051; Azevedo da Silva Ribeiro Pinto, Jose Adriano/0000-0001-9397-3722; Silva, Carlos/0000-0002-1015-5095; Pereira, Sergio/0000-0002-4298-0903													0278-0062	1558-254X				MAY	2016	35	5			SI		1240	1251		10.1109/TMI.2016.2538465	http://dx.doi.org/10.1109/TMI.2016.2538465								26960222					WOS:000375550500009
J	Yang, F; Murugan, R; Wang, S; Ramakrishna, S				Yang, F; Murugan, R; Wang, S; Ramakrishna, S			Electrospinning of nano/micro scale poly(L-lactic acid) aligned fibers and their potential in neural tissue engineering	BIOMATERIALS												Efficacy of aligned poly(L-lactic acid) (PLLA) nano/micro fibrous scaffolds for neural tissue engineering is described and their performance with random PLLA scaffolds is compared as well in this study. Perfectly aligned PLLA fibrous scaffolds were fabricated by an electrospinning technique under optimum condition and the diameter of the electrospun fibers can easily be tailored by adjusting the concentration of polymer solution. As the structure of PLLA scaffold was intended for neural tissue engineering, its suitability was evaluated in vitro using neural stem cells (NSCs) as a model cell line. Cell morphology, differentiation and neurite outgrowth were studied by various microscopic techniques. The results show that the direction of NSC elongation and its neurite outgrowth is parallel to the direction of PLLA fibers for aligned scaffolds. No significant changes were observed on the cell orientation with respect to the fiber diameters. However, the rate of NSC differentiation was higher for PLLA nanofibers than that of micro fibers and it was independent of the fiber alignment. Based on the experimental results, the aligned nanofibrous PLLA scaffold could be used as a potential cell carrier in neural tissue engineering. (C) 2004 Elsevier Ltd. All rights reserved.					Ramakrishna, Seeram/E-5186-2011; wang, shu/H-6744-2012; Yang, Fang/E-1937-2011; Ramalingam, Murugan/AAV-1702-2020	Yang, Fang/0000-0002-4022-7643; Ramalingam, Murugan/0000-0001-6498-9792													0142-9612	1878-5905				MAY	2005	26	15					2603	2610		10.1016/j.biomaterials.2004.06.051	http://dx.doi.org/10.1016/j.biomaterials.2004.06.051								15585263					WOS:000226698400043
J	Schuhmacher, D; Vo, BT; Vo, BN				Schuhmacher, Dominic; Vo, Ba-Tuong; Vo, Ba-Ngu			A consistent metric for performance evaluation of multi-object filters	IEEE TRANSACTIONS ON SIGNAL PROCESSING												The concept of a miss-distance, or error, between a reference quantity and its estimated/controlled value, plays a fundamental role in any filtering/control problem. Yet there is no satisfactory notion of a miss-distance in the well-established field of multi-object filtering. In this paper, we outline the inconsistencies of existing metrics in the context of multi-object miss-distances for performance evaluation. We then propose a new mathematically and intuitively consistent metric that addresses the drawbacks of current multi-object performance evaluation metrics.					Vo, Ba Tuong/HKO-5071-2023	Vo, Ba Tuong/0000-0002-3954-238X; Vo, Ba-Ngu/0000-0003-4202-7722													1053-587X	1941-0476				AUG	2008	56	8	1				3447	3457		10.1109/TSP.2008.920469	http://dx.doi.org/10.1109/TSP.2008.920469													WOS:000258032800006
J	Boneh, D; Lynn, B; Shacham, H				Boneh, D; Lynn, B; Shacham, H			Short signatures from the Weil pairing	JOURNAL OF CRYPTOLOGY												We introduce a short signature scheme based on the Computational Diffie-Hellman assumption on certain elliptic and hyperelliptic curves. For standard security parameters, the signature length is about half that of a DSA signature with a similar level of security. Our short signature scheme is designed for systems where signatures are typed in by a human or are sent over a low-bandwidth channel. We survey a number of properties of our signature scheme such as signature aggregation and batch verification.																			0933-2790	1432-1378				FAL	2004	17	4					297	319		10.1007/s00145-004-0314-9	http://dx.doi.org/10.1007/s00145-004-0314-9													WOS:000224027300005
J	Zheng, Y; Liu, J; Liang, J; Jaroniec, M; Qiao, SZ				Zheng, Yao; Liu, Jian; Liang, Ji; Jaroniec, Mietek; Qiao, Shi Zhang			Graphitic carbon nitride materials: controllable synthesis and applications in fuel cells and photocatalysis	ENERGY & ENVIRONMENTAL SCIENCE												Graphitic carbon nitrides (g-C3N4) are becoming increasingly significant due to the theoretical prediction of their unusual properties and promising applications ranging from photocatalysis, heterogeneous catalysis, to fuel cells. Recently, a variety of nanostructured and nanoporous g-C3N4 materials have been developed for a wide range of new applications. This feature article gives, at first, an overview on the synthesis of g-C3N4 nanomaterials with controllable structure and morphology, and secondly, presents and categorizes applications of g-C3N4 as multifunctional metal-free catalysts for environmental protection, energy conversion and storage. A special emphasis is placed on the potential applications of nanostructured g-C3N4 in the areas of artificial photocatalysis for hydrogen production, oxygen reduction reaction (ORR) for fuel cells, and metal-free heterogeneous catalysis. Finally, this perspective highlights crucial issues that should be addressed in the future in the aforementioned exciting research areas.					Liang, Ji/ABD-6279-2021; Jaroniec, Mietek/A-9733-2008; Zheng, Yao/F-2588-2017; Liu, Jian/C-5665-2009; Qiao, Shi Zhang/A-6057-2010	Liang, Ji/0000-0001-8217-8045; Jaroniec, Mietek/0000-0002-1178-5611; Zheng, Yao/0000-0002-2411-8041; Liu, Jian/0000-0002-5114-0404; Qiao, Shi Zhang/0000-0002-4568-8422													1754-5692	1754-5706				MAY	2012	5	5					6717	6731		10.1039/c2ee03479d	http://dx.doi.org/10.1039/c2ee03479d													WOS:000303251500008
J	Miyato, T; Maeda, SI; Koyama, M; Ishii, S				Miyato, Takeru; Maeda, Shin-Ichi; Koyama, Masanori; Ishii, Shin			Virtual Adversarial Training: A Regularization Method for Supervised and Semi-Supervised Learning	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												We propose a new regularization method based on virtual adversarial loss: a new measure of local smoothness of the conditional label distribution given input. Virtual adversarial loss is defined as the robustness of the conditional label distribution around each input data point against local perturbation. Unlike adversarial training, our method defines the adversarial direction without label information and is hence applicable to semi-supervised learning. Because the directions in which we smooth the model are only "virtually" adversarial, we call our method virtual adversarial training (VAT). The computational cost of VAT is relatively low. For neural networks, the approximated gradient of virtual adversarial loss can be computed with no more than two pairs of forward- and back-propagations. In our experiments, we applied VAT to supervised and semi-supervised learning tasks on multiple benchmark datasets. With a simple enhancement of the algorithm based on the entropy minimization principle, our VATachieves state-of-the-art performance for semi-supervised learning tasks on SVHN and CIFAR-10.						Miyato, Takeru/0000-0002-7363-1773; Ishii, Shin/0000-0001-9385-8230													0162-8828	1939-3539				AUG	2019	41	8					1979	1993		10.1109/TPAMI.2018.2858821	http://dx.doi.org/10.1109/TPAMI.2018.2858821								30040630					WOS:000473598800014
J	Nasir, AA; Zhou, XY; Durrani, S; Kennedy, RA				Nasir, Ali A.; Zhou, Xiangyun; Durrani, Salman; Kennedy, Rodney A.			Relaying Protocols for Wireless Energy Harvesting and Information Processing	IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS												An emerging solution for prolonging the lifetime of energy constrained relay nodes in wireless networks is to avail the ambient radio-frequency (RF) signal and to simultaneously harvest energy and process information. In this paper, an amplify-and-forward (AF) relaying network is considered, where an energy constrained relay node harvests energy from the received RF signal and uses that harvested energy to forward the source information to the destination. Based on the time switching and power splitting receiver architectures, two relaying protocols, namely, i) time switching-based relaying (TSR) protocol and ii) power splitting-based relaying (PSR) protocol are proposed to enable energy harvesting and information processing at the relay. In order to determine the throughput, analytical expressions for the outage probability and the ergodic capacity are derived for delay-limited and delay-tolerant transmission modes, respectively. The numerical analysis provides practical insights into the effect of various system parameters, such as energy harvesting time, power splitting ratio, source transmission rate, source to relay distance, noise power, and energy harvesting efficiency, on the performance of wireless energy harvesting and information processing using AF relay nodes. In particular, the TSR protocol outperforms the PSR protocol in terms of throughput at relatively low signal-to-noise-ratios and high transmission rates.					Nasir, Ali/AAV-3709-2021; Kennedy, Rodney/B-8215-2009; Durrani, Salman/G-1668-2012	Kennedy, Rodney/0000-0002-3946-3673; Zhou, Xiangyun/0000-0001-8973-9079; Nasir, Ali Arshad/0000-0001-5012-1562; Durrani, Salman/0000-0002-7124-282X													1536-1276					JUL	2013	12	7					3622	3636		10.1109/TWC.2013.062413.122042	http://dx.doi.org/10.1109/TWC.2013.062413.122042													WOS:000322661200043
J	Roy, K; Mukhopadhyay, S; Mahmoodi-Meimand, H				Roy, K; Mukhopadhyay, S; Mahmoodi-Meimand, H			Leakage current mechanisms and leakage reduction techniques in deep-submicrometer CMOS circuits	PROCEEDINGS OF THE IEEE												High leakage current in deep-submicrometer regimes is becoming a significant contributor to power dissipation of CMOS circuits as threshold voltage, channel length, and gate oxide thickness are reduced. Consequently, the identification and modeling of different leakage components is very important for estimation and reduction of leakage power especially for low-power applications. This paper reviews various transistor intrinsic leakage mechanisms, including weak inversion, drain-induced barrier lowering, gate-induced drain leakage, and gate oxide tunneling. Channel engineering techniques including retrograde well and halo doping are explained as means to manage short-channel effects for continuous scaling of CMOS devices. Finally, the paper explores different circuit techniques to reduce the leakage power consumption.					Mukhopadhyay, Saibal/C-5943-2009	Mahmoodi, Hamid/0000-0003-4237-3086													0018-9219	1558-2256				FEB	2003	91	2					305	327		10.1109/JPROC.2002.808156	http://dx.doi.org/10.1109/JPROC.2002.808156													WOS:000181263300006
J	Ku, H; Wang, H; Pattarachaiyakoop, N; Trada, M				Ku, H.; Wang, H.; Pattarachaiyakoop, N.; Trada, M.			A review on the tensile properties of natural fiber reinforced polymer composites	COMPOSITES PART B-ENGINEERING												This paper is a review on the tensile properties of natural fiber reinforced polymer composites. Natural fibers have recently become attractive to researchers, engineers and scientists as an alternative reinforcement for fiber reinforced polymer (FRP) composites. Due to their low cost, fairly good mechanical properties, high specific strength, non-abrasive, eco-friendly and bio-degradability characteristics, they are exploited as a replacement for the conventional fiber, such as glass, aramid and carbon. The tensile properties of natural fiber reinforce polymers (both thermoplastics and thermosets) are mainly influenced by the interfacial adhesion between the matrix and the fibers. Several chemical modifications are employed to improve the interfacial matrix-fiber bonding resulting in the enhancement of tensile properties of the composites. In general, the tensile strengths of the natural fiber reinforced polymer composites increase with fiber content, up to a maximum or optimum value, the value will then drop. However, the Young's modulus of the natural fiber reinforced polymer composites increase with increasing fiber loading. Khoathane et al. [1] found that the tensile strength and Young's modulus of composites reinforced with bleached hemp fibers increased incredibly with increasing fiber loading. Mathematical modelling was also mentioned. It was discovered that the rule of mixture (ROM) predicted and experimental tensile strength of different natural fibers reinforced HDPE composites were very close to each other. Halpin-Tsai equation was found to be the most effective equation in predicting the Young's modulus of composites containing different types of natural fibers. (C) 2011 Elsevier Ltd. All rights reserved.					Wang, Hao/A-7340-2016	Wang, Hao/0000-0001-8869-9669													1359-8368	1879-1069				JUN	2011	42	4					856	873		10.1016/j.compositesb.2011.01.010	http://dx.doi.org/10.1016/j.compositesb.2011.01.010													WOS:000289880100028
J	Jin, KH; McCann, MT; Froustey, E; Unser, M				Jin, Kyong Hwan; McCann, Michael T.; Froustey, Emmanuel; Unser, Michael			Deep Convolutional Neural Network for Inverse Problems in Imaging	IEEE TRANSACTIONS ON IMAGE PROCESSING												In this paper, we propose a novel deep convolutional neural network (CNN)-based algorithm for solving ill-posed inverse problems. Regularized iterative algorithms have emerged as the standard approach to ill-posed inverse problems in the past few decades. These methods produce excellent results, but can be challenging to deploy in practice due to factors including the high computational cost of the forward and adjoint operators and the difficulty of hyperparameter selection. The starting point of this paper is the observation that unrolled iterative methods have the form of a CNN (filtering followed by pointwise non-linearity) when the normal operator (H* H, where H* is the adjoint of the forward imaging operator, H) of the forward model is a convolution. Based on this observation, we propose using direct inversion followed by a CNN to solve normal-convolutional inverse problems. The direct inversion encapsulates the physical model of the system, but leads to artifacts when the problem is ill posed; the CNN combines multiresolution decomposition and residual learning in order to learn to remove these artifacts while preserving image structure. We demonstrate the performance of the proposed network in sparse-view reconstruction (down to 50 views) on parallel beam X-ray computed tomography in synthetic phantoms as well as in real experimental sinograms. The proposed network outperforms total variation-regularized iterative reconstruction for the more realistic phantoms and requires less than a second to reconstruct a 512 x 512 image on the GPU.					McCann, Michael/AAG-5257-2021; Jin, Kyong/AAA-4494-2021; Unser, Michael/A-1550-2008	Unser, Michael/0000-0003-1248-2513; Jin, Kyong Hwan/0000-0001-7885-4792; McCann, Michael/0000-0001-7645-252X													1057-7149	1941-0042				SEP	2017	26	9					4509	4522		10.1109/TIP.2017.2713099	http://dx.doi.org/10.1109/TIP.2017.2713099								28641250					WOS:000405701500004
J	Guo, ZH; Zhang, L; Zhang, D				Guo, Zhenhua; Zhang, Lei; Zhang, David			A Completed Modeling of Local Binary Pattern Operator for Texture Classification	IEEE TRANSACTIONS ON IMAGE PROCESSING												In this correspondence, a completed modeling of the local binary pattern (LBP) operator is proposed and an associated completed LBP (CLBP) scheme is developed for texture classification. A local region is represented by its center pixel and a local difference sign-magnitude transform (LDSMT). The center pixels represent the image gray level and they are converted into a binary code, namely CLBP-Center (CLBP_C), by global thresholding. LDSMT decomposes the image local differences into two complementary components: the signs and the magnitudes, and two operators, namely CLBP-Sign (CLBP_S) and CLBP-Magnitude (CLBP_M), are proposed to code them. The traditional LBP is equivalent to the CLBP_S part of CLBP, and we show that CLBP_S preserves more information of the local structure than CLBP_M, which explains why the simple LBP operator can extract the texture features reasonably well. By combining CLBP_S, CLBP_M, and CLBP_C features into joint or hybrid distributions, significant improvement can be made for rotation invariant texture classification.					guo, zhenhua/AAD-1578-2020; Zhang, Lei/P-8881-2014; Zhang, David/O-9396-2016	Zhang, Lei/0000-0002-2078-4215; Zhang, David/0000-0002-5027-5286													1057-7149	1941-0042				JUN	2010	19	6					1657	1663		10.1109/TIP.2010.2044957	http://dx.doi.org/10.1109/TIP.2010.2044957								20215079					WOS:000277773200023
J	Gupta, A; Jha, RK				Gupta, Akhil; Jha, Rakesh Kumar			A Survey of 5G Network: Architecture and Emerging Technologies	IEEE ACCESS												In the near future, i.e., beyond 4G, some of the prime objectives or demands that need to be addressed are increased capacity, improved data rate, decreased latency, and better quality of service. To meet these demands, drastic improvements need to be made in cellular network architecture. This paper presents the results of a detailed survey on the fifth generation (5G) cellular network architecture and some of the key emerging technologies that are helpful in improving the architecture and meeting the demands of users. In this detailed survey, the prime focus is on the 5G cellular network architecture, massive multiple input multiple output technology, and device-to-device communication (D2D). Along with this, some of the emerging technologies that are addressed in this paper include interference management, spectrum sharing with cognitive radio, ultra-dense networks, multi-radio access technology association, full duplex radios, millimeter wave solutions for 5G cellular networks, and cloud technologies for 5G radio access networks and software defined networks. In this paper, a general probable 5G cellular network architecture is proposed, which shows that D2D, small cell access points, network cloud, and the Internet of Things can be a part of 5G cellular network architecture. A detailed survey is included regarding current research projects being conducted in different countries by research groups and institutions that are working on 5G technologies.					JHA, RAKESH/F-9808-2011; Gupta, Akhil/AAE-5370-2020	Jha, Rakesh Kumar/0000-0001-7321-4753; Gupta, Akhil/0000-0002-0054-3801													2169-3536						2015	3						1206	1232		10.1109/ACCESS.2015.2461602	http://dx.doi.org/10.1109/ACCESS.2015.2461602													WOS:000371388200091
J	Sidky, EY; Pan, XC				Sidky, Emil Y.; Pan, Xiaochuan			Image reconstruction in circular cone-beam computed tomography by constrained, total-variation minimization	PHYSICS IN MEDICINE AND BIOLOGY												An iterative algorithm, based on recent work in compressive sensing, is developed for volume image reconstruction from a circular cone-beam scan. The algorithm minimizes the total variation (TV) of the image subject to the constraint that the estimated projection data is within a specified tolerance of the available data and that the values of the volume image are non-negative. The constraints are enforced by the use of projection onto convex sets (POCS) and the TV objective is minimized by steepest descent with an adaptive step-size. The algorithm is referred to as adaptive-steepest-descent-POCS (ASD-POCS). It appears to be robust against cone-beam artifacts, and may be particularly useful when the angular range is limited or when the angular sampling rate is low. The ASD-POCS algorithm is tested with the Defrise disk and jaw computerized phantoms. Some comparisons are performed with the POCS and expectation-maximization (EM) algorithms. Although the algorithm is presented in the context of circular cone-beam image reconstruction, it can also be applied to scanning geometries involving other x-ray source trajectories.					Sidky, Emil/P-7957-2019														0031-9155	1361-6560				SEP 7	2008	53	17					4777	4807		10.1088/0031-9155/53/17/021	http://dx.doi.org/10.1088/0031-9155/53/17/021								18701771					WOS:000258537000022
J	Zhang, KP; Zhang, ZP; Li, ZF; Qiao, Y				Zhang, Kaipeng; Zhang, Zhanpeng; Li, Zhifeng; Qiao, Yu			Joint Face Detection and Alignment Using Multitask Cascaded Convolutional Networks	IEEE SIGNAL PROCESSING LETTERS												Face detection and alignment in unconstrained environment are challenging due to various poses, illuminations, and occlusions. Recent studies show that deep learning approaches can achieve impressive performance on these two tasks. In this letter, we propose a deep cascaded multitask framework that exploits the inherent correlation between detection and alignment to boost up their performance. In particular, our framework leverages a cascaded architecture with three stages of carefully designed deep convolutional networks to predict face and landmark location in a coarse-to-fine manner. In addition, we propose a new online hard sample mining strategy that further improves the performance in practice. Our method achieves superior accuracy over the state-of-the-art techniques on the challenging face detection dataset and benchmark and WIDER FACE benchmarks for face detection, and annotated facial landmarks in the wild benchmark for face alignment, while keeps real-time performance.					zhang, zhanpeng/AAE-7897-2019; Qiao, Yu/ABD-5787-2021														1070-9908	1558-2361				OCT	2016	23	10					1499	1503		10.1109/LSP.2016.2603342	http://dx.doi.org/10.1109/LSP.2016.2603342													WOS:000384293500003
J	Goldsmith, A; Jafar, SA; Jindal, N; Vishwanath, S				Goldsmith, A; Jafar, SA; Jindal, N; Vishwanath, S			Capacity limits of MIMO channels	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS												We provide an overview of the extensive recent results on the Shannon capacity of single-user and multiuser multiple-input multiple-output (MIMO) channels. Although enormous capacity gains have been predicted for such channels, these predictions are based on somewhat unrealistic assumptions about the underlying time-varying channel model and how well it can be tracked at the receiver, as well as at the transmitter. More realistic assumptions can dramatically impact the potential capacity gains of MIMO techniques. For time-varying MIMO channels there are multiple Shannon theoretic capacity definitions and, for each definition, different correlation models and channel information assumptions that we consider. We first provide a comprehensive summary of ergodic and capacity versus outage results for single-user MIMO channels. These results indicate that the capacity gain obtained from multiple antennas heavily depends on the available channel information at either the receiver or transmitter, the channel signal-to-noise ratio, and the correlation between the channel gains on each antenna element. We then focus attention on the capacity region of the multiple-access channels (MACs) and the largest known achievable rate region for the broadcast channel. In contrast to single-user MIMO channels, capacity results for these multiuser MIMO channels are quite difficult to obtain, even for constant channels. We. summarize results for the MIMO broadcast and MAC for channels that are either constant or fading with perfect instantaneous knowledge of the antenna gains at,both transmitter(s) and receiver(s). We show that the capacity region of the MIMO multiple access and the largest known achievable rate region (called the dirty-paper region) for the MIMO broadcast channel are intimately related via a duality transformation. This transformation facilitates finding the transmission strategies that achieve a point on the boundary of the MIMO MAC capacity region in terms of the transmission strategies of the MIMO broadcast dirty-paper region and vice-versa. Finally, we discuss capacity results for multicell MIMO channels with base station cooperation. The base stations then act as a spatially diverse antenna array and transmission strategies that exploit this structure exhibit significant capacity gains. This section also provides a brief discussion of system level issues associated with MIMO cellular. Open problems in this field abound and are discussed throughout the paper.					Goldsmith, Andrea/F-8335-2010; Jafar, Syed/G-2477-2010	Jafar, Syed/0000-0003-2038-2977; Goldsmith, Andrea/0000-0001-5686-800X													0733-8716	1558-0008				JUN	2003	21	5					684	702		10.1109/JSAC.2003.810294	http://dx.doi.org/10.1109/JSAC.2003.810294													WOS:000183366800002
J	Garrido-Jurado, S; Muñoz-Salinas, R; Madrid-Cuevas, FJ; Marín-Jiménez, MJ				Garrido-Jurado, S.; Munoz-Salinas, R.; Madrid-Cuevas, F. J.; Marin-Jimenez, M. J.			Automatic generation and detection of highly reliable fiducial markers under occlusion	PATTERN RECOGNITION												This paper presents a fiducial marker system specially appropriated for camera pose estimation in applications such as augmented reality and robot localization. Three main contributions are presented. First, we propose an algorithm for generating configurable marker dictionaries (in size and number of bits) following a criterion to maximize the inter-marker distance and the number of bit transitions. In the process, we derive the maximum theoretical inter-marker distance that dictionaries of square binary markers can have. Second, a method for automatically detecting the markers and correcting possible errors is proposed. Third, a solution to the occlusion problem in augmented reality applications is shown. To that aim, multiple markers are combined with an occlusion mask calculated by color segmentation. The experiments conducted show that our proposal obtains dictionaries with higher inter-marker distances and lower false negative rates than state-of-the-art systems, and provides an effective solution to the occlusion problem. (C) 2014 Elsevier Ltd. All rights reserved.					Marin-Jimenez, Manuel/AAS-9152-2020; Madrid-Cuevas, Francisco Jose/H-1396-2015; Munoz-Salinas, Rafael/K-5999-2014	Marin-Jimenez, Manuel J./0000-0001-9294-6714; Garrido-Jurado, Sergio/0000-0001-6872-7458; Madrid-Cuevas, Francisco Jose/0000-0001-6557-7431; Munoz-Salinas, Rafael/0000-0002-8773-8571													0031-3203	1873-5142				JUN	2014	47	6					2280	2292		10.1016/j.patcog.2014.01.005	http://dx.doi.org/10.1016/j.patcog.2014.01.005													WOS:000334004600016
J	Figueiredo, MAT; Jain, AK				Figueiredo, MAT; Jain, AK			Unsupervised learning of finite mixture models	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												This paper proposes an unsupervised algorithm for learning a finite mixture model from multivariate data. The adjective "unsupervised" is justified by two properties of the algorithm: 1) it is capable of selecting the number of components and 2) unlike the standard expectation-maximization (EM) algorithm, it does not require careful initialization. The proposed method also avoids another drawback of EM for mixture fitting: the possibility of convergence toward a singular estimate at the boundary of the parameter space. The novelty of our approach is that we do not use a model selection criterion to choose one among a set of preestimated candidate models; instead, we seamlessly integrate estimation and model selection in a single algorithm. Our technique can be applied to any type of parametric mixture model for which it is possible to write an EM algorithm; in this paper, we illustrate it with experiments involving Gaussian mixtures. These experiments testify for the good performance of our approach.					Figueiredo, Mario/C-5428-2008	Figueiredo, Mario/0000-0002-0970-7745													0162-8828	1939-3539				MAR	2002	24	3					381	396		10.1109/34.990138	http://dx.doi.org/10.1109/34.990138													WOS:000174035900007
J	Rao, AB; Rubin, ES				Rao, AB; Rubin, ES			A technical, economic, and environmental assessment of amine-based CO<sub>2</sub> capture technology for power plant greenhouse gas control	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Capture and sequestration of CO2 from fossil fuel power plants is gaining widespread interest as a potential method of controlling greenhouse gas emissions. Performance and cost models of an amine (MEA)-based CO2 absorption system for postcombustion flue gas applications have been developed and integrated with an existing power plant modeling framework that-includes multipollutant control technologies for other regulated emissions. The integrated model has been applied to study the feasibility and cost of carbon capture and sequestration at both new and existing coal-burning power plants. The cost of carbon avoidance was shown to depend strongly on assumptions about the reference plant design, details of the CO2 capture system design, interactions with other pollution control systems, and method of CO2 storage. The CO2 avoidance cost for retrofit systems was found to be generally higher than for new plants, mainly because of the higher energy penalty resulting from less efficient heat integration;as well as site-specific difficulties typically encountered in retrofit applications. For all cases, a small, reduction in CO2 capture cost was afforded by the SO2 emission trading credits generated by amine-based capture systems. Efforts are underway to model a broader suite of carbon capture and sequestration technologies for more comprehensive assessments in the context of multipollutant environmental management.					Rubin, Edward/D-7629-2013														0013-936X					OCT 15	2002	36	20					4467	4475		10.1021/es0158861	http://dx.doi.org/10.1021/es0158861								12387425					WOS:000178581300037
J	Ding, ZG; Yang, Z; Fan, PZ; Poor, HV				Ding, Zhiguo; Yang, Zheng; Fan, Pingzhi; Poor, H. Vincent			On the Performance of Non-Orthogonal Multiple Access in 5G Systems with Randomly Deployed Users	IEEE SIGNAL PROCESSING LETTERS												In this letter, the performance of non-orthogonal multiple access (NOMA) is investigated in a cellular downlink scenario with randomly deployed users. The developed analytical results show that NOMA can achieve superior performance in terms of ergodic sumrates; however, the outage performance of NOMA depends critically on the choices of the users' targeted data rates and allocated power. In particular, a wrong choice of the targeted data rates and allocated power can lead to a situation in which the user's outage probability is always one, i.e. the user's targeted quality of service will never be met.					Poor, H./S-5027-2016; Ding, Zhiguo/B-9805-2017	Poor, H. Vincent/0000-0002-2062-131X; Ding, Zhiguo/0000-0001-5280-384X													1070-9908	1558-2361				DEC	2014	21	12					1501	1505		10.1109/LSP.2014.2343971	http://dx.doi.org/10.1109/LSP.2014.2343971													WOS:000340454600006
J	Liu, BD; Liu, YK				Liu, BD; Liu, YK			Expected value of fuzzy variable and fuzzy expected value models	IEEE TRANSACTIONS ON FUZZY SYSTEMS												This paper will present a novel concept of expected values of fuzzy variables, which is essentially a type of Choquet integral and coincides with that of random variables. In order to calculate the expected value of general fuzzy variable, a fuzzy simulation technique is also designed. Finally, we construct a spectrum, of fuzzy expected value models,,and integrate fuzzy simulation, neural network, and genetic algorithms to produce a hybrid intelligent algorithm for solving general fuzzy expected value models.					Liu, Baoding/E-6052-2011; Liu, Yan-Kui/IUN-3017-2023	Liu, Yan-Kui/0000-0002-3106-6761													1063-6706	1941-0034				AUG	2002	10	4					445	450		10.1109/TFUZZ.2002.800692	http://dx.doi.org/10.1109/TFUZZ.2002.800692													WOS:000177372700003
J	Broder, A; Kumar, R; Maghoul, F; Raghavan, P; Rajagopalan, S; Stata, R; Tomkins, A; Wiener, J				Broder, A; Kumar, R; Maghoul, F; Raghavan, P; Rajagopalan, S; Stata, R; Tomkins, A; Wiener, J			Graph structure in the Web	COMPUTER NETWORKS-THE INTERNATIONAL JOURNAL OF COMPUTER AND TELECOMMUNICATIONS NETWORKING					9th International World Wide Web Conference (WWW9)	MAY 15-19, 2000	AMSTERDAM, NETHERLANDS					The study of the Web as a graph is not only fascinating in its own right, but also yields valuable insight into Web algorithms for crawling, searching and community discovery, and the sociological phenomena which characterize its evolution. We report on experiments on local and global properties of the Web graph using two AltaVista crawls each with over 200 million pages and 1.5 billion links. Our study indicates that the macroscopic structure of the Web is considerably more intricate than suggested by earlier experiments on a smaller scale. (C) 2000 Published by Elsevier Science B.V. All rights reserved.						Raghavan, Prabhakar/0000-0001-9853-7604													1389-1286					JUN	2000	33	1-6					309	320		10.1016/S1389-1286(00)00083-9	http://dx.doi.org/10.1016/S1389-1286(00)00083-9													WOS:000087626600022
J	Arandjelovic, R; Gronat, P; Torii, A; Pajdla, T; Sivic, J				Arandjelovic, Relja; Gronat, Petr; Torii, Akihiko; Pajdla, Tomas; Sivic, Josef			NetVLAD: CNN Architecture for Weakly Supervised Place Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												We tackle the problem of large scale visual place recognition, where the task is to quickly and accurately recognize the location of a given query photograph. We present the following four principal contributions. First, we develop a convolutional neural network (CNN) architecture that is trainable in an end-to-end manner directly for the place recognition task. The main component of this architecture, NetVLAD, is a new generalized VLAD layer, inspired by the "Vector of Locally Aggregated Descriptors" image representation commonly used in image retrieval. The layer is readily pluggable into any CNN architecture and amenable to training via backpropagation. Second, we create a new weakly supervised ranking loss, which enables end-to-end learning of the architecture's parameters from images depicting the same places over time downloaded from Google Street View Time Machine. Third, we develop an efficient training procedure which can be applied on very large-scale weakly labelled tasks. Finally, we show that the proposed architecture and training procedure significantly outperform non-learnt image representations and off-the-shelf CNN descriptors on challenging place recognition and image retrieval benchmarks.					Pajdla, Tomas/K-7954-2013; Torii, Akihiko/B-9270-2015	Pajdla, Tomas/0000-0001-6325-0072													0162-8828	1939-3539				JUN	2018	40	6					1437	1451		10.1109/TPAMI.2017.2711011	http://dx.doi.org/10.1109/TPAMI.2017.2711011								28622667					WOS:000431524700012
J	Taal, CH; Hendriks, RC; Heusdens, R; Jensen, J				Taal, Cees H.; Hendriks, Richard C.; Heusdens, Richard; Jensen, Jesper			An Algorithm for Intelligibility Prediction of Time-Frequency Weighted Noisy Speech	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING												In the development process of noise-reduction algorithms, an objective machine-driven intelligibility measure which shows high correlation with speech intelligibility is of great interest. Besides reducing time and costs compared to real listening experiments, an objective intelligibility measure could also help provide answers on how to improve the intelligibility of noisy unprocessed speech. In this paper, a short-time objective intelligibility measure (STOI) is presented, which shows high correlation with the intelligibility of noisy and time-frequency weighted noisy speech (e.g., resulting from noise reduction) of three different listening experiments. In general, STOI showed better correlation with speech intelligibility compared to five other reference objective intelligibility models. In contrast to other conventional intelligibility models which tend to rely on global statistics across entire sentences, STOI is based on shorter time segments (386 ms). Experiments indeed show that it is beneficial to take segment lengths of this order into account. In addition, a free Matlab implementation is provided.																			1558-7916	1558-7924				SEP	2011	19	7					2125	2136		10.1109/TASL.2011.2114881	http://dx.doi.org/10.1109/TASL.2011.2114881													WOS:000293734500024
J	Zhu, QS; Mai, JM; Shao, L				Zhu, Qingsong; Mai, Jiaming; Shao, Ling			A Fast Single Image Haze Removal Algorithm Using Color Attenuation Prior	IEEE TRANSACTIONS ON IMAGE PROCESSING												Single image haze removal has been a challenging problem due to its ill-posed nature. In this paper, we propose a simple but powerful color attenuation prior for haze removal from a single input hazy image. By creating a linear model for modeling the scene depth of the hazy image under this novel prior and learning the parameters of the model with a supervised learning method, the depth information can be well recovered. With the depth map of the hazy image, we can easily estimate the transmission and restore the scene radiance via the atmospheric scattering model, and thus effectively remove the haze from a single image. Experimental results show that the proposed approach outperforms state-of-the-art haze removal algorithms in terms of both efficiency and the dehazing effect.					Shao, Ling/D-3535-2011	Shao, Ling/0000-0002-8264-6117													1057-7149	1941-0042				NOV	2015	24	11					3522	3533		10.1109/TIP.2015.2446191	http://dx.doi.org/10.1109/TIP.2015.2446191								26099141					WOS:000357793200012
J	Warfield, SK; Zou, KH; Wells, WM				Warfield, SK; Zou, KH; Wells, WM			Simultaneous truth and performance level estimation (STAPLE): An algorithm for the validation of image segmentation	IEEE TRANSACTIONS ON MEDICAL IMAGING												Characterizing the performance of image segmentation approaches has been a persistent challenge. Performance analysis is important since segmentation algorithms often have limited accuracy and precision. Interactive drawing of the desired segmentation by human raters has often been the only acceptable approach, and yet suffers from intra-rater and inter-rater variability. Automated algorithms have been sought in order to remove the variability introduced by raters, but such algorithms must be assessed to ensure they are suitable for the task. The performance of raters (human or algorithmic) generating segmentations of medical images has been difficult to quantify because of the difficulty of obtaining or estimating a known true segmentation for clinical data. Although physical and digital phantoms can be constructed for which ground truth is known or readily estimated, such phantoms do not fully reflect clinical images due to the difficulty of constructing phantoms which reproduce the full range of imaging characteristics and normal and pathological anatomical variability observed in clinical data. Comparison to a collection of segmentations by raters is an attractive alternative since it can be carried out directly on the relevant clinical imaging data. However, the most appropriate measure or set of measures with which to compare such segmentations has not been clarified and several measures are used in practice. We present here an expectation-maximization algorithm for simultaneous truth and performance level estimation (STAPLE). The algorithm considers a collection of segmentations and computes a probabilistic estimate of the true segmentation and a measure of the performance level represented by each segmentation. The source of each segmentation in the collection may be an appropriately trained human rater or raters, or may be an automated segmentation algorithm. The probabilistic estimate of the true segmentation is formed by estimating an optimal combination of the segmentations, weighting each segmentation depending upon the estimated performance level, and incorporating a prior model for the spatial distribution of structures being segmented as well as spatial homogeneity constraints. STAPLE is straightforward to apply to clinical imaging data, it readily enables assessment of the performance of an automated image segmentation algorithm, and enables direct comparison of human rater and algorithm performance.					Warfield, Simon/B-3352-2009	Warfield, Simon/0000-0002-7659-3880													0278-0062	1558-254X				JUL	2004	23	7					903	921		10.1109/TMI.2004.828354	http://dx.doi.org/10.1109/TMI.2004.828354								15250643					WOS:000222428100013
J	Song, CS				Song, Chunshan			Global challenges and strategies for control, conversion and utilization of CO<sub>2</sub> for sustainable development involving energy, catalysis, adsorption and chemical processing	CATALYSIS TODAY					8th International Conference on Carbon Dioxide Utilization	JUN 20-23, 2005	Univ Oslo, Oslo, NORWAY		Univ Oslo			Utilization of carbon dioxide (CO2) has become an important global issue due to the significant and continuous rise in atmospheric CO2 concentrations, accelerated growth in the consumption of carbon-based energy worldwide, depletion of carbon-based energy resources, and low efficiency in current energy systems. The barriers for CO2 utilization include: (1) Costs Of CO2 capture, separation, purification, and transportation to user site; (2) energy requirements of CO2 chemical conversion (plus source and cost of co-reactants); (3) market size limitations, little investment-incentives and lack of industrial commitments for enhancing CO2-based chemicals; and (4) the lack of socio-economical driving forces. The strategic objectives may include: (1) use CO2 for environmentally-benign physical and chemical processing that adds value to the process; (2) use CO2 to produce industrially useful chemicals and materials that adds value to the products; (3) use CO2 as a beneficial fluid for processing or as a medium for energy recovery and emission reduction; and (4) use CO2 recycling involving renewable sources of energy to conserve carbon resources for sustainable development. The approaches for enhancing CO2 utilization may include one or more of the following: (1) for applications that do not require pure CO2, develop effective processes for using the CO2-Concentrated flue gas from industrial plants or CO2-rich resources without CO2 separation; (2) for applications that need pure CO2, develop more efficient and less-energy intensive processes for separation of CO2 selectively without the negative impacts of co-existing gases such as H2O, 02, and N-2; (3) replace a hazardous or less-effective substance in existing processes with CO2 as an alternate medium or solvent or co-reactant or a combination of them; (4) make use of CO2 based on the unique physical properties as supercritical fluid or as either solvent or anti-solvent; (5) use CO2 based on the unique chemical properties for CO2 to be incorporated with high 'atom efficiency' such as carboxylation and carbonate synthesis; (6) produce useful chemicals and materials using CO2 as a reactant or feedstock; (7) use CO2 for energy recovery while reducing its emissions to the atmosphere by sequestration; (8) recycle CO2 as C-source for chemicals and fuels using renewable sources of energy; and (9) convert CO2 under either bio-chemical or geologic-formation conditions into "new fossil" energies. Several cases are discussed in more detail. The first example is tri-reforming of methane versus the well-known CO2 reforming over transition metal catalysts such as supported Ni catalysts. Using CO2 along with H2O and 02 in flue gases of power plants without separation, tri-reforming is a synergetic combination of CO2 reforming, steam reforming and partial oxidation and it can eliminate carbon deposition problem and produces syngas with desired H-2/CO ratios for industrial applications. The second example is a CO2 "molecular basket" as CO2-selective high-capacity adsorbent which was developed using mesoporous molecular sieve MCM-41 and polyethylenimine (PEI). The MCM41-PEI adsorbent has higher adsorption capacity than either PEI or MCM-41 alon and can be used as highly CO2-selective adsorbent for gas mixtures without the pre-removal of moisture because it even enhances CO2 adsorption capacity. The third example is synthesis of dimethyl carbonate using CO2 and methanol, which demonstrates the environmental benefit of avoiding toxic phosgene and a processing advantage. The fourth example is the application of supercritical CO2 for extraction and for chemical processing where CO2 is either a solvent or a co-reactant, or both. The CO2 utilization contributes to enhancing sustainability, since various chemicals, materials, and fuels can be synthesized using CO2, which should be a sustainable way in the long term when renewable sources of energy are used as energy input. (c) 2006 Elsevier B.V. All rights reserved.					Song, Chunshan/B-3524-2008	Song, Chunshan/0000-0003-2344-9911													0920-5861	1873-4308				JUN 30	2006	115	1-4					2	32		10.1016/j.cattod.2006.02.029	http://dx.doi.org/10.1016/j.cattod.2006.02.029													WOS:000238416100002
J	Van Gerpen, J				Van Gerpen, J			Biodiesel processing and production	FUEL PROCESSING TECHNOLOGY												Biodiesel is an alternative diesel fuel that is produced from vegetable oils and animal fats. It consists of the monoalkyl esters formed by a catalyzed reaction of the triglycerides in the oil or fat with a simple monohydric alcohol. The reaction conditions generally involve a trade-off between reaction time and temperature as reaction completeness is the most critical fuel quality parameter. Much of the process complexity originates from contaminants in the feedstock, such as water and free fatty acids, or impurities in the final product, such as methanol, free glycerol, and soap. Processes have been developed to produce biodiesel from high free fatty acid feedstocks, such as recycled restaurant grease, animal fats, and soapstock. (c) 2004 Elsevier B.V. All rights reserved.																			0378-3820	1873-7188				JUN 25	2005	86	10					1097	1107		10.1016/j.fuproc.2004.11.005	http://dx.doi.org/10.1016/j.fuproc.2004.11.005													WOS:000229403500005
J	Heinz, DC; Chang, CI				Heinz, DC; Chang, CI			Fully constrained least squares linear spectral mixture analysis method for material quantification in hyperspectral imagery	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING												Linear spectral mixture analysis (LSMA) is a widely used technique in remote sensing to estimate abundance fractions of materials present in an image pixel. In order for an LSMA-based estimator to produce accurate amounts of material abundance, it generally requires two constraints imposed on the linear mixture model used in LSMA, which are the abundance sum-to-one constraint and the abundance nonnegativity constraint. The first constraint requires the sum of the abundance fractions of materials present in an image pixel to be one and the second imposes a constraint that these abundance fractions be nonnegative. While the first constraint is easy to deal with, the second constraint is difficult to implement since it results in a set of inequalities and can only be solved by numerical methods. Consequently, most LSMA-based methods are unconstrained and produce solutions that do not necessarily reflect the true abundance fractions of materials. In this case, they can only be used for the purposes of material detection, discrimination, and classification, but not for material quantification. In this paper, we present a fully constrained least squares (FCLS) linear spectral mixture analysis method for material quantification. Since no closed form can be derived for this method, an efficient algorithm is developed to yield optimal solutions. In order to further apply the designed algorithm to unknown image scenes, an unsupervised least squares error (LSE)-based method is also proposed to extend the FCLS method in an unsupervised manner. A series of computer simulations and real hyperspectral data experiments were conducted to demonstrate the performance of the proposed FCLS LSMA approach in material quantification.																			0196-2892	1558-0644				MAR	2001	39	3					529	545		10.1109/36.911111	http://dx.doi.org/10.1109/36.911111													WOS:000167628100006
J	Reddy, JN				Reddy, JN			Analysis of functionally graded plates	INTERNATIONAL JOURNAL FOR NUMERICAL METHODS IN ENGINEERING												Theoretical formulation, Navier's solutions of rectangular plates, and finite element models based on the third-order shear deformation plate theory are presented for the analysis of through-thickness functionally graded plates. The plates are assumed to have isotropic, two-constituent material distribution through the thickness, and the modulus of elasticity of the plate is assumed to vary according to a power-law distribution in terms of the volume fractions of the constituents. The formulation accounts for the thermomechanical coupling, time dependency, and the von Karman-type geometric Iron-linearity. Numerical results of the linear third-order theory and non-linear first-order theory are presented to show the effect of the material distribution on the deflections and stresses. Copyright (C) 2000 John Wiley & Sons, Ltd.					Reddy, Junuthula/D-7737-2013	Reddy, Junuthula/0000-0002-9739-1639													0029-5981					JAN 10	2000	47	1-3					663	684		10.1002/(SICI)1097-0207(20000110/30)47:1/3<663::AID-NME787>3.0.CO;2-8	http://dx.doi.org/10.1002/(SICI)1097-0207(20000110/30)47:1/3<663::AID-NME787>3.0.CO;2-8													WOS:000084864500030
J	Jeffrey, SJ; Carter, JO; Moodie, KB; Beswick, AR				Jeffrey, SJ; Carter, JO; Moodie, KB; Beswick, AR			Using spatial interpolation to construct a comprehensive archive of Australian climate data	ENVIRONMENTAL MODELLING & SOFTWARE												A comprehensive archive of Australian rainfall and climate data has been constructed from ground-based observational data. Continuous, daily time step records have been constructed using spatial interpolation algorithms to estimate missing data. Datasets have been constructed for daily rainfall, maximum and minimum temperatures, evaporation, solar radiation and vapour pressure. Datasets are available for approximately 4600 locations across Australia, commencing in 1890 for rainfall and 1957 for climate variables. The datasets can be accessed on the Internet at http://www.dnr.qld.gov.au/silo. Interpolated surfaces have been computed on a regular 0.05 degrees grid extending from latitude 10 degreesS to 44 degreesS and longitude 112 degreesE to 154 degreesE. A thin plate smoothing spline was used to interpolate daily climate variables, and ordinary kriging was used to interpolate daily and monthly rainfall. Independent cross validation has been used to analyse the temporal and spatial error of the interpolated data. An Internet based facility has been developed which allows database clients to interrogate the gridded surfaces at any desired location. (C) 2001 Elsevier Science Ltd. All rights reserved.																			1364-8152						2001	16	4					309	330		10.1016/S1364-8152(01)00008-1	http://dx.doi.org/10.1016/S1364-8152(01)00008-1													WOS:000168591400002
J	Blankertz, B; Tomioka, R; Lemm, S; Kawanabe, M; Müller, KR				Blankertz, Benjamin; Tomioka, Ryota; Lemm, Steven; Kawanabe, Motoaki; Mueller, Klaus-Robert			Optimizing spatial filters for robust EEG single-trial analysis	IEEE SIGNAL PROCESSING MAGAZINE												Due to the volume conduction multichannel electroencephalogram (EEG) recordings give a rather blurred image of brain activity. Therefore spatial filters are extremely useful in single-trial analysis in order to improve the signal-to-noise ratio. There are powerful methods from machine learning and signal processing that permit the optimization of spatio-temporal filters for each subject in a data dependent fashion beyond the fixed filters based on the sensor geometry, e.g., Laplacians. Here we elucidate the theoretical background of the common spatial pattern (CSP) algorithm, a popular method in brain-computer interface (BCI) research. Apart from reviewing several variants of the basic algorithm, we reveal tricks of the trade for achieving a powerful CSP performance, briefly elaborate on theoretical aspects of CSP, and demonstrate the application of CSP-type preprocessing in our studies of the Berlin BCI (BBCI) project.					Mueller, Klaus-Robert/C-3196-2013	Blankertz, Benjamin/0000-0002-2437-4846; Mueller, Klaus-Robert/0000-0002-3861-7685													1053-5888	1558-0792				JAN	2008	25	1					41	56		10.1109/MSP.2008.4408441	http://dx.doi.org/10.1109/MSP.2008.4408441													WOS:000251906900008
J	Ball, JM; Lee, MM; Hey, A; Snaith, HJ				Ball, James M.; Lee, Michael M.; Hey, Andrew; Snaith, Henry J.			Low-temperature processed meso-superstructured to thin-film perovskite solar cells	ENERGY & ENVIRONMENTAL SCIENCE												We have reduced the processing temperature of the bulk absorber layer in CH3NH3PbI3-xClx perovskite solar cells from 500 to <150 degrees C and achieved power conversion efficiencies up to 12.3%. Remarkably, we find that devices with planar thin-film architecture, where the ambipolar perovskite transports both holes and electrons, convert the absorbed photons into collected charge with close to 100% efficiency.					Ball, James/HHM-5640-2022; Snaith, Henry/A-7367-2016	Snaith, Henry/0000-0001-8511-790X													1754-5692					JUN	2013	6	6					1739	1743		10.1039/c3ee40810h	http://dx.doi.org/10.1039/c3ee40810h													WOS:000319284200005
J	Goel, S; Negi, R				Goel, Satashu; Negi, Rohit			Guaranteeing secrecy using artificial noise	IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS					62nd IEEE Vehicular Technology Conference	SEP 25-28, 2005	Dallas, TX	IEEE				The broadcast nature of the wireless medium makes the communication over this medium vulnerable to eavesdropping. This paper considers the problem of secret communication between two nodes, over a fading wireless medium, in the presence of a passive eavesdropper. The assumption used is that the transmitter and its helpers (amplifying relays) have more antennas than the eavesdropper. The transmitter ensures secrecy of communication by utilizing some of the available power to produce 'artificial noise', such that only the eavesdropper's channel is degraded. Two scenarios are considered, one where the transmitter has multiple transmit antennas, and the other where amplifying relays simulate the effect of multiple antennas. The channel state information (CSI) is assumed to be publicly known, and hence, the secrecy of communication is independent of the secrecy of CSI.																			1536-1276	1558-2248				JUN	2008	7	6					2180	2189		10.1109/TWC.2008.060848	http://dx.doi.org/10.1109/TWC.2008.060848													WOS:000256886200028
J	Zhao, GX; Li, JX; Ren, XM; Chen, CL; Wang, XK				Zhao, Guixia; Li, Jiaxing; Ren, Xuemei; Chen, Changlun; Wang, Xiangke			Few-Layered Graphene Oxide Nanosheets As Superior Sorbents for Heavy Metal Ion Pollution Management	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Graphene has attracted multidisciplinary study because of its unique physicochemical properties. Herein, few-layered graphene oxide nanosheets were synthesized from graphite using the modified Hummers method, and were used as sorbents for the removal of Cd(II) and Co(II) ions from large volumes of aqueous solutions. The effects of pH, ionic strength, and humic acid on Cd(II) and Co (II) sorption were investigated. The results indicated that Cd(II) and Co(II) sorption on graphene oxide nanosheets was strongly dependent on pH and weakly dependent on ionic strength. The abundant oxygen-containing functional groups on the surfaces of graphene oxide nanosheets played an important role on Cd(II) and Co(II) sorption. The presence of humic acid reduced Cd(II) and Co(II) sorption on graphene oxide nanosheets at pH < 8. The maximum sorption capacities (C-smax) of Cd(II) and Co (II) on graphene oxide nanosheets at pH 6.0 +/- 0.1 and T = 303 K were about 106.3 and 68.2 mg/g, respectively, higher than any currently reported. The thermodynamic parameters calculated from temperature-dependent sorption isotherms suggested that Cd(II) and Co(II) sorptions on graphene oxide nanosheets were endothermic and spontaneous processes. The graphene oxide nanosheets may be suitable materials in heavy metal ion pollution cleanup if they are synthesized in large scale and at low price in near future.					Wang, Xiangke/I-5806-2012; Li, Jiaxing/H-9805-2012; ren, xuemei/AFO-2665-2022; Zhao, Guixia/N-3160-2017; chen, zhang lun/H-9177-2012	Zhao, Guixia/0000-0003-4537-3508; chen, zhang lun/0000-0003-1636-2412; Li, Jiaxing/0000-0002-7683-2482													0013-936X	1520-5851				DEC 15	2011	45	24					10454	10462		10.1021/es203439v	http://dx.doi.org/10.1021/es203439v								22070750					WOS:000298118300028
J	Doppler, K; Rinne, M; Wijting, C; Ribeiro, CB; Hugl, K				Doppler, Klaus; Rinne, Mika; Wijting, Carl; Ribeiro, Cassio B.; Hugl, Klaus			Device-to-Device Communication as an Underlay to LTE-Advanced Networks	IEEE COMMUNICATIONS MAGAZINE												In this article device-to-device (D2D) communication underlaying a 3GPP LTE-Advanced cellular network is studied as an enabler of local services with limited interference impact on the primary cellular network. The approach of the study is a tight integration of D2D communication into an LTE-Advanced network. In particular, we propose mechanisms for D2D communication session setup and management involving procedures in the LTE System Architecture Evolution. Moreover, we present numerical results based on system simulations in an interference limited local area scenario. Our results show that D2D communication can increase the total throughput observed in the cell area.																			0163-6804					DEC	2009	47	12					42	49		10.1109/MCOM.2009.5350367	http://dx.doi.org/10.1109/MCOM.2009.5350367													WOS:000272693000010
J	Ruparelia, JP; Chatteriee, AK; Duttagupta, SP; Mukherji, S				Ruparelia, Jayesh P.; Chatteriee, Arup Kumar; Duttagupta, Siddhartha P.; Mukherji, Suparna			Strain specificity in antimicrobial activity of silver and copper nanoparticles	ACTA BIOMATERIALIA												The antimicrobial properties of silver and copper nanoparticles were investigated using Escherichia coli (four strains), Bacillus subtilis and Staphylococcus aureus (three strains). The average sizes of the silver and copper nanoparticles were 3 nm and 9 nm, respectively, as determined through transmission electron microscopy. Energy-dispersive X-ray spectra of silver and copper nanoparticles revealed that while silver was in its pure form, an oxide layer existed on the copper nanoparticles. The bactericidal effect of silver and copper nanoparticles were compared based on diameter of inhibition zone in disk diffusion tests and minimum inhibitory concentration (MIC) and minimum bactericidal concentration (MBC) of nanoparticles dispersed in batch cultures. Bacterial sensitivity to nanoparticles was found to vary depending on the microbial species. Disk diffusion studies with E. coli and S. aureus revealed greater effectiveness of the silver nanoparticles compared to the copper nanoparticles. B. subtilis depicted the highest sensitivity to nanoparticles compared to the other strains and was more adversely affected by the copper nanoparticles. Good correlation was observed between MIC and MBC (r(2)=0.98) measured in liquid cultures. For copper nanoparticles a good negative correlation was observed between the inhibition zone observed in disk diffusion test and MIC/MBC determined based on liquid cultures with the various strains (r(2)=-0.75). Although strain-specific variation in MIC/MBC was negligible for S. aureus, some strain-specific variation was observed for E. coli. (c) 2007 Acta Materialia Inc. Published by Elsevier Ltd. All rights reserved.					Ruparelia, Jayesh/AAD-7714-2020; Mukherji, Suparna/I-6018-2018	Mukherji, Suparna/0000-0001-5722-3369													1742-7061	1878-7568				MAY	2008	4	3					707	716		10.1016/j.actbio.2007.11.006	http://dx.doi.org/10.1016/j.actbio.2007.11.006								18248860					WOS:000255790500027
J	Fritzmann, C; Löwenberg, J; Wintgens, T; Melin, T				Fritzmann, C.; Loewenberg, J.; Wintgens, T.; Melin, T.			State-of-the-art of reverse osmosis desalination	DESALINATION												Throughout the world, water scarcity is being recognised as a present or future threat to human activity and as a consequence, a definite trend to develop alternative water resources such as desalination can be observed. The most commonly used desalination technologies are reverse osmosis (RO) and thermal processes such as multi-stage flash (MSF) and multi-effect distillation (MED). In Europe, reverse osmosis, due to its lower energy consumption has gained much wider acceptance than its thermal alternatives. This review summarises the current state-of-the art of reverse osmosis desalination, dealing not only with the reverse osmosis stage, but with the entire process from raw water intake to post treatment of product water. The discussion of process fundamentals, membranes and membrane modules and of current and future developments in membrane technology is accompanied by an analysis of operational issues as fouling and scaling and of measures for their prevention such as adequate cleaning procedures and antiscalant use. Special focus is placed on pre-treatment of raw water and post-treatment of brine as well as of product water to meet drinking and irrigation water standards, including evaluation of current boron removal options. Energy requirements of reverse osmosis plants as well as currently applied energy recovery systems for reduction of energy consumption are described and cost and cost structure of reverse osmosis desalination are outlined. Finally, current practices of waste management and disposal as well as new trends such as the use of hybrid plants, i.e. combining reverse osmosis with thermal processes and/or power generation are addressed.						Wintgens, Thomas/0000-0002-5160-1805													0011-9164	1873-4464				OCT 5	2007	216	1-3					1	76		10.1016/j.desal.2006.12.009	http://dx.doi.org/10.1016/j.desal.2006.12.009													WOS:000250705400001
J	Federici, JF; Schulkin, B; Huang, F; Gary, D; Barat, R; Oliveira, F; Zimdars, D				Federici, JF; Schulkin, B; Huang, F; Gary, D; Barat, R; Oliveira, F; Zimdars, D			THz imaging and sensing for security applications - explosives, weapons and drugs	SEMICONDUCTOR SCIENCE AND TECHNOLOGY												Over the past 5 years, there has been a significant interest in employing terahertz (THz) technology, spectroscopy and imaging for security applications. There are three prime motivations for this interest: (a) THz radiation can detect concealed weapons since many non-metallic, non-polar materials are transparent to THz radiation; (b) target compounds such as explosives and illicit drugs have characteristic THz spectra that can be used to identify these compounds and (c) THz radiation poses no health risk for scanning of people. In this paper, stand-off interferometric imaging and sensing for the detection of explosives, weapons and drugs is emphasized. Future prospects of THz technology are discussed.					Gary, Dale/M-9786-2019	Zimdars, David/0009-0001-3935-7678; Gary, Dale/0000-0003-2520-8396; Federici, John/0000-0003-4722-0038													0268-1242	1361-6641				JUL	2005	20	7					S266	S280		10.1088/0268-1242/20/7/018	http://dx.doi.org/10.1088/0268-1242/20/7/018													WOS:000230709300019
J	Yue, S; Pilon, P; Cavadias, G				Yue, S; Pilon, P; Cavadias, G			Power of the Mann-Kendall and Spearman's rho tests for detecting monotonic trends in hydrological series	JOURNAL OF HYDROLOGY												In many hydrological studies, two non-parametric rank-based statistical tests, namely the Mann-Kendall test and Spearman's rho test are used for detecting monotonic trends in time series data. However, the power of these tests has not been well documented. This study investigates the power of the tests by Monte Carlo simulation. Simulation results indicate that their power depends on the pre-assigned significance level. magnitude of trend. sample size. and the amount of variation within a time series. That is. the bigger the absolute magnitude of trend. the more powerful are the tests, as the sample size increases, the tests become more powerful: and as the amount of variation increases within a time series. the power of the tests decrease. When a trend is present. the power is also dependent on the distribution type and skewness of the time series. The simulation results also demonstrate that these two tests have similar power in detecting a trend, to the point of being indistinguishable in practice. The two tests are implemented to assess the significance of trends in annual maximum daily streamflow data of 20 pristine basins in Ontario, Canada. Results indicate that the P-values computed by these different tests are almost identical. By the binomial distribution. the field significant downward trend was assessed at the significance level of 0.05, Results indicate that a higher number of sites show evidence of decreasing trends than one might expect due to chance alone. (C) 2002 Elsevier Science B.V. All rights reserved.																			0022-1694	1879-2707				MAR 1	2002	259	1-4					254	271	PII S0022-1694(01)00594-7	10.1016/S0022-1694(01)00594-7	http://dx.doi.org/10.1016/S0022-1694(01)00594-7													WOS:000173950200017
J	Nedic, A; Ozdaglar, A; Parrilo, PA				Nedic, Angelia; Ozdaglar, Asuman; Parrilo, Pablo A.			Constrained Consensus and Optimization in Multi-Agent Networks	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												We present distributed algorithms that can be used by multiple agents to align their estimates with a particular value over a network with time-varying connectivity. Our framework is general in that this value can represent a consensus value among multiple agents or an optimal solution of an optimization problem, where the global objective function is a combination of local agent objective functions. Our main focus is on constrained problems where the estimates of each agent are restricted to lie in different convex sets. To highlight the effects of constraints, we first consider a constrained consensus problem and present a distributed "projected consensus algorithm" in which agents combine their local averaging operation with projection on their individual constraint sets. This algorithm can be viewed as a version of an alternating projection method with weights that are varying over time and across agents. We establish convergence and convergence rate results for the projected consensus algorithm. We next study a constrained optimization problem for optimizing the sum of local objective functions of the agents subject to the intersection of their local constraint sets. We present a distributed "projected subgradient algorithm" which involves each agent performing a local averaging operation, taking a subgradient step to minimize its own objective function, and projecting on its constraint set. We show that, with an appropriately selected stepsize rule, the agent estimates generated by this algorithm converge to the same optimal solution for the cases when the weights are constant and equal, and when the weights are time-varying but all agents have the same constraint set.						Parrilo, Pablo/0000-0003-1132-8477; Nedich, Angelia/0000-0001-9365-6321													0018-9286	1558-2523				APR	2010	55	4					922	938		10.1109/TAC.2010.2041686	http://dx.doi.org/10.1109/TAC.2010.2041686													WOS:000276251300009
J	Ackermann, T; Andersson, G; Söder, L				Ackermann, T; Andersson, G; Söder, L			Distributed generation:: a definition	ELECTRIC POWER SYSTEMS RESEARCH												Distributed generation (DG) is expected to become more important in the future generation system. The current literature, however, does not use a consistent definition of DG. This paper discusses the relevant issues and aims at providing a general definition for distributed power generation in competitive electricity markets. In general, DG can be defined as electric power generation within distribution networks or on the customer side of the network. In addition, the terms distributed resources, distributed capacity and distributed utility are discussed. Network and connection issues of distributed generation are presented, too. (C) 2001 Elsevier Science S.A. All rights reserved.																			0378-7796	1873-2046				APR 20	2001	57	3					195	204		10.1016/S0378-7796(01)00101-8	http://dx.doi.org/10.1016/S0378-7796(01)00101-8													WOS:000168951400007
J	Stoica, I; Morris, R; Liben-Nowell, D; Karger, DR; Kaashoek, MF; Dabek, F; Balakrishnan, H				Stoica, I; Morris, R; Liben-Nowell, D; Karger, DR; Kaashoek, MF; Dabek, F; Balakrishnan, H			Chord: A scalable peer-to-peer lookup protocol for Internet applications	IEEE-ACM TRANSACTIONS ON NETWORKING												A fundamental problem that confronts peer-to-peer applications is the efficient location of the node that stores a desired data item. This paper presents Chord, a distributed lookup protocol that addresses this problem. Chord provides support for just one operation: given a key, it maps the key onto a node. Data location can be easily implemented on top of Chord by associating a key with each data item, and storing the key/data pair at the node to which the key maps. Chord adapts efficiently as nodes join and leave the system, and can answer queries even if the system is continuously changing. Results from theoretical analysis and simulations show that Chord is scalable: Communication cost and the state maintained by each node scale logarithmically with the number of Chord nodes.						Karger, David/0000-0002-0024-5847; /0000-0001-7098-586X													1063-6692	1558-2566				FEB	2003	11	1					17	32		10.1109/TNET.2002.808407	http://dx.doi.org/10.1109/TNET.2002.808407													WOS:000181934200002
J	Pasqualetti, F; Dörfler, F; Bullo, F				Pasqualetti, Fabio; Doerfler, Florian; Bullo, Francesco			Attack Detection and Identification in Cyber-Physical Systems	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												Cyber-physical systems are ubiquitous in power systems, transportation networks, industrial control processes, and critical infrastructures. These systems need to operate reliably in the face of unforeseen failures and external malicious attacks. In this paper: i) we propose a mathematical framework for cyber-physical systems, attacks, and monitors; ii) we characterize fundamental monitoring limitations from system-theoretic and graph-theoretic perspectives; and ii) we design centralized and distributed attack detection and identification monitors. Finally, we validate our findings through compelling examples.					Bullo, Francesco/B-8146-2013; Dörfler, Florian/AAI-8538-2020; Pasqualetti, Fabio/H-5807-2013	Bullo, Francesco/0000-0002-4785-2118; Dorfler, Florian/0000-0002-9649-5305; Pasqualetti, Fabio/0000-0002-8457-8656													0018-9286	1558-2523				NOV	2013	58	11					2715	2729		10.1109/TAC.2013.2266831	http://dx.doi.org/10.1109/TAC.2013.2266831													WOS:000326339500001
J	Kerr, YH; Waldteufel, P; Wigneron, JP; Delwart, S; Cabot, F; Boutin, J; Escorihuela, MJ; Font, J; Reul, N; Gruhier, C; Juglea, SE; Drinkwater, MR; Hahne, A; Martín-Neira, M; Mecklenburg, S				Kerr, Yann H.; Waldteufel, Philippe; Wigneron, Jean-Pierre; Delwart, Steven; Cabot, Francois; Boutin, Jacqueline; Escorihuela, Maria-Jose; Font, Jordi; Reul, Nicolas; Gruhier, Claire; Juglea, Silvia Enache; Drinkwater, Mark R.; Hahne, Achim; Martin-Neira, Manuel; Mecklenburg, Susanne			The SMOS Mission: New Tool for Monitoring Key Elements of the Global Water Cycle	PROCEEDINGS OF THE IEEE												It is now well understood that data on soil moisture and sea surface salinity (SSS) are required to improve meteorological and climate predictions. These two quantities are not yet available globally or with adequate temporal or spatial sampling. It is recognized that a spaceborne L-band radiometer with a suitable antenna is the most promising way of fulfilling this gap. With these scientific objectives and technical solution at the heart of a proposed mission concept the European Space Agency (ESA) selected the Soil Moisture and Ocean Salinity (SMOS) mission as its second Earth Explorer Opportunity Mission. The development of the SMOS mission was led by ESA in collaboration with the Centre National d'Etudes Spatiales (CNES) in France and the Centro para el Desarrollo Tecnologico Industrial (CDTI) in Spain. SMOS carries a single payload, an L-Band 2-D interferometric radiometer operating in the 1400-1427-MHz protected band [1]. The instrument receives the radiation emitted from Earth's surface, which can then be related to the moisture content in the first few centimeters of soil over land, and to salinity in the surface waters of the oceans. SMOS will achieve an unprecedented maximum spatial resolution of 50 km at L-band over land (43 km on average over the field of view), providing multiangular dual polarized (or fully polarized) brightness temperatures over the globe. SMOS has a revisit time of less than 3 days so as to retrieve soil moisture and ocean salinity data, meeting the mission's science objectives. The caveat in relation to its sampling requirements is that SMOS will have a somewhat reduced sensitivity when compared to conventional radiometers. The SMOS satellite was launched successfully on November 2, 2009.					Wigneron, Jean-Pierre/ABD-9939-2021; Waldteufel, Philippe/AAA-8039-2021; Kerr, Yann/Z-2432-2019; Escorihuela, Maria/AAB-5851-2020; reul, nicolas/C-4895-2009; /M-2253-2016; Drinkwater, Mark/C-2478-2011; Font, Jordi/E-5355-2013	/0000-0003-2845-4912; Drinkwater, Mark/0000-0002-9250-3806; wigneron, jean-pierre/0000-0001-5345-3618; Font, Jordi/0000-0003-2590-1457; Escorihuela, Maria Jose/0000-0002-7780-7334; Reul, Nicolas/0000-0003-4881-2967													0018-9219	1558-2256				MAY	2010	98	5					666	687		10.1109/JPROC.2010.2043032	http://dx.doi.org/10.1109/JPROC.2010.2043032													WOS:000277493400004
J	Beck, A; Teboulle, M				Beck, Amir; Teboulle, Marc			Fast Gradient-Based Algorithms for Constrained Total Variation Image Denoising and Deblurring Problems	IEEE TRANSACTIONS ON IMAGE PROCESSING												This paper studies gradient-based schemes for image denoising and deblurring problems based on the discretized total variation (TV) minimization model with constraints. We derive a fast algorithm for the constrained TV-based image deburring problem. To achieve this task, we combine an acceleration of the well known dual approach to the denoising problem with a novel monotone version of a fast iterative shrinkage/thresholding algorithm (FISTA) we have recently introduced. The resulting gradient-based algorithm shares a remarkable simplicity together with a proven global rate of convergence which is significantly better than currently known gradient projections-based methods. Our results are applicable to both the anisotropic and isotropic discretized TV functionals. Initial numerical results demonstrate the viability and efficiency of the proposed algorithms on image deblurring problems with box constraints.																			1057-7149					NOV	2009	18	11					2419	2434		10.1109/TIP.2009.2028250	http://dx.doi.org/10.1109/TIP.2009.2028250								19635705					WOS:000270744400003
J	Annadurai, G; Juang, RS; Lee, DJ				Annadurai, G; Juang, RS; Lee, DJ			Use of cellulose-based wastes for adsorption of dyes from aqueous solutions	JOURNAL OF HAZARDOUS MATERIALS												Low-cost banana and orange peels were prepared as adsorbents for the adsorption of dyes from aqueous solutions. Dye concentration and pH were varied. The adsorption capacities for both peels decreased in the order methyl orange (MO) > methylene blue (MB) > Rhodamine B (RB) > Congo red (CR) > methyl violet (MV) > amido black 10B (AB). The isotherm data could be well described by the Freundlich and Langmuir equations in the concentration range of 10-120 mg/l. An alkaline pH was favorable for the adsorption of dyes. Based on the adsorption capacity, it was shown that banana peel was more effective than orange peel. Kinetic parameters of adsorption such as the Langergren rate constant and the intraparticle diffusion rate constant were determined. For the present adsorption process intraparticle diffusion of dyes within the particle was identified to be rate limiting. Both peel wastes were shown to be promising materials for adsorption removal of dyes from aqueous solutions. (C) 2002 Elsevier Science B.V. All rights reserved.					GURUSAMY, ANNADURAI/ABE-5224-2020; Lee, Duu-Jong/ABI-4722-2022; Juang, Ruey-Shin/B-5335-2011	Juang, Ruey-Shin/0000-0002-6373-9668; Lee, Duu-Jong/0000-0002-8820-8097; li, du zhong/0000-0002-5111-2390													0304-3894					JUN 10	2002	92	3					263	274	PII S0304-3894(02)00017-1	10.1016/S0304-3894(02)00017-1	http://dx.doi.org/10.1016/S0304-3894(02)00017-1								12031611					WOS:000176151400004
J	Li, X; Orchard, MT				Li, X; Orchard, MT			New edge-directed interpolation	IEEE TRANSACTIONS ON IMAGE PROCESSING												This paper proposes an edge-directed interpolation algorithm for natural images. The basic idea is to first estimate local covariance coefficients from a low-resolution image and then use these covariance estimates to adapt the interpolation at a higher resolution based on the geometric duality between the low-resolution covariance and the high-resolution covariance. The edge-directed property of covariance-based adaptation attributes to its capability of tuning the interpolation coefficients to match an arbitrarily oriented step edge. A hybrid approach of switching between bilinear interpolation and covariance-based adaptive interpolation is proposed to reduce the overall computational complexity. Two important applications of the new interpolation algorithm are studied: resolution enhancement of grayscale images and reconstruction of color images from CCD samples. Simulation results demonstrate that our new interpolation algorithm substantially improves the subjective quality of the interpolated images over conventional linear interpolation.					Li, Xin/A-7884-2011	Li, Xin/0000-0003-2067-2763													1057-7149	1941-0042				OCT	2001	10	10					1521	1527		10.1109/83.951537	http://dx.doi.org/10.1109/83.951537								18255495					WOS:000171135800011
J	Chen, B; Wornell, GW				Chen, B; Wornell, GW			Quantization index modulation: A class of provably good methods for digital watermarking and information embedding	IEEE TRANSACTIONS ON INFORMATION THEORY												We consider the problem of embedding one signal (e,g,, a digital watermark), within another "host" Signal to form a third, "composite" signal. The embedding is designed to achieve efficient tradeoffs among the three conflicting goals of maximizing information-embedding rate, minimizing distortion between the host signal and composite signal, and maximizing the robustness of the embedding. We introduce new classes of embedding methods, termed quantization index modulation (QIM) and distortion-compensated QIM (DC-QIM), and develop convenient realizations in the form of what we refer to as dither modulation. Using deterministic models to evaluate digital watermarking methods, we show that QIM is "provably good" against arbitrary bounded and fully informed attacks, which arise in several copyright applications, and in particular, it achieves provably better rate distortion-robustness tradeoffs than currently popular spread-spectrum and low-bit(s) modulation methods. Furthermore, we show that for some important classes of probabilistic models, DC-QIM is optimal (capacity-achieving) and regular QIM is near-optimal. These include both additive white Gaussian noise (AWGN) channels, which mag be good models for hybrid transmission applications such as digital audio broadcasting, and mean-square-error-constrained attack channels that model private-key watermarking applications.						Wornell, Gregory/0000-0001-9166-4758													0018-9448	1557-9654				MAY	2001	47	4					1423	1443		10.1109/18.923725	http://dx.doi.org/10.1109/18.923725													WOS:000168790600011
J	Lin, J; Yu, W; Zhang, N; Yang, XY; Zhang, HL; Zhao, W				Lin, Jie; Yu, Wei; Zhang, Nan; Yang, Xinyu; Zhang, Hanlin; Zhao, Wei			A Survey on Internet of Things: Architecture, Enabling Technologies, Security and Privacy, and Applications	IEEE INTERNET OF THINGS JOURNAL												Fog/edge computing has been proposed to be integrated with Internet of Things (IoT) to enable computing services devices deployed at network edge, aiming to improve the user's experience and resilience of the services in case of failures. With the advantage of distributed architecture and close to end-users, fog/edge computing can provide faster response and greater quality of service for IoT applications. Thus, fog/edge computing-based IoT becomes future infrastructure on IoT development. To develop fog/edge computing-based IoT infrastructure, the architecture, enabling techniques, and issues related to IoT should be investigated first, and then the integration of fog/edge computing and IoT should be explored. To this end, this paper conducts a comprehensive overview of IoT with respect to system architecture, enabling technologies, security and privacy issues, and present the integration of fog/edge computing and IoT, and applications. Particularly, this paper first explores the relationship between cyber-physical systems and IoT, both of which play important roles in realizing an intelligent cyber-physical world. Then, existing architectures, enabling technologies, and security and privacy issues in IoT are presented to enhance the understanding of the state of the art IoT development. To investigate the fog/edge computing-based IoT, this paper also investigate the relationship between IoT and fog/edge computing, and discuss issues in fog/edge computing-based IoT. Finally, several applications, including the smart grid, smart transportation, and smart cities, are presented to demonstrate how fog/edge computing-based IoT to be implemented in real-world applications.					Yu, Wei/GZL-3831-2022; Zhao, Wei/B-7130-2019	Zhao, Wei/0000-0002-6268-2559; Yu, Wei/0000-0003-4522-7340													2327-4662					OCT	2017	4	5			SI		1125	1142		10.1109/JIOT.2017.2683200	http://dx.doi.org/10.1109/JIOT.2017.2683200													WOS:000412362300003
J	Kiureghian, AD; Didevsen, O				Kiureghian, Armen Der; Didevsen, Ove			Aleatory or epistemic? Does it matter?	STRUCTURAL SAFETY												The Sources and characters Of uncertainties in engineering modeling for risk and reliability analyses are discussed. While many sources of uncertainty may exist, they are generally categorized as either aleatory or epistemic. Uncertainties are characterized as epistemic, if the modeler sees a possibility to reduce them by gathering more data or by refining models. Uncertainties are categorized as aleatory if the modeler does not foresee the possibility of reducing them. From a pragmatic standpoint, it is useful to thus categorize the uncertainties within a model, since it then becomes clear as to which uncertainties have the potential of being reduced. More importantly, epistemic uncertainties may introduce dependence among random events, which may not be properly noted if the character of uncertainties is not correctly modeled. Influences of the two types of uncertainties in reliability assessment, codified design, performance-based engineering and risk-based decision-making are discussed. Two simple examples demonstrate the influence of statistical dependence arising from epistemic uncertainties on systems and time-variant reliability problems. (c) 2008 Elsevier Ltd. All rights reserved.																			0167-4730	1879-3355					2009	31	2					105	112		10.1016/j.strusafe.2008.06.020	http://dx.doi.org/10.1016/j.strusafe.2008.06.020													WOS:000262421600003
J	Bioucas-Dias, JM; Figueiredo, MAT				Bioucas-Dias, Jose M.; Figueiredo, Mario A. T.			A new TwIST: Two-step iterative shrinkage/thresholding algorithms for image restoration	IEEE TRANSACTIONS ON IMAGE PROCESSING												Iterative shrinkage/thresholding (IST) algorithms have been recently proposed to handle a class of convex unconstrained optimization problems arising in image restoration and other linear inverse problems. This class of problems results from combining a linear observation model with a nonquadratic regularizer (e.g., total variation or wavelet-based regularization). It happens that the convergence rate of these IST algorithms depends heavily on the linear observation operator, becoming very slow when this operator is ill-conditioned or ill-posed. In this paper, we introduce two-step IST (TwIST) algorithms, exhibiting much faster convergence rate than IST for ill-conditioned problems. For a vast class of nonquadratic convex regularizers (EP norms, some Besov norms, and total variation), we show that TWIST converges to a minimizer of the objective function, for a given range of values of its parameters. For noninvertible observation operators, we introduce a monotonic version of TWIST (NITWIST); although the convergence proof does not apply to this scenario, we give experimental evidence that MTwIST exhibits similar speed gains over IST. The effectiveness of the new methods are experimentally confirmed on problems of image deconvolution and of restoration with missing samples.					Bioucas-Dias, Jose/C-5479-2009; Figueiredo, Mario/C-5428-2008	Bioucas-Dias, Jose/0000-0002-0166-5149; Figueiredo, Mario/0000-0002-0970-7745													1057-7149	1941-0042				DEC	2007	16	12					2992	3004		10.1109/TIP.2007.909319	http://dx.doi.org/10.1109/TIP.2007.909319								18092598					WOS:000251295700012
J	Zeng, Y; Zhang, R				Zeng, Yong; Zhang, Rui			Energy-Efficient UAV Communication With Trajectory Optimization	IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS												Wireless communication with unmanned aerial vehicles (UAVs) is a promising technology for future communication systems. In this paper, assuming that the UAV flies horizontally with a fixed altitude, we study energy-efficient UAV communication with a ground terminal via optimizing the UAV's trajectory, a new design paradigm that jointly considers both the communication throughput and the UAV's energy consumption. To this end, we first derive a theoretical model on the propulsion energy consumption of fixed-wing UAVs as a function of the UAV's flying speed, direction, and acceleration. Based on the derived model and by ignoring the radiation and signal processing energy consumption, the energy efficiency of UAV communication is defined as the total information bits communicated normalized by the UAV propulsion energy consumed for a finite time horizon. For the case of unconstrained trajectory optimization, we show that both the rate-maximization and energy-minimization designs lead to vanishing energy efficiency and thus are energy-inefficient in general. Next, we introduce a simple circular UAV trajectory, under which the UAV's flight radius and speed are jointly optimized to maximize the energy efficiency. Furthermore, an efficient design is proposed for maximizing the UAV's energy efficiency with general constraints on the trajectory, including its initial/final locations and velocities, as well as minimum/maximum speed and acceleration. Numerical results show that the proposed designs achieve significantly higher energy efficiency for UAV communication as compared with other benchmark schemes.					Zeng, Yong/AFM-8040-2022; Zhang, Rui/C-2657-2011	Zhang, Rui/0000-0002-8729-8393													1536-1276	1558-2248				JUN	2017	16	6					3747	3760		10.1109/TWC.2017.2688328	http://dx.doi.org/10.1109/TWC.2017.2688328													WOS:000403495400022
J	Ye, W; Heidemann, J; Estrin, D				Ye, W; Heidemann, J; Estrin, D			Medium access control with coordinated adaptive sleeping for wireless sensor networks	IEEE-ACM TRANSACTIONS ON NETWORKING												This paper proposes S-MAC, a medium access control (MAC) protocol designed for wireless sensor networks. Wireless sensor networks use battery-operated computing and sensing devices. A network of these devices will collaborate for a common application such as environmental monitoring. We expect sensor networks to be deployed in an ad hoc fashion, with nodes remaining largely inactive for long time, but becoming suddenly active when something is detected. These characteristics of sensor networks and applications motivate a MAC that is different from traditional wireless MACs such as IEEE 802.11 in several ways: energy conservation and self-configuration are primary goals, while per-node fairness and latency are less important. S-MAC uses a few novel techniques to reduce energy consumption and support self-configuration. It enables low-duty-cycle operation in a multihop network. Nodes form virtual clusters based on common sleep schedules to reduce control overhead and enable traffic-adaptive wake-up. S-MAC uses in-channel signaling to avoid overhearing unnecessary traffic. Finally, S-MAC applies message passing to reduce contention latency for applications that require in-network data processing. The paper presents measurement results of S-MAC performance on a sample sensor node, the UC Berkeley Mote, and reveals fundamental tradeoffs on energy, latency and throughput. Results show that S-MAC obtains significant energy savings compared with an 802.11-like MAC without sleeping.						Heidemann, John/0000-0002-1225-7562													1063-6692	1558-2566				JUN	2004	12	3					493	506		10.1109/TNET.2004.828953	http://dx.doi.org/10.1109/TNET.2004.828953													WOS:000222229100008
J	Yoo, T; Goldsmith, A				Yoo, T; Goldsmith, A			On the optimality of multiantenna broadcast scheduling using zero-forcing beamforming	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS												Although the capacity of multiple-input/multiple-output (MIMO) broadcast channels (BCs) can be achieved by dirty paper coding (DPC), it is difficult to implement in practical systems. This paper investigates if., for a large number of users, simpler schemes can achieve the same performance. Specifically, we show that a zero-forcing beamforming (ZFBF) strategy, while generally suboptimal, can achieve the same asymptotic sum capacity as that of DPC, as the number of users goes to infinity. In proving this asymptotic result, we provide an algorithm for determining which users should be active under ZFBF. These users are semiorthogonal to one another and can be grouped for simultaneous transmission to enhance the throughput of scheduling algorithms. Based on the user grouping, we propose and compare two fair scheduling schemes in round-robin ZFBF and proportional-fair ZFBF. We provide numerical results to confirm the optimality of ZFBF and to compare the performance of ZFBF and proposed fair scheduling schemes with that of various MIMO BC strategies.					Goldsmith, Andrea/F-8335-2010														0733-8716	1558-0008				MAR	2006	24	3					528	541		10.1109/JSAC.2005.862421	http://dx.doi.org/10.1109/JSAC.2005.862421													WOS:000236289300012
J	Li, ZZ; Hoiem, D				Li, Zhizhong; Hoiem, Derek			Learning without Forgetting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												When building a unified vision system or gradually adding new apabilities to a system, the usual assumption is that training data for all tasks is always available. However, as the number of tasks grows, storing and retraining on such data becomes infeasible. A new problem arises where we add new capabilities to a Convolutional Neural Network (CNN), but the training data for its existing capabilities are unavailable. We propose our Learning without Forgetting method, which uses only new task data to train the network while preserving the original capabilities. Our method performs favorably compared to commonly used feature extraction and fine-tuning adaption techniques and performs similarly to multitask learning that uses original task data we assume unavailable. A more surprising observation is that Learning without Forgetting may be able to replace fine-tuning with similar old and new task datasets for improved new task performance.																			0162-8828	1939-3539				DEC	2018	40	12					2935	2947		10.1109/TPAMI.2017.2773081	http://dx.doi.org/10.1109/TPAMI.2017.2773081								29990101					WOS:000449355500011
J	Liang, QL; Mendel, JM				Liang, QL; Mendel, JM			Interval type-2 fuzzy logic systems: Theory and design	IEEE TRANSACTIONS ON FUZZY SYSTEMS												In this paper, we present the theory and design of interval type-2 fuzzy logic systems (FLSs), We propose an efficient and simplified method to compute the input and antecedent operations for interval type-2 FLSs; one that is based on a general inference formula for them. We introduce the concept of upper and lower membership functions (MFs) and illustrate our efficient inference method for the case of Gaussian primary MFs, We also propose a method for designing an interval type-2 FLS in which we tune its parameters, Finally, we design type-2 FLSs to perform time-series forecasting when a nonstationary time-series is corrupted by additive mise where SNR is uncertain and demonstrate improved performance over type-1 FLSs.																			1063-6706	1941-0034				OCT	2000	8	5					535	550		10.1109/91.873577	http://dx.doi.org/10.1109/91.873577													WOS:000089820400005
J	Kim, SJ; Koh, K; Lustig, M; Boyd, S; Gorinevsky, D				Kim, Seung-Jean; Koh, K.; Lustig, M.; Boyd, Stephen; Gorinevsky, Dimitry			An Interior-Point Method for Large-Scale <i>l</i><sub>1</sub>-Regularized Least Squares	IEEE JOURNAL OF SELECTED TOPICS IN SIGNAL PROCESSING												Recently, a lot of attention has been paid to l(1) regularization based methods for sparse signal reconstruction (e.g., basis pursuit denoising and compressed sensing) and feature selection (e.g., the Lasso algorithm) in signal processing, statistics, and related fields. These problems can be cast as l(1)-regularized least-squares programs (LSPs), which can be reformulated as convex quadratic programs, and then solved by several standard methods such as interior-point methods, at least for small and medium size problems. In this paper, we describe a specialized interior-point method for solving large-scale, l(1)-regularized LSPs that uses the preconditioned conjugate gradients algorithm to compute the search direction. The interior-point method can solve large sparse problems, with a million variables and observations, in a few tens of minutes on a PC. It can efficiently solve large dense problems, that arise in sparse signal recovery with orthogonal transforms, by exploiting fast algorithms for these transforms. The method is illustrated on a magnetic resonance imaging data set.					Lustig, Michael/G-7081-2012	Koh, Kwangmoo/0000-0002-5126-2946													1932-4553	1941-0484				DEC	2007	1	4					606	617		10.1109/JSTSP.2007.910971	http://dx.doi.org/10.1109/JSTSP.2007.910971													WOS:000265494900008
J	Taubman, D				Taubman, D			High performance scalable image compression with EBCOT	IEEE TRANSACTIONS ON IMAGE PROCESSING												A new image compression algorithm is proposed, based on independent Embedded Block Coding with Optimized Truncation of the embedded bit-streams (EBCOT), The algorithm exhibits state-of-the-art compression performance while producing a bit-stream with a rich set of features, including resolution and SNR scalability together with a "random access" property, The algorithm has modest complexity and is suitable for applications involving remote browsing of large compressed images. The algorithm lends itself to explicit optimization with respect to MSE as well as more realistic psychovisual metrics, capable of modeling the spatially varying visual masking phenomenon.						Taubman, David/0000-0002-8458-6402													1057-7149	1941-0042				JUL	2000	9	7					1158	1170		10.1109/83.847830	http://dx.doi.org/10.1109/83.847830								18262955					WOS:000087939500002
S	Ewing, R; Cervero, R			TRB; TRB	Ewing, R; Cervero, R			Travel and the built environment - A synthesis	LAND DEVELOPMENT AND PUBLIC INVOLVEMENT IN TRANSPORTATION: PLANNING AND ADMINISTRATION	TRANSPORTATION RESEARCH RECORD-SERIES				80th Annual Meeting of the Transportation-Research-Board	JAN, 2001	WASHINGTON, D.C.	Transportat Res Board				The potential to moderate travel demand through changes in the built environment is the subject of more than 50 recent empirical studies. The majority of recent studies are summarized. Elasticities of travel demand with respect to density, diversity, design, and regional accessibility are then derived from selected studies. These elasticity values may be useful in travel forecasting and sketch planning and have already been incorporated into one sketch planning tool, the Environmental Protection Agency's Smart Growth Index model. In weighing the evidence, what can be said, with a degree of certainty, about the effects of built environments on key transportation "outcome" variables: trip frequency, trip length, mode choice, and composite measures of travel demand, vehicle miles traveled (VMT) and vehicle hours traveled (VHT)? Trip frequencies have attracted considerable academic interest of late. They appear to be primarily a function of socioeconomic characteristics of travelers and secondarily a function of the built environment. Trip lengths have received relatively little attention, which may account for the various degrees of importance attributed to the built environment in recent studies. Trip lengths are primarily a function of the built environment and secondarily a function of socioeconomic characteristics. Mode choices have received the most intensive study over the decades. Mode choices depend on both the built environment and socioeconomics (although they probably depend more on the latter). Studies of overall VMT or VHT find the built environment to be much more significant, a product of the differential trip lengths that factor into calculations of VMT and VHT.																			0361-1981		0-309-07241-7				2001		1780					87	114	UNSP 01-3515	10.3141/1780-10	http://dx.doi.org/10.3141/1780-10													WOS:000176639200010
J	Mayne, DQ				Mayne, David Q.			Model predictive control: Recent developments and future promise	AUTOMATICA												This paper recalls a few past achievements in Model Predictive Control, gives an overview of some current developments and suggests a few avenues for future research. (C) 2014 Elsevier Ltd. All rights reserved.																			0005-1098	1873-2836				DEC	2014	50	12					2967	2986		10.1016/j.automatica.2014.10.128	http://dx.doi.org/10.1016/j.automatica.2014.10.128													WOS:000347760100002
J	Niu, SM; Wang, SH; Lin, L; Liu, Y; Zhou, YS; Hu, YF; Wang, ZL				Niu, Simiao; Wang, Sihong; Lin, Long; Liu, Ying; Zhou, Yu Sheng; Hu, Youfan; Wang, Zhong Lin			Theoretical study of contact-mode triboelectric nanogenerators as an effective power source	ENERGY & ENVIRONMENTAL SCIENCE												A theoretical model for contact-mode TENGs was constructed in this paper. Based on the theoretical model, its real-time output characteristics and the relationship between the optimum resistance and TENG parameters were derived. The theory presented here is the first in-depth interpretation of the contact-mode TENG, which can serve as important guidance for rational design of the TENG structure in specific applications.					Wang, Sihong/E-4425-2014; Lin, Long/C-9751-2012; Niu, Simiao/D-3019-2012; Liu, Ying/B-1511-2014; Wang, Zhong Lin/E-2176-2011; Hu, Youfan/C-9519-2011; zhou, yusheng/M-5772-2014	Niu, Simiao/0000-0003-1973-2204; Liu, Ying/0000-0003-1590-0995; Wang, Zhong Lin/0000-0002-5530-0380; Wang, Sihong/0000-0002-3611-0004; Hu, Youfan/0000-0001-9798-1631; zhou, yusheng/0000-0002-7350-5048													1754-5692	1754-5706				DEC	2013	6	12					3576	3583		10.1039/c3ee42571a	http://dx.doi.org/10.1039/c3ee42571a													WOS:000327250300016
J	Anipsitakis, GP; Dionysiou, DD				Anipsitakis, GP; Dionysiou, DD			Degradation of organic contaminants in water with sulfate radicals generated by the conjunction of peroxymonosulfate with cobalt	ENVIRONMENTAL SCIENCE & TECHNOLOGY												A highly efficient advanced oxidation process for the destruction of organic contaminants in water is reported. The technology is based on the cobalt-mediated decomposition of peroxymonosulfate that leads to the formation of very strong oxidizing species (sulfate radicals) in the aqueous phase. The system is a modification of the Fenton Reagent, since an oxidant is coupled with a transition metal in a similar manner. Sulfate radicals were identified with quenching studies using specific alcohols. The study was primarily focused on comparing the cobalt/peroxymonosulfate (Co/PMS) reagent with the traditional Fenton Reagent [Fe(II)/H2O2] in the dark, at the pH range 2.0-9.0 with and without the presence of buffers such as phosphate and carbonate. Three model contaminants that show diversity in structure were tested: 2,4-dichlorophenol, atrazine, and naphthalene. Cobalt/peroxymonosulf ate was consistently proven to be more efficient than the Fenton Reagent for the degradation of 2,4-dichlorophenol and atrazine, at all the conditions tested. At high pH values, where the efficiency of the Fenton Reagent was diminished, the reactivity of the Co/PMS system was sustained at high values. When naphthalene was treated with the two oxidizing systems in comparison, the Fenton Reagent demonstrated higher degradation efficiencies than cobalt/peroxymonosulfate at acidic pH, but, at higher pH (neutral), the latter was proven much more effective. The extent of mineralization, as total organic carbon removed, was also monitored, and again the Co/PMS reagent demonstrated higher efficiencies than the Fenton Reagent. Cobalt showed true catalytic activity in the overall process, since extremely low concentrations (in the range of mug/L) were sufficient for the decomposition of the oxidant and thus the radical generation. The advantage of Co/PMS compared to the traditional Fenton Reagent is attributed primarily to the oxidizing strength of the radicals formed, since sulfate radicals are stronger oxidants than hydroxyl and the thermodynamics of the transition-metal-oxidant coupling.																			0013-936X	1520-5851				OCT 15	2003	37	20					4790	4797		10.1021/es0263792	http://dx.doi.org/10.1021/es0263792								14594393					WOS:000186133000037
J	Abbaspour, KC; Yang, J; Maximov, I; Siber, R; Bogner, K; Mieleitner, J; Zobrist, J; Srinivasan, R				Abbaspour, Karim C.; Yang, Jing; Maximov, Ivan; Siber, Rosi; Bogner, Konrad; Mieleitner, Johanna; Zobrist, Juerg; Srinivasan, Raghavan			Modelling hydrology and water quality in the pre-alpine/alpine Thur watershed using SWAT	JOURNAL OF HYDROLOGY												In a national effort, since 1972, the Swiss Government started the "National Long-term Monitoring of Swiss Rivers" (NADUF) program aimed at evaluating the chemical and physical states of major rivers leaving Swiss potitical, boundaries. The established monitoring network of 19 sampling stations included locations on all major rivers of Switzerland. This study complements the monitoring program and aims to model one of the program's catchments - Thur River basin (area 1700 km(2)), which is located in the north-east of Switzerland and is a direct tributary to the Rhine. The program SWAT (Soil and Water Assessment Tool was used to simutate all related processes affecting water quantity, sediment, and nutrient toads in the catchment. The main objectives were to test the performance of SWAT and the feasibility of using this model as a simulator of flow and transport processes at a watershed scale. Model calibration and uncertainty analysis were performed with SUFI-2 (Sequential Uncertainty FItting Ver. 2), which was interfaced with SWAT using the generic iSWAT program. Two measures were used to assess the goodness of calibration: (1) the percentage of data bracketed by the 95% prediction uncertainty calculated at the 2.5 and 97.5 percentiles of the cumulative distribution of the simulated variables, and (2) the d-factor, which is the ratio of the average distance between the above percentiles and the standard deviation of the corresponding measured variable. These statistics showed excellent results for discharge and nitrate and quite good results for sediment and total phosphorous. We concluded that: in watersheds similar to Thur with good data quality and availability and relatively small model uncertainty - it is feasible to use SWAT as a flow and transport simulator. This is a precursor for watershed management studies. (c) 2006 Elsevier B.V. All rights reserved.					Srinivasan, R/D-3937-2009; zobrist, juerg/AAG-9379-2020														0022-1694	1879-2707				FEB 15	2007	333	2-4					413	430		10.1016/j.jhydrol.2006.09.014	http://dx.doi.org/10.1016/j.jhydrol.2006.09.014													WOS:000244160900019
J	Zhao, ZM; Zhao, JW; Hu, ZL; Li, JD; Li, JJ; Zhang, YJ; Wang, C; Cui, GL				Zhao, Zhiming; Zhao, Jingwen; Hu, Zhenglin; Li, Jiedong; Li, Jiajia; Zhang, Yaojian; Wang, Cheng; Cui, Guanglei			Long-life and deeply rechargeable aqueous Zn anodes enabled by a multifunctional brightener-inspired interphase	ENERGY & ENVIRONMENTAL SCIENCE												Aqueous Zn anodes have been revisited for their intrinsic safety, low cost, and high volumetric capacity; however, deep-seated issues of dendrite growth and intricate side-reactions hindered their rejuvenation. Herein, a "brightener-inspired'' polyamide coating layer which elevates the nucleation barrier and restricts Zn2+ 2D diffusion is constructed to effectively regulate the aqueous Zn deposition behavior. Importantly, serving as a buffer layer that isolates active Zn from bulk electrolytes, this interphase also suppresses free water/O2-induced corrosion and passivation. With this synergy effect, the polymermodified Zn anode produces reversible, dendrite-free plating/stripping with a 60-fold enhancement in running lifetime (over 8000 hours) compared to the bare Zn, and even at an ultrahigh areal capacity of 10 mA h cm(-2) (10 mA cm(-2) for 1 h, 85% depth of discharge). This efficient rechargeability for Zn anodes enables a substantially stable full-cell paired with a MnO2 cathode. The strategy presented here is straightforward and scalable, representing a stark, but promising approach to solve the anode issues in advanced Zn batteries.					Cui, Guanglei/D-4816-2011	Zhao, Zhiming/0000-0001-7338-1471; Zhao, Jingwen/0000-0002-8695-159X; Zhao, Zhiming/0009-0003-4002-9297													1754-5692	1754-5706				JUN 1	2019	12	6					1938	1949		10.1039/c9ee00596j	http://dx.doi.org/10.1039/c9ee00596j													WOS:000471283100013
J	Abdel-Hamid, O; Mohamed, AR; Jiang, H; Deng, L; Penn, G; Yu, D				Abdel-Hamid, Ossama; Mohamed, Abdel-Rahman; Jiang, Hui; Deng, Li; Penn, Gerald; Yu, Dong			Convolutional Neural Networks for Speech Recognition	IEEE-ACM TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING												Recently, the hybrid deep neural network (DNN)hidden Markov model (HMM) has been shown to significantly improve speech recognition performance over the conventional Gaussian mixture model (GMM)-HMM. The performance improvement is partially attributed to the ability of the DNN to model complex correlations in speech features. In this paper, we show that further error rate reduction can be obtained by using convolutional neural networks (CNNs). We first present a concise description of the basic CNN and explain how it can be used for speech recognition. We further propose a limited-weight-sharing scheme that can better model speech features. The special structure such as local connectivity, weight sharing, and pooling in CNNs exhibits some degree of invariance to small shifts of speech features along the frequency axis, which is important to deal with speaker and environment variations. Experimental results show that CNNs reduce the error rate by 6%-10% compared with DNNs on the TIMIT phone recognition and the voice search large vocabulary speech recognition tasks.					jiang, hui/KYP-5273-2024; yu, dong/KRO-7922-2024; Penn, Gerald/LQK-8675-2024	Penn, Gerald/0000-0003-3553-8305													2329-9290	2329-9304				OCT	2014	22	10					1533	1545		10.1109/TASLP.2014.2339736	http://dx.doi.org/10.1109/TASLP.2014.2339736													WOS:000340037200007
J	da Cunha, AL; Zhou, JP; Do, MN				da Cunha, Arthur L.; Zhou, Jianping; Do, Minh N.			The nonsubsampled contourlet transform: Theory, design, and applications	IEEE TRANSACTIONS ON IMAGE PROCESSING												In this paper, we develop the nonsubsampled contourlet transform (NSCT) and study its applications. The construction proposed in this paper is based on a nonsubsampled pyramid structure and nonsubsampled directional filter banks. The result is a flexible multiscale, multidirection, and shift-invariant image decomposition that can be efficiently implemented via the a trous algorithm. At the core of the proposed scheme is the nonseparable two-channel nonsubsampled filter bank (NSFB). We exploit the less stringent design condition of the NSFB to design filters that lead to a NSCT with better frequency selectivity and regularity when compared to the contourlet transform. We propose a design framework based on the mapping approach, that allows for a fast implementation based on a lifting or ladder structure, and only uses one-dimensional filtering in some cases. In addition, our design ensures that the corresponding frame elements are regular, symmetric, and the frame is close to a tight one. We assess the performance of the NSCT in image denoising and enhancement applications. In both applications the NSCT compares favorably to other existing methods in the literature.					Cunha, Arthur/ABC-1420-2020; Do, Minh/AAX-8498-2020	Do, Minh/0000-0001-5132-4986													1057-7149	1941-0042				OCT	2006	15	10					3089	3101		10.1109/TIP.2006.877507	http://dx.doi.org/10.1109/TIP.2006.877507								17022272					WOS:000240776200019
J	Guo, XJ; Li, Y; Ling, HB				Guo, Xiaojie; Li, Yu; Ling, Haibin			LIME: Low-Light Image Enhancement via Illumination Map Estimation	IEEE TRANSACTIONS ON IMAGE PROCESSING												When one captures images in low-light conditions, the images often suffer from low visibility. Besides degrading the visual aesthetics of images, this poor quality may also significantly degenerate the performance of many computer vision and multimedia algorithms that are primarily designed for high-quality inputs. In this paper, we propose a simple yet effective low-light image enhancement (LIME) method. More concretely, the illumination of each pixel is first estimated individually by finding the maximum value in R, G, and B channels. Furthermore, we refine the initial illumination map by imposing a structure prior on it, as the final illumination map. Having the well-constructed illumination map, the enhancement can be achieved accordingly. Experiments on a number of challenging low-light images are present to reveal the efficacy of our LIME and show its superiority over several state-of-the-arts in terms of enhancement quality and efficiency.					Li, Yumeng/JBS-1868-2023; Guo, Xiaojie/AAC-3114-2022	LI, Yu/0000-0003-1865-8276													1057-7149	1941-0042				FEB	2017	26	2					982	993		10.1109/TIP.2016.2639450	http://dx.doi.org/10.1109/TIP.2016.2639450								28113318					WOS:000404773100029
J	Zhou, X; Zhang, R; Ho, CK				Zhou, Xun; Zhang, Rui; Ho, Chin Keong			Wireless Information and Power Transfer: Architecture Design and Rate-Energy Tradeoff	IEEE TRANSACTIONS ON COMMUNICATIONS												Simultaneous information and power transfer over the wireless channels potentially offers great convenience to mobile users. Yet practical receiver designs impose technical constraints on its hardware realization, as practical circuits for harvesting energy from radio signals are not yet able to decode the carried information directly. To make theoretical progress, we propose a general receiver operation, namely, dynamic power splitting (DPS), which splits the received signal with adjustable power ratio for energy harvesting and information decoding, separately. Three special cases of DPS, namely, time switching (TS), static power splitting (SPS) and on-off power splitting (OPS) are investigated. The TS and SPS schemes can be treated as special cases of OPS. Moreover, we propose two types of practical receiver architectures, namely, separated versus integrated information and energy receivers. The integrated receiver integrates the front-end components of the separated receiver, thus achieving a smaller form factor. The rate-energy tradeoff for the two architectures are characterized by a so-called rate-energy (R-E) region. The optimal transmission strategy is derived to achieve different rate-energy tradeoffs. With receiver circuit power consumption taken into account, it is shown that the OPS scheme is optimal for both receivers. For the ideal case when the receiver circuit does not consume power, the SPS scheme is optimal for both receivers. In addition, we study the performance for the two types of receivers under a realistic system setup that employs practical modulation. Our results provide useful insights to the optimal practical receiver design for simultaneous wireless information and power transfer (SWIPT).					Zhang, Rui/C-2657-2011	Zhang, Rui/0000-0002-8729-8393													0090-6778	1558-0857				NOV	2013	61	11					4754	4767		10.1109/TCOMM.2013.13.120855	http://dx.doi.org/10.1109/TCOMM.2013.13.120855													WOS:000330223000029
J	Poppe, R				Poppe, Ronald			A survey on vision-based human action recognition	IMAGE AND VISION COMPUTING												Vision-based human action recognition is the process of labeling image sequences with action labels. Robust solutions to this problem have applications in domains such as visual surveillance, video retrieval and human-computer interaction. The task is challenging due to variations in motion performance, recording settings and inter-personal differences. In this survey, we explicitly address these challenges. We provide a detailed overview of current advances in the field. Image representations and the subsequent classification process are discussed separately to focus on the novelties of recent research. Moreover, we discuss limitations of the state of the art and outline promising directions of research. (C) 2009 Elsevier B.V. All rights reserved.						Poppe, Ronald/0000-0002-0843-7878													0262-8856	1872-8138				JUN	2010	28	6					976	990		10.1016/j.imavis.2009.11.014	http://dx.doi.org/10.1016/j.imavis.2009.11.014													WOS:000276861200012
J	Shan, CF; Gong, SG; McOwan, PW				Shan, Caifeng; Gong, Shaogang; McOwan, Peter W.			Facial expression recognition based on Local Binary Patterns: A comprehensive study	IMAGE AND VISION COMPUTING												Automatic facial expression analysis is an interesting and challenging problem, and impacts important applications in many areas such as human-computer interaction and data-driven animation. Deriving an effective facial representation from original face images is a vital step for successful facial expression recognition. In this paper, we empirically evaluate facial representation based on statistical local features, Local Binary Patterns, for person-independent facial expression recognition. Different machine learning methods are systematically examined on several databases. Extensive experiments illustrate that LBP features are effective and efficient for facial expression recognition. We further formulate Boosted-LBP to extract the most discriminant LBP features, and the best recognition performance is obtained by using Support Vector Machine classifiers with Boosted-LBP features. Moreover, we investigate LBP features for low-resolution facial expression recognition, which is a critical problem but seldom addressed in the existing work. We observe in our experiments that LBP features perform stably and robustly over a useful range of low resolutions of face images, and yield promising performance in Compressed low-resolution video sequences captured in real-world environments. (C) 2008 Elsevier B.V. All rights reserved.					Shan, Caifeng/W-6178-2019	Shan, Caifeng/0000-0002-2131-1671													0262-8856	1872-8138				MAY 4	2009	27	6					803	816		10.1016/j.imavis.2008.08.005	http://dx.doi.org/10.1016/j.imavis.2008.08.005													WOS:000265807000019
J	Bloch, M; Barros, J; Rodrigues, MRD; McLaughlin, SW				Bloch, Matthieu; Barros, Joao; Rodrigues, Miguel R. D.; McLaughlin, Steven W.			Wireless information-theoretic security	IEEE TRANSACTIONS ON INFORMATION THEORY					IEEE Information Theory Workshop	OCT 22-26, 2006	Chengdu, PEOPLES R CHINA	IEEE Informat Soc				This paper considers the transmission of confidential data over wireless channels. Based on an information-theoretic formulation of the problem, in which two legitimates partners communicate over a quasi-static fading channel and an eavesdropper observes their transmissions through a second independent quasi-static fading channel, the important role of fading is characterized in terms of average secure communication rates and outage probability. Based on the insights from this analysis, a practical secure communication protocol is developed, which uses a four-step procedure to ensure wireless information-theoretic security: (i) common randomness via opportunistic transmission, (ii) message reconciliation, (iii) common key generation via privacy amplification, and (iv) message protection with a secret key. A reconciliation procedure based on multilevel coding and optimized low-density parity-check (LDPC) codes is introduced, which allows to achieve communication rates close to the fundamental security limits in several relevant instances. Finally, a set of metrics for assessing average secure key generation rates is established, and it is shown that the protocol is effective in secure key renewal-even in the presence of imperfect channel state information.					de Barros, João/M-4497-2017	Barros, Joao/0000-0003-0465-1751													0018-9448	1557-9654				JUN	2008	54	6					2515	2534		10.1109/TIT.2008.921908	http://dx.doi.org/10.1109/TIT.2008.921908													WOS:000258033700009
J	Wen, DS; Ding, YL				Wen, DS; Ding, YL			Experimental investigation into convective heat transfer of nanofluids at the entrance region under laminar flow conditions	INTERNATIONAL JOURNAL OF HEAT AND MASS TRANSFER												This paper reports an experimental work on the convective heat transfer of nanofluids, made of gamma-Al2O3 nanoparticles and de-ionized water, flowing through a copper tube in the laminar flow regime. The results showed considerable enhancement of convective heat transfer using the nanofluids. The enhancement was particularly significant it. the entrance region, and was much higher than that solely due to the enhancement on thermal conduction. It was also shown that the classical Shah equation failed to predict the heat transfer behaviour of nanofluids. Possible reasons for the enhancement were discussed. Migration of nanoparticles, and the resulting disturbance of the boundary layer were proposed to be the main reasons. (C) 2004 Elsevier Ltd. All rights reserved.					Ding, Yulong/AAA-8358-2019; Wen, Dongsheng/A-5307-2010	Ding, Yulong/0000-0001-8490-5349; Wen, Dongsheng/0000-0003-3492-7982													0017-9310	1879-2189				NOV	2004	47	24					5181	5188		10.1016/j.ijheatmasstransfer.2004.07.012	http://dx.doi.org/10.1016/j.ijheatmasstransfer.2004.07.012													WOS:000224450400002
J	Stern, LA; Feng, LG; Song, F; Hu, XL				Stern, Lucas-Alexandre; Feng, Ligang; Song, Fang; Hu, Xile			Ni<sub>2</sub>P as a Janus catalyst for water splitting: the oxygen evolution activity of Ni<sub>2</sub>P nanoparticles	ENERGY & ENVIRONMENTAL SCIENCE												Electrochemical water splitting into hydrogen and oxygen is a promising method for solar energy storage. The development of efficient electrocatalysts for water splitting has drawn much attention. However, catalysts that are active for both the hydrogen evolution and oxygen evolution reactions are rare. Herein, we show for the first time that nickel phosphide (Ni2P), an excellent hydrogen evolving catalyst, is also highly active for oxygen evolution. A current density of 10 mA cm(-2) is generated at an overpotential of only 290mV in 1M KOH. The high activity is attributed to the core-shell (Ni2P/NiOx) structure that the material adopts under catalytic conditions. The Ni2P nanoparticles can serve as both cathode and anode catalysts for an alkaline electrolyzer, which generates 10 mA cm(-2) at 1.63 V.					Feng, Ligang/E-9507-2014; Hu, Xile/A-7687-2010; Song, Fang/G-5307-2018	Feng, Ligang/0000-0001-9879-0773; Hu, Xile/0000-0001-8335-1196; Song, Fang/0000-0002-2953-0537													1754-5692	1754-5706					2015	8	8					2347	2351		10.1039/c5ee01155h	http://dx.doi.org/10.1039/c5ee01155h													WOS:000358730600009
J	Osseiran, A; Boccardi, F; Braun, V; Kusume, K; Marsch, P; Maternia, M; Queseth, O; Schellmann, M; Schotten, H; Taoka, H; Tullberg, H; Uusitalo, MA; Timus, B; Fallgren, M				Osseiran, Afif; Boccardi, Federico; Braun, Volker; Kusume, Katsutoshi; Marsch, Patrick; Maternia, Michal; Queseth, Olav; Schellmann, Malte; Schotten, Hans; Taoka, Hidekazu; Tullberg, Hugo; Uusitalo, Mikko A.; Timus, Bogdan; Fallgren, Mikael			Scenarios for 5G Mobile and Wireless Communications: The Vision of the METIS Project	IEEE COMMUNICATIONS MAGAZINE												METIS is the EU flagship 5G project with the objective of laying the foundation for 5G systems and building consensus prior to standardization. The METIS overall approach toward 5G builds on the evolution of existing technologies complemented by new radio concepts that are designed to meet the new and challenging requirements of use cases today's radio access networks cannot support. The integration of these new radio concepts, such as massive MIMO, ultra dense networks, moving networks, and device-to-device, ultra reliable, and massive machine communications, will allow 5G to support the expected increase in mobile data volume while broadening the range of application domains that mobile communications can support beyond 2020. In this article, we describe the scenarios identified for the purpose of driving the 5G research direction. Furthermore, we give initial directions for the technology components (e.g., link level components, multinode/multi-antenna, multi-RAT, and multi-layer networks and spectrum handling) that will allow the fulfillment of the requirements of the identified 5G scenarios.					Schellmann, Malte/HHN-7281-2022; Osseiran, Afif/AAQ-8710-2020; Schotten, Hans/K-9671-2017	Nwachukwu, Anthony/0009-0003-4960-1210; Schellmann, Malte/0000-0003-2651-0191; Uusitalo, Mikko/0000-0002-3792-7681; Schotten, Hans/0000-0001-5005-3635													0163-6804	1558-1896				MAY	2014	52	5					26	35		10.1109/MCOM.2014.6815890	http://dx.doi.org/10.1109/MCOM.2014.6815890													WOS:000338032200003
J	Hochwald, BM; ten Brink, S				Hochwald, BM; ten Brink, S			Achieving near-capacity on a multiple-antenna channel	IEEE TRANSACTIONS ON COMMUNICATIONS					39th Annual Allerton Conference on Communication, Control and Computing	OCT 03-05, 2001	Monticello, IL					Recent advancements in iterative processing of channel codes and the development of turbo codes have allowed the communications industry to achieve near-capacity on a single-antenna Gaussian or fading channel with low complexity. We show how these iterative techniques can also be used to achieve near-capacity on a multiple-antenna system where the receiver knows the channel. Combining iterative processing with multiple-antenna channels is particularly challenging because the channel capacities can be a factor of ten or more higher than their single-antenna counterparts. Using a "list" version of the sphere decoder, we provide a simple method to iteratively detect and decode any linear space-time mapping combined with any channel code that can be decoded using so-called "soft" inputs and outputs. We exemplify our technique by directly transmitting symbols that are coded with a channel code; we show that iterative processing with even this simple scheme can achieve near-capacity. We consider both simple convolutional and powerful turbo channel codes and show that excellent performance at very high data rates can be attained with either. We compare our simulation results with Shannon capacity limits for ergodic multiple-antenna channel.																			0090-6778	1558-0857				MAR	2003	51	3					389	399		10.1109/TCOMM.2003.809789	http://dx.doi.org/10.1109/TCOMM.2003.809789													WOS:000182341900014
J	Shi, BG; Bai, X; Yao, C				Shi, Baoguang; Bai, Xiang; Yao, Cong			An End-to-End Trainable Neural Network for Image-Based Sequence Recognition and Its Application to Scene Text Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Image-based sequence recognition has been a long-standing research topic in computer vision. In this paper, we investigate the problem of scene text recognition, which is among the most important and challenging tasks in image-based sequence recognition. A novel neural network architecture, which integrates feature extraction, sequence modeling and transcription into a unified framework, is proposed. Compared with previous systems for scene text recognition, the proposed architecture possesses four distinctive properties: (1) It is end-to-end trainable, in contrast to most of the existing algorithms whose components are separately trained and tuned. (2) It naturally handles sequences in arbitrary lengths, involving no character segmentation or horizontal scale normalization. (3) It is not confined to any predefined lexicon and achieves remarkable performances in both lexicon-free and lexicon-based scene text recognition tasks. (4) It generates an effective yet much smaller model, which is more practical for real-world application scenarios. The experiments on standard benchmarks, including the IIIT-5K, Street View Text and ICDAR datasets, demonstrate the superiority of the proposed algorithm over the prior arts. Moreover, the proposed algorithm performs well in the task of image-based music score recognition, which evidently verifies the generality of it.						Bai, Xiang/0000-0002-3449-5940													0162-8828	1939-3539				NOV	2017	39	11					2298	2304		10.1109/TPAMI.2016.2646371	http://dx.doi.org/10.1109/TPAMI.2016.2646371								28055850					WOS:000412028600014
J	Turner, LK; Collins, FG				Turner, Louise K.; Collins, Frank G.			Carbon dioxide equivalent (CO<sub>2</sub>-e) emissions: A comparison between geopolymer and OPC cement concrete	CONSTRUCTION AND BUILDING MATERIALS												Concrete for construction has traditionally been based on an Ordinary Portland Cement (OPC) binder. Geopolymers, an alternative binder based on fly ash (a fine waste collected from the emissions liberated by coal burning power stations) that is activated by an alkaline activator, have potential to lower the significant carbon footprint of OPC concrete. This paper presents the results of comprehensive carbon footprint estimates for both geopolymer and OPC concrete, including energy expending activities associated with mining and transport of raw materials, manufacturing and concrete construction. Previous studies have shown a wide variation of reported emission estimates: the results of this study are benchmarked with data from those studies. (C) 2013 Elsevier Ltd. All rights reserved.					collins, frank/A-7444-2012	collins, frank/0000-0001-6331-5390													0950-0618	1879-0526				JUN	2013	43						125	130		10.1016/j.conbuildmat.2013.01.023	http://dx.doi.org/10.1016/j.conbuildmat.2013.01.023													WOS:000319232900013
J	Maeda, N; Atarashi, H; Sawahashi, M				Maeda, N; Atarashi, H; Sawahashi, M			Performance comparison of channel interleaving methods in frequency domain for VSF-OFCDM broadband wireless access in forward link	IEICE TRANSACTIONS ON COMMUNICATIONS												This paper presents a performance comparison of the channel-interleaving method in the frequency domain, i.e., bit interleaving after channel encoding, symbol interleaving after data modulation, and chip interleaving after spreading, for Variable Spreading Factor-Orthogonal Frequency and Code Division Multiplexing (VSF-OFCDM) wireless access with frequency domain spreading, in order to reduce the required average received signal energy per symbol-to-background noise power spectrum density ratio (E-s/N-0) and achieve the maximum radio link capacity. Simulation results show that, for QPSK data modulation employing turbo coding with the channel coding rate R = 3/4, the chip-interleaving method decreases the required average received E-s/N-0 the most for various radio parameters and propagation model conditions, where the number of code-multiplexing, C-mux, the spreading factor, SF, the r.m.s. delay spread, sigma, the number of multipaths, L, and the maximum Doppler frequency, f(D), are varied as parameters. For example, when C-mux = 12 of SF = 16, the improvement in the required average received E-s/N-0 from the case without interleaving at the average packet error rate (PER) of 10(-2), is approximately 0.3, 0.3, and 1.4 dB for the bit, symbol, and chip interleaving, respectively, in a L = 12-path exponential decayed Rayleigh fading channel with sigma of 0.043 musec and fD of 20 Hz. This is because the chip interleaving obtains a higher diversity gain by replacing the chip assignment over the entire bandwidth. Meanwhile, in 16QAM data modulation with R = 1/2, the performance of the chip interleaving is deteriorated, when C-mux/SF > 0.25. due to the inter-code interference caused by different fading variations over the spreading duration since the successive chips during the spreading duration are interleaved to the separated sub-carriers. Thus, bit interleaving exhibits the best performance although the difference between bit interleaving and symbol interleaving is slight. Consequently, we conclude that the bit-interleaving method is the best among the three interleaving methods for reducing the required received E-s/N-0 considering the tradeoff between the randomization effect of burst errors and the mitigation of inter-code interference assuming the application of adaptive modulation and channel coding scheme in OFCDM employing frequency domain spreading.																			0916-8516	1745-1345				JAN	2003	E86B	1					300	313																WOS:000180491500033
J	Askarzadeh, A				Askarzadeh, Alireza			A novel metaheuristic method for solving constrained engineering optimization problems: Crow search algorithm	COMPUTERS & STRUCTURES												This paper proposes a novel metaheuristic optimizer, named crow search algorithm (CSA), based on the intelligent behavior of crows. CSA is a population-based technique which works based on this idea that crows store their excess food in hiding places and retrieve it when the food is needed. CSA is applied to optimize six constrained engineering design problems which have different natures of objective functions, constraints and decision variables. The results obtained by CSA are compared with the results of various algorithms. Simulation results reveal that using CSA may lead to finding promising results compared to the other algorithms. (C) 2016 Elsevier Ltd. All rights reserved.					Askarzadeh, Alireza/JNE-1460-2023														0045-7949	1879-2243				JUN	2016	169						1	12		10.1016/j.compstruc.2016.03.001	http://dx.doi.org/10.1016/j.compstruc.2016.03.001													WOS:000375630600001
J	Mueller, NC; Nowack, B				Mueller, Nicole C.; Nowack, Bernd			Exposure modeling of engineered nanoparticles in the environment	ENVIRONMENTAL SCIENCE & TECHNOLOGY												The aim of this study was to use a life-cycle perspective to model the quantities of engineered nanoparticles released into the environment. Three types of nanoparticles were studied: nano silver (nano-Ag), nano TiO2 (nano-TiO2), and carbon nanotubes (CNT). The quantification was based on a substance flow analysis from products to air,soil, and water in Switzerland. The following parameters were used as model inputs: estimated worldwide production volume, allocation of the production volume to product categories, particle release from products, and flow coefficients within the environmental compartments. The predicted environmental concentrations (PEC) were then compared to the predicted no effect concentrations (PNEC) derived from the literature to estimate a possible risk. The expected concentrations of the three nanoparticles in the different environmental compartments vary widely, caused by the different life cycles of the nanoparticle-containing products. The PEC values for nano-TiO2 in water are 0.7-16 mu g/L and close to or higher than the PNEC value for nano-TiO2 (< 1 mu g/L). The risk quotients (PEC/PNEC) for CNT and nano-Ag were much smaller than one, therefore comprising no reason to expect adverse effects from those particles. The results of this study make it possible for the first time to carry out a quantitative risk assessment of nanoparticles in the environment and suggest further detailed studies of nano-TiO2.					Nowack, Bernd/B-6425-2008	Nowack, Bernd/0000-0002-5676-112X													0013-936X	1520-5851				JUN 15	2008	42	12					4447	4453		10.1021/es7029637	http://dx.doi.org/10.1021/es7029637								18605569					WOS:000256705600036
J	Wolpaw, JR; Birbaumer, N; Heetderks, WJ; McFarland, DJ; Peckham, PH; Schalk, G; Donchin, E; Quatrano, LA; Robinson, CJ; Vaughan, TM				Wolpaw, JR; Birbaumer, N; Heetderks, WJ; McFarland, DJ; Peckham, PH; Schalk, G; Donchin, E; Quatrano, LA; Robinson, CJ; Vaughan, TM			Brain-computer interface technology: A review of the first international meeting	IEEE TRANSACTIONS ON REHABILITATION ENGINEERING												Over the past decade, many laboratories have begun to explore brain-computer interface (BCI) technology as a radically new communication option for those with neuromuscular impairments that prevent them from using conventional augmentative communication methods. BCI's provide these users with communication channels that do not depend on peripheral nerves and muscles. This article summarizes the first international meeting devoted to BCI research and development. Current BCI's use electroencephalographic (EEG) activity recorded at the scalp or single-unit activity recorded from within cortex to control cursor movement, select letters or icons, or operate a neuroprosthesis. The central element in each BCI is a translation algorithm that converts electrophysiological input from the user into output that controls external devices. BCI operation depends on effective interaction between two adaptive controllers, the user who encodes his or her commands in the electrophysiological input provided to the BCI, and the BCI which recognizes the commands contained in the input and expresses them in device control. Current BCI's have maximum information transfer rates of 5-25 b/min. Achievement of greater speed and accuracy depends on improvements in signal processing, translation algorithms, and user training. These improvements depend on increased interdisciplinary cooperation between neuroscientists, engineers, computer programmers, psychologists, and rehabilitation specialists, and on adoption and widespread application of objective methods for evaluating alternative methods. The practical use of BCI technology depends on the development of appropriate applications, identification of appropriate user groups, and careful attention to the needs and desires of individual users. BCI research and development will also benefit from greater emphasis on peer-reviewed publications, and from adoption of standard venues for presentations and discussion.						Schalk, Gerwin/0000-0003-3443-9487; Wolpaw, Jonathan/0000-0003-0805-1315; Birbaumer, Niels/0000-0002-6786-5127													1063-6528					JUN	2000	8	2					164	173		10.1109/TRE.2000.847807	http://dx.doi.org/10.1109/TRE.2000.847807								10896178					WOS:000087976700002
J	Deng, L; Yu, D				Deng, Li; Yu, Dong			Deep Learning: Methods and Applications	FOUNDATIONS AND TRENDS IN SIGNAL PROCESSING												This monograph provides an overview of general deep learning methodology and its applications to a variety of signal and information processing tasks. The application areas are chosen with the following three criteria in mind: (1) expertise or knowledge of the authors; (2) the application areas that have already been transformed by the successful use of deep learning technology, such as speech recognition and computer vision; and (3) the application areas that have the potential to be impacted significantly by deep learning and that have been experiencing research growth, including natural language and text processing, information retrieval, and multimodal information processing empowered by multi-task deep learning.					yu, dong/KRO-7922-2024														1932-8346	1932-8354					2013	7	3-4					I	387		10.1561/2000000039	http://dx.doi.org/10.1561/2000000039													WOS:000409611900001
J	Franquelo, LG; Rodríguez, J; Leon, JI; Kouro, S; Portillo, R; Prats, MM				Franquelo, Leopoldo G.; Rodriguez, Jose; Leon, Jose I.; Kouro, Samir; Portillo, Ramon; Prats, Maria M.			The Age of Multilevel Converters Arrives	IEEE INDUSTRIAL ELECTRONICS MAGAZINE																	Leon, Jose/AAF-9843-2019; Portillo, Ramon/M-1439-2014; Martin Prats, Maria Angeles/L-9043-2014; Kouro, Samir/E-9167-2012; Franquelo, Leopoldo Garcia/D-5450-2009; Leon, Jose I./L-2409-2014; Rodriguez, Jose/A-2534-2013	Portillo, Ramon/0000-0001-6453-8617; Martin Prats, Maria Angeles/0000-0002-6499-7925; Kouro, Samir/0000-0002-1690-4624; Franquelo, Leopoldo Garcia/0000-0002-1976-9747; Leon, Jose I./0000-0001-5760-8066; Rodriguez, Jose/0000-0002-1410-4121													1932-4529	1941-0115				JUN	2008	2	2					28	39		10.1109/MIE.2008.923519	http://dx.doi.org/10.1109/MIE.2008.923519													WOS:000272999900006
J	Gilles, J				Gilles, Jerome			Empirical Wavelet Transform	IEEE TRANSACTIONS ON SIGNAL PROCESSING												Some recent methods, like the empirical mode decomposition (EMD), propose to decompose a signal accordingly to its contained information. Even though its adaptability seems useful for many applications, the main issue with this approach is its lack of theory. This paper presents a new approach to build adaptive wavelets. The main idea is to extract the different modes of a signal by designing an appropriate wavelet filter bank. This construction leads us to a new wavelet transform, called the empirical wavelet transform. Many experiments are presented showing the usefulness of this method compared to the classic EMD.						Gilles, Jerome/0000-0002-5626-8386													1053-587X	1941-0476				AUG	2013	61	16					3999	4010		10.1109/TSP.2013.2265222	http://dx.doi.org/10.1109/TSP.2013.2265222													WOS:000322335100004
J	Pruden, A; Pei, RT; Storteboom, H; Carlson, KH				Pruden, Amy; Pei, Ruoting; Storteboom, Heather; Carlson, Kenneth H.			Antibiotic resistance genes as emerging contaminants: Studies in northern Colorado	ENVIRONMENTAL SCIENCE & TECHNOLOGY												This study explores antibiotic resistance genes (ARGs) as emerging environmental contaminants. The purpose of this study was to investigate the occurrence of ARGs in various environmental compartments in northern Colorado, including Cache La Poudre (Poudre) River sediments, irrigation ditches, dairy lagoons, and the effluents of wastewater recycling and drinking water treatment plants. Additionally, ARG concentrations in the Poudre River sediments were analyzed at three time points at five sites with varying levels of urban/agricultural impact and compared with two previously published time points. It was expected that ARG concentrations would be significantly higher in environments directly impacted by urban/ agricultural activity than in pristine and lesser-impacted environments. Polymerase chain reaction (PCR) detection assays were applied to detect the presence/absence of several tetracycline and sulfonamide ARGs. Quantitative real-time PCR was used to further quantify two tetracycline ARGs (tet(W) and tet(O)) and two sulfonamide ARGs (sul- (I) and sul(II)). The following trend was observed with respect to ARG concentrations (normalized to eubacterial 16S rRNA genes): dairy lagoon water > irrigation ditch water > urban/agriculturally impacted river sediments (p < 0.0001), except for sul(II), which was absent in ditch water. It was noted that tet(W) and tet(O) were also present in treated drinking water and recycled wastewater, suggesting that these are potential pathways for the spread of ARGs to and from humans. On the basis of this study, there is a need for environmental scientists and engineers to help address the issue of the spread of ARGs in the environment.					Smith, Ken/ABB-6677-2021														0013-936X	1520-5851				DEC 1	2006	40	23					7445	7450		10.1021/es060413l	http://dx.doi.org/10.1021/es060413l								17181002					WOS:000242367100055
J	Sauvola, J; Pietikäinen, M				Sauvola, J; Pietikäinen, M			Adaptive document image binarization	PATTERN RECOGNITION												A new method is presented for adaptive document image binarization, where the page is considered as a collection of subcomponents such as text, background and picture. The problems caused by noise, illumination and many source type-related degradations are addressed. Two new algorithms are applied to determine a local threshold for each pixel. The performance evaluation of the algorithm utilizes test images with ground-truth, evaluation metrics for binarization of textual and synthetic images, and a weight-based ranking procedure for the final result presentation. The proposed algorithms were tested with images including different types of document components and degradations. The results were compared with a number of known techniques in the literature. The benchmarking results show that the method adapts and performs well in each case qualitatively and quantitatively. (C) 1999 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.																			0031-3203	1873-5142				FEB	2000	33	2					225	236		10.1016/S0031-3203(99)00055-2	http://dx.doi.org/10.1016/S0031-3203(99)00055-2													WOS:000084262800005
J	Barnich, O; Van Droogenbroeck, M				Barnich, Olivier; Van Droogenbroeck, Marc			ViBe: A Universal Background Subtraction Algorithm for Video Sequences	IEEE TRANSACTIONS ON IMAGE PROCESSING												This paper presents a technique for motion detection that incorporates several innovative mechanisms. For example, our proposed technique stores, for each pixel, a set of values taken in the past at the same location or in the neighborhood. It then compares this set to the current pixel value in order to determine whether that pixel belongs to the background, and adapts the model by choosing randomly which values to substitute from the background model. This approach differs from those based upon the classical belief that the oldest values should be replaced first. Finally, when the pixel is found to be part of the background, its value is propagated into the background model of a neighboring pixel. We describe our method in full details (including pseudo-code and the parameter values used) and compare it to other background subtraction techniques. Efficiency figures show that our method outperforms recent and proven state-of-the-art methods in terms of both computation speed and detection rate. We also analyze the performance of a downscaled version of our algorithm to the absolute minimum of one comparison and one byte of memory per pixel. It appears that even such a simplified version of our algorithm performs better than mainstream techniques.						Van Droogenbroeck, Marc/0000-0001-6260-6487													1057-7149	1941-0042				JUN	2011	20	6					1709	1724		10.1109/TIP.2010.2101613	http://dx.doi.org/10.1109/TIP.2010.2101613								21189241					WOS:000290732600019
J	Choi, WY; Park, BG; Lee, JD; Liu, TJK				Choi, Woo Young; Park, Byung-Gook; Lee, Jong Duk; Liu, Tsu-Jae King			Tunneling field-effect transistors (TFETs) with subthreshold swing (SS) less than 60 mV/dec	IEEE ELECTRON DEVICE LETTERS												We have demonstrated a 70-nm n-channel tunneling field-effect transistor (TFET) which has a subthreshold swing (SS) of 52.8 mV/dec at room temperature. It is the first experimental result that shows a sub-60-mV/dec SS in the silicon-based TFETs. Based on simulation results, the gate oxide and silicon-on-insulator layer thicknesses were scaled down to 2 and 70 nm, respectively. However, the ON/OFF current ratio of the TFET was still lower than that of the MOSFET. In order to increase the ON current further, the following approaches can be considered: reduction of effective gate oxide thickness, increase in the steepness of the gradient of the source to channel doping profile, and utilization of a lower bandgap channel material.					Lee, Jeeyun/I-7171-2015; Choi, Woo Young/ACK-4652-2022	Choi, Woo Young/0000-0002-5515-2912													0741-3106	1558-0563				AUG	2007	28	8					743	745		10.1109/LED.2007.901273	http://dx.doi.org/10.1109/LED.2007.901273													WOS:000248315400025
J	Levelt, PF; Van den Oord, GHJ; Dobber, MR; Mälkki, A; Visser, H; de Vries, J; Stammes, P; Lundell, JOV; Saari, H				Levelt, PF; Van den Oord, GHJ; Dobber, MR; Mälkki, A; Visser, H; de Vries, J; Stammes, P; Lundell, JOV; Saari, H			The Ozone Monitoring Instrument	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING												The Ozone Monitoring Instrument (OMI) flies on the National Aeronautics and Space Adminsitration's Earth Observing System Aura satellite launched in July 2004. OMI is a ultraviolet/visible (UV/VIS) nadir solar backscatter spectrometer, which provides nearly global coverage in one day with a spatial resolution of 13 km x 24 km. Trace gases measured include 03, NO,, SO,, HCHO, BrO, and OClO. In addition, OMI will measure aerosol characteristics, cloud top heights, and UV irradiance at the surface. OMI's unique capabilities for measuring important trace gases with a small footprint and daily global coverage will be a major contribution to our understanding of stratospheric and tropospheric chemistry and climate change. OMI's high spatial resolution is unprecedented and will enable detection of air pollution on urban scale resolution. In this paper, the instrument and its performance will be discussed.					Levelt, Pieternel/AAE-3835-2022														0196-2892	1558-0644				MAY	2006	44	5					1093	1101		10.1109/TGRS.2006.872333	http://dx.doi.org/10.1109/TGRS.2006.872333													WOS:000237167100004
J	Platnick, S; King, MD; Ackerman, SA; Menzel, WP; Baum, BA; Riédi, JC; Frey, RA				Platnick, S; King, MD; Ackerman, SA; Menzel, WP; Baum, BA; Riédi, JC; Frey, RA			The MODIS cloud products:: Algorithms and examples from Terra	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING												The Moderate Resolution Imaging Spectroradiometer (MODIS) is one of five instruments aboard the Terra Earth Observing System (EOS) platform launched in December 1999. After achieving final orbit, MODIS began earth observations in late February 2000 and has been acquiring data since that time. The instrument is also being flown on the Aqua spacecraft, launched in May 2002. A comprehensive set of remote sensing algorithms for cloud detection and the retrieval of cloud physical and optical properties have been developed by members of the MODIS atmosphere science team. The archived products from these algorithms have applications in climate change studies, climate modeling, numerical weather prediction, as well as fundamental atmospheric research. In addition to an extensive cloud mask, products include cloud-top properties (temperature, pressure, effective emissivity), cloud thermodynamic phase, cloud optical and microphysical parameters (optical thickness, effective particle radius, water path), as well as derived statistics. We will describe the various algorithms being used for the remote sensing of cloud properties from MODIS data with an emphasis on the pixel-level retrievals (referred to as Level-2 products), with 1-km or 5-km spatial resolution at nadir. An example of each Level-2 cloud product from a common data granule (5 min of data) off the coast of South America will be discussed. Future efforts will also be mentioned. Relevant points related to the global gridded statistics products (Level-3) are highlighted though additional details are given in an accompanying paper in this issue.					King, Michael/C-7153-2011; Baum, Bryan/B-7670-2011; RIEDI, Jérôme/AGE-4779-2022; Platnick, Steven/J-9982-2014; Menzel, W. Paul/B-8306-2011; Ackerman, Steven/G-1640-2011	Platnick, Steven/0000-0003-3964-3567; Menzel, W. Paul/0000-0001-5690-1201; Riedi, Jerome/0000-0002-0374-7316; Ackerman, Steven/0000-0002-4476-0269; King, Michael/0000-0003-2645-7298													0196-2892	1558-0644				FEB	2003	41	2					459	473		10.1109/TGRS.2002.808301	http://dx.doi.org/10.1109/TGRS.2002.808301													WOS:000182494600027
J	Wright, J; Ma, Y; Mairal, J; Sapiro, G; Huang, TS; Yan, SC				Wright, John; Ma, Yi; Mairal, Julien; Sapiro, Guillermo; Huang, Thomas S.; Yan, Shuicheng			Sparse Representation for Computer Vision and Pattern Recognition	PROCEEDINGS OF THE IEEE												Techniques from sparse signal representation are beginning to see significant impact in computer vision, often on nontraditional applications where the goal is not just to obtain a compact high-fidelity representation of the observed signal, but also to extract semantic information. The choice of dictionary plays a key role in bridging this gap: unconventional dictionaries consisting of, or learned from, the training samples themselves provide the key to obtaining state-of-the-art results and to attaching semantic meaning to sparse signal representations. Understanding the good performance of such unconventional dictionaries in turn demands new algorithmic and analytical techniques. This review paper highlights a few representative examples of how the interaction between sparse signal representation and computer vision can enrich both fields, and raises a number of open questions for further study.					Yan, Shuicheng/HCI-1431-2022; Mairal, Julien/AAL-5611-2021; Ma, Yi/K-1458-2014	Yan, Shuicheng/0000-0001-8906-3777													0018-9219	1558-2256				JUN	2010	98	6					1031	1044		10.1109/JPROC.2010.2044470	http://dx.doi.org/10.1109/JPROC.2010.2044470													WOS:000277884900014
J	Ngo, HQ; Ashikhmin, A; Yang, H; Larsson, EG; Marzetta, TL				Hien Quoc Ngo; Ashikhmin, Alexei; Yang, Hong; Larsson, Erik G.; Marzetta, Thomas L.			Cell-Free Massive MIMO Versus Small Cells	IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS												A Cell-Free Massive MIMO (multiple-input multiple-output) system comprises a very large number of distributed access points (APs), which simultaneously serve a much smaller number of users over the same time/frequency resources based on directly measured channel characteristics. The APs and users have only one antenna each. The APs acquire channel state information through time-division duplex operation and the reception of uplink pilot signals transmitted by the users. The APs perform multiplexing/de-multiplexing through conjugate beamforming on the downlink and matched filtering on the uplink. Closed-form expressions for individual user uplink and downlink throughputs lead to max-min power control algorithms. Max-min power control ensures uniformly good service throughout the area of coverage. A pilot assignment algorithm helps to mitigate the effects of pilot contamination, but power control is far more important in that regard. Cell-Free Massive MIMO has considerably improved performance with respect to a conventional small-cell scheme, whereby each user is served by a dedicated AP, in terms of both 95%-likely per-user throughput and immunity to shadow fading spatial correlation. Under uncorrelated shadow fading conditions, the cell-free scheme provides nearly fivefold improvement in 95%-likely per-user throughput over the small-cell scheme, and tenfold improvement when shadow fading is correlated.					Larsson, Erik/ADV-7383-2022; Marzetta, Thomas/AEB-0112-2022; Ngo, Hien/AAJ-5745-2020	Ngo, Hien/0000-0002-3367-2220													1536-1276	1558-2248				MAR	2017	16	3					1834	1850		10.1109/TWC.2017.2655515	http://dx.doi.org/10.1109/TWC.2017.2655515													WOS:000396404600036
J	Yan, Y; Mao, YX; Li, B				Yan, Yan; Mao, Yuxing; Li, Bo			SECOND: Sparsely Embedded Convolutional Detection	SENSORS												LiDAR-based or RGB-D-based object detection is used in numerous applications, ranging from autonomous driving to robot vision. Voxel-based 3D convolutional networks have been used for some time to enhance the retention of information when processing point cloud LiDAR data. However, problems remain, including a slow inference speed and low orientation estimation performance. We therefore investigate an improved sparse convolution method for such networks, which significantly increases the speed of both training and inference. We also introduce a new form of angle loss regression to improve the orientation estimation performance and a new data augmentation approach that can enhance the convergence speed and performance. The proposed network produces state-of-the-art results on the KITTI 3D object detection benchmarks while maintaining a fast inference speed.																				1424-8220				OCT	2018	18	10							3337	10.3390/s18103337	http://dx.doi.org/10.3390/s18103337								30301196					WOS:000448661500165
J	Armstrong, J				Armstrong, Jean			OFDM for Optical Communications	JOURNAL OF LIGHTWAVE TECHNOLOGY												Orthogonal frequency division multiplexing (OFDM) is a modulation technique which is now used in most new and emerging broadband wired and wireless communication systems because it is an effective solution to intersymbol interference caused by a dispersive channel. Very recently a number of researchers have shown that OFDM is also a promising technology for optical communications. This paper gives a tutorial overview of OFDM highlighting the aspects that are likely to be important in optical applications. To achieve good performance in optical systems OFDM must be adapted in various ways. The constraints imposed by single mode optical fiber, multimode optical fiber and optical wireless are discussed and the new forms of optical OFDM which have been developed are outlined. The main drawbacks or OFDM are its high peak to average power ratio and its sensitivity to phase noise and frequency offset. The impairments that these cause are described and their implications for optical systems discussed.					Armstrong, Jean/G-3027-2010	Armstrong, Jean/0000-0002-8002-0225													0733-8724	1558-2213				JAN-FEB	2009	27	1-4					189	204		10.1109/JLT.2008.2010061	http://dx.doi.org/10.1109/JLT.2008.2010061													WOS:000263768300023
J	Li, XM; Chen, H; Qi, XJ; Dou, Q; Fu, CW; Heng, PA				Li, Xiaomeng; Chen, Hao; Qi, Xiaojuan; Dou, Qi; Fu, Chi-Wing; Heng, Pheng-Ann			H-DenseUNet: Hybrid Densely Connected UNet for Liver and Tumor Segmentation From CT Volumes	IEEE TRANSACTIONS ON MEDICAL IMAGING												Liver cancer is one of the leading causes of cancer death. To assist doctors in hepatocellular carcinoma diagnosis and treatment planning, an accurate and automatic liver and tumor segmentation method is highly demanded in the clinical practice. Recently, fully convolutional neural networks (FCNs), including 2-D and 3-D FCNs, serve as the backbone in many volumetric image segmentation. However, 2-D convolutions cannot fully leverage the spatial information along the third dimension while 3-D convolutions suffer from high computational cost and GPU memory consumption. To address these issues, we propose a novel hybrid densely connected UNet (H-DenseUNet), which consists of a 2-D DenseUNet for efficiently extracting intra-slice features and a 3-D counterpart for hierarchically aggregating volumetric contexts under the spirit of the auto-context algorithm for liver and tumor segmentation. We formulate the learning process of the H-DenseUNet in an end-to-endmanner, where the intra-slice representations and inter-slice features can be jointly optimized through a hybrid feature fusion layer. We extensively evaluated our method on the data set of the MICCAI 2017 Liver Tumor Segmentation Challenge and 3DIRCADb data set. Our method outperformed other state-of-the-arts on the segmentation results of tumors and achieved very competitive performance for liver segmentation even with a single model.					Fu, Chi-Wing/X-4703-2019; Li, Xiaomeng/AAV-6938-2020; Dou, Qi/I-8175-2019; Chen, Hao/V-4299-2019	Chen, Hao/0000-0002-8400-3780; Dou, Qi/0000-0002-3416-9950; Heng, Pheng Ann/0000-0003-3055-5034; Li, Xiaomeng/0000-0003-1105-8083; Xiaojuan, Qi/0000-0002-4285-1626; Fu, Chi Wing/0000-0002-5238-593X													0278-0062	1558-254X				DEC	2018	37	12					2663	2674		10.1109/TMI.2018.2845918	http://dx.doi.org/10.1109/TMI.2018.2845918								29994201					WOS:000451903400011
J	Jolliet, O; Margni, M; Charles, R; Humbert, S; Payet, J; Rebitzer, G; Rosenbaum, R				Jolliet, O; Margni, M; Charles, R; Humbert, S; Payet, J; Rebitzer, G; Rosenbaum, R			IMPACT 2002+: A new life cycle impact assessment methodology	INTERNATIONAL JOURNAL OF LIFE CYCLE ASSESSMENT												The new IMPACT 2002+ life cycle impact assessment methodology proposes a feasible implementation of a combined midpoint/ damage approach, linking all types of life cycle inventory results (elementary flows and other interventions) via 14 midpoint categories to four damage categories. For IMPACT 2002+, new concepts and methods have been developed, especially for the comparative assessment of human toxicity and ecotoxicity. Human Damage Factors are calculated for carcinogens and non-carcinogens, employing intake fractions, best estimates of dose-response slope factors, as well as severities. The transfer of contaminants into the human food is no more based on consumption surveys, but accounts for agricultural and livestock production levels. Indoor and outdoor air emissions can be compared and the intermittent character of rainfall is considered. Both human toxicity and ecotoxicity effect factors are based on mean responses rather than on conservative assumptions. Other midpoint categories are adapted from existing characterizing methods (Eco-indicator 99 and CML 2002). All midpoint scores are expressed in units of a reference substance and related to the four damage categories human health, ecosystem quality, climate change, and resources. Normalization can be performed either at midpoint or at damage level. The IMPACT 2002+ method presently provides characterization factors for almost 1500 different LCI-results, which can be downloaded at http://www.epfl.ch/impact					Rosenbaum, Ralph/AGE-3200-2022; Margni, Manuele/A-4579-2013; Charles, Raphaël/AAA-8722-2022	Rosenbaum, Ralph/0000-0002-7620-1568; Charles, Raphael/0000-0001-6563-7764; Jolliet, Olivier/0000-0001-6955-4210; Margni, Manuele/0000-0002-2475-0768; Payet, Jerome/0000-0003-2435-413X													0948-3349	1614-7502					2003	8	6					324	330		10.1007/BF02978505	http://dx.doi.org/10.1007/BF02978505													WOS:000186715400003
J	Wang, Q; Mao, ZD; Wang, B; Guo, L				Wang, Quan; Mao, Zhendong; Wang, Bin; Guo, Li			Knowledge Graph Embedding: A Survey of Approaches and Applications	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING												Knowledge graph (KG) embedding is to embed components of a KG including entities and relations into continuous vector spaces, so as to simplify the manipulation while preserving the inherent structure of the KG. It can benefit a variety of downstream tasks such as KG completion and relation extraction, and hence has quickly gained massive attention. In this article, we provide a systematic review of existing techniques, including not only the state-of-the-arts but also those with latest trends. Particularly, we make the review based on the type of information used in the embedding task. Techniques that conduct embedding using only facts observed in the KG are first introduced. We describe the overall framework, specific model design, typical training procedures, as well as pros and cons of such techniques. After that, we discuss techniques that further incorporate additional information besides facts. We focus specifically on the use of entity types, relation paths, textual descriptions, and logical rules. Finally, we briefly introduce how KG embedding can be applied to and benefit a wide variety of downstream tasks such as KG completion, relation extraction, question answering, and so forth.																			1041-4347	1558-2191				DEC	2017	29	12					2724	2743		10.1109/TKDE.2017.2754499	http://dx.doi.org/10.1109/TKDE.2017.2754499													WOS:000414712700008
J	Guerrero, JM; Chandorkar, M; Lee, TL; Loh, PC				Guerrero, Josep M.; Chandorkar, Mukul; Lee, Tzung-Lin; Loh, Poh Chiang			Advanced Control Architectures for Intelligent Microgrids-Part I: Decentralized and Hierarchical Control	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS												This paper presents a review of advanced control techniques for microgrids. This paper covers decentralized, distributed, and hierarchical control of grid-connected and islanded microgrids. At first, decentralized control techniques for microgrids are reviewed. Then, the recent developments in the stability analysis of decentralized controlled microgrids are discussed. Finally, hierarchical control for microgrids that mimic the behavior of the mains grid is reviewed.					Loh, Poh/A-5047-2011; Guerrero, Josep/D-5519-2014	Lee, Tzung-Lin/0000-0002-8461-8398; Guerrero, Josep/0000-0001-5236-4592													0278-0046	1557-9948				APR	2013	60	4					1254	1262		10.1109/TIE.2012.2194969	http://dx.doi.org/10.1109/TIE.2012.2194969													WOS:000311790200002
J	Gao, F; Masek, J; Schwaller, M; Hall, F				Gao, Feng; Masek, Jeff; Schwaller, Matt; Hall, Forrest			On the blending of the Landsat and MODIS surface reflectance: Predicting daily Landsat surface reflectance	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING												The 16-day revisit cycle of Landsat has long limited its use for studying global biophysical processes, which evolve rapidly during the growing season. In cloudy areas of the Earth, the problem is compounded, and researchers are fortunate to get two to three clear images per year. At the same time, the coarse resolution of sensors such as the Advanced Very High Resolution Radiometer and Moderate Resolution Imaging Spectroradiometer (MODIS) limits the sensors' ability to quantify biophysical processes in heterogeneous landscapes. In this paper, the authors present a new spatial and temporal adaptive reflectance fusion model (STARFM) algorithm to blend Landsat and MODIS surface reflectance. Using this approach, high-frequency temporal information from MODIS and high-resolution spatial information from Landsat can be blended for applications that require high resolution in both time and space. The MODIS daily 500-m surface reflectance and the 16-day repeat cycle Landsat Enhanced Thematic Mapper Plus (ETM+) 30-m surface reflectance are used to produce a synthetic "daily" surface reflectance product at ETM+ spatial resolution. The authors present results both with simulated (model) data and actual Landsat/MODIS acquisitions. In general, the STARFM accurately predicts surface reflectance at an effective resolution close to that of the ETM+. However, the performance depends on the characteristic patch size of the landscape and degrades somewhat when used on extremely heterogeneous fine-grained landscapes.					Masek, Jeffrey/D-7673-2012; Gao, Feng/F-3944-2010	Gao, Feng/0000-0002-1865-2846													0196-2892	1558-0644				AUG	2006	44	8					2207	2218		10.1109/TGRS.2006.872081	http://dx.doi.org/10.1109/TGRS.2006.872081													WOS:000239404000019
J	Pointcheval, D; Stern, J				Pointcheval, D; Stern, J			Security arguments for digital signatures and blind signatures	JOURNAL OF CRYPTOLOGY												Since the appearance of public-key cryptography in the seminal Diffie-Hellman paper, many new schemes have been proposed and many have been broken. Thus, the simple fact that a cryptographic algorithm withstands cryptanalytic attacks for several years is often considered as a kind of validation procedure. A much more convincing line of research has tried to provide "provable" security for cryptographic protocols. Unfortunately, in many cases, provable security is at the cost of a considerable loss in terms of efficiency. Another way to achieve some kind of provable security is to identify concrete cryptographic objects, such as hash functions, with ideal random objects and to use arguments from relativized complexity theory. The model underlying this approach is often called the "random oracle model." We use the word "arguments" for security results proved in this model. As usual, these arguments are relative to well-established hard algorithmic problems such as factorization or the discrete logarithm. In this paper we offer security arguments for a large class of known signature schemes. Moreover, we give for the first time an argument for a very slight variation of the well-known El Gamal signature scheme. In spite of the existential forgery of the original scheme, we prove that our variant resists existential forgeries even against an adaptively chosen-message attack. This is provided that the discrete logarithm problem is hard to solve. Next, we study the security of blind signatures which are the most important ingredient for anonymity in off-line electronic cash systems. We first define an appropriate notion of security related to the setting of electronic cash. We then propose new schemes for which one can provide security arguments.						Pointcheval, David/0000-0002-6668-683X													0933-2790	1432-1378				SUM	2000	13	3					361	396		10.1007/s001450010003	http://dx.doi.org/10.1007/s001450010003													WOS:000087797500004
J	Wong, HSP; Raoux, S; Kim, S; Liang, JL; Reifenberg, JP; Rajendran, B; Asheghi, M; Goodson, KE				Wong, H. -S. Philip; Raoux, Simone; Kim, SangBum; Liang, Jiale; Reifenberg, John P.; Rajendran, Bipin; Asheghi, Mehdi; Goodson, Kenneth E.			Phase Change Memory	PROCEEDINGS OF THE IEEE												In this paper, recent progress of phase change memory (PCM) is reviewed. The electrical and thermal properties of phase change materials are surveyed with a focus on the scalability of the materials and their impact on device design. Innovations in the device structure, memory cell selector, and strategies for achieving multibit operation and 3-D, multilayer high-density memory arrays are described. The scaling properties of PCM are illustrated with recent experimental results using special device test structures and novel material synthesis. Factors affecting the reliability of PCM are discussed.					Raoux, Simone/G-3920-2016; Liang, Jiale/I-5021-2012; Goodson, Kenneth/C-3545-2011; Rajendran, Bipin/C-6369-2009; Kim, Sangbum/B-7069-2016	Rajendran, Bipin/0000-0002-2960-6909; Kim, Sangbum/0000-0001-7460-3750; Subramoni, Hari/0000-0002-1200-2754													0018-9219	1558-2256				DEC	2010	98	12					2201	2227		10.1109/JPROC.2010.2070050	http://dx.doi.org/10.1109/JPROC.2010.2070050													WOS:000284410800016
J	Zhao, H; Gallo, O; Frosio, I; Kautz, J				Zhao, Hang; Gallo, Orazio; Frosio, Iuri; Kautz, Jan			Loss Functions for Image Restoration With Neural Networks	IEEE TRANSACTIONS ON COMPUTATIONAL IMAGING												Neural networks are becoming central in several areas of computer vision and image processing and different architectures have been proposed to solve specific problems. The impact of the loss layer of neural networks, however, has not received much attention in the context of image processing: the default and virtually only choice is l(2). In this paper, we bring attention to alternative choices for image restoration. In particular, we show the importance of perceptually-motivated losses when the resulting image is to be evaluated by a human observer. We compare the performance of several losses, and propose a novel, differentiable error function. We show that the quality of the results improves significantly with better loss functions, even when the network architecture is left unchanged.					frosio, iuri/G-8917-2012														2573-0436	2333-9403				MAR	2017	3	1					47	57		10.1109/TCI.2016.2644865	http://dx.doi.org/10.1109/TCI.2016.2644865													WOS:000395665800005
J	Angelidaki, I; Alves, M; Bolzonella, D; Borzacconi, L; Campos, JL; Guwy, AJ; Kalyuzhnyi, S; Jenicek, P; van Lier, JB				Angelidaki, I.; Alves, M.; Bolzonella, D.; Borzacconi, L.; Campos, J. L.; Guwy, A. J.; Kalyuzhnyi, S.; Jenicek, P.; van Lier, J. B.			Defining the biomethane potential (BMP) of solid organic wastes and energy crops: a proposed protocol for batch assays	WATER SCIENCE AND TECHNOLOGY												The application of anaerobic digestion technology is growing worldwide because of its economic and environmental benefits. As a consequence, a number of studies and research activities dealing with the determination of the biogas potential of solid organic substrates have been carrying out in the recent years. Therefore, it is of particular importance to define a protocol for the determination of the ultimate methane potential for a given solid substrates. In fact, this parameter determines, to a certain extent, both design and economic details of a biogas plant. Furthermore, the definition of common units to be used in anaerobic assays is increasingly requested from the scientific and engineering community. This paper presents some guidelines for biomethane potential assays prepared by the Task Group for the Anaerobic Biodegradation, Activity and Inhibition Assays of the Anaerobic Digestion Specialist Group of the International Water Association. This is the first step for the definition of a standard protocol.					Guwy, Alan/AAH-5518-2021; Kalyuzhnyi, Sergey/A-5007-2010; Jenicek, Pavel/AAA-4448-2021; Angelidaki, Irini/AAX-2562-2020; bolzonella, david/A-6213-2008; Alves, Madalena/C-1487-2012; Guwy, Alan/HKE-3038-2023	bolzonella, david/0000-0002-3240-7417; van Lier, Jules/0000-0003-2607-5425; Alves, Madalena/0000-0002-9078-3613; Guwy, Alan/0000-0002-7002-9242; Jenicek, Pavel/0000-0001-8438-1231; Angelidaki, Irini/0000-0002-6357-578X													0273-1223	1996-9732					2009	59	5					927	934		10.2166/wst.2009.040	http://dx.doi.org/10.2166/wst.2009.040								19273891					WOS:000264598100010
J	Chen, BL; Zhou, DD; Zhu, LZ				Chen, Baoliang; Zhou, Dandan; Zhu, Lizhong			Transitional adsorption and partition of nonpolar and polar aromatic contaminants by biochars of pine needles with different pyrolytic temperatures	ENVIRONMENTAL SCIENCE & TECHNOLOGY												The combined adsorption and partition effects of biochars with varying fractions of noncarbonized organic matter have not been clearly defined. Biochars, produced by pyrolysis of pine needles at different temperatures (100-700 degrees C, referred as P100-P700), were characterized by elemental analysis, BET-N(2) surface areas and FIR. Sorption isotherms of naphthalene, nitrobenzene, and m-dinitrobenzene from water to the biochars were compared. Sorption parameters (N and log K(f)) are linearly related to sorbent aromaticities, which increase with the pyrolytic temperature. Sorption mechanisms of biochars are evolved from partitioning-dominant at low pyrolytic temperatures to adsorption-dominant at higher pyrolytic temperatures. The quantitative contributions of adsorption and partition are determined by the relative carbonized and noncarbonized fractions and their surface and bulk properties. The partition of P100-P300 biochars originates from an amorphous aliphatic fraction, which is enhanced with a reduction of the substrate polarity; for P400-P600, the partition occurs with a condensed aromatic core that diminishes with a further reduction of the polarity. Simultaneously, the adsorption component exhibits a transition from a polarity-selective (P200-P400) to a porosity-selective (P500-P600) process, and displays no selectivity with P700 and AC in which the adsorptive saturation capacities are comparable to predicted values based on the monolayer surface coverage of molecule.					Chen, Baoliang/A-9275-2015														0013-936X					JUL 15	2008	42	14					5137	5143		10.1021/es8002684	http://dx.doi.org/10.1021/es8002684								18754360					WOS:000257620000021
J	Rodríguez, JJ; Kuncheva, LI				Rodriguez, Juan J.; Kuncheva, Ludmila I.			Rotation forest:: A new classifier ensemble method	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												We propose a method for generating classifier ensembles based on feature extraction. To create the training data for a base classifier, the feature set is randomly split into K subsets (K is a parameter of the algorithm) and Principal Component Analysis (PCA) is applied to each subset. All principal components are retained in order to preserve the variability information in the data. Thus, K axis rotations take place to form the new features for a base classifier. The idea of the rotation approach is to encourage simultaneously individual accuracy and diversity within the ensemble. Diversity is promoted through the feature extraction for each base classifier. Decision trees were chosen here because they are sensitive to rotation of the feature axes, hence the name "forest." Accuracy is sought by keeping all principal components and also using the whole data set to train each base classifier. Using WEKA, we examined the Rotation Forest ensemble on a random selection of 33 benchmark data sets from the UCI repository and compared it with Bagging, AdaBoost, and Random Forest. The results were favorable to Rotation Forest and prompted an investigation into diversity-accuracy landscape of the ensemble models. Diversity-error diagrams revealed that Rotation Forest ensembles construct individual classifiers which are more accurate than these in AdaBoost and Random Forest, and more diverse than these in Bagging, sometimes more accurate as well.					Kuncheva, Ludmila/J-4357-2014; Rodriguez, Juan J./B-1014-2008; Alonso Gonzalez, Carlos Javier/G-1073-2018	Kuncheva, Ludmila/0000-0002-0415-6964; Rodriguez, Juan J./0000-0002-3291-2739; Alonso Gonzalez, Carlos Javier/0000-0003-4136-9632													0162-8828	1939-3539				OCT	2006	28	10					1619	1630		10.1109/TPAMI.2006.211	http://dx.doi.org/10.1109/TPAMI.2006.211								16986543					WOS:000239605500006
J	Richter, H; Howard, JB				Richter, H; Howard, JB			Formation of polycyclic aromatic hydrocarbons and their growth to soot - a review of chemical reaction pathways	PROGRESS IN ENERGY AND COMBUSTION SCIENCE					1st Mediterranean Combustion Symposium (MCS-99)	JUN 20-25, 1999	ANTALYA, TURKEY	Combust Inst, Int Ctr Heat & Mass Transfer				The generation by combustion processes of airborne species of current health concern such as polycyclic aromatic hydrocarbons (PAH) and soot particles necessitates a detailed understanding of chemical reaction pathways responsible for their formation. The present review discusses a general scheme of PAH formation and sequential growth of PAH by reactions with stable and radical species, including single-ring aromatics, other PAH and acetylene, followed by the nucleation or inception of small soot particles, soot growth by coagulation and mass addition from gas phase species, and carbonization of the particulate material. Experimental and theoretical tools which have allowed the achievement of deeper insight into the corresponding chemical processes are presented. The significant roles of propargyl (C3H3) and cyclopentadienyl (C5H5) radicals in the formation of first aromatic rings in combustion of aliphatic fuels are discussed. Detailed kinetic modeling of well-defined combustion systems, such as premixed flames, for which sufficient experimental data for a quantitative understanding are available, is of increasing importance. Reliable thermodynamic and kinetic property data are also required for meaningful conclusions, and computational techniques for their determination are presented. Routes of ongoing and future research leading to mon detailed experimental data as well as computational approaches for the exploration of elementary reaction steps and the description of systems of increasing complexity are discussed. (C) 2000 Elsevier Science Ltd. All rights reserved.																			0360-1285	1873-216X					2000	26	4-6					565	608		10.1016/S0360-1285(00)00009-5	http://dx.doi.org/10.1016/S0360-1285(00)00009-5													WOS:000088568900010
J	Islam, SMR; Kwak, D; Kabir, MH; Hossain, M; Kwak, KS				Islam, S. M. Riazul; Kwak, Daehan; Kabir, Md. Humaun; Hossain, Mahmud; Kwak, Kyung-Sup			The Internet of Things for Health Care: A Comprehensive Survey	IEEE ACCESS												The Internet of Things (IoT) makes smart objects the ultimate building blocks in the development of cyber-physical smart pervasive frameworks. The IoT has a variety of application domains, including health care. The IoT revolution is redesigning modern health care with promising technological, economic, and social prospects. This paper surveys advances in IoT-based health care technologies and reviews the state-of-the-art network architectures/platforms, applications, and industrial trends in IoT-based health care solutions. In addition, this paper analyzes distinct IoT security and privacy features, including security requirements, threat models, and attack taxonomies from the health care perspective. Further, this paper proposes an intelligent collaborative security model to minimize security risk; discusses how different innovations such as big data, ambient intelligence, and wearables can be leveraged in a health care context; addresses various IoT and eHealth policies and regulations across the world to determine how they can facilitate economies and societies in terms of sustainable development; and provides some avenues for future research on IoT-based health care based on a set of open issues and challenges.					Hossain, Mahmud/J-2624-2019; Kwak, Daehan/B-9688-2015; Islam, S. M. Riazul/F-1471-2017	Kwak, Daehan/0000-0001-5614-0190; Islam, S. M. Riazul/0000-0003-2968-9561; Hossain, Mahmud/0000-0002-4102-8056													2169-3536						2015	3						678	708		10.1109/ACCESS.2015.2437951	http://dx.doi.org/10.1109/ACCESS.2015.2437951													WOS:000371388200050
J	Liu, JY; Hurt, RH				Liu, Jingyu; Hurt, Robert H.			Ion Release Kinetics and Particle Persistence in Aqueous Nano-Silver Colloids	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Many important aspects of nanosilver behavior are influenced by the ionic activity associated with the particle suspension, including antibacterial potency, eukaryotic toxicity, environmental release, and particle persistence. The present study synthesizes pure, ion-free, citrate-stabilized nanosilver (nAg) colloids as model systems, and measures their time-dependent release of dissolved silver using centrifugal ultrafiltration and atomic absorption spectroscopy. Ion release is shown to be a cooperative oxidation process requiring both dissolved dioxygen and protons. It produces peroxide intermediates, and proceeds to complete reactive dissolution under some conditions. Ion release rates increase with temperature in the range 0-37 degrees C, and decrease with increasing pH or addition of humic or fulvic acids. Sea salts have only a minor effect on dissolved silver release. Silver nanoparticle surfaces can adsorb Ag+, so even simple colloids contain three forms of silver: Ag-0 solids, free Ag+ or its complexes, and surface-adsorbed Ag+. Both thermodynamic analysis and kinetic measurements indicate that Ag-0 nanciparticles will not be persistent in realistic environmental compartments containing dissolved oxygen. An empirical kinetic law is proposed that reproduces the observed effects of dissolution time, pH, humic/fulvic acid content, and temperature observed here in the low range of nanosilver concentration most relevant for the environment.					Liu, Jingyu/A-1503-2015	Hurt, Robert/0000-0002-2036-9337													0013-936X	1520-5851				MAR 15	2010	44	6					2169	2175		10.1021/es9035557	http://dx.doi.org/10.1021/es9035557								20175529					WOS:000275325600047
J	Koutsopoulos, S				Koutsopoulos, S			Synthesis and characterization of hydroxyapatite crystals: A review study on the analytical methods	JOURNAL OF BIOMEDICAL MATERIALS RESEARCH												For the synthesis of hydroxyapatite crystals from aqueous solutions three preparation methods were employed. From the experimental processes and the characterization of the crystals it was concluded that aging and precipitation kinetics are critical for the purity of the product and its crystallographic characteristics. The authentication details are presented along with the results from infrared spectroscopy, X-ray powder diffraction, Raman spectroscopy, transmission and scanning electron photographs, and chemical analysis. Analytical data for several calcium phosphates were collected from the literature, extensively reviewed, and the results were grouped and presented in tables to provide comparison with the data obtained here. (C) 2002 Wiley Periodicals, Inc.					Koutsopoulos, Sotirios/B-4184-2008	Koutsopoulos, Sotirios/0000-0003-1235-9515													0021-9304					DEC 15	2002	62	4					600	612		10.1002/jbm.10280	http://dx.doi.org/10.1002/jbm.10280								12221709					WOS:000178374200016
J	Larson, EC; Chandler, DM				Larson, Eric C.; Chandler, Damon M.			Most apparent distortion: full-reference image quality assessment and the role of strategy	JOURNAL OF ELECTRONIC IMAGING												The mainstream approach to image quality assessment has centered around accurately modeling the single most relevant strategy employed by the human visual system (HVS) when judging image quality (e. g., detecting visible differences, and extracting image structure/information). In this work, we suggest that a single strategy may not be sufficient; rather, we advocate that the HVS uses multiple strategies to determine image quality. For images containing near-threshold distortions, the image is most apparent, and thus the HVS attempts to look past the image and look for the distortions (a detection-based strategy). For images containing clearly visible distortions, the distortions are most apparent, and thus the HVS attempts to look past the distortion and look for the image's subject matter (an appearance-based strategy). Here, we present a quality assessment method [most apparent distortion (MAD)], which attempts to explicitly model these two separate strategies. Local luminance and contrast masking are used to estimate detection-based perceived distortion in high-quality images, whereas changes in the local statistics of spatial-frequency components are used to estimate appearance-based perceived distortion in low-quality images. We show that a combination of these two measures can perform well in predicting subjective ratings of image quality. (C) 2010 SPIE and IS&T. [DOI: 10.1117/1.3267105]					Larson, Eric/HGF-0653-2022														1017-9909	1560-229X				JAN-MAR	2010	19	1							011006	10.1117/1.3267105	http://dx.doi.org/10.1117/1.3267105													WOS:000276944100006
J	MacFarlane, DR; Tachikawa, N; Forsyth, M; Pringle, JM; Howlett, PC; Elliott, GD; Davis, JH; Watanabe, M; Simon, P; Angell, CA				MacFarlane, Douglas R.; Tachikawa, Naoki; Forsyth, Maria; Pringle, Jennifer M.; Howlett, Patrick C.; Elliott, Gloria D.; Davis, James H., Jr.; Watanabe, Masayoshi; Simon, Patrice; Angell, C. Austen			Energy applications of ionic liquids	ENERGY & ENVIRONMENTAL SCIENCE												Ionic liquids offer a unique suite of properties that make them important candidates for a number of energy related applications. Cation-anion combinations that exhibit low volatility coupled with high electrochemical and thermal stability, as well as ionic conductivity, create the possibility of designing ideal electrolytes for batteries, super-capacitors, actuators, dye sensitised solar cells and thermo-electrochemical cells. In the field of water splitting to produce hydrogen they have been used to synthesize some of the best performing water oxidation catalysts and some members of the protic ionic liquid family co-catalyse an unusual, very high energy efficiency water oxidation process. As fuel cell electrolytes, the high proton conductivity of some of the protic ionic liquid family offers the potential of fuel cells operating in the optimum temperature region above 100 degrees C. Beyond electrochemical applications, the low vapour pressure of these liquids, along with their ability to offer tuneable functionality, also makes them ideal as CO2 absorbents for post-combustion CO2 capture. Similarly, the tuneable phase properties of the many members of this large family of salts are also allowing the creation of phase-change thermal energy storage materials having melting points tuned to the application. This perspective article provides an overview of these developing energy related applications of ionic liquids and offers some thoughts on the emerging challenges and opportunities.					MacFarlane, Douglas/A-9642-2008; WATANABE, Masayoshi/M-4816-2014; Forsyth, Maria/ABH-8102-2020; Pringle, Jennifer/D-5459-2012; SIMON, Patrice/N-6777-2016	Howlett, Patrick/0000-0002-2151-2932; Forsyth, Maria/0000-0002-4273-8105; MacFarlane, Douglas/0000-0001-5963-9659; Pringle, Jennifer/0000-0002-2729-2838; SIMON, Patrice/0000-0002-0461-8268													1754-5692	1754-5706				JAN	2014	7	1					232	250		10.1039/c3ee42099j	http://dx.doi.org/10.1039/c3ee42099j													WOS:000329550700010
J	Wen, L; Li, XY; Gao, L; Zhang, YY				Wen, Long; Li, Xinyu; Gao, Liang; Zhang, Yuyan			A New Convolutional Neural Network-Based Data-Driven Fault Diagnosis Method	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS												Fault diagnosis is vital in manufacturing system, since early detections on the emerging problem can save invaluable time and cost. With the development of smart manufacturing, the data-driven fault diagnosis becomes a hot topic. However, the traditional data-driven fault diagnosis methods rely on the features extracted by experts. The feature extraction process is an exhausted work and greatly impac7ts the final result. Deep learning (DL) provides an effective way to extract the features of raw data automatically. Convolutional neural network (CNN) is an effective DL method. In this study, a new CNN based on LeNet-5 is proposed for fault diagnosis. Through a conversion method converting signals into two-dimensional (2-D) images, the proposed method can extract the features of the converted 2-D images and eliminate the effect of handcrafted features. The proposed method which is tested on three famous datasets, including motor bearing dataset, self-priming centrifugal pump dataset, and axial piston hydraulic pump dataset, has achieved prediction accuracy of 99.79%, 99.481%, and 100%, respectively. The results have been compared with other DL and traditional methods, including adaptive deep CNN, sparse filter, deep belief network, and support vector machine. The comparisons show that the proposed CNN-based data-driven fault diagnosis method has achieved significant improvements.					Li, Lambert/F-7146-2015; Wen, Long/AAQ-5397-2021; GAO, Liang/C-7528-2009	Wen, Long/0000-0002-8355-9947; , Yuyan/0000-0003-3375-3482; GAO, Liang/0000-0002-1485-0722													0278-0046	1557-9948				JUL	2018	65	7					5990	5998		10.1109/TIE.2017.2774777	http://dx.doi.org/10.1109/TIE.2017.2774777													WOS:000427132300076
J	Witte, F				Witte, Frank			The history of biodegradable magnesium implants: A review	ACTA BIOMATERIALIA					1st Symposium on Degradable Metals for Biomedical Applications held at THERMEC 2009	AUG 25-29, 2009	Berlin, GERMANY					Today, more than 200 years after the first production of metallic magnesium by Sir Humphry Davy in 1808, biodegradable magnesium-based metal implants are currently breaking the paradigm in biomaterial science to develop only highly corrosion resistant metals. This groundbreaking approach to temporary metallic implants is one of the latest developments in biomaterials science that is being rediscovered. It is a challenging topic, and several secrets still remain that might revolutionize various biomedical implants currently in clinical use. Magnesium alloys were investigated as implant materials long ago. A very early clinical report was given in 1878 by the physician Edward C. Huse. He used magnesium wires as ligature for bleeding vessels. Magnesium alloys for clinical use were explored during the last two centuries mainly by surgeons with various clinical backgrounds, such as cardiovascular, musculoskeletal and general surgery. Nearly all patients benefited from the treatment with magnesium implants. Although most patients experienced subcutaneous gas cavities caused by rapid implant corrosion, most patients had no pain and almost no infections were observed during the postoperative follow-up. This review critically summarizes the in vitro and in vivo knowledge and experience that has been reported on the use of magnesium and its alloys to advance the field of biodegradable metals. (C) 2010 Acta Materialia Inc. Published by Elsevier Ltd. All rights reserved.					Witte, Frank/AFK-1556-2022; Witte, Frank/D-9294-2014	Witte, Frank/0000-0001-9154-6217													1742-7061					MAY	2010	6	5					1680	1692		10.1016/j.actbio.2010.02.028	http://dx.doi.org/10.1016/j.actbio.2010.02.028								20172057					WOS:000277847500002
J	Bridgwater, AV				Bridgwater, AV			Renewable fuels and chemicals by thermal processing of biomass	CHEMICAL ENGINEERING JOURNAL					15th International Conference on Chemical Reactor Modeling (CHEMREACTOR 15)	JUN 05-08, 2001	HELSINKI, FINLAND					Bio-energy is now accepted as having the potential to provide the major part of the projected renewable energy provisions of the future. There are three main routes to providing these bio-fuels-biological conversion, physical conversion and thermal conversion-all of which employ a range of chemical reactors configurations and designs. This review concentrates on thermal conversion processes and particularly the reactors that have been developed to provide the necessary conditions to optimise performance. A number of primary and secondary products can be derived as gas, liquid and solid fuels and electricity as well as a considerable number of chemicals. The basic conversion processes are summarised with their products and the main technical and non-technical barriers to implementation are identified. (C) 2002 Elsevier Science B.V. All rights reserved.					Bridgwater, Tony/ABE-1659-2020	Bridgwater, Tony/0000-0001-7362-6205													1385-8947	1873-3212				MAR 15	2003	91	2-3					87	102	PII S1385-8947(02)00142-0	10.1016/S1385-8947(02)00142-0	http://dx.doi.org/10.1016/S1385-8947(02)00142-0													WOS:000181148600002
J	Tao, F; Cheng, JF; Qi, QL; Zhang, M; Zhang, H; Sui, FY				Tao, Fei; Cheng, Jiangfeng; Qi, Qinglin; Zhang, Meng; Zhang, He; Sui, Fangyuan			Digital twin-driven product design, manufacturing and service with big data	INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY					12th International Conference on Frontiers of Design and Manufacturing (ICFDM)	AUG 10-12, 2016	Natl Nat Sci Fdn China, Shenyang, PEOPLES R CHINA	Shien Ming Wu Fdn USA	Natl Nat Sci Fdn China			Nowadays, along with the application of new-generation information technologies in industry and manufacturing, the big data-driven manufacturing era is coming. However, although various big data in the entire product lifecycle, including product design, manufacturing, and service, can be obtained, it can be found that the current research on product lifecycle data mainly focuses on physical products rather than virtual models. Besides, due to the lack of convergence between product physical and virtual space, the data in product lifecycle is isolated, fragmented, and stagnant, which is useless for manufacturing enterprises. These problems lead to low level of efficiency, intelligence, sustainability in product design, manufacturing, and service phases. However, physical product data, virtual product data, and connected data that tie physical and virtual product are needed to support product design, manufacturing, and service. Therefore, how to generate and use converged cyber-physical data to better serve product lifecycle, so as to drive product design, manufacturing, and service to be more efficient, smart, and sustainable, is emphasized and investigated based on our previous study on big data in product lifecycle management. In this paper, a new method for product design, manufacturing, and service driven by digital twin is proposed. The detailed application methods and frameworks of digital twin-driven product design, manufacturing, and service are investigated. Furthermore, three cases are given to illustrate the future applications of digital twin in the three phases of a product respectively.					Zhang, He/KBP-7473-2024; Qi, Qinglin/N-3496-2018; Tao, Fei/F-8944-2012	Cheng, Jiangfeng/0000-0003-0386-3533; Qi, Qinglin/0000-0002-3247-0440; Tao, Fei/0000-0002-9020-0633													0268-3768	1433-3015				FEB	2018	94	9-12					3563	3576		10.1007/s00170-017-0233-1	http://dx.doi.org/10.1007/s00170-017-0233-1													WOS:000425592900043
J	Kouro, S; Cortés, P; Vargas, R; Ammann, U; Rodríguez, J				Kouro, Samir; Cortes, Patricio; Vargas, Rene; Ammann, Ulrich; Rodriguez, Jose			Model Predictive Control-A Simple and Powerful Method to Control Power Converters	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS												This paper presents a detailed description of Finite Control Set Model Predictive Control (FCS-MPC) applied to power converters. Several key aspects related to this methodology are, in depth, presented and compared with traditional power converter control techniques, such as linear controllers with pulsewidth-modulation-based methods. The basic concepts, operating principles, control diagrams, and results are used to provide a comparison between the different control strategies. The analysis is performed on a traditional three-phase voltage source inverter, used as a simple and comprehensive reference frame. However, additional topologies and power systems are addressed to highlight differences, potentialities, and challenges of FCS-MPC. Among the conclusions are the feasibility and great potential of FCS-MPC due to present-day signal-processing capabilities, particularly for power systems with a reduced number of switching states and more complex operating principles, such as matrix converters. In addition, the possibility to address different or additional control objectives easily in a single cost function enables a simple, flexible, and improved performance controller for power-conversion systems.					Rodriguez, Jose/A-2534-2013; Kouro, Samir/E-9167-2012	Rodriguez, Jose/0000-0002-1410-4121; Kouro, Samir/0000-0002-1690-4624													0278-0046	1557-9948				JUN	2009	56	6					1826	1838		10.1109/TIE.2008.2008349	http://dx.doi.org/10.1109/TIE.2008.2008349													WOS:000266723000002
J	Agnew, SR; Duygulu, Ö				Agnew, SR; Duygulu, Ö			Plastic anisotropy and the role of non-basal slip in magnesium alloy AZ31B	INTERNATIONAL JOURNAL OF PLASTICITY					International Symposium on Plasticity	JUL 07-10, 2003	Quebec City, CANADA					Mechanistic explanations for the plastic behavior of a wrought magnesium alloy are developed using a combination of experimental and simulation techniques. Parameters affecting the practical sheet formability, such as strain hardening rate, strain rate sensitivity, the degree of anisotropy, and the stresses and strains at fracture, are examined systematically by conducting tensile tests of variously oriented samples at a range of temperatures (room temperature to 250 degreesC and strain rates (10(-5)-0.1s(-1)). Polycrystal plasticity simulations are used to model the observed anisotropy and texture evolution. Strong in-plane anisotropy observed at low temperatures is attributed to the initial texture and the greater than anticipated non-basal cross-slip of dislocations with dropadrop type Burgers vectors. The agreement between the measured and simulated anisotropy and texture is further validated by direct observations of the dislocation microstructures using transmission electron microscopy. The increase in the ductility with temperature is accompanied by a decrease in the flow stress, an increase in the strain rate sensitivity, and a decrease in the normal anisotropy. Polycrystal simulations indicate that an increased activity of non-basal, dropc + adrop, dislocations provides a self-consistent explanation for the observed changes in the anisotropy with increasing temperature. (C) 2004 Elsevier Ltd. All rights reserved.					Duygulu, Ozgur/A-9076-2015	Duygulu, Ozgur/0000-0001-8646-0363													0749-6419	1879-2154					2005	21	6					1161	1193		10.1016/j.ijplas.2004.05.018	http://dx.doi.org/10.1016/j.ijplas.2004.05.018													WOS:000227141000005
J	Eckert, F; Klamt, A				Eckert, F; Klamt, A			Fast solvent screening via quantum chemistry: COSMO-RS approach	AICHE JOURNAL												COSMO-RS, a general and fast methodology for the a priori prediction of thermophysical data of liquids is presented. It is based on cheap unimolecular quantum chemical calculations, which, combined with exact statistical thermodynamics, provide the information necessary for the evaluation of molecular interactions in liquids. COSMO-RS is an alternative to structure interpolating group contribution methods. The method is independent of experimental data and generally applicable. A methodological comparison with group contribution methods is given. The applicability, of the COSMO-RS method to the goal of solvent screening is demonstrated at various examples of vapor-liquid-, liquid-liquid-, solid-liquid-equilibria and vapor-pressure predictions.					Klamt, Andreas/GRO-3684-2022	Klamt, Andreas/0000-0002-5320-6219													0001-1541	1547-5905				FEB	2002	48	2					369	385		10.1002/aic.690480220	http://dx.doi.org/10.1002/aic.690480220													WOS:000173922300019
J	Vo, BN; Ma, WK				Vo, Ba-Ngu; Ma, Wing-Kin			The Gaussian mixture probability hypothesis density filter	IEEE TRANSACTIONS ON SIGNAL PROCESSING												A new recursive algorithm is proposed for jointly estimating the time-varying number of targets and their states from a sequence of observation sets in the presence of data association uncertainty, detection uncertainty, noise, and false alarms. The approach involves modelling the respective collections of targets and measurements as random finite sets and applying the probability hypothesis density (PHD) recursion to propagate the posterior intensity, which is a first-order statistic of the random finite set of targets, in time. At present, there is no closed-form solution to the PHD recursion. This paper shows that under linear, Gaussian assumptions on the target dynamics and birth process, the posterior intensity at any time step is a Gaussian mixture. More importantly, closed-form recursions for propagating the means, covariances, and weights of the constituent Gaussian components of the posterior intensity are derived. The proposed algorithm combines these recursions with a strategy for managing the number of Gaussian components to increase efficiency. This algorithm is extended to accommodate mildly nonlinear target dynamics using approximation strategies from the extended and unscented Kalman filters.					; Ma, Wing-Kin/K-2433-2013	Vo, Ba-Ngu/0000-0003-4202-7722; Ma, Wing-Kin/0000-0001-7314-3537													1053-587X	1941-0476				NOV	2006	54	11					4091	4104		10.1109/TSP.2006.881190	http://dx.doi.org/10.1109/TSP.2006.881190													WOS:000241537700002
J	Clarkson, CR; Solano, N; Bustin, RM; Bustin, AMM; Chalmers, GRL; He, L; Melnichenko, YB; Radlinski, AP; Blach, TP				Clarkson, C. R.; Solano, N.; Bustin, R. M.; Bustin, A. M. M.; Chalmers, G. R. L.; He, L.; Melnichenko, Y. B.; Radlinski, A. P.; Blach, T. P.			Pore structure characterization of North American shale gas reservoirs using USANS/SANS, gas adsorption, and mercury intrusion	FUEL												Small-angle and ultra-small-angle neutron scattering (SANS and USANS), low-pressure adsorption (N-2 and CO2), and high-pressure mercury intrusion measurements were performed on a suite of North American shale reservoir samples providing the first ever comparison of all these techniques for characterizing the complex pore structure of shales. The techniques were used to gain insight into the nature of the pore structure including pore geometry, pore size distribution and accessible versus inaccessible porosity. Reservoir samples for analysis were taken from currently-active shale gas plays including the Barnett, Marcellus, Haynesville, Eagle Ford, Woodford, Muskwa, and Duvernay shales. Low-pressure adsorption revealed strong differences in BET surface area and pore volumes for the sample suite, consistent with variability in composition of the samples. The combination of CO2 and N-2 adsorption data allowed pore size distributions to be created for micro-meso-macroporosity up to a limit of similar to 1000 angstrom. Pore size distributions are either uni- or multi-modal. The adsorption-derived pore size distributions for some samples are inconsistent with mercury intrusion data, likely owing to a combination of grain compression during high-pressure intrusion, and the fact that mercury intrusion yields information about pore throat rather than pore body distributions. SANS/USANS scattering data indicate a fractal geometry (power-law scattering) for a wide range of pore sizes and provide evidence that nanometer-scale spatial ordering occurs in lower mesopore-micropore range for some samples, which may be associated with inter-layer spacing in clay minerals. SANS/USANS pore radius distributions were converted to pore volume distributions for direct comparison with adsorption data. For the overlap region between the two methods, the agreement is quite good. Accessible porosity in the pore size (radius) range 5 nm-10 mu m was determined for a Barnett shale sample using the contrast matching method with pressurized deuterated methane fluid. The results demonstrate that accessible porosity is pore-size dependent. (C) 2012 Elsevier Ltd. All rights reserved.					Solano, Nisael/AAH-2803-2019; Chalmers, Gareth/JQJ-0003-2023; He, Lilin/O-4994-2016	He, Lilin/0000-0002-9560-8101; Chalmers, Gareth/0000-0001-6648-5619													0016-2361	1873-7153				JAN	2013	103						606	616		10.1016/j.fuel.2012.06.119	http://dx.doi.org/10.1016/j.fuel.2012.06.119													WOS:000311932200076
J	Simonin, JP				Simonin, Jean-Pierre			On the comparison of pseudo-first order and pseudo-second order rate laws in the modeling of adsorption kinetics	CHEMICAL ENGINEERING JOURNAL												In most works in the current literature about liquid/solid adsorption kinetics, the respective abilities of pseudo-first order and pseudo-second kinetics for describing the data are compared. In nearly all cases, it is concluded that the latter surpasses the former. The aim of this work is to point out that more caution should be exercised in this comparison. Indeed, it appears that the method generally used is flawed and that it unfairly favors pseudo-second order kinetics. A different method is proposed to analyze experimental results. It is employed here to reexamine experimental data taken from the literature. (C) 2016 Elsevier B.V. All rights reserved.						SIMONIN, Jean-Pierre/0000-0002-8246-8154													1385-8947	1873-3212				SEP 15	2016	300						254	263		10.1016/j.cej.2016.04.079	http://dx.doi.org/10.1016/j.cej.2016.04.079													WOS:000378181400026
J	Pal, P; Vaidyanathan, PP				Pal, Piya; Vaidyanathan, P. P.			Nested Arrays: A Novel Approach to Array Processing With Enhanced Degrees of Freedom	IEEE TRANSACTIONS ON SIGNAL PROCESSING												A new array geometry, which is capable of significantly increasing the degrees of freedom of linear arrays, is proposed. This structure is obtained by systematically nesting two or more uniform linear arrays and can provide O(N-2) degrees of freedom using only physical sensors when the second-order statistics of the received data is used. The concept of nesting is shown to be easily extensible to multiple stages and the structure of the optimally nested array is found analytically. It is possible to provide closed form expressions for the sensor locations and the exact degrees of freedom obtainable from the proposed array as a function of the total number of sensors. This cannot be done for existing classes of arrays like minimum redundancy arrays which have been used earlier for detecting more sources than the number of physical sensors. In minimum-input-minimum-output (MIMO) radar, the degrees of freedom are increased by constructing a longer virtual array through active sensing. The method proposed here, however, does not require active sensing and is capable of providing increased degrees of freedom in a completely passive setting. To utilize the degrees of freedom of the nested co-array, a novel spatial smoothing based approach to DOA estimation is also proposed, which does not require the inherent assumptions of the traditional techniques based on fourth-order cumulants or quasi stationary signals. As another potential application of the nested array, a new approach to beamforming based on a nonlinear preprocessing is also introduced, which can effectively utilize the degrees of freedom offered by the nested arrays. The usefulness of all the proposed methods is verified through extensive computer simulations.																			1053-587X	1941-0476				AUG	2010	58	8					4167	4181		10.1109/TSP.2010.2049264	http://dx.doi.org/10.1109/TSP.2010.2049264													WOS:000282087000017
J	Hartmann, NB; Hüffer, T; Thompson, RC; Hassellöv, M; Verschoor, A; Daugaard, AE; Rist, S; Karlsson, T; Brennholt, N; Cole, M; Herrling, MP; Hess, MC; Ivleva, NP; Lusher, AL; Wagner, M				Hartmann, Nanna B.; Hueffer, Thorsten; Thompson, Richard C.; Hassellov, Martin; Verschoor, Anja; Daugaard, Anders E.; Rist, Sinja; Karlsson, Therese; Brennholt, Nicole; Cole, Matthew; Herrling, Maria P.; Hess, Maren C.; Ivleva, Natalia P.; Lusher, Amy L.; Wagner, Martin			Are We Speaking the Same Language? Recommendations for a Definition and Categorization Framework for Plastic Debris	ENVIRONMENTAL SCIENCE & TECHNOLOGY												The accumulation of plastic litter in natural environments is a global issue. Concerns over potential negative impacts on the economy, wildlife, and human health provide strong incentives for improving the sustainable use of plastics. Despite the many voices raised on the issue, we lack a consensus on how to define and categorize plastic debris. This is evident for microplastics, where inconsistent size classes are used and where the materials to be included are under debate. While this is inherent in an emerging research field, an ambiguous terminology results in confusion and miscommunication that may compromise progress in research and mitigation measures. Therefore, we need to be explicit on what exactly we consider plastic debris. Thus, we critically discuss the advantages and disadvantages of a unified terminology, propose a definition and categorization framework, and highlight areas of uncertainty. Going beyond size classes, our framework includes physicochemical properties (polymer composition, solid state, solubility) as defining criteria and size, shape, color, and origin as classifiers for categorization. Acknowledging the rapid evolution of our knowledge on plastic pollution, our framework will promote consensus building within the scientific and regulatory community based on a solid scientific foundation.					Cole, Matthew/KHZ-6806-2024; Thompson, Richard/J-8879-2014; Herrling, Maria/E-9791-2017; Lusher, Amy/Q-3483-2018; Hüffer, Thorsten/M-5017-2013; Wagner, Martin/E-9893-2011; Rist, Sinja/P-4916-2017; Ivleva, Natalia/AAQ-9987-2020; Daugaard, Anders Egede/B-6020-2015; Hassellov, Martin/G-8890-2018; Hartmann, Nanna B./A-1678-2009	Verschoor, Anja/0000-0002-6844-8368; Wagner, Martin/0000-0002-4402-3234; Rist, Sinja/0000-0003-3002-0793; Lusher, Amy/0000-0003-0539-2974; Huffer, Thorsten/0000-0002-5639-8789; Ivleva, Natalia/0000-0002-7685-5166; Thompson, Richard/0000-0003-2262-6621; Karlsson, Therese/0009-0002-3749-6217; Daugaard, Anders Egede/0000-0002-0627-6310; Hassellov, Martin/0000-0003-1440-6143; Cole, Matthew/0000-0001-5910-1189; Hartmann, Nanna B./0000-0002-0442-245X													0013-936X	1520-5851				FEB 5	2019	53	3					1039	1047		10.1021/acs.est.8b05297	http://dx.doi.org/10.1021/acs.est.8b05297								30608663					WOS:000458220600001
J	Shafi, M; Molisch, AF; Smith, PJ; Haustein, T; Zhu, PY; De Silva, P; Tufvesson, F; Benjebbour, A; Wunder, G				Shafi, Mansoor; Molisch, Andreas F.; Smith, Peter J.; Haustein, Thomas; Zhu, Peiying; De Silva, Prasan; Tufvesson, Fredrik; Benjebbour, Anass; Wunder, Gerhard			5G: A Tutorial Overview of Standards, Trials, Challenges, Deployment, and Practice	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS												There is considerable pressure to define the key requirements of 5G, develop 5G standards, and perform technology trials as quickly as possible. Normally, these activities are best done in series but there is a desire to complete these tasks in parallel so that commercial deployments of 5G can begin by 2020. 5G will not be an incremental improvement over its predecessors; it aims to be a revolutionary leap forward in terms of data rates, latency, massive connectivity, network reliability, and energy efficiency. These capabilities are targeted at realizing highspeed connectivity, the Internet of Things, augmented virtual reality, the tactile internet, and so on. The requirements of 5G are expected to be met by new spectrum in the microwave bands (3.3-4.2 GHz), and utilizing large bandwidths available in mm-wave bands, increasing spatial degrees of freedom via large antenna arrays and 3-D MIMO, network densification, and new waveforms that provide scalability and flexibility to meet the varying demands of 5G services. Unlike the one size fits all 4G core networks, the 5G core network must be flexible and adaptable and is expected to simultaneously provide optimized support for the diverse 5G use case categories. In this paper, we provide an overview of 5G research, standardization trials, and deployment challenges. Due to the enormous scope of 5G systems, it is necessary to provide some direction in a tutorial article, and in this overview, the focus is largely user centric, rather than device centric. In addition to surveying the state of play in the area, we identify leading technologies, evaluating their strengths and weaknesses, and outline the key challenges ahead, with research test beds delivering promising performance but pre-commercial trials lagging behind the desired 5G targets.					Zhu, peiying/KIL-4285-2024; Molisch, Andreas/F-3691-2012; Shafi, Mansoor/JHU-4782-2023	Tufvesson, Fredrik/0000-0003-1072-0784; Smith, Peter/0000-0001-8707-2581													0733-8716	1558-0008				JUN	2017	35	6					1201	1221		10.1109/JSAC.2017.2692307	http://dx.doi.org/10.1109/JSAC.2017.2692307													WOS:000402731600002
J	Lu, YF; Zhang, Y; Deng, YF; Jiang, W; Zhao, YP; Geng, JJ; Ding, LL; Ren, HQ				Lu, Yifeng; Zhang, Yan; Deng, Yongfeng; Jiang, Wei; Zhao, Yanping; Geng, Jinju; Ding, Lili; Ren, Hongqiang			Uptake and Accumulation of Polystyrene Microplastics in Zebrafish (<i>Danio rerio</i>) and Toxic Effects in Liver	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Microplastics have become emerging contaminants, causing widespread concern about their potential toxic effects. In this study, the uptake and tissue accumulation of polystyrene microplastics (PS-MPs) in zebrafish were detected, and the toxic effects in liver were investigated. The results showed that after 7 days of exposure, 5 mu m diameter MPs accumulated in fish gills, liver, and gut, while 20 mu m diameter MPs accumulated only in fish gills and gut. Histopathological analysis showed that both 5 mu m and 70 nm PS-MPs caused inflammation and lipid accumulation in fish liver. PS-MPs also induced significantly increased activities of superoxide dismutase and catalase, indicating that, oxidative stress was induced after treatment with MPs. In addition, metabolomic analysis suggested that exposure to MPs induced alterations of metabolic profiles in fish liver and disturbed the lipid and energy metabolism. These findings provide new insights into the toxic effects of MPs on fish.					Zhang, Yan/AAO-6966-2021; hq, ren/AGA-1128-2022	Ren, Hong-qiang/0000-0001-6136-800X													0013-936X	1520-5851				APR 5	2016	50	7					4054	4060		10.1021/acs.est.6b00183	http://dx.doi.org/10.1021/acs.est.6b00183								26950772					WOS:000373655800088
J	Xydeas, CS; Petrovic, V				Xydeas, CS; Petrovic, V			Objective image fusion performance measure	ELECTRONICS LETTERS												A measure for objectively assessing the pixel level fusion performance is defined. The proposed metric reflects the quality of,visual information obtained from the fusion of input images and can he used to compare the performance of different image fusion algorithms. Experimental results clearly indicate that this metric is perceptually meaningful.																			0013-5194					FEB 17	2000	36	4					308	309		10.1049/el:20000267	http://dx.doi.org/10.1049/el:20000267													WOS:000085671500015
J	Ganti, RK; Ye, F; Lei, H				Ganti, Raghu K.; Ye, Fan; Lei, Hui			Mobile Crowdsensing: Current State and Future Challenges	IEEE COMMUNICATIONS MAGAZINE												An emerging category of devices at the edge of the Internet are consumer-centric mobile sensing and computing devices, such as smartphones, music players, and in-vehicle sensors. These devices will fuel the evolution of the Internet of Things as they feed sensor data to the Internet at a societal scale. In this article, we examine a category of applications that we term mobile crowdsensing, where individuals with sensing and computing devices collectively share data and extract information to measure and map phenomena of common interest. We present a brief overview of existing mobile crowdsensing applications, explain their unique characteristics, illustrate various research challenges, and discuss possible solutions. Finally, we argue the need for a unified architecture and envision the requirements it must satisfy.																			0163-6804	1558-1896				NOV	2011	49	11					32	39		10.1109/MCOM.2011.6069707	http://dx.doi.org/10.1109/MCOM.2011.6069707													WOS:000297054400004
J	Lachheb, H; Puzenat, E; Houas, A; Ksibi, M; Elaloui, E; Guillard, C; Herrmann, JM				Lachheb, H; Puzenat, E; Houas, A; Ksibi, M; Elaloui, E; Guillard, C; Herrmann, JM			Photocatalytic degradation of various types of dyes (Alizarin S, Crocein Orange G, Methyl Red, Congo Red, Methylene Blue) in water by UV-irradiated titania	APPLIED CATALYSIS B-ENVIRONMENTAL												The photocatalytic degradation of five various dyes has been investigated in TiO2/UV aqueous suspensions. It was attempted to determine the feasibility of such a degradation by varying the chemical structures, either anthraquinonic (Alizarin S (AS)), or azoic (Crocein Orange G (OG), Methyl Red (MR), Congo Red (CR)) or heteropolyaromatic (Methylene Blue (MB)). In addition to a prompt removal of the colors, TiO2/UV-based photocatalysis was simultaneously able to fully oxidize the dyes, with a complete mineralization of carbon into CO2. Sulfur heteroatoms were converted into innocuous SO(4)(2-)ions. The mineralization of nitrogen was more complex. Nitrogen atoms in the -3 oxidation state, such as in amino-groups, remain at this reduction degree and produced NH4+ cations, subsequently and very slowly converted into NO3- ions. For azo-dye (OG, MR, CR) degradation, the complete mass balance in nitrogen indicated that the central -N=N- azo-group was converted in gaseous dinitrogen, which is the ideal issue for the elimination of nitrogen-containing pollutants, not only for environmental photocatalysis but also for any physicochemical method. The aromatic rings were submitted to successive attacks by photogenerated OH. radicals leading to hydroxylated metabolites before the ring opening and the final evolution of CO2 induced by repeated subsequent "photo-Kolbe" reactions with carboxylic intermediates. These results suggest that TiO2/UV photocatalysis maybe envisaged as a method for treatment of diluted colored waste waters not only for decolorization, but also for detoxification, in particular in textile industries in semi-arid countries. (C) 2002 Elsevier Science B.V. All rights reserved.					ksibi, Mohamed/AAI-4759-2020; Puzenat, Eric/A-7134-2008; Ksibi, Mohamed/B-8214-2019	HOUAS, Ammar/0000-0001-8432-072X; Guillard, chantal/0000-0002-9527-827X; Ksibi, Mohamed/0000-0001-5389-1773													0926-3373	1873-3883				NOV 8	2002	39	1					75	90	PII S0926-3373(02)00078-4	10.1016/S0926-3373(02)00078-4	http://dx.doi.org/10.1016/S0926-3373(02)00078-4													WOS:000179456700005
J	Chen, YH; Krishna, T; Emer, JS; Sze, V				Chen, Yu-Hsin; Krishna, Tushar; Emer, Joel S.; Sze, Vivienne			Eyeriss: An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks	IEEE JOURNAL OF SOLID-STATE CIRCUITS												Eyeriss is an accelerator for state-of-the-art deep convolutional neural networks (CNNs). It optimizes for the energy efficiency of the entire system, including the accelerator chip and off-chip DRAM, for various CNN shapes by reconfiguring the architecture. CNNs are widely used in modern AI systems but also bring challenges on throughput and energy efficiency to the underlying hardware. This is because its computation requires a large amount of data, creating significant data movement from on-chip and off-chip that is more energyconsuming than computation. Minimizing data movement energy cost for any CNN shape, therefore, is the key to high throughput and energy efficiency. Eyeriss achieves these goals by using a proposed processing dataflow, called row stationary (RS), on a spatial architecture with 168 processing elements. RS dataflow reconfigures the computation mapping of a given shape, which optimizes energy efficiency by maximally reusing data locally to reduce expensive data movement, such as DRAM accesses. Compression and data gating are also applied to further improve energy efficiency. Eyeriss processes the convolutional layers at 35 frames/s and 0.0029 DRAM access/multiply and accumulation (MAC) for AlexNet at 278 mW (batch size N = 4), and 0.7 frames/s and 0.0035 DRAM access/MAC for VGG-16 at 236 mW (N = 3).																			0018-9200	1558-173X				JAN	2017	52	1			SI		127	138		10.1109/JSSC.2016.2616357	http://dx.doi.org/10.1109/JSSC.2016.2616357													WOS:000395641800011
J	Xia, GS; Hu, JW; Hu, F; Shi, BG; Bai, X; Zhong, YF; Zhang, LP; Lu, XQ				Xia, Gui-Song; Hu, Jingwen; Hu, Fan; Shi, Baoguang; Bai, Xiang; Zhong, Yanfei; Zhang, Liangpei; Lu, Xiaoqiang			AID: A Benchmark Data Set for Performance Evaluation of Aerial Scene Classification	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING												Aerial scene classification, which aims to automatically label an aerial image with a specific semantic category, is a fundamental problem for understanding high-resolution remote sensing imagery. In recent years, it has become an active task in the remote sensing area, and numerous algorithms have been proposed for this task, including many machine learning and data-driven approaches. However, the existing data sets for aerial scene classification, such as UC-Merced data set and WHU-RS19, contain relatively small sizes, and the results on them are already saturated. This largely limits the development of scene classification algorithms. This paper describes the Aerial Image data set (AID): a large-scale data set for aerial scene classification. The goal of AID is to advance the state of the arts in scene classification of remote sensing images. For creating AID, we collect and annotate more than 10 000 aerial scene images. In addition, a comprehensive review of the existing aerial scene classification techniques as well as recent widely used deep learning methods is given. Finally, we provide a performance analysis of typical aerial scene classification and deep learning approaches on AID, which can be served as the baseline results on this benchmark.					Zhang, Liangpei/ADI-7616-2022; Xia, Gui-Song/HII-9232-2022	Xia, Gui-Song/0000-0001-7660-6090; Lu, Xiaoqiang/0000-0002-7037-5188													0196-2892	1558-0644				JUL	2017	55	7					3965	3981		10.1109/TGRS.2017.2685945	http://dx.doi.org/10.1109/TGRS.2017.2685945													WOS:000404300900027
J	Jaouen, F; Proietti, E; Lefèvre, M; Chenitz, R; Dodelet, JP; Wu, G; Chung, HT; Johnston, CM; Zelenay, P				Jaouen, Frederic; Proietti, Eric; Lefevre, Michel; Chenitz, Regis; Dodelet, Jean-Pol; Wu, Gang; Chung, Hoon Taek; Johnston, Christina Marie; Zelenay, Piotr			Recent advances in non-precious metal catalysis for oxygen-reduction reaction in polymer electrolyte fuel cells	ENERGY & ENVIRONMENTAL SCIENCE												Hydrogen produced from water and renewable energy could fuel a large fleet of proton-exchange-fuel-cell vehicles in the future. However, the dependence on expensive Pt-based electrocatalysts in such fuel cells remains a major obstacle for a widespread deployment of this technology. One solution to overcome this predicament is to reduce the Pt content by a factor of ten by replacing the Pt-based catalysts with non-precious metal catalysts at the oxygen-reducing cathode. Fe-and Co-based electrocatalysts for this reaction have been studied for over 50 years, but they were insufficiently active for the high efficiency and power density needed for transportation fuel cells. Recently, several breakthroughs occurred that have increased the activity and durability of non-precious metal catalysts (NPMCs), which can now be regarded as potential competitors to Pt-based catalysts. This review focuses on the new synthesis methods that have led to these breakthroughs. A modeling analysis is also conducted to analyze the improvements required from NPMC-based cathodes to match the performance of Pt-based cathodes, even at high current density. While no further breakthrough in volume-specific activity of NPMCs is required, incremental improvements of the volume-specific activity and effective protonic conductivity within the fuel-cell cathode are necessary. Regarding durability, NPMCs with the best combination of durability and activity result in ca. 3 times lower fuel cell performance than the most active NPMCs at 0.80 V. Thus, major tasks will be to combine durability with higher activity, and also improve durability at cell voltages greater than 0.60 V.					Johnston, Christina/A-7344-2011; jaouen, frederic/D-7912-2019; Zelenay, Piotr/AEC-7961-2022; Lefèvre, Michel/B-5729-2009; chenitz, regis/Q-4713-2018; Chung, Hoon/A-7916-2012; Wu, Gang/E-8536-2010	chenitz, regis/0000-0002-4622-841X; Chung, Hoon/0000-0002-5367-9294; jaouen, frederic/0000-0001-9836-3261; Lefevre, Michel/0000-0003-3042-6128; Wu, Gang/0000-0003-4956-5208													1754-5692	1754-5706				JAN	2011	4	1					114	130		10.1039/c0ee00011f	http://dx.doi.org/10.1039/c0ee00011f													WOS:000285748400009
J	Allen, RG; Tasumi, M; Trezza, R				Allen, Richard G.; Tasumi, Masahiro; Trezza, Ricardo			Satellite-based energy balance for mapping evapotranspiration with internalized calibration (METRIC) - Model	JOURNAL OF IRRIGATION AND DRAINAGE ENGINEERING												Mapping evapotranspiration at high resolution with internalized calibration (METRIC) is a satellite-based image-processing model for calculating evapotranspiration (ET) as a residual of the surface energy balance. METRIC uses as its foundation the pioneering SEBAL energy balance process developed in The Netherlands by Bastiaanssen, where the near-surface temperature gradients are an indexed function of radiometric surface temperature, thereby eliminating the need for absolutely accurate surface temperature and the need for air-temperature measurements. The surface energy balance is internally calibrated using ground-based reference ET to reduce computational biases inherent to remote sensing-based energy balance and to provide congruency with traditional methods for ET. Slope and aspect functions and temperature lapsing are used in applications in mountainous terrain. METRIC algorithms are designed for relatively routine application by trained engineers and other technical professionals who possess a familiarity with energy balance and basic radiation physics. The primary inputs for the model are short-wave and long-wave (thermal) images from a satellite (e.g., Landsat and MODIS), a digital elevation model and ground-based weather data measured within or near the area of interest. ET "maps" (i.e., images) via METRIC provide the means to quantify ET on a field-by-field basis in terms of both the rate and spatial distribution. METRIC has some significant advantages over many traditional applications of satellite-based energy balance in that its calibration is made using reference ET, rather than the evaporative fraction. The use of reference ET for the extrapolation of instantaneous ET from periods of 24 h and longer compensates for regional advection effects by not tying the evaporative fraction to net radiation, since ET can exceed daily net radiation in many and or semi-arid locations. METRIC has some significant advantages over conventional methods of estimating ET from crop coefficient curves in that neither the crop development stages, nor the specific crop type need to be known with METRIC. In addition, energy balance can detect reduced ET caused by water shortage.					Allen, Richard/AAA-6753-2021; Lorite, Ignacio/B-8261-2011	Lorite, Ignacio/0000-0002-0833-9362; Tasumi, Masahiro/0000-0003-3594-838X													0733-9437	1943-4774				JUL-AUG	2007	133	4					380	394		10.1061/(ASCE)0733-9437(2007)133:4(380)	http://dx.doi.org/10.1061/(ASCE)0733-9437(2007)133:4(380)													WOS:000248099200011
J	Fischl, B; Liu, A; Dale, AM				Fischl, B; Liu, A; Dale, AM			Automated manifold surgery: Constructing geometrically accurate and topologically correct models of the human cerebral cortex	IEEE TRANSACTIONS ON MEDICAL IMAGING												Highly accurate surface models of the cerebral cortex are becoming increasingly important as tools in the investigation of the functional organization of the human brain. The construction of such models is difficult using current neuroimaging technology due to the high degree of cortical folding. Even single voxel misclassifications can result in erroneous connections being created between adjacent hanks of a sulcus, resulting in a topologically inaccurate model. These topological defects cause the cortical model to no longer be homeomorphic to a sheet, preventing the accurate inflation, flattening, or spherical morphing of the reconstructed cortex. Surface deformation techniques can guarantee the topological correctness of a model, but are time-consuming and may result in geometrically inaccurate models. in order to address this need we have developed a technique for taking a model of the cortex, detecting and fixing the topological defects while leaving that majority of the model intact, resulting in a surface that is both geometrically accurate and topologically correct.					Dale, Anders/A-5180-2010														0278-0062	1558-254X				JAN	2001	20	1					70	80		10.1109/42.906426	http://dx.doi.org/10.1109/42.906426								11293693					WOS:000167324900007
J	Yue, D; Tian, EG; Han, QL				Yue, Dong; Tian, Engang; Han, Qing-Long			A Delay System Method for Designing Event-Triggered Controllers of Networked Control Systems	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												This note is concerned with event-triggered H-infinity controller design for networked control systems. A novel event-triggering scheme is proposed, which has some advantages over some existing schemes. A delay system model for the analysis is firstly constructed by investigating the effect of the network transmission delay. Then, based on this model, criteria for stability with an H-infinity norm bound and criteria for co-designing both the feedback gain and the trigger parameters are derived. These criteria are formulated in terms of linear matrix inequalities. Simulation results have shown that the proposed event-triggering scheme is superior to some existing event-triggering schemes in the literature.					Yue, Dong/ITW-1999-2023; Han, Qing-Long/B-6635-2013	Han, Qing-Long/0000-0002-7207-0716													0018-9286	1558-2523				FEB	2013	58	2					475	481		10.1109/TAC.2012.2206694	http://dx.doi.org/10.1109/TAC.2012.2206694													WOS:000314163100018
J	Mercelis, P; Kruth, JP				Mercelis, Peter; Kruth, Jean-Pierre			Residual stresses in selective laser sintering and selective laser melting	RAPID PROTOTYPING JOURNAL					2005 Solid Freeform Fabrication Symposium (SFFS)	AUG 06-08, 2005	Austin, TX					Purpose - This paper presents an investigation into residual stresses in selective laser sintering (SLS) and selective laser melting (SLM), aiming at a better understanding of this phenomenon. Design/methodology/approach - First, the origin of residual stresses is explored and a simple theoretical model is developed to predict residual stress distributions. Next, experimental methods are used to measure the residual stress profiles in a set of test samples produced with different process parameters. Findings - Residual stresses are found to be very large in SLM parts. In general, the residual stress profile consists of two zones of large tensile stresses at the top and bottom of the part, and a large zone of intermediate compressive stress in between. The most important parameters determining the magnitude and shape of the residual stress profiles are the material properties, the sample and substrate height, the laser scanning strategy and the heating conditions. Research limitations/implications - All experiments were conducted on parts produced from stainless steel powder (316L) and quantitative results cannot be simply extrapolated to other materials. However, most qualitative results can still be generalized. Originality/value - This paper can serve as an aid in understanding the importance of residual stresses in SLS/SLM and other additive manufacturing processes involving a localized heat input. Some of the conclusions can be used to avoid problems associated with residual stresses.																			1355-2546	1758-7670					2006	12	5					254	265		10.1108/13552540610707013	http://dx.doi.org/10.1108/13552540610707013													WOS:000242521000003
J	Yager, RR				Yager, Ronald R.			Generalized Orthopair Fuzzy Sets	IEEE TRANSACTIONS ON FUZZY SYSTEMS												We note that orthopair fuzzy subsets are such that that their membership grades are pairs of values, from the unit interval, one indicating the degree of support for membership in the fuzzy set and the other support against membership. We discuss two examples, Atanassov's classic intuitionistic sets and a second kind of intuitionistic set called Pythagorean. We note that for classic intuitionistic sets the sum of the support for and against is bounded by one, while for the second kind, Pythagorean, the sum of the squares of the support for and against is bounded by one. Here we introduce a general class of these sets called q-rung orthopair fuzzy sets in which the sum of the qth power of the support for and the qth power of the support against is bonded by one. We note that as q increases the space of acceptable orthopairs increases and thus gives the user more freedom in expressing their belief about membership grade. We investigate various set operations as well as aggregation operations involving these types of sets.																			1063-6706	1941-0034				OCT	2017	25	5					1222	1230		10.1109/TFUZZ.2016.2604005	http://dx.doi.org/10.1109/TFUZZ.2016.2604005													WOS:000412200500017
J	Koetter, R; Médard, M				Koetter, R; Médard, M			An algebraic approach to network coding	IEEE-ACM TRANSACTIONS ON NETWORKING												We take a new look at the issue of network capacity. It is shown that network coding is an essential ingredient in achieving the capacity of a network. Building on recent work by Li et al., who examined the network capacity of multicast networks, we extend the network coding framework to arbitrary networks and robust networking. For networks which are restricted to using linear network codes, we find necessary and sufficient conditions for the feasibility of any given set of connections over a given network. We also consider the problem of network recovery for nonergodic link failures. For the multicast setup we prove that there exist coding strategies that provide maximally robust networks and that do not require adaptation of the network interior to the failure pattern in question. The results are derived for both delay-free networks and networks with delays.																			1063-6692					OCT	2003	11	5					782	795		10.1109/TNET.2003.818197	http://dx.doi.org/10.1109/TNET.2003.818197													WOS:000186002800008
J	Liu, CJ; Wechsler, H				Liu, CJ; Wechsler, H			Gabor feature based classification using the enhanced Fisher linear discriminant model for face recognition	IEEE TRANSACTIONS ON IMAGE PROCESSING												This paper introduces a novel Gabor-Fisher Classifier (GFC) for face recognition. The GFC method, which is robust to changes in illumination and facial expression, applies the Enhanced Fisher linear discriminant Model (EFM) to an augmented Gabor feature vector derived from the Gabor wavelet representation of face images. The novelty of this paper comes from 1) the derivation of an augmented Gabor feature vector, whose dimensionality is further reduced using the EFM by considering both data compression and recognition (generalization) performance; 2) the development of a Gabor-Fisher classifier for multi-class problems; and 3) extensive performance evaluation studies. In particular, we performed comparative studies of different similarity measures applied to various classifiers. We also performed comparative experimental studies of various face recognition schemes, including our novel GFC method, the Gabor wavelet method, the Eigenfaces method, the Fisherfaces method, the EFM method, the combination of Gabor and the Eigenfaces method, and the combination of Gabor and the Fisherfaces method. The feasibility of the new GFC method has been successfully tested on face recognition using 600 FERET frontal face images corresponding to 200 subjects, which were acquired under variable illumination and facial expressions. The novel GFC method achieves 100% accuracy on face recognition using only 62 features.																			1057-7149					APR	2002	11	4					467	476	PII S1057-7149(02)03548-0	10.1109/TIP.2002.999679	http://dx.doi.org/10.1109/TIP.2002.999679								18244647					WOS:000175398300012
J	Li, SQ; Mi, CC				Li, Siqi; Mi, Chunting Chris			Wireless Power Transfer for Electric Vehicle Applications	IEEE JOURNAL OF EMERGING AND SELECTED TOPICS IN POWER ELECTRONICS												Wireless power transfer (WPT) using magnetic resonance is the technology which could set human free from the annoying wires. In fact, the WPT adopts the same basic theory which has already been developed for at least 30 years with the term inductive power transfer. WPT technology is developing rapidly in recent years. At kilowatts power level, the transfer distance increases from several millimeters to several hundred millimeters with a grid to load efficiency above 90%. The advances make the WPT very attractive to the electric vehicle (EV) charging applications in both stationary and dynamic charging scenarios. This paper reviewed the technologies in the WPT area applicable to EV wireless charging. By introducing WPT in EVs, the obstacles of charging time, range, and cost can be easily mitigated. Battery technology is no longer relevant in the mass market penetration of EVs. It is hoped that researchers could be encouraged by the state-of-the-art achievements, and push forward the further development of WPT as well as the expansion of EV.					Li, Siqi/I-9849-2019; Mi, Chris/E-3769-2013	Mi, Chris/0000-0002-5471-8953; Li, Siqi/0000-0003-2085-4938													2168-6777					MAR	2015	3	1			SI		4	17		10.1109/JESTPE.2014.2319453	http://dx.doi.org/10.1109/JESTPE.2014.2319453													WOS:000358608700002
J	Mishra, UK; Shen, L; Kazior, TE; Wu, YF				Mishra, Umesh K.; Shen, Likun; Kazior, Thomas E.; Wu, Yi-Feng			GaN-Based RF power devices and amplifiers	PROCEEDINGS OF THE IEEE												The rapid development of the RF power electronics requires the introduction of wide bandgap material due to its potential in high Output power density, high operation voltage and high input impedance. GaN-based RF power devices have made substantial progresses in the last decade. This paper attempts to review the latest developments of the GaN HEMT technologies, including material growth, processing technologies, device epitaxial structures and MMIC designs, to achieve the state-of-the-art microwave and millimeter-wave performance. The reliability and manufacturing challenges are also discussed.					Wu, Yifeng/AAD-7201-2020														0018-9219	1558-2256				FEB	2008	96	2					287	305		10.1109/JPROC.2007.911060	http://dx.doi.org/10.1109/JPROC.2007.911060													WOS:000252583700008
J	Dollár, P; Appel, R; Belongie, S; Perona, P				Dollar, Piotr; Appel, Ron; Belongie, Serge; Perona, Pietro			Fast Feature Pyramids for Object Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Multi-resolution image features may be approximated via extrapolation from nearby scales, rather than being computed explicitly. This fundamental insight allows us to design object detection algorithms that are as accurate, and considerably faster, than the state-of-the-art. The computational bottleneck of many modern detectors is the computation of features at every scale of a finely-sampled image pyramid. Our key insight is that one may compute finely sampled feature pyramids at a fraction of the cost, without sacrificing performance: for a broad family of features we find that features computed at octave-spaced scale intervals are sufficient to approximate features on a finely-sampled pyramid. Extrapolation is inexpensive as compared to direct feature computation. As a result, our approximation yields considerable speedups with negligible loss in detection accuracy. We modify three diverse visual recognition systems to use fast feature pyramids and show results on both pedestrian detection (measured on the Caltech, INRIA, TUD-Brussels and ETH data sets) and general object detection (measured on the PASCAL VOC). The approach is general and is widely applicable to vision algorithms requiring fine-grained multi-scale analysis. Our approximation is valid for images with broad spectra (most natural images) and fails for images with narrow band-pass spectra (e.g., periodic textures).						Belongie, Serge/0000-0002-0388-5217													0162-8828	1939-3539				AUG	2014	36	8					1532	1545		10.1109/TPAMI.2014.2300479	http://dx.doi.org/10.1109/TPAMI.2014.2300479								26353336					WOS:000340191900004
J	Skogestad, S				Skogestad, S			Simple analytic rules for model reduction and PID controller tuning	JOURNAL OF PROCESS CONTROL												The aim of this paper is to present analytic rules for PID controller tuning that are simple and still result in good closed-loop behavior. The starting point has been the IMC-PID tuning rules that have achieved widespread industrial acceptance. The rule for the integral term has been modified to improve disturbance rejection for integrating processes. Furthermore, rather than deriving separate rules for each transfer function model, there is a just a single tuning rule for a first-order or second-order time delay model. Simple analytic rules for model reduction are presented to obtain a model in this form, including the "half rule" for obtaining the effective time delay. (C) 2002 Elsevier Science Ltd. All rights reserved.					Skogestad, Sigurd/C-1449-2008														0959-1524					JUN	2003	13	4					291	309	PII S0959-1524(02)00062-8	10.1016/S0959-1524(02)00062-8	http://dx.doi.org/10.1016/S0959-1524(02)00062-8													WOS:000181778400002
J	Rabczuk, T; Belytschko, T				Rabczuk, T; Belytschko, T			Cracking particles: a simplified meshfree method for arbitrary evolving cracks	INTERNATIONAL JOURNAL FOR NUMERICAL METHODS IN ENGINEERING												A new approach for modelling discrete cracks in meshfree methods is described. In this method, the crack can be arbitrarily oriented, but its growth is represented discretely by activation of crack surfaces at individual particles, so no representation of the crack's topology is needed. The crack is modelled by a local enrichment of the test and trial functions with a sign function (a variant of the Heaviside step function), so that the discontinuities are along the direction of the crack. The discontinuity consists of cylindrical planes centred at the particles in three dimensions, lines centred at the particles in two dimensions. The model is applied to several 2D problems and compared to experimental data. Copyright (C) 2004 John Wiley Sons, Ltd.					Rabczuk, Timon/A-3067-2009; Belytschko, Ted/B-6710-2009														0029-5981	1097-0207				DEC 7	2004	61	13					2316	2343		10.1002/nme.1151	http://dx.doi.org/10.1002/nme.1151													WOS:000225633200007
J	Qu, J; Zhao, X; Liang, YP; Zhang, TL; Ma, PX; Guo, BL				Qu, Jin; Zhao, Xin; Liang, Yongping; Zhang, Tianlong; Ma, Peter X.; Guo, Baolin			Antibacterial adhesive injectable hydrogels with rapid self-healing, extensibility and compressibility as wound dressing for joints skin wound healing	BIOMATERIALS												Designing wound dressing materials with outstanding therapeutic effects, self-healing, adhesiveness and suitable mechanical property has great practical significance in healthcare, especially for joints skin wound healing. Here, we designed a kind of self-healing injectable micelle/hydrogel composites with multi-functions as wound dressing for joint skin damage. By combining the dynamic Schiff base and copolymer micelle cross-linking in one system, a series of hydrogels were prepared by mixing quaternized chitosan (QCS) and benzaldehyde-terminated Pluronic (center dot)F127 (PF127-CHO) under physiological conditions. The inherent antibacterial property, pH-dependent biodegradation and release behavior were investigated to confirm multi-functions of wound dressing. The hydrogel dressings showed suitable stretchable and compressive property, comparable modulus with human skin, good adhesiveness and fast self-healing ability to bear deformation. The hydrogels exhibited efficient hemostatic performance and biocompatibility. Moreover, the curcumin loaded hydrogel showed good antioxidant ability and pH responsive release profiles. In vivo experiments indicated that curcumin loaded hydrogels significantly accelerated wound healing rate with higher granulation tissue thickness and collagen disposition and upregulated vascular endothelial growth factor (VEGF) in a full-thickness skin defect model. Taken together, the antibacterial adhesive hydrogels with self-healing and good mechanical property offer significant promise as dressing materials for joints skin wound healing.					X, Peter/E-4895-2011; Zhang, Tianlong/AEW-8278-2022; Guo, Baolin/ISV-0506-2023; liang, yongping/AAE-4329-2019; Zhao, Xin/KGL-2713-2024; Guo, Baolin/A-1297-2011	Zhang, Tianlong/0000-0002-1877-8238; liang, yongping/0000-0001-6335-0428; Zhao, Xin/0000-0002-7190-423X; Qu, Jin/0009-0002-5968-1069; Guo, Baolin/0000-0001-6756-1441													0142-9612	1878-5905				NOV	2018	183						185	199		10.1016/j.biomaterials.2018.08.044	http://dx.doi.org/10.1016/j.biomaterials.2018.08.044								30172244					WOS:000447116600017
J	Hassenzahl, M; Tractinsky, N				Hassenzahl, M; Tractinsky, N			User experience - a research agenda	BEHAVIOUR & INFORMATION TECHNOLOGY												Over the last decade, 'user experience' (UX) became a buzzword in the field of human computer interaction (HCI) and interaction design. As technology matured, interactive products became not only more useful and usable, but also fashionable, fascinating things to desire. Driven by the impression that a narrow focus on interactive products as tools does not capture the variety and emerging aspects of technology use, practitioners and researchers alike, seem to readily embrace the notion of UX as a viable alternative to traditional HCI. And, indeed, the term promises change and a fresh look, without being too specific about its definite meaning. The present introduction to the special issue on ` Empirical studies of the user experience' attempts to give a provisional answer to the question of what is meant by ` the user experience'. It provides a cursory sketch of UX and how we think UX research will look like in the future. It is not so much meant as a forecast of the future, but as a proposal - a stimulus for further UX research.					Hassenzahl, Marc/B-1200-2018; Tractinsky, Noam/F-1905-2012	Tractinsky, Noam/0000-0001-7277-6164													0144-929X	1362-3001				MAR-APR	2006	25	2					91	97		10.1080/01449290500330331	http://dx.doi.org/10.1080/01449290500330331													WOS:000234267900001
J	Yu, YJ; Acton, ST				Yu, YJ; Acton, ST			Speckle reducing anisotropic diffusion	IEEE TRANSACTIONS ON IMAGE PROCESSING												This paper provides the derivation of speckle reducing anisotropic diffusion (SRAD), a diffusion method tailored to ultrasonic and radar imaging applications. SRAD is the edge-sensitive diffusion for speckled images, in the same way that conventional anisotropic diffusion is the edge-sensitive diffusion for images corrupted with additive noise. We first show that the Lee and Frost filters can be cast as partial differential equations, and then we derive SRAD by allowing edge-sensitive anisotropic diffusion within this context. Just as the Lee and Frost filters utilize the coefficient of variation in adaptive filtering, SRAD exploits the instantaneous coefficient of variation, which is shown to be a function of the local gradient magnitude and Laplacian operators. We validate the new algorithm using both synthetic and real linear scan ultrasonic imagery of the carotid artery. We also demonstrate the algorithm performance with real SAR data. The performance measures obtained by means of computer simulation of carotid artery images are compared with three existing speckle reduction schemes. In the presence of speckle noise, speckle reducing anisotropic diffusion excels over the traditional speckle removal filters and over the conventional anisotropic diffusion method in terms of mean preservation, variance reduction, and edge localization.																			1057-7149	1941-0042				NOV	2002	11	11					1260	1270		10.1109/TIP.2002.804279	http://dx.doi.org/10.1109/TIP.2002.804279								18249696					WOS:000179628500005
J	Ahmed, MN; Yamany, SM; Mohamed, N; Farag, AA; Moriarty, T				Ahmed, MN; Yamany, SM; Mohamed, N; Farag, AA; Moriarty, T			A modified fuzzy C-means algorithm for bias field estimation and segmentation of MRI data	IEEE TRANSACTIONS ON MEDICAL IMAGING												In this paper, we present a novel algorithm for fuzzy segmentation of magnetic resonance imaging (MRI) data and estimation of intensity inhomogeneities using fuzzy logic. MRI intensity inhomogeneities can be attributed to imperfections in the radio-frequency coils or to problems associated with the acquisition sequences. The result is a slowly varying shading artifact over the image that can produce errors with conventional intensity-based classification. Our algorithm is formulated by modifying the objective function of the standard fuzzy c-means (FCM) algorithm to compensate for such inhomogeneities and to allow the labeling of a pixel (voxel) to be influenced by the labels in its immediate neighborhood. The neighborhood effect acts as a regularizer and biases the solution toward piecewise-homogeneous labelings. Such a regularization is useful in segmenting scans corrupted by salt and pepper noise. Experimental results on both synthetic images and MR data are given to demonstrate the effectiveness and efficiency of the proposed algorithm.																			0278-0062	1558-254X				MAR	2002	21	3					193	199	PII S0278-0062(02)040880-	10.1109/42.996338	http://dx.doi.org/10.1109/42.996338								11989844					WOS:000175063900001
J	Montavon, G; Samek, W; Müller, KR				Montavon, Gregoire; Samek, Wojciech; Mueller, Klaus-Robert			Methods for interpreting and understanding deep neural networks	DIGITAL SIGNAL PROCESSING												This paper provides an entry point to the problem of interpreting a deep neural network model and explaining its predictions. It is based on a tutorial given at ICASSP 2017. As a tutorial paper, the set of methods covered here is not exhaustive, but sufficiently representative to discuss a number of questions in interpretability, technical challenges, and possible applications. The second part of the tutorial focuses on the recently proposed layer-wise relevance propagation (LRP) technique, for which we provide theory, recommendations, and tricks, to make most efficient use of it on real data. (C) 2017 The Authors. Published by Elsevier Inc.					Mueller, Klaus-Robert/C-3196-2013; Samek, Wojciech/AAZ-2165-2021; Montavon, Grégoire/Q-1836-2016	Mueller, Klaus-Robert/0000-0002-3861-7685													1051-2004	1095-4333				FEB	2018	73						1	15		10.1016/j.dsp.2017.10.011	http://dx.doi.org/10.1016/j.dsp.2017.10.011													WOS:000422703400001
J	Fredlake, CP; Crosthwaite, JM; Hert, DG; Aki, SNVK; Brennecke, JF				Fredlake, CP; Crosthwaite, JM; Hert, DG; Aki, SNVK; Brennecke, JF			Thermophysical properties of imidazolium-based ionic liquids	JOURNAL OF CHEMICAL AND ENGINEERING DATA												Ionic liquids (ILs) are salts that are liquid at low temperatures, usually including the region around room temperature. They are under intense investigation, especially as replacement solvents for reactions and separations, since they exhibit negligible vapor pressure and would not, therefore, contribute to air pollution. Clearly, basic thermophysical properties are vital for design and evaluation for these applications. We present density as a function of temperature, melting temperatures, glass-transition temperatures, decomposition temperatures, and heat capacities as a function of temperature for a series of 13 of the popular imidazolium-based ILs. The ionic liquids investigated here are 1-butyl-3-methylimidazolium tetrafluoroborate, 1-butyl-3-methylimidazolium hexafluorophosphate, 1-butyl-3-methylimidazolium chloride, 1-butyl-3-methylimidazolium bromide, 1-butyl-3-methylimidazolium dicyanamide, 1-butyl-3-methylimidazolium trifluoromethanesulfonate, 1-butyl-3-methylimidazolium tris(trifluoromethylsulfonyl)methide, 1-butyl-3-methylimidazolium bis(trifluoromethylsulfonyl)imide, 1-ethyl-3-methylimidazolium his(trifluoromethylsulfonyl)imide, 2,3-dimethyl-1-ethylimidazolium bis(trifluoromethylsulfonyl)imide, 2,3-dimethyl-1-propylimidazolium bis(trifluoromethylsulfonyl)imide, 1-butyl-2,3-dimethylimidazolium tetrafluoroborate, and 1-butyl-2,3-dimethylimidazolium hexafluorophosphate. The properties follow quite reasonable trends. For instance, density decreases as the length of the alkyl chain on the cation increases. For a given cation, the density increases as the molecular weight of the anion increases for the anions studied here. Many of the ILs tend to subcool easily, forming glasses at very low temperatures rather than exhibiting crystallization or melting transitions. The thermal stability increases with increasing anion size, and heat capacities increase with temperature and increasing number of atoms in the IL.																			0021-9568	1520-5134				JUL-AUG	2004	49	4					954	964		10.1021/je034261a	http://dx.doi.org/10.1021/je034261a													WOS:000222535100042
J	Sim, T; Baker, S; Bsat, M				Sim, T; Baker, S; Bsat, M			The CMU pose, illumination, and expression database	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												In the Fall of 2000, we collected a database of more than 40,000 facial images of 68 people. Using the Carnegie Mellon University 3D Room, we imaged each person across 13 different poses, under 43 different illumination conditions, and with four different expressions. We call this the CMU Pose, Illumination, and Expression (PIE) database. We describe the imaging hardware, the collection procedure, the organization of the images, several possible uses, and how to obtain the database.						Sim, Terence/0000-0002-0198-094X													0162-8828					DEC	2003	25	12					1615	1618		10.1109/tpami.2003.1251154	http://dx.doi.org/10.1109/tpami.2003.1251154													WOS:000186765000011
J	Nitzl, C; Roldan, JL; Cepeda, G				Nitzl, Christian; Roldan, Jose L.; Cepeda, Gabriel			Mediation analysis in partial least squares path modeling Helping researchers discuss more sophisticated models	INDUSTRIAL MANAGEMENT & DATA SYSTEMS												Purpose - Indirect or mediated effects constitute a type of relationship between constructs that often occurs in partial least squares (PLS) path modeling. Over the past few years, the methods for testing mediation have become more sophisticated. However, many researchers continue to use outdated methods to test mediating effects in PLS, which can lead to erroneous results. One reason for the use of outdated methods or even the lack of their use altogether is that no systematic tutorials on PLS exist that draw on the newest statistical findings. The paper aims to discuss these issues. Design/methodology/approach - This study illustrates the state-of-the-art use of mediation analysis in the context of PLS-structural equation modeling (SEM). Findings - This study facilitates the adoption of modern procedures in PLS-SEM by challenging the conventional approach to mediation analysis and providing more accurate alternatives. In addition, the authors propose a decision tree and classification of mediation effects. Originality/value - The recommended approach offers a wide range of testing options (e.g. multiple mediators) that go beyond simple mediation analysis alternatives, helping researchers discuss their studies in a more accurate way.					Roldan, Jose L./E-6307-2010; Cepeda, Gabriel/E-6284-2010	Roldan, Jose L./0000-0003-4053-7526; Cepeda, Gabriel/0000-0003-3839-2006													0263-5577	1758-5783					2016	116	9			SI		1849	1864		10.1108/IMDS-07-2015-0302	http://dx.doi.org/10.1108/IMDS-07-2015-0302													WOS:000387099700002
J	Benn, TM; Westerhoff, P				Benn, Troy M.; Westerhoff, Paul			Nanoparticle silver released into water from commercially available sock fabrics	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Manufacturers of clothing articles employ nanosilver (n-Ag) as an antimicrobial agent, but the environmental impacts of n-Ag release from commercial products are unknown. The quantity and form of the nanomaterials released from consumer products should be determined to assess the environmental risks of nanotechnology. This paper investigates silver released from commercial clothing (socks) into water, and its fate in wastewater treatment plants (WWTPs). Six types of socks contained up to a maximum of 1360 mu g-Ag/g-sock and leached as much as 650 mu g of silver in 500 mL of distilled water. Microscopy conducted on sock material and wash water revealed the presence of silver particles from 10 to 500 nm in diameter. Physical separation and ion selective electrode (ISE) analyses suggest that both colloidal and ionic silver leach from the socks. Variable leaching rates among sock types suggests that the sock manufacturing process may control the release of silver, The adsorption of the leached silver to WWTP biomass was used to develop a model which predicts that a typical wastewater treatment facility could treat a high concentration of influent silver. However, the high silver concentration may limit the disposal of the biosolids as agricultural fertilizer.					Westerhoff, Paul/AAF-1850-2019														0013-936X					JUN 1	2008	42	11					4133	4139		10.1021/es7032718	http://dx.doi.org/10.1021/es7032718								18589977					WOS:000256274300039
J	Picard, RW; Vyzas, E; Healey, J				Picard, RW; Vyzas, E; Healey, J			Toward machine emotional intelligence: Analysis of affective physiological state	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												The ability to recognize emotion is one of the hallmarks of emotional intelligence, an aspect of human intelligence that has been argued to be even more important than mathematical and verbal intelligences. This paper proposes that machine intelligence needs to include emotional intelligence and demonstrates results toward this goal: developing a machine's ability to recognize human affective state given four physiological signals. We describe difficult Issues unique to obtaining reliable affective data and collect a large set of data from a subject trying to elicit and experience each of eight emotional states, daily, over multiple weeks. This paper presents and compares multiple algorithms for feature-based recognition of emotional state from this data. We analyze four physiological signals that exhibit problematic day-to-day variations: The features of different emotions on the same day tend to cluster more tightly than do the features of the same emotion on different days. To handle the daily variations, we propose new features and algorithms and compare their performance, We find that the technique of seeding a Fisher Projection with the results of Sequential Floating Forward Search improves the performance of the Fisher Projection and provides the highest recognition rates reported to date for classification of affect from physiology: 81 percent recognition accuracy on eight classes of emotion, including neutral.																			0162-8828	1939-3539				OCT	2001	23	10					1175	1191		10.1109/34.954607	http://dx.doi.org/10.1109/34.954607													WOS:000171586600011
J	Nguyen, KT; West, JL				Nguyen, KT; West, JL			Photopolymerizable hydrogels for tissue engineering applications	BIOMATERIALS												Photopolymerized hydrogels are being investigated for a number of tissue engineering applications because of the ability to form these materials in situ in a minimally invasive manner such as by injection. In addition, hydrogels, three-dimensional networks of hydrophilic polymers that are able to swell large amounts of water, can be made to resemble the physical characteristics of soft tissues. Hydrogel materials also generally exhibit high permeability and good biocompatibility making, these materials attractive for use in cell encapsulation and tissue engineering applications. A number of hydrogel materials can be formed via photopolymerization processes mild enough to be carried out in the presence of living cells. This allows one to homogeneously seed cells throughout the scaffold material and to form hydrogels in situ. This review presents advantages of photopolymerization of hydrogels and describes the photoinitiators and materials in current use. Applications of photopolymerized hydrogels in tissue engineering that have been investigated are summarized. (C) 2002 Elsevier Science Ltd. All rights reserved.					nguyen, kytai/A-6593-2008; West, Jennifer/A-4582-2008														0142-9612					NOV	2002	23	22					4307	4314	PII S0142-9612(02)00175-8	10.1016/S0142-9612(02)00175-8	http://dx.doi.org/10.1016/S0142-9612(02)00175-8								12219820					WOS:000177667400002
J	Medford, AJ; Vojvodic, A; Hummelshoj, JS; Voss, J; Abild-Pedersen, F; Studt, F; Bligaard, T; Nilsson, A; Norskov, JK				Medford, Andrew J.; Vojvodic, Aleksandra; Hummelshoj, Jens S.; Voss, Johannes; Abild-Pedersen, Frank; Studt, Felix; Bligaard, Thomas; Nilsson, Anders; Norskov, Jens K.			From the Sabatier principle to a predictive theory of transition-metal heterogeneous catalysis	JOURNAL OF CATALYSIS												We discuss three concepts that have made it possible to develop a quantitative understanding of trends in transition-metal catalysis: scaling relations, activity maps, and the d-band model. Scaling relations are correlations between surface bond energies of different adsorbed species including transition states; they open the possibility of mapping the many parameters determining the rate of a full catalytic reaction onto a few descriptors. The resulting activity map can be viewed as a quantitative implementation of the classical Sabatier principle, which states that there is an optimum "bond strength" defining the best catalyst for a given reaction. In the modern version, the scaling relations determine the relevant "bond strengths" and the fact that these descriptors can be measured or calculated makes it a quantitative theory of catalysis that can be tested experimentally by making specific predictions of new catalysts. The quantitative aspect of the model therefore provides new possibilities in catalyst design. Finally, the d-band model provides an understanding of the scaling relations and variations in catalytic activity in terms of the electronic structure of the transition-metal surface. (C) 2015 Published by Elsevier Inc.					Medford, Andrew/H-5405-2019; Bligaard, Thomas/A-6161-2011; Bligaard, Thomas/A-6161-2011; Vojvodic, Aleksandra/C-3383-2014; Nilsson, Anders/E-1943-2011; Norskov, Jens/D-2539-2017; Voss, Johannes/AAB-7296-2020; Studt, Felix/C-7874-2017; Abild-Pedersen, Frank/C-3248-2014	Bligaard, Thomas/0000-0001-9834-9179; Bligaard, Thomas/0000-0003-0386-0201; Vojvodic, Aleksandra/0000-0002-5584-6711; Nilsson, Anders/0000-0003-1968-8696; Medford, Andrew/0000-0001-8311-9581; Norskov, Jens/0000-0002-4427-7728; Voss, Johannes/0000-0001-7740-8811; Studt, Felix/0000-0001-6841-4232; Abild-Pedersen, Frank/0000-0002-1911-074X													0021-9517	1090-2694				AUG	2015	328				SI		36	42		10.1016/j.jcat.2014.12.033	http://dx.doi.org/10.1016/j.jcat.2014.12.033													WOS:000356748300007
J	Chen, WH; Ballance, DJ; Gawthrop, PJ; O'Reilly, J				Chen, WH; Ballance, DJ; Gawthrop, PJ; O'Reilly, J			A nonlinear disturbance observer for robotic manipulators	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS					38th IEEE Control and Decision Conference	DEC 07-10, 1999	PHOENIX, AZ	IEEE				A new nonlinear disturbance observer (NDO) for robotic manipulators is derived in this paper. The global exponential stability of the proposed disturbance observer (DO) is guaranteed by selecting design parameters, which depend on the maximum velocity and physical parameters of robotic manipulators. This new observer overcomes the disadvantages of existing DO's, which are designed or analyzed by linear system techniques. It can be applied in robotic manipulators for various purposes such as friction compensation, independent joint control, sensorless torque control, and fault diagnosis. The performance of the proposed observer is demonstrated by the friction estimation and compensation for a two-link robotic manipulator. Both simulation and experimental results show the NDO works well.					; Chen, Wen-Hua/C-5993-2009	Gawthrop, Peter/0000-0002-6029-515X; Chen, Wen-Hua/0000-0003-3356-2889; Ballance, Donald John/0009-0006-7976-4813													0278-0046	1557-9948				AUG	2000	47	4					932	938		10.1109/41.857974	http://dx.doi.org/10.1109/41.857974													WOS:000088717200024
J	Li, CM; Kao, CY; Gore, JC; Ding, ZH				Li, Chunming; Kao, Chiu-Yen; Gore, Joint C.; Ding, Zhaohua			Minimization of region-scalable fitting energy for image segmentation	IEEE TRANSACTIONS ON IMAGE PROCESSING												Intensity inhomogeneities often occur in real-world images and may cause considerable difficulties in image segmentation. In order to overcome the difficulties caused by intensity inhomogeneities, we propose a region-based active contour model that draws upon intensity information in local regions at a controllable scale. A data fitting energy is defined in terms of a contour and two fitting functions that locally approximate the image intensities on the two sides of the contour. This energy is then incorporated into a variational level set formulation with a level set regularization term, from which a curve evolution equation is derived for energy minimization. Due to a kernel function in the data fitting term, intensity information in local regions is extracted to guide the motion of the contour, which thereby enables our model to cope with intensity inhomogeneity. In addition, the regularity of the level set function is intrinsically preserved by the level set regularization term to ensure accurate computation and avoids expensive reinitialization of the evolving level set function. Experimental results for synthetic and real images show desirable performances of our method.					Ding, Zhaohua/AHC-7551-2022; Li, Chunming/AAC-1022-2020	Kao, Chiu-Yen/0000-0003-3082-4943; Li, Chunming/0000-0002-4159-7048													1057-7149	1941-0042				OCT	2008	17	10					1940	1949		10.1109/TIP.2008.2002304	http://dx.doi.org/10.1109/TIP.2008.2002304								18784040					WOS:000259372100017
J	Huang, J; Ling, CX				Huang, J; Ling, CX			Using AUC and accuracy in evaluating learning algorithms	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING												The area under the ROC ( Receiver Operating Characteristics) curve, or simply AUC, has been traditionally used in medical diagnosis since the 1970s. It has recently been proposed as an alternative single-number measure for evaluating the predictive ability of learning algorithms. However, no formal arguments were given as to why AUC should be preferred over accuracy. In this paper, we establish formal criteria for comparing two different measures for learning algorithms and we show theoretically and empirically that AUC is a better measure ( defined precisely) than accuracy. We then reevaluate well-established claims in machine learning based on accuracy using AUC and obtain interesting and surprising new results. For example, it has been well-established and accepted that Naive Bayes and decision trees are very similar in predictive accuracy. We show, however, that Naive Bayes is significantly better than decision trees in AUC. The conclusions drawn in this paper may make a significant impact on machine learning and data mining applications.																			1041-4347					MAR	2005	17	3					299	310		10.1109/TKDE.2005.50	http://dx.doi.org/10.1109/TKDE.2005.50													WOS:000226358200001
J	Tian, YH; Li, SP; Song, J; Ji, TJ; Zhu, MT; Anderson, GJ; Wei, JY; Nie, GJ				Tian, Yanhua; Li, Suping; Song, Jian; Ji, Tianjiao; Zhu, Motao; Anderson, Gregory J.; Wei, Jingyan; Nie, Guangjun			A doxorubicin delivery platform using engineered natural membrane vesicle exosomes for targeted tumor therapy	BIOMATERIALS												Targeted drug delivery vehicles with low immunogenicity and toxicity are needed for cancer therapy. Here we show that exosomes, endogenous nano-sized membrane vesicles secreted by most cell types, can deliver chemotherapeutics such as doxorubicin (Dox) to tumor tissue in BALB/c nude mice. To reduce immunogenicity and toxicity, mouse immature dendritic cells (imDCs) were used for exosome production. Tumor targeting was facilitated by engineering the imDCs to express a well-characterized exosomal membrane protein (Lamp2b) fused to alpha v integrin-specific iRGD peptide (CRGDKGPDC). Purified exosomes from imDCs were loaded with Dox via electroporation, with an encapsulation efficiency of up to 20%. iRGD exosomes showed highly efficient targeting and Dox delivery to am integrin-positive breast cancer cells in vitro as demonstrated by confocal imaging and flow cytometry. Intravenously injected targeted exosomes delivered Dox specifically to tumor tissues, leading to inhibition of tumor growth without overt toxicity. Our results suggest that exosomes modified by targeting ligands can be used therapeutically for the delivery of Dox to tumors, thus having great potential value for clinical applications. (c) 2013 Elsevier Ltd. All rights reserved.					Tian, Yanhua/AAE-9384-2021; Nie, Guangjun/A-9954-2011; ji, tianjiao/HCH-4631-2022; Anderson, Gregory/G-4148-2013	nie, guangjun/0000-0001-5040-9793; Anderson, Gregory/0000-0002-8814-5866													0142-9612	1878-5905				FEB	2014	35	7					2383	2390		10.1016/j.biomaterials.2013.11.083	http://dx.doi.org/10.1016/j.biomaterials.2013.11.083								24345736					WOS:000331502300032
J	Lackner, S; Gilbert, EM; Vlaeminck, SE; Joss, A; Horn, H; van Loosdrecht, MCM				Lackner, Susanne; Gilbert, Eva M.; Vlaeminck, Siegfried E.; Joss, Adriano; Horn, Harald; van Loosdrecht, Mark C. M.			Full-scale partial nitritation/anammox experiences - An application survey	WATER RESEARCH												Partial nitritation/anammox (PN/A) has been one of the most innovative developments in biological wastewater treatment in recent years. With its discovery in the 1990s a completely new way of ammonium removal from wastewater became available. Over the past decade many technologies have been developed and studied for their applicability to the PN/A concept and several have made it into full-scale. With the perspective of reaching 100 full-scale installations in operation worldwide by 2014 this work presents a summary of PN/A technologies that have been successfully developed, implemented and optimized for high-strength ammonium wastewaters with low C:N ratios and elevated temperatures. The data revealed that more than 50% of all PN/A installations are sequencing batch reactors, 88% of all plants being operated as single-stage systems, and 75% for sidestream treatment of municipal wastewater. Additionally an in-depth survey of 14 full-scale installations was conducted to evaluate practical experiences and report on operational control and troubleshooting. Incoming solids, aeration control and nitrate built up were revealed as the main operational difficulties. The information provided gives a unique/new perspective throughout all the major technologies and discusses the remaining obstacles. (C) 2014 Elsevier Ltd. All rights reserved.					Lackner, Susanne/AAL-9352-2021; van Loosdrecht, Mark/B-2738-2009; Vlaeminck, Siegfried/B-4203-2014; , Harald/H-1650-2013	Vlaeminck, Siegfried/0000-0002-2596-8857; Lackner, Susanne/0000-0002-9163-9541; , Harald/0000-0002-9385-3883; van Loosdrecht, Mark/0000-0003-0658-4775													0043-1354					MAY 15	2014	55						292	303		10.1016/j.watres.2014.02.032	http://dx.doi.org/10.1016/j.watres.2014.02.032								24631878					WOS:000335201500029
J	Khor, E; Lim, LY				Khor, E; Lim, LY			Implantable applications of chitin and chitosan	BIOMATERIALS												Chitin, extracted primarily from shellfish sources, is a unique biopolymer based on the N-acetyl-glucosamine monomer. More than 40 years have lapsed since this biopolymer had aroused the interest of the scientific community around the world for its potential biomedical applications. Chitin, together with its variants, especially its deacetylated counterpart chitosan, has been shown to be useful as a wound dressing material, drug delivery vehicle and increasingly a candidate for tissue engineering. The promise for this biomaterial is vast and will continue to increase as the chemistry to extend its capabilities and new biomedical applications are investigated. It is interesting to note that a majority of this work has come from Asia. Japan has been the undisputed leader, but other Asian nations, namely Korea, Singapore, Taiwan and Thailand have also. made notable contributions. More recently, China has joined the club to become an increasingly major research source for chitin and chitosan in Asia, This review surveys select works of key groups in Asia developing chitin and chitosan materials for implantable biomedical applications. (C) 2003 Elsevier Science Ltd. All rights reserved.					Lim, Lee Yong/C-6144-2013	Lim, Lee Yong/0000-0002-7307-0742													0142-9612	1878-5905				JUN	2003	24	13					2339	2349		10.1016/S0142-9612(03)00026-7	http://dx.doi.org/10.1016/S0142-9612(03)00026-7								12699672					WOS:000182280400025
J	Frank, AG; Dalenogare, LS; Ayala, NF				Frank, Alejandro German; Dalenogare, Lucas Santos; Ayala, Nestor Fabian			Industry 4.0 technologies: Implementation patterns in manufacturing companies	INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS												Industry 4.0 has been considered a new industrial stage in which several emerging technologies are converging to provide digital solutions. However, there is a lack of understanding of how companies implement these technologies. Thus, we aim to understand the adoption patterns of Industry 4.0 technologies in manufacturing firms. We propose a conceptual framework for these technologies, which we divided into front-end and base technologies. Front-end technologies consider four dimensions: Smart Manufacturing, Smart Products, Smart Supply Chain and Smart Working, while base technologies consider four elements: internet of things, cloud services, big data and analytics. We performed a survey in 92 manufacturing companies to study the implementation of these technologies. Our findings show that Industry 4.0 is related to a systemic adoption of the front-end technologies, in which Smart Manufacturing plays a central role. Our results also show that the implementation of the base technologies is challenging companies, since big data and analytics are still low implemented in the sample studied. We propose a structure of Industry 4.0 technology layers and we show levels of adoption of these technologies and their implication for manufacturing companies.					Ayala, Néstor/AAK-3803-2021; Frank, Alejandro G./H-7379-2014	Frank, Alejandro G./0000-0001-5041-6467; AYALA, NESTOR FABIAN/0000-0001-8888-9227													0925-5273	1873-7579				APR	2019	210						15	26		10.1016/j.ijpe.2019.01.004	http://dx.doi.org/10.1016/j.ijpe.2019.01.004													WOS:000466056100002
J	Ding, ZG; Liu, YW; Choi, J; Sun, Q; Elkashlan, M; I, CL; Poor, HV				Ding, Zhiguo; Liu, Yuanwei; Choi, Jinho; Sun, Qi; Elkashlan, Maged; I, Chih-Lin; Poor, H. Vincent			Application of Non-Orthogonal Multiple Access in LTE and 5G Networks	IEEE COMMUNICATIONS MAGAZINE												As the latest member of the multiple access family, non-orthogonal multiple access (NOMA) has been recently proposed for 3GPP LIE and is envisioned to be an essential component of 5G mobile networks. The key feature of NOMA is to serve multiple users at the same time/frequency/code, but with different power levels, which yields a significant spectral efficiency gain over conventional orthogonal MA. The article provides a systematic treatment of this newly emerging technology, from its combination with MIMO technologies to cooperative NOMA, as well as the interplay between NOMA and cognitive radio. This article also reviews the state of the art in the standardization activities concerning the implementation of NOMA in LTE and 5G networks.					Ding, Zhiguo/B-9805-2017; Poor, H./S-5027-2016; Elkashlan, Maged/C-1177-2011; Choi, Jinho/X-4157-2018; Liu, Yuanwei/AAA-2444-2020	Choi, Jinho/0000-0002-4895-6680; Poor, H. Vincent/0000-0002-2062-131X; Liu, Yuanwei/0000-0002-6389-8941													0163-6804	1558-1896				FEB	2017	55	2					185	191		10.1109/MCOM.2017.1500657CM	http://dx.doi.org/10.1109/MCOM.2017.1500657CM													WOS:000395574900029
J	Altafini, C				Altafini, Claudio			Consensus Problems on Networks With Antagonistic Interactions	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												In a consensus protocol an agreement among agents is achieved thanks to the collaborative efforts of all agents, expresses by a communication graph with nonnegative weights. The question we ask in this paper is the following: is it possible to achieve a form of agreement also in presence of antagonistic interactions, modeled as negative weights on the communication graph? The answer to this question is affirmative: on signed networks all agents can converge to a consensus value which is the same for all agents except for the sign. Necessary and sufficient conditions are obtained to describe cases in which this is possible. These conditions have strong analogies with the theory of monotone systems. Linear and non-linear Laplacian feedback designs are proposed.					Altafini, Claudio/AAL-4235-2020	Altafini, Claudio/0000-0003-4142-6502													0018-9286	1558-2523				APR	2013	58	4					935	946		10.1109/TAC.2012.2224251	http://dx.doi.org/10.1109/TAC.2012.2224251													WOS:000316807300009
J	Kong, WC; Dong, ZY; Jia, YW; Hill, DJ; Xu, Y; Zhang, Y				Kong, Weicong; Dong, Zhao Yang; Jia, Youwei; Hill, David J.; Xu, Yan; Zhang, Yuan			Short-Term Residential Load Forecasting Based on LSTM Recurrent Neural Network	IEEE TRANSACTIONS ON SMART GRID												As the power system is facing a transition toward a more intelligent, flexible, and interactive system with higher penetration of renewable energy generation, load forecasting, especially short-term load forecasting for individual electric customers plays an increasingly essential role in the future grid planning and operation. Other than aggregated residential load in a large scale, forecasting an electric load of a single energy user is fairly challenging due to the high volatility and uncertainty involved. In this paper, we propose a long short-term memory (LSTM) recurrent neural network-based framework, which is the latest and one of the most popular techniques of deep learning, to tackle this tricky issue. The proposed framework is tested on a publicly available set of real residential smart meter data, of which the performance is comprehensively compared to various benchmarks including the state-of-the-arts in the field of load forecasting. As a result, the proposed LSTM approach outperforms the other listed rival algorithms in the task of short-term load forecasting for individual residential households.					Xu, Yan/KJM-5910-2024; Hill, David/AAG-2576-2019; Kong, Weicong/Y-5291-2019; yang, dong zhao/AFP-5094-2022; Jia, Youwei/AAU-6073-2021; Hill, David John/L-2218-2013	Hill, David John/0000-0003-4036-0839; Dong, Zhao Yang/0000-0001-9659-0858													1949-3053	1949-3061				JAN	2019	10	1					841	851		10.1109/TSG.2017.2753802	http://dx.doi.org/10.1109/TSG.2017.2753802													WOS:000455180900077
J	Zein, I; Hutmacher, DW; Tan, KC; Teoh, SH				Zein, I; Hutmacher, DW; Tan, KC; Teoh, SH			Fused deposition modeling of novel scaffold architectures for tissue engineering applications	BIOMATERIALS												Fused deposition modeling, a rapid prototyping technology, was used to produce novel scaffolds with honeycomb-like pattern, fully interconnected channel network, and controllable porosity and channel size. A bioresorbable polymer poly(epsilon -caprolactone) (PCL) was developed as a filament modeling material to produce porous scaffolds. made of layers of directionally aligned microfilaments, using this computer-controlled extrusion and deposition process. The PCL scaffolds were produced with a range of channel size 160-700 mum, filament diameter 260-370 mum and porosity 48-77%, and regular geometrical honeycomb pores, depending on the processing parameters. The scaffolds of different porosity also exhibited a pattern of compressive stress-strain behavior characteristic of porous solids under such loading. The compressive stiffness ranged from 4 to 77 MPa, yield strength from 0.4 to 3.6MPa and yield strain from 4% to 28%. Analysis of the measured data shows a high correlation between the scaffold porosity and the compressive properties based on a power-law relationship. (C) 2001 Elsevier Science Ltd. All rights reserved.					Hutmacher, Dietmar/AEO-9578-2022	Hutmacher, Dietmar Werner/0000-0001-5678-2134													0142-9612					FEB	2002	23	4					1169	1185		10.1016/S0142-9612(01)00232-0	http://dx.doi.org/10.1016/S0142-9612(01)00232-0								11791921					WOS:000172738500023
J	Cheng, G; Zhou, PC; Han, JW				Cheng, Gong; Zhou, Peicheng; Han, Junwei			Learning Rotation-Invariant Convolutional Neural Networks for Object Detection in VHR Optical Remote Sensing Images	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING												Object detection in very high resolution optical remote sensing images is a fundamental problem faced for remote sensing image analysis. Due to the advances of powerful feature representations, machine-learning-based object detection is receiving increasing attention. Although numerous feature representations exist, most of them are handcrafted or shallow-learning-based features. As the object detection task becomes more challenging, their description capability becomes limited or even impoverished. More recently, deep learning algorithms, especially convolutional neural networks (CNNs), have shown their much stronger feature representation power in computer vision. Despite the progress made in nature scene images, it is problematic to directly use the CNN feature for object detection in optical remote sensing images because it is difficult to effectively deal with the problem of object rotation variations. To address this problem, this paper proposes a novel and effective approach to learn a rotation-invariant CNN (RICNN) model for advancing the performance of object detection, which is achieved by introducing and learning a new rotation-invariant layer on the basis of the existing CNN architectures. However, different from the training of traditional CNN models that only optimizes the multinomial logistic regression objective, our RICNN model is trained by optimizing a new objective function via imposing a regularization constraint, which explicitly enforces the feature representations of the training samples before and after rotating to be mapped close to each other, hence achieving rotation invariance. To facilitate training, we first train the rotation-invariant layer and then domain-specifically fine-tune the whole RICNN network to further boost the performance. Comprehensive evaluations on a publicly available ten-class object detection data set demonstrate the effectiveness of the proposed method.					Han, Junwei/AEX-0831-2022; Cheng, Gong/I-9551-2019	Cheng, Gong/0000-0001-5030-0683													0196-2892	1558-0644				DEC	2016	54	12					7405	7415		10.1109/TGRS.2016.2601622	http://dx.doi.org/10.1109/TGRS.2016.2601622													WOS:000385713500051
J	Li, ZJ; Gu, XN; Lou, SQ; Zheng, YF				Li, Zijian; Gu, Xunan; Lou, Siquan; Zheng, Yufeng			The development of binary Mg-Ca alloys for use as biodegradable materials within bone	BIOMATERIALS												Binary Mg-Ca alloys with various Ca contents were fabricated under different working conditions. X-ray diffraction (XRD) analysis and optical microscopy observations showed that Mg-xCa (x = 1-3 wt%) alloys were composed of two phases, alpha(Mg) and Mg2Ca. The results of tensile tests and in vitro corrosion tests indicated that the mechanical properties could be adjusted by controlling the Ca content and processing treatment. The yield strength (YS), ultimate tensile strength (UTS) and elongation decreased with increasing Ca content. The UTS and elongation of as-cast Mg-1Ca alloy (71.38 +/- 3.01 MPa and 1.87 +/- 0.14%) were largely improved after hot rolling (166.7 +/- 3.01 MPa and 3 +/- 0.78%) and hot extrusion (239.63 +/- 7.21 MPa and 10.63 +/- 0.64%). The in vitro corrosion test in simulated body fluid (SBF) indicated that the microstructure and working history of Mg-xCa alloys strongly affected their corrosion behaviors. An increasing content of Mg2Ca phase led to a higher corrosion rate whereas hot rolling and hot extrusion could reduce it. The cytotoxicity evaluation using L-929 cells revealed that Mg-1Ca alloy did not induce toxicity to cells, and the viability of cells for Mg-1Ca alloy extraction medium was better than that of control. Moreover, Mg-1Ca alloy pins, with commercial pure Ti pins as control, were implanted into the left and right rabbit femoral shafts, respectively, and observed for 1, 2 and 3 months. High activity of ostroblast and osteocytes were observed around the Mg-1Ca alloy pins as shown by hematoxylin and eosin stained tissue sections. Radiographic examination revealed that the Mg-1Ca alloy pins gradually degraded in vivo within 90 days and the newly formed bone was clearly seen at month 3. Both the in vitro and in vivo corrosion suggested that a mixture of Mg(OH)(2) and hydroxyapatite formed on the surface of Mg-1Ca alloy with the extension of immersion/implantation time. In addition, no significant difference (p > 0.05) of serum magnesium was detected at different degradation stages. All these results revealed that Mg-1Ca alloy had the acceptable biocompatibility as a new kind of biodegradable implant material. Based on the above results, a solid alloy/liquid solution interface model was also proposed to interpret the biocorrosion process and the associated hydroxyapatite mineralization. (c) 2007 Elsevier Ltd. All rights reserved.					YAN, Zheng-Guang/HGC-8374-2022; Li, Zi-Jian/IWM-1489-2023; Gu, Xuenan/F-5354-2011	Zheng, Y.F./0000-0002-7402-9979													0142-9612	1878-5905				APR	2008	29	10					1329	1344		10.1016/j.biomaterials.2007.12.021	http://dx.doi.org/10.1016/j.biomaterials.2007.12.021								18191191					WOS:000253406300005
J	Bligaard, T; Norskov, JK; Dahl, S; Matthiesen, J; Christensen, CH; Sehested, J				Bligaard, T; Norskov, JK; Dahl, S; Matthiesen, J; Christensen, CH; Sehested, J			The Bronsted-Evans-Polanyi relation and the volcano curve in heterogeneous catalysis	JOURNAL OF CATALYSIS												A number of elementary reactions at metal surfaces show a linear Bronsted-Evans-Polanyi relation between the activation energy and the reaction energy, and reactions belonging to the same class even follow the same relation. We investigate the implications of this finding on the kinetics of surface-catalyzed chemical processes. We focus in particular on the variation in the activity from one metal to the next. By analyzing a number of simple microkinetic models we show that the reaction rate under given reaction conditions shows a maximum as a function of the dissociative adsorption energy of the key reactant, and that for most conditions this maximum is in the same range of reaction energies. We also provide a database of chemisorption energies calculated using density-functional theory for a number of simple gas molecules on 13 different transition metals. An important part of the analysis consists of developing a general framework for analyzing the maximum rate. We use these concepts to rationalize trends in the catalytic activity of a number of metals for the methanation process. (C) 2004 Elsevier Inc. All rights reserved.					Dahl, Søren/A-4898-2011; Bligaard, Thomas/A-6161-2011; Matthiesen, Jesper/N-2477-2014; Norskov, Jens/D-2539-2017; Bligaard, Thomas/A-6161-2011	Bligaard, Thomas/0000-0003-0386-0201; Matthiesen, Jesper/0000-0003-1040-1919; Norskov, Jens/0000-0002-4427-7728; Bligaard, Thomas/0000-0001-9834-9179													0021-9517	1090-2694				MAY 15	2004	224	1					206	217		10.1016/j.jcat.2004.02.034	http://dx.doi.org/10.1016/j.jcat.2004.02.034													WOS:000221200700023
J	Rodriguez, J; Kazmierkowski, MP; Espinoza, JR; Zanchetta, P; Abu-Rub, H; Young, HA; Rojas, CA				Rodriguez, Jose; Kazmierkowski, Marian P.; Espinoza, Jose R.; Zanchetta, Pericle; Abu-Rub, Haitham; Young, Hector A.; Rojas, Christian A.			State of the Art of Finite Control Set Model Predictive Control in Power Electronics	IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS												This paper addresses to some of the latest contributions on the application of Finite Control Set Model Predictive Control (FCS-MPC) in Power Electronics. In FCS-MPC, the switching states are directly applied to the power converter, without the need of an additional modulation stage. The paper shows how the use of FCS-MPC provides a simple and efficient computational realization for different control objectives in Power Electronics. Some applications of this technology in drives, active filters, power conditioning, distributed generation and renewable energy are covered. Finally, attention is paid to the discussion of new trends in this technology and to the identification of open questions and future research topics.					Rojas, Christian/T-5865-2019; Abu-Rub, Haitham/AFO-9012-2022; Young, Hector/AFS-9585-2022; Kazmierkowski, Marian/K-6558-2018; Espinoza, Jose R./E-9730-2012; Rojas, Christian/M-7172-2015; Rodriguez, Jose/A-2534-2013	Espinoza, Jose R./0000-0001-6648-7518; Rojas, Christian/0000-0002-2071-1665; Rodriguez, Jose/0000-0002-1410-4121; Abu-Rub, Haitham/0000-0001-8687-3942; Young, Hector/0000-0002-6138-5245													1551-3203	1941-0050				MAY	2013	9	2					1003	1016		10.1109/TII.2012.2221469	http://dx.doi.org/10.1109/TII.2012.2221469													WOS:000313706700044
J	Lesser, GR; Roelvink, JA; van Kester, JATM; Stelling, GS				Lesser, GR; Roelvink, JA; van Kester, JATM; Stelling, GS			Development and validation of a three-dimensional morphological model	COASTAL ENGINEERING												Computer modeling of sediment transport patterns is generally recognized as a valuable tool for understanding and predicting morphological developments. In practice, state-of-the-art computer models are one- or two-dimensional (depth-averaged) and have a limited ability to model many of the important three-dimensional flow phenomena found in nature. This paper presents the implementation and validation of sediment transport formulations within the proven DELFT3D three-dimensional (hydrostatic, free surface) flow solver. The paper briefly discusses the operation of the DELFT3D-FLOW module, presents the key features of the formulations used to model both suspended and bedload transport of noncohesive sediment, and describes the implemented morphological updating scheme. The modeling of the three-dimensional effects of waves is also discussed. Following the details of the implementation, the results of a number of validation studies are presented. The model is shown to perform well in several theoretical, laboratory, and real-life situations. (C) 2004 Elsevier B.V. All rights reserved.					stelling, gustaaf/M-7775-2014; Roelvink, Dano/C-6940-2009	Roelvink, Dano/0000-0002-5367-0003													0378-3839	1872-7379				OCT	2004	51	8-9					883	915		10.1016/j.coastaleng.2004.07.014	http://dx.doi.org/10.1016/j.coastaleng.2004.07.014													WOS:000224452000014
J	Liu, J; Musialski, P; Wonka, P; Ye, JP				Liu, Ji; Musialski, Przemyslaw; Wonka, Peter; Ye, Jieping			Tensor Completion for Estimating Missing Values in Visual Data	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												In this paper, we propose an algorithm to estimate missing values in tensors of visual data. The values can be missing due to problems in the acquisition process or because the user manually identified unwanted outliers. Our algorithm works even with a small amount of samples and it can propagate structure to fill larger missing regions. Our methodology is built on recent studies about matrix completion using the matrix trace norm. The contribution of our paper is to extend the matrix case to the tensor case by proposing the first definition of the trace norm for tensors and then by building a working algorithm. First, we propose a definition for the tensor trace norm that generalizes the established definition of the matrix trace norm. Second, similarly to matrix completion, the tensor completion is formulated as a convex optimization problem. Unfortunately, the straightforward problem extension is significantly harder to solve than the matrix case because of the dependency among multiple constraints. To tackle this problem, we developed three algorithms: simple low rank tensor completion (SiLRTC), fast low rank tensor completion (FaLRTC), and high accuracy low rank tensor completion (HaLRTC). The SiLRTC algorithm is simple to implement and employs a relaxation technique to separate the dependant relationships and uses the block coordinate descent (BCD) method to achieve a globally optimal solution; the FaLRTC algorithm utilizes a smoothing scheme to transform the original nonsmooth problem into a smooth one and can be used to solve a general tensor trace norm minimization problem; the HaLRTC algorithm applies the alternating direction method of multipliers (ADMMs) to our problem. Our experiments show potential applications of our algorithms and the quantitative evaluation indicates that our methods are more accurate and robust than heuristic approaches. The efficiency comparison indicates that FaLTRC and HaLRTC are more efficient than SiLRTC and between FaLRTC and HaLRTC the former is more efficient to obtain a low accuracy solution and the latter is preferred if a high-accuracy solution is desired.					Musialski, Przemyslaw/O-2617-2013	Musialski, Przemyslaw/0000-0001-6429-8190													0162-8828	1939-3539				JAN	2013	35	1					208	220		10.1109/TPAMI.2012.39	http://dx.doi.org/10.1109/TPAMI.2012.39								22271823					WOS:000311127700018
J	Sample, AP; Meyer, DA; Smith, JR				Sample, Alanson P.; Meyer, David A.; Smith, Joshua R.			Analysis, Experimental Results, and Range Adaptation of Magnetically Coupled Resonators for Wireless Power Transfer	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS												Wireless power technology offers the promise of cutting the last cord, allowing users to seamlessly recharge mobile devices as easily as data are transmitted through the air. Initial work on the use of magnetically coupled resonators for this purpose has shown promising results. We present new analysis that yields critical insight into the design of practical systems, including the introduction of key figures of merit that can be used to compare systems with vastly different geometries and operating conditions. A circuit model is presented along with a derivation of key system concepts, such as frequency splitting, the maximum operating distance (critical coupling), and the behavior of the system as it becomes undercoupled. This theoretical model is validated against measured data and shows an excellent average coefficient of determination (R-2) of 0.9875. An adaptive frequency tuning technique is demonstrated, which compensates for efficiency variations encountered when the transmitter-to-receiver distance and/or orientation are varied. The method demonstrated in this paper allows a fixed-load receiver to be moved to nearly any position and/or orientation within the range of the transmitter and still achieve a near-constant efficiency of over 70% for a range of 0-70 cm.						Sample, Alanson/0000-0002-8046-0538													0278-0046	1557-9948				FEB	2011	58	2					544	554		10.1109/TIE.2010.2046002	http://dx.doi.org/10.1109/TIE.2010.2046002													WOS:000286109500021
J	Gong, YC; Lazebnik, S; Gordo, A; Perronnin, F				Gong, Yunchao; Lazebnik, Svetlana; Gordo, Albert; Perronnin, Florent			Iterative Quantization: A Procrustean Approach to Learning Binary Codes for Large-Scale Image Retrieval	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												This paper addresses the problem of learning similarity-preserving binary codes for efficient similarity search in large-scale image collections. We formulate this problem in terms of finding a rotation of zero-centered data so as to minimize the quantization error of mapping this data to the vertices of a zero-centered binary hypercube, and propose a simple and efficient alternating minimization algorithm to accomplish this task. This algorithm, dubbed iterative quantization (ITQ), has connections to multiclass spectral clustering and to the orthogonal Procrustes problem, and it can be used both with unsupervised data embeddings such as PCA and supervised embeddings such as canonical correlation analysis (CCA). The resulting binary codes significantly outperform several other state-of-the-art methods. We also show that further performance improvements can result from transforming the data with a nonlinear kernel mapping prior to PCA or CCA. Finally, we demonstrate an application of ITQ to learning binary attributes or "classemes" on the ImageNet data set.																			0162-8828	1939-3539				DEC	2013	35	12					2916	2929		10.1109/TPAMI.2012.193	http://dx.doi.org/10.1109/TPAMI.2012.193								24136430					WOS:000326502200009
J	Candès, EJ; Tao, T				Candes, Emmanuel J.; Tao, Terence			The Power of Convex Relaxation: Near-Optimal Matrix Completion	IEEE TRANSACTIONS ON INFORMATION THEORY												This paper is concerned with the problem of recovering an unknown matrix from a small fraction of its entries. This is known as the matrix completion problem, and comes up in a great number of applications, including the famous Netflix Prize and other similar questions in collaborative filtering. In general, accurate recovery of a matrix from a small number of entries is impossible, but the knowledge that the unknown matrix has low rank radically changes this premise, making the search for solutions meaningful. This paper presents optimality results quantifying the minimum number of entries needed to recover a matrix of rank r exactly by any method whatsoever (the information theoretic limit). More importantly, the paper shows that, under certain incoherence assumptions on the singular vectors of the matrix, recovery is possible by solving a convenient convex program as soon as the number of entries is on the order of the information theoretic limit (up to logarithmic factors). This convex program simply finds, among all matrices consistent with the observed entries, that with minimum nuclear norm. As an example, we show that on the order of nr log(n) samples are needed to recover a random n x n matrix of rank by any method, and to be sure, nuclear norm minimization succeeds as soon as the number of entries is of the form nr log(n).					Tao, Terence/M-1837-2015														0018-9448					MAY	2010	56	5					2053	2080		10.1109/TIT.2010.2044061	http://dx.doi.org/10.1109/TIT.2010.2044061													WOS:000278067900001
J	Sarkis, J; Zhu, QH; Lai, KH				Sarkis, Joseph; Zhu, Qinghua; Lai, Kee-hung			An organizational theoretic review of green supply chain management literature	INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS												Green supply chain management (GSCM) has gained increasing attention within both academia and industry. As the literature grows, finding new directions by critically evaluating the research and identifying future directions becomes important in advancing knowledge for the field. Using organizational theories to help categorize the literature provides opportunities to address both the objectives of understanding where the field currently stands and identifying research opportunities and directions. After providing a background discussion on GSCM, we categorize and review recent GSCM literature under nine broad organizational theories, with a special emphasis on investigation of adoption, diffusion and outcomes of GSCM practices. Within this review framework, we also identify GSCM research questions that are worthy of investigation. Additional organizational theories which are considered valuable for future GSCM research are also identified with a conclusion for this review. (C) 2010 Elsevier B.V. All rights reserved.					Zhu, Qinghua/M-3408-2016; Sarkis, Joseph/F-4508-2014; Lai, Kee-hung/B-4054-2009	Sarkis, Joseph/0000-0003-0143-804X; Lai, Kee-hung/0000-0001-9296-0882; ZHU, Qinghua/0000-0003-2648-0260													0925-5273	1873-7579				MAR	2011	130	1					1	15		10.1016/j.ijpe.2010.11.010	http://dx.doi.org/10.1016/j.ijpe.2010.11.010													WOS:000287341100001
J	Nistér, D				Nistér, D			An efficient solution to the five-point relative pose problem	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												An efficient algorithmic solution to the classical five-point relative pose problem is presented. The problem is to find the possible solutions for relative camera pose between two calibrated views given five corresponding points. The algorithm consists of computing the coefficients of a tenth degree polynomial in closed form and, subsequently, finding its roots. It is the first algorithm well-suited for numerical implementation that also corresponds to the inherent complexity of the problem. We investigate the numerical precision of the algorithm. We also study its performance under noise in minimal as well as overdetermined cases. The performance is compared to that of the well-known 8 and 7-point methods and a 6-point scheme. The algorithm is used in a robust hypothesize-and-test framework to estimate structure and motion in real-time with low delay. The real-time system uses solely visual input and has been demonstrated at major conferences.																			0162-8828	1939-3539				JUN	2004	26	6					756	770		10.1109/TPAMI.2004.17	http://dx.doi.org/10.1109/TPAMI.2004.17								18579936					WOS:000220756500009
J	Li, ST; Kang, XD; Hu, JW				Li, Shutao; Kang, Xudong; Hu, Jianwen			Image Fusion with Guided Filtering	IEEE TRANSACTIONS ON IMAGE PROCESSING												A fast and effective image fusion method is proposed for creating a highly informative fused image through merging multiple images. The proposed method is based on a two-scale decomposition of an image into a base layer containing large scale variations in intensity, and a detail layer capturing small scale details. A novel guided filtering-based weighted average technique is proposed to make full use of spatial consistency for fusion of the base and detail layers. Experimental results demonstrate that the proposed method can obtain state-of-the-art performance for fusion of multispectral, multifocus, multimodal, and multiexposure images.					Kang, Xudong/JOZ-0917-2023; Li, Shutao/Y-3102-2019														1057-7149	1941-0042				JUL	2013	22	7					2864	2875		10.1109/TIP.2013.2244222	http://dx.doi.org/10.1109/TIP.2013.2244222								23372084					WOS:000321924600028
J	Kerr, YH; Waldteufel, P; Wigneron, JP; Martinuzzi, JM; Font, J; Berger, M				Kerr, YH; Waldteufel, P; Wigneron, JP; Martinuzzi, JM; Font, J; Berger, M			Soil moisture retrieval from space: The Soil Moisture and Ocean Salinity (SMOS) mission	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING												Microwave radiometry at low frequencies (L-band: 1.4 GHz, 21 cm) is an established technique for estimating surface soil moisture and sea surface salinity with a suitable sensitivity. However, from space, large antennas (several meters) are required to achieve an adequate spatial resolution at L-band. So as to reduce the problem of putting into orbit a large filled antenna, the possibility of using antenna synthesis methods has been investigated. Such a system, relying on a deployable structure, has now proved to be feasible and has led to the Soil Moisture and Ocean Salinity (SMOS) mission, which is described in this paper. The main objective of the SMOS mission is to deliver key variables of the land surfaces (soil moisture fields), and of ocean surfaces (sea surface salinity fields). The SMOS mission is based on a dual polarized L-band radiometer using aperture synthesis (two-dimensional [2-D] interferometer) so as to achieve a ground resolution of 50 km at the swath edges coupled with multiangular acquisitions. The radiometer will enable frequent and global coverage of the globe and deliver surface soil moisture fields over land and sea surface salinity over the oceans. The SMOS mission was proposed to the European Space Agency (ESA) in the framework of the Earth Explorer Opportunity Missions. It was selected for a tentative launch in 2005. The goal of this paper is to present the main aspects of the baseline mission(1) and describe how soil moisture will be retrieved from SMOS data.					Wigneron, Jean-Pierre/ABD-9939-2021; Kerr, Yann/Z-2432-2019; Waldteufel, Philippe/AAA-8039-2021; Font, Jordi/E-5355-2013	Font, Jordi/0000-0003-2590-1457; wigneron, jean-pierre/0000-0001-5345-3618													0196-2892					AUG	2001	39	8					1729	1735		10.1109/36.942551	http://dx.doi.org/10.1109/36.942551													WOS:000170682500013
J	Jain, A; Nandakumar, K; Ross, A				Jain, A; Nandakumar, K; Ross, A			Score normalization in multimodal biometric systems	PATTERN RECOGNITION												Multimodal biometric systems consolidate the evidence presented by multiple biometric sources and typically provide better recognition performance compared to systems based on a single biometric modality. Although information fusion in a multimodal system can be performed at various levels, integration at the matching score level is the most common approach due to the ease in accessing and combining the scores generated by different matchers. Since the matching scores output by the various modalities are heterogeneous, score normalization is needed to transform these scores into a common domain, prior to combining them. In this paper, we have studied the performance of different normalization techniques and fusion rules in the context of a multimodal biometric system based on the face, fingerprint and hand-geometry traits of a user. Experiments conducted on a database of 100 users indicate that the application of min-max, z-score, and tanh normalization schemes followed by a simple sum of scores fusion method results in better recognition performance compared to other methods. However, experiments also reveal that the min-max and z-score normalization techniques are sensitive to outliers in the data, highlighting the need for a robust and efficient normalization procedure like the tanh normalization. It was also observed that multimodal systems utilizing user-specific weights perform better compared to systems that assign the same set of weights to the multiple biometric traits of all users. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.					Nandakumar, Karthik/AAC-4414-2022														0031-3203	1873-5142				DEC	2005	38	12					2270	2285		10.1016/j.patcog.2005.01.012	http://dx.doi.org/10.1016/j.patcog.2005.01.012													WOS:000232703000005
J	Nabar, RU; Bölcskei, H; Kneubühler, FW				Nabar, RU; Bölcskei, H; Kneubühler, FW			Fading relay channels:: Performance limits and space-time signal design	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS												Cooperative diversity is a transmission technique, where multiple terminals pool their,resources to form a virtual antenna array that realizes spatial diversity gain in a distributed fashion. In this paper, we examine the basic building block of cooperative diversity systems, a simple fading relay channel where the source, destination, and relay terminals are each equipped with single antenna transceivers. We consider three different time-division multiple-access-based cooperative protocols that vary the degree of broadcasting and receive collision. The relay terminal operates in either the amplify-and-forward (AF) or decode-and-forward (DF) modes. For each protocol, we study the ergodic and outage capacity behavior (assuming Gaussian code books) under the AF and DF modes of relaying. We analyze the spatial diversity performance of the various protocols and find that full spatial diversity (second-order in this case) is achieved by certain protocols provided that appropriate power control is employed. Our analysis unifies previous results reported in the literature and establishes the superiority (both from a capacity, as well as a diversity point-of-view) of a new protocol proposed in this paper. The second part of the paper is devoted to (distributed) space-time code design for fading relay channels operating in the AF mode. We show that the corresponding code design criteria consist of the traditional rank and determinant criteria for the case of colocated antennas, as well as appropriate power control rules. Consequently space-time codes designed for the case of colocated multiantenna. channels can be used to realize cooperative diversity provided that appropriate power control is employed.					Bolcskei, Helmut/B-3937-2011														0733-8716	1558-0008				AUG	2004	22	6					1099	1109		10.1109/JSAC.2004.830922	http://dx.doi.org/10.1109/JSAC.2004.830922													WOS:000223150700015
J	Li, CM; Xu, CY; Gui, CF; Fox, MD				Li, Chunming; Xu, Chenyang; Gui, Changfeng; Fox, Martin D.			Distance Regularized Level Set Evolution and Its Application to Image Segmentation	IEEE TRANSACTIONS ON IMAGE PROCESSING												Level set methods have been widely used in image processing and computer vision. In conventional level set formulations, the level set function typically develops irregularities during its evolution, which may cause numerical errors and eventually destroy the stability of the evolution. Therefore, a numerical remedy, called reinitialization, is typically applied to periodically replace the degraded level set function with a signed distance function. However, the practice of reinitialization not only raises serious problems as when and how it should be performed, but also affects numerical accuracy in an undesirable way. This paper proposes a new variational level set formulation in which the regularity of the level set function is intrinsically maintained during the level set evolution. The level set evolution is derived as the gradient flow that minimizes an energy functional with a distance regularization term and an external energy that drives the motion of the zero level set toward desired locations. The distance regularization term is defined with a potential function such that the derived level set evolution has a unique forward-and-backward (FAB) diffusion effect, which is able to maintain a desired shape of the level set function, particularly a signed distance profile near the zero level set. This yields a new type of level set evolution called distance regularized level set evolution (DRLSE). The distance regularization effect eliminates the need for reinitialization and thereby avoids its induced numerical errors. In contrast to complicated implementations of conventional level set formulations, a simpler and more efficient finite difference scheme can be used to implement the DRLSE formulation. DRLSE also allows the use of more general and efficient initialization of the level set function. In its numerical implementation, relatively large time steps can be used in the finite difference scheme to reduce the number of iterations, while ensuring sufficient numerical accuracy. To demonstrate the effectiveness of the DRLSE formulation, we apply it to an edge-based active contour model for image segmentation, and provide a simple narrowband implementation to greatly reduce computational cost.					Gui, Changfeng/JCE-6761-2023; Li, Chunming/AAC-1022-2020														1057-7149	1941-0042				DEC	2010	19	12					3243	3254		10.1109/TIP.2010.2069690	http://dx.doi.org/10.1109/TIP.2010.2069690								20801742					WOS:000284362400014
J	Lane, ND; Miluzzo, E; Lu, H; Peebles, D; Choudhury, T; Campbell, AT				Lane, Nicholas D.; Miluzzo, Emiliano; Lu, Hong; Peebles, Daniel; Choudhury, Tanzeem; Campbell, Andrew T.			A Survey of Mobile Phone Sensing	IEEE COMMUNICATIONS MAGAZINE												Mobile phones or smartphones are rapidly becoming the central computer and communication device in people's lives. Application delivery channels such as the Apple AppStore are transforming mobile phones into App Phones, capable of downloading a myriad of applications in an instant. Importantly, today's smartphones are programmable and come with a growing set of cheap powerful embedded sensors, such as an accelerometer, digital compass, gyroscope, GPS, microphone, and camera, which are enabling the emergence of personal, group, and community-scale sensing applications. We believe that sensor-equipped mobile phones will revolutionize many sectors of our economy, including business, healthcare, social networks, environmental monitoring, and transportation. In this article we survey existing mobile phone sensing algorithms, applications, and systems. We discuss the emerging sensing paradigms, and formulate an architectural framework for discussing a number of the open issues and challenges emerging in the new area of mobile phone sensing research.																			0163-6804	1558-1896				SEP	2010	48	9					140	150		10.1109/MCOM.2010.5560598	http://dx.doi.org/10.1109/MCOM.2010.5560598													WOS:000283240800017
J	Tzanetakis, G; Cook, P				Tzanetakis, G; Cook, P			Musical genre classification of audio signals	IEEE TRANSACTIONS ON SPEECH AND AUDIO PROCESSING												Musical genres are categorical labels created by humans to characterize pieces of music. A musical genre is characterized by the common characteristics shared by its members. These characteristics typically are related to the instrumentation, rhythmic structure, and harmonic content of the music. Genre hierarchies are commonly used to structure the large collections of music available on the Web. Currently musical genre annotation is performed manually. Automatic musical genre classification can assist or replace the human user in this process and would be a valuable addition to music information retrieval systems. In addition, automatic musical genre classification provides a framework for developing and evaluating features for any type of content-based analysis of musical signals. In this paper, the automatic classification of audio signals into an hierarchy of musical genres is explored. More specifically, three feature sets for representing timbral texture, rhythmic content and pitch content are proposed. The performance and relative importance of the proposed features is investigated by training statistical pattern recognition classifiers using real-world audio collections. Both whole file and real-time frame-based classification schemes are described. Using the proposed feature sets, classification of 61% for ten musical genres is achieved. This result is comparable to results reported for human musical genre classification.					Tzanetakis, George/I-6593-2013	Tzanetakis, George/0000-0002-6844-7912													1063-6676					JUL	2002	10	5					293	302		10.1109/TSA.2002.800560	http://dx.doi.org/10.1109/TSA.2002.800560													WOS:000177208900005
J	Gu, ZW; Cheng, J; Fu, HZ; Zhou, K; Hao, HY; Zhao, YT; Zhang, TY; Gao, SH; Liu, J				Gu, Zaiwang; Cheng, Jun; Fu, Huazhu; Zhou, Kang; Hao, Huaying; Zhao, Yitian; Zhang, Tianyang; Gao, Shenghua; Liu, Jiang			CE-Net: Context Encoder Network for 2D Medical Image Segmentation	IEEE TRANSACTIONS ON MEDICAL IMAGING												Medical image segmentation is an important step in medical image analysis. With the rapid development of a convolutional neural network in image processing, deep learning has been used for medical image segmentation, such as optic disc segmentation, blood vessel detection, lung segmentation, cell segmentation, and so on. Previously, U-net based approaches have been proposed. However, the consecutive pooling and strided convolutional operations led to the loss of some spatial information. In this paper, we propose a context encoder network (CE-Net) to capture more high-level information and preserve spatial information for 2D medical image segmentation. CE-Net mainly contains three major components: a feature encoder module, a context extractor, and a feature decoder module. We use the pretrained ResNet block as the fixed feature extractor. The context extractor module is formed by a newly proposed dense atrous convolution block and a residual multi-kernel pooling block. We applied the proposed CE-Net to different 2D medical image segmentation tasks. Comprehensive results show that the proposed method outperforms the original U-Net method and other state-of-the-art methods for optic disc segmentation, vessel detection, lung segmentation, cell contour segmentation, and retinal optical coherence tomography layer segmentation.					Gu, Zaiwang/AAT-8063-2020; Zhao, Yitian/AAM-4907-2021; LIU, JIANG/AHB-8921-2022; Cheng, Jun/E-7778-2016; Fu, Huazhu/A-1411-2014	Zhang, Tianyang/0000-0002-5833-7840; Zhou, Kang/0000-0001-8789-4243; Gu, Zaiwang/0000-0001-8764-0622; liu, jiang/0000-0001-6281-6505; Cheng, Jun/0000-0003-1786-6188; Fu, Huazhu/0000-0002-9702-5524													0278-0062	1558-254X				OCT	2019	38	10					2281	2292		10.1109/TMI.2019.2903562	http://dx.doi.org/10.1109/TMI.2019.2903562								30843824					WOS:000489784000004
J	Fu, MY; Xie, LH				Fu, MY; Xie, LH			The sector bound approach to quantized feedback control	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												This paper studies a number of quantized feedback design problems for linear systems. We consider the case where quantizers are static (memoryless). The common aim of these design problems is to stabilize the given system or to achieve certain performance with the coarsest quantization density. Our main discovery is that the classical sector bound approach is nonconservative for studying these design problems. Consequently, we are able to convert many quantized feedback design problems to well-known robust control problems with sector bound uncertainties. In particular, we derive the coarsest quantization densities for stabilization for multiple-input-multiple-output systems in both state feedback and output feedback cases; and we also derive conditions for quantized feedback control for quadratic cost and H-infinity performances.					Xie, Lihua/D-2236-2009	Fu, Minyue/0000-0002-4659-601X													0018-9286	1558-2523				NOV	2005	50	11					1698	1711		10.1109/TAC.2005.858689	http://dx.doi.org/10.1109/TAC.2005.858689													WOS:000233442700005
J	McCarty, PL; Bae, J; Kim, J				McCarty, Perry L.; Bae, Jaeho; Kim, Jeonghwan			Domestic Wastewater Treatment as a Net Energy Producer-Can This be Achieved?	ENVIRONMENTAL SCIENCE & TECHNOLOGY												In seeking greater sustainability in water resources management, wastewater is now being considered more as a resource than as a waste-a resource for water, for plant nutrients, and for energy. Energy, the primary focus of this article, can be obtained from wastewater's organic as well as from its thermal content. Also, using wastewater's nitrogen and P nutrients for plant fertilization, rather than wasting them, helps offset the high energy cost of producing synthetic fertilizers. Microbial fuel cells offer potential for direct biological conversion of wastewater's organic materials into electricity, although significant improvements are needed for this process to be competitive with anaerobic biological conversion of wastewater organics into biogas, a renewable fuel used in electricity generation. Newer membrane processes coupled with complete anaerobic treatment of wastewater offer the potential for wastewater treatment to become a net generator of energy, rather than the large energy consumer that it is today.					McCarty, Perry/H-1132-2011	McCarty, Perry/0000-0002-7031-0106													0013-936X	1520-5851				SEP 1	2011	45	17					7100	7106		10.1021/es2014264	http://dx.doi.org/10.1021/es2014264								21749111					WOS:000294373400002
J	Abbasi, AA; Younis, M				Abbasi, Ameer Ahmed; Younis, Mohamed			A survey on clustering algorithms for wireless sensor networks	COMPUTER COMMUNICATIONS												The past few years have witnessed increased interest in the potential use of wireless sensor networks (WSNs) in applications such as disaster management, combat field reconnaissance, border protection and security surveillance. Sensors in these applications are expected to be remotely deployed in large numbers and to operate autonomously in unattended environments. To support scalability, nodes are often grouped into disjoint and mostly non-overlapping clusters. In this paper, we present a taxonomy and general classification of published clustering schemes. We survey different clustering algorithms for WSNs; highlighting their objectives, features, complexity, etc. We also compare of these clustering algorithms based on metrics such as convergence rate, cluster stability, cluster overlapping, location-awareness and support for node mobility. (C) 2007 Published by Elsevier B.V.					Younis, Mohamed/ADC-2368-2022	Younis, Mohamed/0000-0003-3865-9217													0140-3664	1873-703X				OCT 15	2007	30	14-15					2826	2841		10.1016/j.comcom.2007.05.024	http://dx.doi.org/10.1016/j.comcom.2007.05.024													WOS:000250747000013
J	Benotti, MJ; Trenholm, RA; Vanderford, BJ; Holady, JC; Stanford, BD; Snyder, SA				Benotti, Mark J.; Trenholm, Rebecca A.; Vanderford, Brett J.; Holady, Janie C.; Stanford, Benjamin D.; Snyder, Shane A.			Pharmaceuticals and Endocrine Disrupting Compounds in US Drinking Water	ENVIRONMENTAL SCIENCE & TECHNOLOGY												The drinking water for more than 28 million people was screened for a diverse group of pharmaceuticals, potential endocrine disrupting compounds (EDCs), and other unregulated organic contaminants. Source water, finished drinking water, and distribution system (tap) water from 19 U.S. water utilities was analyzed for 51 compounds between 2006 and 2007. The 11 most frequently detected compounds were atenolol, atrazine, carbamazepine, estrone, gemfibrozil, meprobamate, naproxen, phenytoin, sulfamethoxazole, TCEP, and trimethoprim. Median concentrations of these compounds were less than 10 ng/L, except for sulfamethoxazole in source water (12 ng/L), TCEP in source water (120 ng/L), and atrazine in source, finished, and distribution system water (32, 49, and 49 ng/L). Atrazine was detected in source waters far removed from agricultural application where wastewater was the only known source of organic contaminants. The occurrence of compounds in finished drinking water was controlled by the type of chemical oxidation (ozone or chlorine) used at each plant. At one drinking water treatment plant, summed monthly concentrations of the detected analytes in source and finished water are reported. Atenolol, atrazine, DEET, estrone, meprobamate, and trimethoprim can serve as indicator compounds representing potential contamination from other pharmaceuticals and EDCs and can gauge the efficacy of treatment processes.					Stanford, Benjamin/F-2615-2010; Snyder, Shane/AAE-8252-2021; Snyder, Shane/A-3302-2011	Stanford, Benjamin/0000-0002-3486-3432; Snyder, Shane/0000-0003-2709-9840													0013-936X	1520-5851				FEB 1	2009	43	3					597	603		10.1021/es801845a	http://dx.doi.org/10.1021/es801845a								19244989					WOS:000262926400015
J	Echard, B; Gayton, N; Lemaire, M				Echard, B.; Gayton, N.; Lemaire, M.			AK-MCS: An active learning reliability method combining Kriging and Monte Carlo Simulation	STRUCTURAL SAFETY												An important challenge in structural reliability is to keep to a minimum the number of calls to the numerical models. Engineering problems involve more and more complex computer codes and the evaluation of the probability of failure may require very time-consuming computations. Metamodels are used to reduce these computation times. To assess reliability, the most popular approach remains the numerous variants of response surfaces. Polynomial Chaos [1] and Support Vector Machine [2] are also possibilities and have gained considerations among researchers in the last decades. However, recently, Kriging, originated from geostatistics, have emerged in reliability analysis. Widespread in optimisation, Kriging has just started to appear in uncertainty propagation [3] and reliability [4,5] studies. It presents interesting characteristics such as exact interpolation and a local index of uncertainty on the prediction which can be used in active learning methods. The aim of this paper is to propose an iterative approach based on Monte Carlo Simulation and Kriging metamodel to assess the reliability of structures in a more efficient way. The method is called AK-MCS for Active learning reliability method combining Kriging and Monte Carlo Simulation. It is shown to be very efficient as the probability of failure obtained with AK-MCS is very accurate and this, for only a small number of calls to the performance function. Several examples from literature are performed to illustrate the methodology and to prove its efficiency particularly for problems dealing with high non-linearity, non-differentiability, non-convex and non-connex domains of failure and high dimensionality. (C) 2011 Elsevier Ltd. All rights reserved.																			0167-4730						2011	33	2					145	154		10.1016/j.strusafe.2011.01.002	http://dx.doi.org/10.1016/j.strusafe.2011.01.002													WOS:000290355800003
J	Krasner, SW; Weinberg, HS; Richardson, SD; Pastor, SJ; Chinn, R; Sclimenti, MJ; Onstad, GD; Thruston, AD				Krasner, Stuart W.; Weinberg, Howard S.; Richardson, Susan D.; Pastor, Salvador J.; Chinn, Russell; Sclimenti, Michael J.; Onstad, Gretchen D.; Thruston, Alfred D., Jr.			Occurrence of a new generation of disinfection byproducts	ENVIRONMENTAL SCIENCE & TECHNOLOGY												A survey of disinfection byproduct (DBP) occurrence in the United States was conducted at 12 drinking water treatment plants. In addition to currently regulated DBPs, more than 50 DBPs that rated a high priority for potential toxicity were studied. These priority DBPs included iodinated trihalomethanes (THMs), other halomethanes, a nonregulated haloacid, haloacetonitriles, haloketones, halonitromethanes, haloaldehydes, halogenated furanones, haloamides, and nonhalogenated carbonyls. The purpose of this study was to obtain quantitative occurrence information for new DBPs (beyond those currently regulated and/or studied) for prioritizing future health effects studies. An effort was made to select plants treating water that was high in total organic carbon and/or bromide to enable the detection of priority DBPs that contained bromine and/or iodine. THMs and haloacetic acids (HAAs) represented the two major classes of halogenated DBPs formed on a weight basis. Haloacetaldehydes represented the third major class formed in many of the waters. In addition to obtaining quantitative occurrence data, important new information was discovered or confirmed at full-scale plants on the formation and control of DBPs with alternative disinfectants to chlorine. Although the use of alternative disinfectants (ozone, chlorine dioxide, and chloramines) minimized the formation of the four regulated THMs, trihalogenated HAAs, and total organic halogen (TOX), several priority DBPs were formed at higher levels with the alternative disinfectants as compared with chlorine. For example, the highest levels of iodinated THMs-which are not part of the four regulated THMs-were found at a plant that used chloramination with no prechlorination. The highest concentration of dichloroacetaldehyde was at a plant that used chloramines and ozone; however, this disinfection scheme reduced the formation of trichloroacetaldehyde. Preozonation was found to increase the formation of trihalonitromethanes. In addition to the chlorinated furanones that have been measured previously, brominated furanones-which have seldom been analyzed- were detected, especially in high-bromide waters. The presence of bromide resulted in a shift to the formation of other bromine-containing DBPs not normally measured (e.g., brominated ketones, acetaldehydes, nitromethanes, acetamides). Collectively, similar to 30 and 39% of the TOX and total organic bromine, respectively, were accounted for (on a median basis) by the sum of the measured halogenated DBPs. In addition, 28 new, previously unidentified DBPs were detected. These included brominated and iodinated haloacids, a brominated ketone, and chlorinated and iodinated aldehydes.																			0013-936X	1520-5851				DEC 1	2006	40	23					7175	7185		10.1021/es060353j	http://dx.doi.org/10.1021/es060353j								17180964					WOS:000242367100017
J	Hensher, DA; Greene, WH				Hensher, DA; Greene, WH			The Mixed Logit model: The state of practice	TRANSPORTATION												The mixed logit model is considered to be the most promising state of the art discrete choice model currently available. Increasingly researchers and practitioners are estimating mixed logit models of various degrees of sophistication with mixtures of revealed preference and stated choice data. It is timely to review progress in model estimation since the learning curve is steep and the unwary are likely to fall into a chasm if not careful. These chasms are very deep indeed given the complexity of the mixed logit model. Although the theory is relatively clear, estimation and data issues are far from clear. Indeed there is a great deal of potential mis-inference consequent on trying to extract increased behavioural realism from data that are often not able to comply with the demands of mixed logit models. Possibly for the first time we now have an estimation method that requires extremely high quality data if the analyst wishes to take advantage of the extended behavioural capabilities of such models. This paper focuses on the new opportunities offered by mixed logit models and some issues to be aware of to avoid misuse of such advanced discrete choice methods by the practitioner.					Hensher, David/C-4145-2011	Hensher, David/0000-0003-0058-2242													0049-4488	1572-9435				MAY	2003	30	2					133	176		10.1023/A:1022558715350	http://dx.doi.org/10.1023/A:1022558715350													WOS:000181088100003
J	Park, HS; Jun, CH				Park, Hae-Sang; Jun, Chi-Hyuck			A simple and fast algorithm for K-medoids clustering	EXPERT SYSTEMS WITH APPLICATIONS												This paper proposes a new algorithm for K-medoids clustering which runs like the K-means algorithm and tests several methods for selecting initial medoids. The proposed algorithm calculates the distance matrix once and uses it for finding new medoids at every iterative step. To evaluate the proposed algorithm, we use some real and artificial data sets and compare with the results of other algorithms in terms of the adjusted Rand index. Experimental results show that the proposed algorithm takes a significantly reduced time ill computation with comparable performance against the partitioning around medoids. (C) 2008 Elsevier Ltd. All rights reserved.					Jun, Chi-Hyuck/AAE-1695-2019														0957-4174	1873-6793				MAR	2009	36	2	2				3336	3341		10.1016/j.eswa.2008.01.039	http://dx.doi.org/10.1016/j.eswa.2008.01.039													WOS:000262178100077
J	Cortés, P; Kazmierkowski, MP; Kennel, RM; Quevedo, DE; Rodríguez, J				Cortes, Patricio; Kazmierkowski, Marian P.; Kennel, Ralph M.; Quevedo, Daniel E.; Rodriguez, Jose			Predictive Control in Power Electronics and Drives	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS												Predictive control is a very wide class of controllers that have found rather recent application in the control of power converters. Research on this topic has been increased in the last years due to the possibilities of today's microprocessors used for the control. This paper presents the application of different predictive control methods to power electronics and drives. A simple classification of the most important types of predictive control is introduced, and each one of them is explained including some application examples. Predictive control presents several advantages that make it suitable for the control of power converters and drives. The different control schemes and applications presented in this paper illustrate the effectiveness and flexibility of predictive control.					Kazmierkowski, Marian/K-6558-2018; Quevedo, Daniel E./A-8454-2008; Rodriguez, Jose/A-2534-2013	Quevedo, Daniel E./0000-0002-4804-5481; Rodriguez, Jose/0000-0002-1410-4121													0278-0046	1557-9948				DEC	2008	55	12					4312	4324		10.1109/TIE.2008.2007480	http://dx.doi.org/10.1109/TIE.2008.2007480													WOS:000261616700021
J	Lee, KS; Geem, ZW				Lee, KS; Geem, ZW			A new meta-heuristic algorithm for continuous engineering optimization: harmony search theory and practice	COMPUTER METHODS IN APPLIED MECHANICS AND ENGINEERING												Most engineering optimization algorithms are based on numerical linear and nonlinear programming methods that require substantial gradient information and usually seek to improve the solution in the neighborhood of a starting point. These algorithms, however, reveal a limited approach to complicated real-world optimization problems. If there is more than one local optimum in the problem, the result may depend on the selection of an initial point, and the obtained optimal solution may not necessarily be the global optimum. This paper describes a new harmony search (HS) meta-heuristic algorithm-based approach for engineering optimization problems with continuous design variables. This recently developed HS algorithm is conceptualized using the musical process of searching for a perfect state of harmony. It uses a stochastic random search instead of a gradient search so that derivative information is unnecessary. Various engineering optimization problems, including mathematical function minimization and structural engineering optimization problems, are presented to demonstrate the effectiveness and robustness of the HS algorithm. The results indicate that the proposed approach is a powerful search and optimization technique that may yield better solutions to engineering problems than those obtained using current algorithms. (c) 2004 Elsevier B.V. All rights reserved.					Geem, Zong Woo/A-2718-2008	Geem, Zong Woo/0000-0002-0370-5562													0045-7825	1879-2138					2005	194	36-38					3902	3933		10.1016/j.cma.2004.09.007	http://dx.doi.org/10.1016/j.cma.2004.09.007													WOS:000230191000007
J	Cho, SK; Moon, HJ; Kim, CJ				Cho, SK; Moon, HJ; Kim, CJ			Creating, transporting, cutting, and merging liquid droplets by electrowetting-based actuation for digital microfluidic circuits	JOURNAL OF MICROELECTROMECHANICAL SYSTEMS												This paper reports the completion of four fundamental fluidic operations considered essential to build digital microfluidic circuits, which can be used for lab-on-a-chip or micro total analysis system (muTAS): 1) creating, 2) transporting, 3) cutting, and 4) merging liquid droplets, all by electrowetting, i.e., controlling the wetting property of the surface through electric potential. The surface used in this report is, more specifically, an electrode covered with dielectrics, hence, called electrowetting-on-dielectric (EWOD). All the fluidic movement is confined between two plates, which we call parallel-plate channel, rather than through closed channels or on open surfaces. While transporting and merging droplets are easily verified, we discover that there exists a design criterion for a given set of materials beyond which the droplet simply cannot be cut by EWOD mechanism. The condition for successful cutting is theoretically analyzed by examining the channel gap, the droplet size and the degree of contact angle change by electrowetting on dielectric (EWOD). A series of experiments is run and verifies the criterion. A smaller channel gap, a larger droplet size and a larger change in the contact angle enhance the necking of the droplet, helping the completion of the cutting process. Creating droplets from a pool of liquid is highly related to cutting, but much more challenging. Although droplets may be created by simply pulling liquid out of a reservoir, the location of cutting is sensitive to initial conditions and turns out unpredictable. This problem of an inconsistent cutting location is overcome by introducing side electrodes, which pull the liquid perpendicularly to the main fluid path before activating the cutting. All four operations are carried out in air environment at 25 V-dc applied voltage.					Kim, Chang-Jin/F-6730-2011	Moon, Hyejin/0000-0002-8904-2009; Kim, Chang-Jin "CJ"/0000-0002-4600-9962													1057-7157	1941-0158				FEB	2003	12	1					70	80		10.1109/JMEMS.2002.807467	http://dx.doi.org/10.1109/JMEMS.2002.807467													WOS:000181346200009
J	Bai, YL; Wierzbicki, T				Bai, Yuanli; Wierzbicki, Tomasz			A new model of metal plasticity and fracture with pressure and Lode dependence	INTERNATIONAL JOURNAL OF PLASTICITY												Classical metal plasticity theory assumes that the hydrostatic pressure has no or negligible effect on the material strain hardening, and that the flow stress is independent of the third deviatoric stress invariant (or Lode angle parameter). However, recent experiments on metals have shown that both the pressure effect and the effect of the third deviatoric stress invariant should be included in the constitutive description of the material. A general form of asymmetric metal plasticity, considering both the pressure sensitivity and the Lode dependence, is postulated. The calibration method for the new metal plasticity is discussed. Experimental results on aluminum 2024-T351 are shown to validate the new material model. From the similarity between yielding surface and fracture locus, a new 3D asymmetric fracture locus, in the space of equivalent fracture strain, stress triaxiality and the Lode angle parameter, is postulated. Two methods of calibration of the fracture locus are discussed. One is based oil classical round specimens and flat specimens in uniaxial tests, and the other one uses the newly designed butterfly specimen under biaxial testing. Test results of Bao (2003) [Bao, Y., 2003. Prediction of ductile crack formation in uncracked bodies. PhD Thesis, Massachusetts Institute of Technology] on aluminum 2024-T351, and test data points of A710 steel from butterfly specimens under biaxial testing validated the postulated asymmetric 3D fracture locus. (c) 2007 Elsevier Ltd. All rights reserved.																			0749-6419	1879-2154					2008	24	6					1071	1096		10.1016/j.ijplas.2007.09.004	http://dx.doi.org/10.1016/j.ijplas.2007.09.004													WOS:000255431800007
J	Azpiroz, JM; Mosconi, E; Bisquert, J; De Angelis, F				Azpiroz, Jon M.; Mosconi, Edoardo; Bisquert, Juan; De Angelis, Filippo			Defect migration in methylammonium lead iodide and its role in perovskite solar cell operation	ENERGY & ENVIRONMENTAL SCIENCE												In spite of the unprecedented advance of organohalide lead perovskites in the photovoltaics scenario, many of the characteristics of this class of materials, including their slow photoconductivity response, solar cell hysteresis, and switchable photocurrent, remain poorly understood. Many experimental hints point to defect migration as a plausible mechanism underlying these anomalous properties. By means of state-of-the-art first-principles computational analyses carried out on the tetragonal MAPbI(3) (MA = methylammonium) perovskite and on its interface with TiO2, we demonstrate that iodine vacancies and interstitials may easily diffuse across the perovskite crystal, with migration activation energies as low as similar to 0.1 eV. Under working conditions, iodine-related defects are predicted to migrate at the electrodes on very short time scales (<1 mu s). MA and Pb vacancies, with calculated activation barriers of similar to 0.5 and 0.8 eV, respectively, could be responsible for the slow response inherent to perovskites, with typical calculated migration times of the order of tens of ms to minutes. By investigating realistic models of the perovskite/TiO2 interface we show that negatively charged defects, e.g. MA vacancies, close to the electron transport layer (TiO2 in our case) modify the perovskite electronic state landscape, hampering charge extraction at selective contacts, thus possibly contributing to the observed solar cell hysteresis. We further demonstrate the role of the electron transport layer in affecting the initial concentration of defects close to the selective contacts, highlighting how charge separation at the perovskite/TiO2 interface may further change the defect distribution. We believe that this work, identifying the mobile species in perovskite solar cells, their migration across the perovskite material, and their effect on the operational mechanism of the device, may pave the way for the development of new materials and solar cell architectures with improved and stabilized efficiencies.					De Angelis, Filippo/N-4341-2015; Mosconi, Edoardo/F-5469-2016; Bisquert, Juan/O-2543-2013	Mosconi, Edoardo/0000-0001-5075-6664; Bisquert, Juan/0000-0003-4987-4887													1754-5692	1754-5706					2015	8	7					2118	2127		10.1039/c5ee01265a	http://dx.doi.org/10.1039/c5ee01265a													WOS:000357541300023
J	Suss, ME; Porada, S; Sun, X; Biesheuvel, PM; Yoon, J; Presser, V				Suss, M. E.; Porada, S.; Sun, X.; Biesheuvel, P. M.; Yoon, J.; Presser, V.			Water desalination <i>via</i> capacitive deionization: what is it and what can we expect from it?	ENERGY & ENVIRONMENTAL SCIENCE												Capacitive deionization (CDI) is an emerging technology for the facile removal of charged ionic species from aqueous solutions, and is currently being widely explored for water desalination applications. The technology is based on ion electrosorption at the surface of a pair of electrically charged electrodes, commonly composed of highly porous carbon materials. The CDI community has grown exponentially over the past decade, driving tremendous advances via new cell architectures and system designs, the implementation of ion exchange membranes, and alternative concepts such as flowable carbon electrodes and hybrid systems employing a Faradaic (battery) electrode. Also, vast improvements have been made towards unraveling the complex processes inherent to interfacial electrochemistry, including the modelling of kinetic and equilibrium aspects of the desalination process. In our perspective, we critically review and evaluate the current state-of-the-art of CDI technology and provide definitions and performance metric nomenclature in an effort to unify the fast-growing CDI community. We also provide an outlook on the emerging trends in CDI and propose future research and development directions.					Presser, Volker/F-1975-2010; Porada, Slawomir/X-9405-2019; Biesheuvel, Maarten/J-5842-2012	Biesheuvel, Maarten/0000-0002-5468-559X; Suss, Matthew/0000-0002-3813-2274													1754-5692	1754-5706					2015	8	8					2296	2319		10.1039/c5ee00519a	http://dx.doi.org/10.1039/c5ee00519a													WOS:000358730600005
J	Carslaw, DC; Ropkins, K				Carslaw, David C.; Ropkins, Karl			<i>openair</i> - An R package for air quality data analysis	ENVIRONMENTAL MODELLING & SOFTWARE												openair is an R package primarily developed for the analysis of air pollution measurement data but which is also of more general use in the atmospheric sciences. The package consists of many tools for importing and manipulating data, and undertaking a wide range of analyses to enhance understanding of air pollution data. In this paper we consider the development of the package with the purpose of showing how air pollution data can be analysed in more insightful ways. Examples are provided of importing data from UK air pollution networks, source identification and characterisation using bivariate polar plots, quantitative trend estimates and the use of functions for model evaluation purposes. We demonstrate how air pollution data can be analysed quickly and efficiently and in an interactive way, freeing time to consider the problem at hand. One of the central themes of openair is the use of conditioning plots and analyses, which greatly enhance inference possibilities. Finally, some consideration is given to future developments. (C) 2011 Elsevier Ltd. All rights reserved.					Carslaw, David/S-1146-2019	Carslaw, David/0000-0003-0991-950X; Ropkins, Karl/0000-0002-0294-6997													1364-8152	1873-6726				JAN-FEB	2012	27-28						52	61		10.1016/j.envsoft.2011.09.008	http://dx.doi.org/10.1016/j.envsoft.2011.09.008													WOS:000298457000005
J	Menne, MJ; Durre, I; Vose, RS; Gleason, BE; Houston, TG				Menne, Matthew J.; Durre, Imke; Vose, Russell S.; Gleason, Byron E.; Houston, Tamara G.			An Overview of the Global Historical Climatology Network-Daily Database	JOURNAL OF ATMOSPHERIC AND OCEANIC TECHNOLOGY												A database is described that has been designed to fulfill the need for daily climate data over global land areas. The dataset, known as Global Historical Climatology Network (GHCN)-Daily, was developed for a wide variety of potential applications, including climate analysis and monitoring studies that require data at a daily time resolution (e.g., assessments of the frequency of heavy rainfall, heat wave duration, etc.). The dataset contains records from over 80 000 stations in 180 countries and territories, and its processing system produces the official archive for U.S. daily data. Variables commonly include maximum and minimum temperature, total daily precipitation, snowfall, and snow depth; however, about two-thirds of the stations report precipitation only. Quality assurance checks are routinely applied to the full dataset, but the data are not homogenized to account for artifacts associated with the various eras in reporting practice at any particular station (i.e., for changes in systematic bias). Daily updates are provided for many of the station records in GHCN-Daily. The dataset is also regularly reconstructed, usually once per week, from its 20+ data source components, ensuring that the dataset is broadly synchronized with its growing list of constituent sources. The daily updates and weekly reprocessed versions of GHCN-Daily are assigned a unique version number, and the most recent dataset version is provided on the GHCN-Daily website for free public access. Each version of the dataset is also archived at the NOAA/National Climatic Data Center in perpetuity for future retrieval.					Vose, Russell/GSI-5687-2022; Durre, Imke/AAU-8600-2020														0739-0572	1520-0426				JUL	2012	29	7					897	910		10.1175/JTECH-D-11-00103.1	http://dx.doi.org/10.1175/JTECH-D-11-00103.1													WOS:000306717400002
J	Shi, QJ; Razaviyayn, M; Luo, ZQ; He, C				Shi, Qingjiang; Razaviyayn, Meisam; Luo, Zhi-Quan; He, Chen			An Iteratively Weighted MMSE Approach to Distributed Sum-Utility Maximization for a MIMO Interfering Broadcast Channel	IEEE TRANSACTIONS ON SIGNAL PROCESSING												Consider the multiple-input multiple-output (MIMO) interfering broadcast channel whereby multiple base stations in a cellular network simultaneously transmit signals to a group of users in their own cells while causing interference to each other. The basic problem is to design linear beamformers that can maximize the system throughput. In this paper, we propose a linear transceiver design algorithm for weighted sum-rate maximization that is based on iterative minimization of weighted mean-square error (MSE). The proposed algorithm only needs local channel knowledge and converges to a stationary point of the weighted sumrate maximization problem. Furthermore, the algorithm and its convergence can be extended to a general class of sum-utility maximization problem. The effectiveness of the proposed algorithm is validated by numerical experiments.					He, Chen/JLM-5059-2023														1053-587X	1941-0476				SEP	2011	59	9					4331	4340		10.1109/TSP.2011.2147784	http://dx.doi.org/10.1109/TSP.2011.2147784													WOS:000293757300019
J	Borji, A; Itti, L				Borji, Ali; Itti, Laurent			State-of-the-Art in Visual Attention Modeling	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Modeling visual attention-particularly stimulus-driven, saliency-based attention-has been a very active research area over the past 25 years. Many different models of attention are now available which, aside from lending theoretical contributions to other fields, have demonstrated successful applications in computer vision, mobile robotics, and cognitive systems. Here we review, from a computational perspective, the basic concepts of attention implemented in these models. We present a taxonomy of nearly 65 models, which provides a critical comparison of approaches, their capabilities, and shortcomings. In particular, 13 criteria derived from behavioral and computational studies are formulated for qualitative comparison of attention models. Furthermore, we address several challenging issues with models, including biological plausibility of the computations, correlation with eye movement datasets, bottom-up and top-down dissociation, and constructing meaningful performance measures. Finally, we highlight current research trends in attention modeling and provide insights for future.																			0162-8828	1939-3539				JAN	2013	35	1					185	207		10.1109/TPAMI.2012.89	http://dx.doi.org/10.1109/TPAMI.2012.89								22487985					WOS:000311127700017
J	Yang, SY; Bryant, A; Mawby, P; Xiang, DW; Ran, L; Tavner, P				Yang, Shaoyong; Bryant, Angus; Mawby, Philip; Xiang, Dawei; Ran, Li; Tavner, Peter			An Industry-Based Survey of Reliability in Power Electronic Converters	IEEE TRANSACTIONS ON INDUSTRY APPLICATIONS												A questionnaire survey was carried out to determine the industrial requirements and expectations of reliability in power electronic converters. The survey was subjective and conducted with a number of high-profile semiconductor manufacturers, integrators, and users in the aerospace, automation, motor drive, utility power, and other industry sectors. According to the survey, power semiconductor devices ranked the most fragile components. It was concluded that main stresses were from the environment, transients, and heavy loads, which should be considered during power electronic system design and normal operation. This paper has also highlighted that there is a significant need identified by the responders for better reliability-monitoring methods and indicators.																			0093-9994	1939-9367				MAY-JUN	2011	47	3					1441	1451		10.1109/TIA.2011.2124436	http://dx.doi.org/10.1109/TIA.2011.2124436													WOS:000290733800043
J	Mohsenian-Rad, AH; Leon-Garcia, A				Mohsenian-Rad, Amir-Hamed; Leon-Garcia, Alberto			Optimal Residential Load Control With Price Prediction in Real-Time Electricity Pricing Environments	IEEE TRANSACTIONS ON SMART GRID												Real-time electricity pricing models can potentially lead to economic and environmental advantages compared to the current common flat rates. In particular, they can provide end users with the opportunity to reduce their electricity expenditures by responding to pricing that varies with different times of the day. However, recent studies have revealed that the lack of knowledge among users about how to respond to time-varying prices as well as the lack of effective building automation systems are two major barriers for fully utilizing the potential benefits of real-time pricing tariffs. We tackle these problems by proposing an optimal and automatic residential energy consumption scheduling framework which attempts to achieve a desired trade-off between minimizing the electricity payment and minimizing the waiting time for the operation of each appliance in household in presence of a real-time pricing tariff combined with inclining block rates. Our design requires minimum effort from the users and is based on simple linear programming computations. Moreover, we argue that any residential load control strategy in real-time electricity pricing environments requires price prediction capabilities. This is particularly true if the utility companies provide price information only one or two hours ahead of time. By applying a simple and efficient weighted average price prediction filter to the actual hourly-based price values used by the Illinois Power Company from January 2007 to December 2009, we obtain the optimal choices of the coefficients for each day of the week to be used by the price predictor filter. Simulation results show that the combination of the proposed energy consumption scheduling design and the price predictor filter leads to significant reduction not only in users' payments but also in the resulting peak-to-average ratio in load demand for various load scenarios. Therefore, the deployment of the proposed optimal energy consumption scheduling schemes is beneficial for both end users and utility companies.																			1949-3053	1949-3061				SEP	2010	1	2					120	133		10.1109/TSG.2010.2055903	http://dx.doi.org/10.1109/TSG.2010.2055903													WOS:000208787200002
J	Seabaugh, AC; Zhang, Q				Seabaugh, Alan C.; Zhang, Qin			Low-Voltage Tunnel Transistors for Beyond CMOS Logic	PROCEEDINGS OF THE IEEE												Steep subthreshold swing transistors based on interband tunneling are examined toward extending the performance of electronics systems. In particular, this review introduces and summarizes progress in the development of the tunnel field-effect transistors (TFETs) including its origin, current experimental and theoretical performance relative to the metal-oxide-semiconductor field-effect transistor (MOSFET), basic current-transport theory, design tradeoffs, and fundamental challenges. The promise of the TFET is in its ability to provide higher drive current than the MOSFET as supply voltages approach 0.1 V.					Seabaugh, Alan/I-4473-2012	Seabaugh, Alan/0000-0001-6907-4129													0018-9219	1558-2256				DEC	2010	98	12					2095	2110		10.1109/JPROC.2010.2070470	http://dx.doi.org/10.1109/JPROC.2010.2070470													WOS:000284410800010
J	Sisinni, E; Saifullah, A; Han, S; Jennehag, U; Gidlund, M				Sisinni, Emiliano; Saifullah, Abusayeed; Han, Song; Jennehag, Ulf; Gidlund, Mikael			Industrial Internet of Things: Challenges, Opportunities, and Directions	IEEE TRANSACTIONS ON INDUSTRIAL INFORMATICS												Internet of Things (IoT) is an emerging domain that promises ubiquitous connection to the Internet, turning common objects into connected devices. The IoT paradigm is changing the way people interact with things around them. It paves the way for creating pervasively connected infrastructures to support innovative services and promises better flexibility and efficiency. Such advantages are attractive not only for consumer applications, but also for the industrial domain. Over the last few years, we have been witnessing the IoT paradigm making its way into the industry marketplace with purposely designed solutions. In this paper, we clarify the concepts of IoT, Industrial IoT, and Industry 4.0. We highlight the opportunities brought in by this paradigm shift as well as the challenges for its realization. In particular, we focus on the challenges associated with the need of energy efficiency, real-time performance, coexistence, interoperability, and security and privacy. We also provide a systematic overview of the state-of-the-art research efforts and potential research directions to solve Industrial IoT challenges.					Sisinni, Emiliano/M-1500-2019; Gidlund, Mikael/L-7643-2018; SISINNI, Emiliano/G-5208-2010	Gidlund, Mikael/0000-0003-0873-7827; SISINNI, Emiliano/0000-0001-5012-443X; Jennehag, Ulf/0000-0002-5999-5976; Han, Song/0000-0002-1491-7675													1551-3203	1941-0050				NOV	2018	14	11					4724	4734		10.1109/TII.2018.2852491	http://dx.doi.org/10.1109/TII.2018.2852491													WOS:000450168500001
J	Kang, GD; Cao, YM				Kang, Guo-dong; Cao, Yi-ming			Application and modification of poly(vinylidene fluoride) (PVDF) membranes - A review	JOURNAL OF MEMBRANE SCIENCE												Poly(vinylidene fluoride) (PVDF) membranes have been extensively applied to scientific research and industrial process due to its outstanding properties such as high thermal stability, good chemical resistance and membrane forming properties. This article provides an overview of recent progress On the application and modification of PVDF membranes. The applications include water treatment, membrane distillation, gas separation, pollutants removal, bioethanol recovery, separator for lithium ion battery, support for preparing composite membranes, etc. Subsequently, On the basis of two major problems of PVDF membranes in applications, i.e., membrane fouling and membrane wetting, the hydrophilic modification and hydrophobic modification methods are comprehensively reviewed. Finally, the key issues associated with the modification of PVDF membranes for actual applications are discussed. This paper may provide an insight for the development of PVDF membranes in future. (C) 2014 Elsevier B.V. All rights reserved.					kang, guodong/E-1548-2011; Cao, Yiming/D-3541-2013														0376-7388	1873-3123				AUG 1	2014	463						145	165		10.1016/j.memsci.2014.03.055	http://dx.doi.org/10.1016/j.memsci.2014.03.055													WOS:000335508700017
J	Leveson, N				Leveson, N			A new accident model for engineering safer systems	SAFETY SCIENCE												New technology is making fundamental changes in the etiology of accidents and is creating a need for changes in the explanatory mechanisms used. We need better and less subjective understanding of why accidents occur and how to prevent future ones. The most effective models will go beyond assigning blame and instead help engineers to learn as much as possible about all the factors involved, including those related to social and organizational structures. This paper presents a new accident model founded on basic systems theory concepts. The use of such a model provides a theoretical foundation for the introduction of unique new types of accident analysis, hazard analysis, accident prevention strategies including new approaches to designing for safety, risk assessment techniques, and approaches to designing performance monitoring and safety metrics. (C) 2003 Elsevier Ltd. All rights reserved.																			0925-7535	1879-1042				APR	2004	42	4					237	270		10.1016/S0925-7535(03)00047-X	http://dx.doi.org/10.1016/S0925-7535(03)00047-X													WOS:000220498400001
J	Mo, JH; Walrand, J				Mo, JH; Walrand, J			Fair end-to-end window-based congestion control	IEEE-ACM TRANSACTIONS ON NETWORKING												In this paper, we demonstrate the existence of fair end-to-end window-based congestion control protocols for packet-switched networks with first come-first served routers. Our definition of fairness generalizes proportional fairness and includes arbitrarily close approximations of mac-min fairness. The protocols use only information that is available to end hosts and are designed to converge reasonably fast. Our study is based on a multiclass fluid model of the network. The convergence of the protocols is proved using a Lyapunov function. The technical challenge is in the practical implementation of the protocols.					Mo, Jeonghoon/G-8142-2012														1063-6692	1558-2566				OCT	2000	8	5					556	567		10.1109/90.879343	http://dx.doi.org/10.1109/90.879343													WOS:000089953900002
J	Medhat, W; Hassan, A; Korashy, H				Medhat, Walaa; Hassan, Ahmed; Korashy, Hoda			Sentiment analysis algorithms and applications: A survey	AIN SHAMS ENGINEERING JOURNAL												Sentiment Analysis (SA) is an ongoing field of research in text mining field. SA is the computational treatment of opinions, sentiments and subjectivity of text. This survey paper tackles a comprehensive overview of the last update in this field. Many recently proposed algorithms' enhancements and various SA applications are investigated and presented briefly in this survey. These articles are categorized according to their contributions in the various SA techniques. The related fields to SA (transfer learning, emotion detection, and building resources) that attracted researchers recently are discussed. The main target of this survey is to give nearly full image of SA techniques and the related fields with brief details. The main contributions of this paper include the sophisticated categorizations of a large number of recent articles and the illustration of the recent trend of research in the sentiment analysis and its related areas. (C) 2014 Production and hosting by Elsevier B.V.					Hassan, Ahmed/AAB-7241-2019	Medhat, walaa/0000-0001-9482-8412													2090-4479	2090-4495				DEC	2014	5	4					1093	1113		10.1016/j.asej.2014.04.011	http://dx.doi.org/10.1016/j.asej.2014.04.011													WOS:000216227900008
J	Moorthy, AK; Bovik, AC				Moorthy, Anush Krishna; Bovik, Alan Conrad			Blind Image Quality Assessment: From Natural Scene Statistics to Perceptual Quality	IEEE TRANSACTIONS ON IMAGE PROCESSING												Our approach to blind image quality assessment (IQA) is based on the hypothesis that natural scenes possess certain statistical properties which are altered in the presence of distortion, rendering them un-natural; and that by characterizing this un-naturalness using scene statistics, one can identify the distortion afflicting the image and perform no-reference (NR) IQA. Based on this theory, we propose an (NR)/blind algorithm-the Distortion Identification-based Image Verity and INtegrity Evaluation (DIIVINE) index-that assesses the quality of a distorted image without need for a reference image. DIIVINE is based on a 2-stage framework involving distortion identification followed by distortion-specific quality assessment. DIIVINE is capable of assessing the quality of a distorted image across multiple distortion categories, as against most NR IQA algorithms that are distortion-specific in nature. DIIVINE is based on natural scene statistics which govern the behavior of natural images. In this paper, we detail the principles underlying DIIVINE, the statistical features extracted and their relevance to perception and thoroughly evaluate the algorithm on the popular LIVE IQA database. Further, we compare the performance of DIIVINE against leading full-reference (FR) IQA algorithms and demonstrate that DIIVINE is statistically superior to the often used measure of peak signal-to-noise ratio (PSNR) and statistically equivalent to the popular structural similarity index (SSIM). A software release of DIIVINE has been made available online: http://live.ece.utexas.edu/research/quality/DIIVINE_release.zip for public use and evaluation.					Bovik, Alan/B-6717-2012	Bovik, Alan/0000-0001-6067-710X													1057-7149	1941-0042				DEC	2011	20	12					3350	3364		10.1109/TIP.2011.2147325	http://dx.doi.org/10.1109/TIP.2011.2147325								21521667					WOS:000297340300004
J	Kulekci, MK				Kulekci, Mustafa Kemal			Magnesium and its alloys applications in automotive industry	INTERNATIONAL JOURNAL OF ADVANCED MANUFACTURING TECHNOLOGY												The objective of this study is to review and evaluate the applications of magnesium in the automotive industry that can significantly contribute to greater fuel economy and environmental conservation. In the study, the current advantages, limitations, technological barriers and future prospects of Mg alloys in the automotive industry are given. The usage of magnesium in automotive applications is also assessed for the impact on environmental conservation. Recent developments in coating and alloying of Mg improved the creep and corrosion resistance properties of magnesium alloys for elevated temperature and corrosive environments. The results of the study conclude that reasonable prices and improved properties of Mg and its alloys will lead to massive use of magnesium. Compared to using alternative materials, using Mg alloys results in a 22% to 70% weight reduction. Lastly, the use of magnesium in automotive components is increasing as knowledge of forming processes of Mg alloys increases.					Kulekci, Mustafa Kemal/M-7600-2015	Kulekci, Mustafa Kemal/0000-0002-5829-3489													0268-3768	1433-3015				NOV	2008	39	9-10					851	865		10.1007/s00170-007-1279-2	http://dx.doi.org/10.1007/s00170-007-1279-2													WOS:000260699200001
J	Han, SH; Lee, JH				Han, SH; Lee, JH			An overview of peak-to-average power ratio reduction techniques for multicarrier transmission	IEEE WIRELESS COMMUNICATIONS												High peak-to-average power ratio of the transmit signal is a major drawback of multicarrier transmission such as OFDM or DMT. This article describes some of the important PAPR reduction techniques for multicarrier transmission including amplitude clipping and filtering, coding, partial transmit sequence, selected mapping, interleaving, tone reservation, tone injection, and active constellation extension. Also, we make some remarks on the criteria for PAPR reduction technique selection and briefly address the problem of PAPR reduction in OFDMA and MIMO-OFDM.																			1536-1284	1558-0687				APR	2005	12	2					56	65																WOS:000228370300008
J	Hainfeld, JF; Slatkin, DN; Smilowitz, HM				Hainfeld, JF; Slatkin, DN; Smilowitz, HM			The use of gold nanoparticles to enhance radiotherapy in mice	PHYSICS IN MEDICINE AND BIOLOGY												Mice bearing subcutaneous EMT-6 mammary carcinomas received a single intravenous injection of 1.9 nm diameter gold particles (up to 2.7 g Au/kg body weight), which elevated concentrations of gold to 7 mg Au/g in tumours. Tumour-to-normal-tissue gold concentration ratios remained similar to8:1 during several minutes of 250 kVp x-ray therapy. One-year survival was 86% versus 20% with x-rays alone and 0% with gold alone. The increase in tumours safely ablated was dependent on the amount of gold injected. The gold nanoparticles were apparently non-toxic to mice and were largely cleared from the body through the kidneys. This novel use of small gold nanoparticles permitted achievement of the high metal content in tumours necessary for significant high-Z radioenhancement.																			0031-9155	1361-6560				SEP 21	2004	49	18					N309	N315	PII S0031-9155(04)81626-9	10.1088/0031-9155/49/18/N03	http://dx.doi.org/10.1088/0031-9155/49/18/N03								15509078					WOS:000224395600019
J	Batstone, DJ; Keller, J; Angelidaki, I; Kalyuzhnyi, SV; Pavlostathis, SG; Rozzi, A; Sanders, WTM; Siegrist, H; Vavilin, VA				Batstone, DJ; Keller, J; Angelidaki, I; Kalyuzhnyi, SV; Pavlostathis, SG; Rozzi, A; Sanders, WTM; Siegrist, H; Vavilin, VA			The IWA Anaerobic Digestion Model No 1 (ADM1)	WATER SCIENCE AND TECHNOLOGY					9th World Congress on Anaerobic Digestion	SEP 02-06, 2001	ANTWERP, BELGIUM					The IWA Anaerobic Digestion Modelling Task Group was established in 1997 at the 8th World Congress on,Anaerobic Digestion (Sendai, Japan) with the goal of developing a generalised anaerobic digestion model. The structured model includes multiple steps describing biochemical as well as physicochemical processes. The biochemical steps include disintegration from homogeneous particulates to carbohydrates, proteins and lipids; extracellular hydrolysis of these particulate substrates to sugars, amino acids, and long chain fatty acids (LCFA), respectively; acidogenesis from sugars and amino acids to volatile fatty acids (VFAs) and hydrogen; acetogenesis of LCFA and VFAs to acetate; and separate methanogenesis steps from acetate and hydrogen/CO2. The physico-chemical equations describe ion association and dissociation, and gas-liquid transfer. Implemented as a differential and algebraic equation (DAE) set, there are 26 dynamic state concentration variables, and 8 implicit algebraic variables per reactor vessel or element. Implemented as differential equations (DE) only, there are 32 dynamic concentration state variables.					Keller, Jurg/C-3649-2013; Angelidaki, Irini/AAX-2562-2020; Batstone, Damien/N-1896-2014; Vavilin, Vasily/E-6521-2014	Angelidaki, Irini/0000-0002-6357-578X; Vavilin, Vasily/0000-0002-3926-2601													0273-1223						2002	45	10					65	73											12188579					WOS:000177331900011
J	Saad, MA; Bovik, AC; Charrier, C				Saad, Michele A.; Bovik, Alan C.; Charrier, Christophe			Blind Image Quality Assessment: A Natural Scene Statistics Approach in the DCT Domain	IEEE TRANSACTIONS ON IMAGE PROCESSING												We develop an efficient general-purpose blind/no-reference image quality assessment (IQA) algorithm using a natural scene statistics (NSS) model of discrete cosine transform (DCT) coefficients. The algorithm is computationally appealing, given the availability of platforms optimized for DCT computation. The approach relies on a simple Bayesian inference model to predict image quality scores given certain extracted features. The features are based on an NSS model of the image DCT coefficients. The estimated parameters of the model are utilized to form features that are indicative of perceptual quality. These features are used in a simple Bayesian inference approach to predict quality scores. The resulting algorithm, which we name BLIINDS-II, requires minimal training and adopts a simple probabilistic model for score prediction. Given the extracted features from a test image, the quality score that maximizes the probability of the empirically determined inference model is chosen as the predicted quality score of that image. When tested on the LIVE IQA database, BLIINDS-II is shown to correlate highly with human judgments of quality, at a level that is competitive with the popular SSIM index.					rosenberger, Christophe/M-4841-2017; Bovik, Alan/B-6717-2012	Bovik, Alan/0000-0001-6067-710X													1057-7149	1941-0042				AUG	2012	21	8					3339	3352		10.1109/TIP.2012.2191563	http://dx.doi.org/10.1109/TIP.2012.2191563								22453635					WOS:000306598100001
J	Montaldo, G; Tanter, M; Bercoff, J; Benech, N; Fink, M				Montaldo, Gabriel; Tanter, Mickael; Bercoff, Jeremy; Benech, Nicolas; Fink, Mathias			Coherent Plane-Wave Compounding for Very High Frame Rate Ultrasonography and Transient Elastography	IEEE TRANSACTIONS ON ULTRASONICS FERROELECTRICS AND FREQUENCY CONTROL												The emergence of ultrafast frame rates in ultrasonic! imaging has been recently made possible by the development of new imaging modalities such as transient elastography. Data acquisition rates reaching more than thousands (if images per second enable the real-time visualization of shear mechanical waves propagating in biological tissues, which convey in-formation about local viscoelastic properties of tissue. The first proposed approach for reaching such ultrafast frame rates consists of transmitting plane waves into the medium. However, because the beamforming process is then restricted to the receive mode, the echographic images obtained in the ultrafast mode suffer from a low quality in terms of resolution and contrast and affect the robustness of the transient elastography mode. It is here proposed to improve the beamforming process by using it coherent recombination of compounded plane-wave transmissions to recover high-quality echographic images without, degrading the high frame rare capabilities. A theoretical model is derived for the comparison between the proposed method and the conventional B-mode imaging in terms of contrast, signal-to-noise ratio, and resolution. Our model predicts that; a significantly smaller number of insonifications, 10 times lower, is sufficient to reach oil image quality comparable to conventional B-mode. Theoretical predictions are confirmed by in vitro experiments performed in tissue-mimicking phantoms. Such results raise the appeal of coherent compounds for use with standard imaging modes Such as B-mode or color flow. Moreover, in the context of transient elastography, ultrafast frame rates can be preserved while increasing the image quality compared with flat insonifications. Improvements oil the transient elastography mode are presented and discussed.					Montaldo, Gabriel/HMD-8464-2023; Fink, Mathias/M-9437-2016; Tanter, Mickael/H-4657-2012	Benech, Nicolas/0000-0001-5733-4907; Fink, Mathias/0000-0002-8494-7562; Tanter, Mickael/0000-0001-7739-8051													0885-3010					MAR	2009	56	3					489	506		10.1109/TUFFC.2009.1067	http://dx.doi.org/10.1109/TUFFC.2009.1067								19411209					WOS:000263479600009
J	Huber, MM; Canonica, S; Park, GY; Von Gunten, U				Huber, MM; Canonica, S; Park, GY; Von Gunten, U			Oxidation of pharmaceuticals during ozonation and advanced oxidation processes	ENVIRONMENTAL SCIENCE & TECHNOLOGY												This study investigates the oxidation of pharmaceuticals during conventional ozonation and advanced oxidation processes (AOPs) applied in drinking water treatment. In a first step, second-order rate constants for the reactions of selected pharmaceuticals with ozone (k(O3)) and OH radicals (k(OH)) were determined in bench-scale experiments (in brackets apparent k(O3) at pH 7 and T = 20 degreesC): bezafibrate (590 +/- 50 M-1 s(-1)), carbamazepine (similar to3 x 10(5) M-1 s(-1)), diazepam (0.75 +/- 0.15 M-1 s(-1)), diclofenac (similar to1 X 10(6) M-1 s(-1)), 17alpha-ethinylestradiol (similar to3 x 10(6) M-1 s(-1)), ibuprofen (9.6 +/- 1.0 M-1 s(-1)), iopromide (<0.8 M-1 s(-1)), sulfamethoxazole (similar to2.5 x 10(6) M-1 s(-1)), and roxithromycin (similar to7 x 10(4) M-1 s(-1)). For five of the pharmaceuticals the apparent k(O3) at pH 7 was >5 x 10(4) M-1 s(-1), indicating that these compounds are completely transformed during ozonation processes. Values for kOH ranged from 3.3 to 9.8 x 10(9) M-1 s(-1). Compared to other important micropollutants such as MTBE and atrazine, the selected pharmaceuticals reacted about two to three times faster with OH radicals. In the second part of the study, oxidation kinetics of the selected pharmaceuticals were investigated in ozonation experiments performed in different natural waters. It could be shown that the second-order rate constants determined in pure aqueous solution could be applied to predict the behavior of pharmaceuticals dissolved in natural waters. Overall it can be concluded that ozonation and AOPs are promising processes for an efficient removal of pharmaceuticals in drinking waters.					von Gunten, Urs/O-1637-2013														0013-936X					MAR 1	2003	37	5					1016	1024		10.1021/es025896h	http://dx.doi.org/10.1021/es025896h								12666935					WOS:000181258600045
J	White, DJ; Take, WA; Bolton, MD				White, DJ; Take, WA; Bolton, MD			Soil deformation measurement using particle image velocimetry (PIV) and photogrammetry	GEOTECHNIQUE												A deformation measurement system based on particle image velocimetry (PIV) and close-range photogrammetry has been developed for use in geotechnical testing. In this paper, the theory underlying this system is described, and the performance is validated. Digital photography is used to capture images of planar soil deformation. Using PIV, the movement of a fine mesh of soil patches is measured to a high precision. Since PIV operates on the image texture, intrusive target markers need not be installed in the observed soil. The resulting displacement vectors are converted from image space to object space using a photogrammetric transformation. A series of validation experiments are reported. These demonstrate that the precision, accuracy and resolution of the system are an order of magnitude higher than previous image-based deformation methods, and are comparable to local instrumentation used in element testing. This performance is achieved concurrent with an order of magnitude increase in the number of measurement points that can be fitted in an image. The performance of the system is illustrated with two example applications.					; White, David/F-8325-2014	Take, W. Andy/0000-0002-8634-1919; White, David/0000-0002-2968-582X													0016-8505	1751-7656				SEP	2003	53	7					619	631		10.1680/geot.53.7.619.37383	http://dx.doi.org/10.1680/geot.53.7.619.37383													WOS:000185979600002
J	Paden, B; Cáp, M; Yong, SZ; Yershov, D; Frazzoli, E				Paden, Brian; Cap, Michal; Yong, Sze Zheng; Yershov, Dmitry; Frazzoli, Emilio			A Survey of Motion Planning and Control Techniques for Self-Driving Urban Vehicles	IEEE TRANSACTIONS ON INTELLIGENT VEHICLES												Self-driving vehicles are a maturing technology with the potential to reshape mobility by enhancing the safety, accessibility, efficiency, and convenience of automotive transportation. Safety-critical tasks that must be executed by a self-driving vehicle include planning of motions through a dynamic environment shared with other vehicles and pedestrians, and their robust executions via feedback control. The objective of this paper is to survey the current state of the art on planning and control algorithms with particular regard to the urban setting. A selection of proposed techniques is reviewed along with a discussion of their effectiveness. The surveyed approaches differ in the vehicle mobility model used, in assumptions on the structure of the environment, and in computational requirements. The side by side comparison presented in this survey helps to gain insight into the strengths and limitations of the reviewed approaches and assists with system level design choices.						/0000-0002-0505-1400													2379-8858	2379-8904				MAR	2016	1	1					33	55		10.1109/TIV.2016.2578706	http://dx.doi.org/10.1109/TIV.2016.2578706													WOS:000722376200004
J	Campolongo, F; Cariboni, J; Saltelli, A				Campolongo, Francesca; Cariboni, Jessica; Saltelli, Andrea			An effective screening design for sensitivity analysis of large models	ENVIRONMENTAL MODELLING & SOFTWARE												In 1991 Morris proposed an effective screening sensitivity measure to identify the few important factors in models with many factors. The method is based on computing for each input a number of incremental ratios, namely elementary effects, which are then averaged to assess the overall importance of the input. Despite its value, the method is still rarely used and instead local analyses varying one factor at a time around a baseline point are usually employed. In this piece of work we propose a revised version of the elementary effects method, improved in terms of both the definition of the measure and the sampling strategy. In the present form the method shares many of the positive qualities of the variance-based techniques, having the advantage of a lower computational cost, as demonstrated by the analytical examples. The method is employed to assess the sensitivity of a chemical reaction model for dimethylsulphide (DMS), a gas involved in climate change. Results of the sensitivity analysis open up the ground for model reconsideration: some model components may need a more thorough modelling effort while some others may need to be simplified. (c) 2006 Elsevier Ltd. All rights reserved.					Saltelli, Andrea/HTN-9746-2023	saltelli, andrea/0000-0003-4222-6975													1364-8152					OCT	2007	22	10					1509	1518		10.1016/j.envsoft.2006.10.004	http://dx.doi.org/10.1016/j.envsoft.2006.10.004													WOS:000247403800013
J	Chen, CS; Liu, HD; Beardsley, RC				Chen, CS; Liu, HD; Beardsley, RC			An unstructured grid, finite-volume, three-dimensional, primitive equations ocean model: Application to coastal ocean and estuaries	JOURNAL OF ATMOSPHERIC AND OCEANIC TECHNOLOGY												An unstructured grid, finite-volume, three-dimensional (3D) primitive equation ocean model has been developed for the study of coastal oceanic and estuarine circulation. The model consists of momentum, continuity, temperature, salinity, and density equations and is closed physically and mathematically using the Mellor and Yamada level-2.5 turbulent closure submodel. The irregular bottom slope is represented using a sigma-coordinate transformation, and the horizontal grids comprise unstructured triangular cells. The finite-volume method (FVM) used in this model combines the advantages of a finite-element method (FEM) for geometric flexibility and a finite-difference method (FDM) for simple discrete computation. Currents, temperature, and salinity in the model are computed in the integral form of the equations, which provides a better representation of the conservative laws for mass, momentum, and heat in the coastal region with complex geometry. The model was applied to the Bohai Sea, a semienclosed coastal ocean, and the Satilla River, a Georgia estuary characterized by numerous tidal creeks and inlets. Compared with the results obtained from the finite-difference model (ECOM-si), the new model produces a better simulation of tidal elevations and residual currents, especially around islands and tidal creeks. Given the same initial distribution of temperature in the Bohai Sea, the FVCOM and ECOM-si models show similar distributions of temperature and stratified tidal rectified flow in the interior region away from the coast and islands, but FVCOM appears to provide a better simulation of temperature and currents around the islands, barriers, and inlets with complex topography.						Chen, Changsheng/0000-0001-8715-6101													0739-0572					JAN	2003	20	1					159	186		10.1175/1520-0426(2003)020<0159:AUGFVT>2.0.CO;2	http://dx.doi.org/10.1175/1520-0426(2003)020<0159:AUGFVT>2.0.CO;2													WOS:000180282900013
J	von Gioi, RG; Jakubowicz, J; Morel, JM; Randall, G				von Gioi, Rafael Grompone; Jakubowicz, Jeremie; Morel, Jean-Michel; Randall, Gregory			LSD: A Fast Line Segment Detector with a False Detection Control	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												We propose a linear-time line segment detector that gives accurate results, a controlled number of false detections, and requires no parameter tuning. This algorithm is tested and compared to state-of-the-art algorithms on a wide set of natural images.					Morel, Jean-Michel/I-1012-2012	Morel, Jean-Michel/0000-0002-6108-897X													0162-8828	1939-3539				APR	2010	32	4					722	732		10.1109/TPAMI.2008.300	http://dx.doi.org/10.1109/TPAMI.2008.300								20224126					WOS:000274548800012
J	Cucker, F; Smale, S				Cucker, Felipe; Smale, Steve			Emergent behavior in flocks	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												We provide a model (for both continuous and discrete time) describing the evolution of a flock. Our model is parameterized by a constant beta capturing the rate of decay-which in our model is polynomial-of the influence between birds in the flock as they separate in space. Our main result shows that when beta < 1/2 convergence of the flock to a common velocity is guaranteed, while for beta < 1/2 convergence-is guaranteed under some condition on the initial positions and velocities of the birds only.					Smale, Stephen/C-2908-2013	CUCKER FARKAS, Juan Felipe/0000-0002-4569-3248													0018-9286	1558-2523				MAY	2007	52	5					852	862		10.1109/TAC.2007.895842	http://dx.doi.org/10.1109/TAC.2007.895842													WOS:000246670300007
J	Masek, JG; Vermote, EF; Saleous, NE; Wolfe, R; Hall, FG; Huemmrich, KF; Gao, F; Kutler, J; Lim, TK				Masek, JG; Vermote, EF; Saleous, NE; Wolfe, R; Hall, FG; Huemmrich, KF; Gao, F; Kutler, J; Lim, TK			A Landsat surface reflectance dataset for North America, 1990-2000	IEEE GEOSCIENCE AND REMOTE SENSING LETTERS												The Landsat Ecosystem Disturbance Adaptive Processing System (LEDAPS) at the National Aeronautics and Space Administration (NASA) Goddard Space Flight Center has processed and released 2100 Landsat Thematic Mapper and Enhanced Thematic Mapper Plus surface reflectance scenes, providing 30-m resolution wall-to-wall reflectance coverage for North America for epochs centered on 1990 and 2000. This dataset can support decadal assessments of environmental and land-cover change, production of reflectance-based biophysical products, and applications that merge reflectance data from multiple sensors [e.g., the Advanced Spaceborne Thermal Emission and Reflection Radiometer, Multiangle Imaging Spectroradiometer, Moderate Resolution Imaging Spectroradiometer (MODIS)]. The raw imagery was obtained from the orthorectified Landsat GeoCover dataset, purchased by NASA from the Earth Satellite Corporation. Through the LEDAPS project, these data were calibrated, converted to top-of-atmosphere reflectance, and then atmospherically corrected using the MODIS/6S methodology. Initial comparisons with ground-based optical thickness measurements and simultaneously acquired MODIS imagery indicate comparable uncertainty in Landsat surface reflectance compared to the standard MODIS reflectance product (the greater of 0.5% absolute reflectance or 5% of the recorded reflectance value). The rapid automated nature of the processing stream also paves the way for routine high-level products from future Landsat sensors.					Gao, Feng/F-3944-2010; Vermote, Eric/K-3733-2012; Masek, Jeffrey/D-7673-2012; Wolfe, Robert/E-1485-2012; Saleous, Nazmi/F-7410-2015	Wolfe, Robert/0000-0002-0915-1855; Saleous, Nazmi/0000-0001-9378-9263; Gao, Feng/0000-0002-1865-2846													1545-598X					JAN	2006	3	1					68	72		10.1109/LGRS.2005.857030	http://dx.doi.org/10.1109/LGRS.2005.857030													WOS:000234898700015
J	Paulraj, AJ; Gore, DA; Nabar, RU; Bölcskei, H				Paulraj, AJ; Gore, DA; Nabar, RU; Bölcskei, H			An overview of MIMO communications -: A key to gigabit wireless	PROCEEDINGS OF THE IEEE												High data rate wireless communications, nearing 1-Gb/s transmission rates, is of interest in emerging wireless local area networks and home audio/visual networks. Designing very high speed wireless links that offer good quality-of-service and range capability in non-line-of-sight (NLOS) environments constitutes a significant research and engineering challenge. Ignoring fading in NLOS environments, we can, in principle, meet the 1-Gb/s data rate requirement with a single-transmit single-receive antenna wireless system if the product of bandwidth (measured in hertz) and spectral efficiency (measured in bits per second per hertz) is equal to 10(9). As we shall outline in this paper a variety of cost, technology and regulatory constraints make such a brute force solution unattractive if not impossible. The use of multiple antennas at transmitter and receiver popularly known as multiple-input multiple-output (MIMO) wireless is an emerging cost-effective technology that offers substantial leverages in making 1-Gb/s wireless links a reality. This paper provides an overview of MIMO wireless technology covering channel models, performance limits, coding, and transceiver design.					Bolcskei, Helmut/B-3937-2011; Paulraj, Arogyaswami/A-1218-2007														0018-9219	1558-2256				FEB	2004	92	2					198	218		10.1109/JPROC.2003.821915	http://dx.doi.org/10.1109/JPROC.2003.821915													WOS:000188974200002
J	Hu, W; Huang, YY; Wei, L; Zhang, F; Li, HC				Hu, Wei; Huang, Yangyu; Wei, Li; Zhang, Fan; Li, Hengchao			Deep Convolutional Neural Networks for Hyperspectral Image Classification	JOURNAL OF SENSORS												Recently, convolutional neural networks have demonstrated excellent performance on various visual tasks, including the classification of common two-dimensional images. In this paper, deep convolutional neural networks are employed to classify hyperspectral images directly in spectral domain. More specifically, the architecture of the proposed classifier contains five layers with weights which are the input layer, the convolutional layer, the max pooling layer, the full connection layer, and the output layer. These five layers are implemented on each spectral signature to discriminate against others. Experimental results based on several hyperspectral image data sets demonstrate that the proposed method can achieve better classification performance than some traditional methods, such as support vector machines and the conventional deep learning-based methods.					LI, WEI/ABD-5001-2021; Zhang, Fan/W-3340-2019	Zhang, Fan/0000-0002-2058-2373													1687-725X	1687-7268					2015	2015								258619	10.1155/2015/258619	http://dx.doi.org/10.1155/2015/258619													WOS:000359240000001
J	Zhou, D; Zhao, CY; Tian, Y				Zhou, D.; Zhao, C. Y.; Tian, Y.			Review on thermal energy storage with phase change materials (PCMs) in building applications	APPLIED ENERGY												Thermal energy storage with phase change materials (PCMs) offers a high thermal storage density with a moderate temperature variation, and has attracted growing attention due to its important role in achieving energy conservation in buildings with thermal comfort. Various methods have been investigated by previous researchers to incorporate PCMs into the building structures, and it has been found that with the help of PCMs the indoor temperature fluctuations can be reduced significantly whilst maintaining desirable thermal comfort. This paper summarises previous works on latent thermal energy storage in building applications, covering PCMs, the impregnation methods, current building applications and their thermal performance analyses, as well as numerical simulation of buildings with PCMs. Over 100 references are included in this paper. (C) 2011 Elsevier Ltd. All rights reserved.					Zhao, Changying/IUN-8646-2023; ZHOU, DAN/AAY-2255-2020	ZHOU, DAN/0000-0001-6934-4854													0306-2619	1872-9118				APR	2012	92						593	605		10.1016/j.apenergy.2011.08.025	http://dx.doi.org/10.1016/j.apenergy.2011.08.025													WOS:000300463800065
J	Peters, GP; Hertwich, EG				Peters, Glen P.; Hertwich, Edgar G.			CO<sub>2</sub> embodied in international trade with implications for global climate policy	ENVIRONMENTAL SCIENCE & TECHNOLOGY												The flow of pollution through international trade flows has the ability to undermine environmental policies, particularly for global pollutants. In this article we determine the CO2 emissions embodied in international trade among 87 countries for the year 2001. We find that globally there are over 5.3 Gt of CO2 embodied in trade and that Annex B countries are net importers Of CO2 emissions. Depending on country characteristics-such as size variables and geographic location-there are considerable variations in the embodied emissions. We argue that emissions embodied in trade may have a significant impact on participation in and effectiveness of global climate policies such as the Kyoto Protocol. We discuss several policy options to reduce the impact of trade in global climate policy. If countries take binding commitments as a part of a coalition, instead of as individual countries, then the impacts of trade can be substantially reduced. Adjusting emission inventories for trade gives a more consistent description of a country's environmental pressures and circumvents many trade related issues. It also gives opportunities to exploit trade as a means of mitigating emissions. Not least, a better understanding of the role that trade plays in a country's economic and environmental development will help design more effective and participatory climate policy post-Kyoto.,					Peters, Glen/B-1012-2008; Guan, Dabo/Y-2406-2019; Hertwich, Edgar/D-2169-2011; Hubacek, Klaus/GVS-6444-2022	Guan, Dabo/0000-0003-3773-3403; Weber, Christopher/0000-0002-6245-525X; Hertwich, Edgar/0000-0002-4934-3421; Hubacek, Klaus/0000-0003-2561-6090; Peters, Glen/0000-0001-7889-8568													0013-936X	1520-5851				MAR 1	2008	42	5					1401	1407		10.1021/es072023k	http://dx.doi.org/10.1021/es072023k								17937264					WOS:000253521300009
J	Peters, GP; Weber, CL; Guan, D; Hubacek, K				Peters, Glen P.; Weber, Christopher L.; Guan, Dabo; Hubacek, Klaus			China's growing CO<sub>2</sub> emissions -: A race between increasing consumption and efficiency gains	ENVIRONMENTAL SCIENCE & TECHNOLOGY												China's rapidly growing economy and energy consumption are creating serious environmental problems on both local and global scales. Understanding the key drivers behind China's growing energy consumption and the associated CO2 emissions is critical for the development of global climate policies and provides insight into how other emerging economies may develop a low emissions future. Using recently released Chinese economic input-output data and structural decomposition analysis we analyze how changes in China's technology, economic structure, urbanization, and lifestyles affect CO2 emissions. We find that infrastructure construction and urban household consumption, both in turn driven by urbanization and lifestyle changes, have outpaced efficiency improvements in the growth Of CO2 emissions. Net trade had a small effect on total emissions due to equal, but significant, growth in emissions from the production of exports and emissions avoided by imports. Technology and efficiency improvements have only partially offset consumption growth, but there remains considerable untapped potential to reduce emissions by improving both production and consumption systems. As China continues to rapidly develop there is an opportunity to further implement and extend policies, such as the Circular Economy, that will help China avoid the high emissions path taken by today's developed countries.					Peters, Glen/B-1012-2008; Guan, Dabo/Y-2406-2019; Hertwich, Edgar/D-2169-2011; Hubacek, Klaus/GVS-6444-2022	Guan, Dabo/0000-0003-3773-3403; Weber, Christopher/0000-0002-6245-525X; Hertwich, Edgar/0000-0002-4934-3421; Hubacek, Klaus/0000-0003-2561-6090; Peters, Glen/0000-0001-7889-8568													0013-936X	1520-5851				SEP 1	2007	41	17					5939	5944		10.1021/es070108f	http://dx.doi.org/10.1021/es070108f								17937264					WOS:000249240100011
J	Lotero, E; Liu, YJ; Lopez, DE; Suwannakarn, K; Bruce, DA; Goodwin, JG				Lotero, E; Liu, YJ; Lopez, DE; Suwannakarn, K; Bruce, DA; Goodwin, JG			Synthesis of biodiesel via acid catalysis	INDUSTRIAL & ENGINEERING CHEMISTRY RESEARCH												Biodiesel is synthesized via the transesterification of lipid feedstocks with low molecular weight alcohols. Currently, alkaline bases are used to catalyze the reaction. These catalysts require anhydrous conditions and feedstocks with low levels of free fatty acids (FFAs). Inexpensive feedstocks containing high levels of FFAs cannot be directly used with the base catalysts currently employed. Strong liquid acid catalysts are less sensitive to FFAs and can simultaneously conduct esterification and transesterification. However, they are slower and necessitate higher reaction temperatures. Nonetheless, acid-catalyzed processes could produce biodiesel from low-cost feedstocks, lowering production costs. Better yet, if solid acid catalysts could replace liquid acids, the corrosion and environmental problems associated with them could be avoided and product purification protocols reduced, significantly simplifying biodiesel production and reducing cost. This article reviews some of the research related to biodiesel production using acid catalysts, including solid acids.					liu, Yijun/A-6792-2010; Bruce, David/E-9572-2011; Goodwin, James/AAH-8814-2019	Bruce, David/0000-0003-0963-3819													0888-5885					JUL 6	2005	44	14					5353	5363		10.1021/ie049157g	http://dx.doi.org/10.1021/ie049157g													WOS:000230435900054
J	Bourdin, B; Francfort, GA; Marigo, JJ				Bourdin, Blaise; Francfort, Gilles A.; Marigo, Jean-Jacques			The variational approach to fracture	JOURNAL OF ELASTICITY																	Marigo, Jean-Jacques/T-3854-2019; Bourdin, Blaise/X-9144-2019; Francfort, Gilles/KHD-5856-2024; Marigo, Jean-Jacques/N-6041-2014	Marigo, Jean-Jacques/0000-0001-7949-5031; Bourdin, Blaise/0000-0002-1312-9175													0374-3535	1573-2681				APR	2008	91	1-3					5	148		10.1007/s10659-007-9107-3	http://dx.doi.org/10.1007/s10659-007-9107-3													WOS:000254455600003
J	Rankov, B; Wittneben, A				Rankov, Boris; Wittneben, Armin			Spectral efficient protocols for half-duplex fading relay channels	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS					43rd Annual Allerton Conference on Communication, Control and Computing	SEP, 2005	Monticello, IL					We study two-hop communication protocols where one or several relay terminals assist in the communication between two or more terminals. All terminals operate in half-duplex mode, hence the transmission of one information symbol from the source terminal to the destination terminal occupies two channel uses. This leads to a loss in spectral efficiency due to the pre-log factor one-half in corresponding capacity expressions. We propose two new half-duplex relaying protocols that avoid the pre-log factor one-half. Firstly, we consider a relaying protocol where a bidirectional connection between two terminals is established via one amplify-and-forward (AF) or decode-and-forward (DF) relay (two-way relaying). We also extend this protocol to a multi-user scenario, where multiple terminals communicate with multiple partner terminals via several orthogonalize-and-forward (OF) relay terminals, i.e., the relays orthogonalize the different two-way transmissions by a distributed zero-forcing algorithm. Secondly, we propose a relaying protocol where two relays, either AF or DF, alternately forward messages from a source terminal to a destination terminal (two-path relaying). It is shown that both protocols recover a significant portion of the half-duplex loss.																			0733-8716	1558-0008				FEB	2007	25	2					379	389		10.1109/JSAC.2007.070213	http://dx.doi.org/10.1109/JSAC.2007.070213													WOS:000243920200013
J	Namasivayam, C; Kavitha, D				Namasivayam, C; Kavitha, D			Removal of Congo Red from water by adsorption onto activated carbon prepared from coir pith, an agricultural solid waste	DYES AND PIGMENTS												The adsorption of Congo Red by coir pith carbon was carried out by varying the parameters such as agitation time, dye concentration, adsorbent dose, pH and temperature. Equilibrium adsorption data followed both Langmuir and Freundlich isotherms. Adsorption followed second-order rate kinetics. The adsorption capacity was found to be 6.7 mg dye per g of the adsorbent. Acidic pH was favourable for the adsorption of Congo Red. Desorption studies suggest that chemisorption might be the major mode of adsorption. (C) 2002 Elsevier Science Ltd. All rights reserved.					Kavitha, D/AAV-8021-2021														0143-7208					JUL	2002	54	1					47	58	PII S0143-7208(02)00025-6	10.1016/S0143-7208(02)00025-6	http://dx.doi.org/10.1016/S0143-7208(02)00025-6													WOS:000177221000006
J	Deslandes, D; Wu, K				Deslandes, D; Wu, K			Integrated microstrip and rectangular waveguide in planar form	IEEE MICROWAVE AND WIRELESS COMPONENTS LETTERS												Usually transitions from microstrip line to rectangular waveguide are made with three-dimensional (3-D) complex mounting structures. In this paper, a new planar platform is developed in which the microstrip line and rectangular waveguide are fully integrated on the same substrate, and they are interconnected via a simple taper, Our experiments at 28 GHz show that an effective bandwidth of 12% at 20 dB return loss is obtained with an in-band insertion loss better than 0.3 dB, The new transition allows a complete integration of waveguide components on substrate with MIC's and MMIC's.																			1531-1309					FEB	2001	11	2					68	70		10.1109/7260.914305	http://dx.doi.org/10.1109/7260.914305													WOS:000168894400006
J	Ferretti, A; Fumagalli, A; Novali, F; Prati, C; Rocca, F; Rucci, A				Ferretti, Alessandro; Fumagalli, Alfio; Novali, Fabrizio; Prati, Claudio; Rocca, Fabio; Rucci, Alessio			A New Algorithm for Processing Interferometric Data-Stacks: SqueeSAR	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING												Permanent Scatterer SAR Interferometry (PSInSAR) aims to identify coherent radar targets exhibiting high phase stability over the entire observation time period. These targets often correspond to point-wise, man-made objects widely available over a city, but less present in non-urban areas. To overcome the limits of PSInSAR, analysis of interferometric data-stacks should aim at extracting geophysical parameters not only from point-wise deterministic objects (i.e., PS), but also from distributed scatterers (DS). Rather than developing hybrid processing chains where two or more algorithms are applied to the same data-stack, and results are then combined, in this paper we introduce a new approach, SqueeSAR, to jointly process PS and DS, taking into account their different statistical behavior. As it will be shown, PS and DS can be jointly processed without the need for significant changes to the traditional PSInSAR processing chain and without the need to unwrap hundreds of interferograms, provided that the coherence matrix associated with each DS is properly "squeezed" to provide a vector of optimum (wrapped) phase values. Results on real SAR data, acquired over an Alpine area, challenging for any InSAR analysis, confirm the effectiveness of this new approach.					Rucci, Alessio/Y-7047-2019; Ferretti, Alessandro/K-3811-2019	Rocca, Fabio/0000-0002-2266-6212; Ferretti, Alessandro/0000-0002-7802-5019													0196-2892	1558-0644				SEP	2011	49	9			SI		3460	3470		10.1109/TGRS.2011.2124465	http://dx.doi.org/10.1109/TGRS.2011.2124465													WOS:000294536700030
J	Li, Y; Chen, YQ; Podlubny, I				Li, Yan; Chen, YangQuan; Podlubny, Igor			Mittag-Leffler stability of fractional order nonlinear dynamic systems	AUTOMATICA					3rd IFAC Workshop on Fractional Derivative and Applications	NOV 05-07, 2008	Ankara, TURKEY	IFAC				In this paper, we propose the definition of Mittag-Leffler stability and introduce the fractional Lyapunov direct method. Fractional comparison principle is introduced and the application of Riemann-Liouville fractional order systems is extended by using Caputo fractional order systems. Two illustrative examples are provided to illustrate the proposed stability notion. Published by Elsevier Ltd					Podlubny, Igor/J-7462-2012; Li, Yan/K-7292-2012; Chen, YangQuan/A-2301-2008	Chen, YangQuan/0000-0002-7422-5988; Li, Yan/0000-0002-3134-7715; Podlubny, Igor/0000-0003-0183-9249													0005-1098	1873-2836				AUG	2009	45	8					1965	1969		10.1016/j.automatica.2009.04.003	http://dx.doi.org/10.1016/j.automatica.2009.04.003													WOS:000268651300027
J	Blanz, V; Vetter, T				Blanz, V; Vetter, T			Face recognition based on fitting a 3D morphable model	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												This paper presents a method for face recognition across variations in pose, ranging from frontal to profile views, and across a wide range of illuminations, including cast shadows and specular reflections. To account for these variations, the algorithm simulates the process of image formation in 3D space, using computer graphics, and it estimates 3D shape and texture of faces from single images. The estimate is achieved by fitting a statistical, morphable model of 3D faces to images. The model is learned from a set of textured 3D scans of heads. We describe the construction of the morphable model, an algorithm to fit the model to images, and a framework for face identification. In this framework, faces are represented by model parameters for 3D shape and texture. We present results obtained with 4,488 images from the publicly available CMU-PIE database and 1,940 images from the FERET database.					Vetter, Thomas/AAG-9477-2019														0162-8828	1939-3539				SEP	2003	25	9					1063	1074		10.1109/TPAMI.2003.1227983	http://dx.doi.org/10.1109/TPAMI.2003.1227983													WOS:000184977300003
J	Xu, H; Van Deventer, JSJ				Xu, H; Van Deventer, JSJ			The geopolymerisation of alumino-silicate minerals	INTERNATIONAL JOURNAL OF MINERAL PROCESSING												Geopolymers are similar to zeolites in chemical composition, but they reveal an amorphous microstructure. They form by the co-polymerisation of individual alumino and silicate species, which originate from the dissolution of silicon and aluminium containing source materials at a high pH in the presence of soluble alkali metal silicates. It has been shown before that geopolymerisation can transform a wide range of waste alumino-silicate materials into building and mining materials with excellent chemical and physical properties, such as fire and acid resistance. The geopolymerisation of 15 natural AI-Si minerals has been investigated in this paper with the aim to determine the effect of mineral properties on the compressive strength of the synthesised geopolymer. All these AI-Si minerals are to some degree soluble in concentrated alkaline solution, with in general a higher extent of dissolution in NaOH than in KOH medium. Statistical analysis revealed that framework silicates show a higher extent of dissolution in alkaline solution than the chain, sheet and ring structures. In general, minerals with a higher extent of dissolution demonstrate better compressive strength after geopolymerisation. The use of KOH instead of NaOH favours the geopolymerisation in the case of all 15 minerals. Stilbite, when conditioned in KOH solution, gives the geopolymer with the highest compressive strength(i.e., 18 MPa). It is proposed that the mechanism of mineral dissolution as well as the mechanism of geopolymerisation can be explained by ion-pair theory. This study shows that a wide range of natural Al-Si minerals could serve as potential source materials for the synthesis of geopolymers. (C) 2000 Elsevier Science B.V. All rights reserved.																			0301-7516					JUN	2000	59	3					247	266		10.1016/S0301-7516(99)00074-5	http://dx.doi.org/10.1016/S0301-7516(99)00074-5													WOS:000087391700005
J	Zhang, ZQ; Xiao, Y; Ma, Z; Xiao, M; Ding, ZG; Lei, XF; Karagiannidis, GK; Fan, PZ				Zhang, Zhengquan; Xiao, Yue; Ma, Zheng; Xiao, Ming; Ding, Zhiguo; Lei, Xianfu; Karagiannidis, George K.; Fan, Pingzhi			6G WIRELESS NETWORKS <i>Vision, Requirements, Architecture, and Key Technologies</i>	IEEE VEHICULAR TECHNOLOGY MAGAZINE																	ma, zheng/HJY-2110-2023; XIAO, YUE/GWV-6558-2022; Xu, Ming/HSI-3016-2023; Xiao, Ming/I-5517-2018; Karagiannidis, George K./A-5190-2014	Xiao, Ming/0000-0002-5407-0835; Karagiannidis, George K./0000-0001-8810-0345													1556-6072	1556-6080				SEP	2019	14	3					28	41		10.1109/MVT.2019.2921208	http://dx.doi.org/10.1109/MVT.2019.2921208													WOS:000481980100006
J	Wright, SJ; Nowak, RD; Figueiredo, MAT				Wright, Stephen J.; Nowak, Robert D.; Figueiredo, Mario A. T.			Sparse Reconstruction by Separable Approximation	IEEE TRANSACTIONS ON SIGNAL PROCESSING												Finding sparse approximate solutions to large underdetermined linear systems of equations is a common problem in signal/image processing and statistics. Basis pursuit, the least absolute shrinkage and selection operator (LASSO), wavelet-based deconvolution and reconstruction, and compressed sensing (CS) are a few well-known areas in which problems of this type appear. One standard approach is to minimize an objective function that includes a quadratic (l(2)) error term added to a sparsity-inducing (usually l(1)) regularizater. We present an algorithmic framework for the more general problem of minimizing the sum of a smooth convex function and a nonsmooth, possibly nonconvex regularizer. We propose iterative methods in which each step is obtained by solving an optimization subproblem involving a quadratic term with diagonal Hessian (i.e., separable in the unknowns) plus the original sparsity-inducing regularizer; our approach is suitable for cases in which this subproblem can be solved much more rapidly than the original problem. Under mild conditions (namely convexity of the regularizer), we prove convergence of the proposed iterative algorithm to a minimum of the objective function. In addition to solving the standard l(2) - l(1) case, our framework yields efficient solution techniques for other regularizers, such as an l(infinity) norm and group-separable regularizers. It also generalizes immediately to the case in which the data is complex rather than real. Experiments with CS problems show that our approach is competitive with the fastest known methods for the standard l(2) - l(1) problem, as well as being efficient on problems with other separable regularization terms.					Figueiredo, Mario/C-5428-2008	Figueiredo, Mario/0000-0002-0970-7745													1053-587X	1941-0476				JUL	2009	57	7					2479	2493		10.1109/TSP.2009.2016892	http://dx.doi.org/10.1109/TSP.2009.2016892													WOS:000267379200005
J	Vazquez, S; Rodriguez, J; Rivera, M; Franquelo, LG; Norambuena, M				Vazquez, Sergio; Rodriguez, Jose; Rivera, Marco; Franquelo, Leopoldo G.; Norambuena, Margarita			Model Predictive Control for Power Converters and Drives: Advances and Trends	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS												Model predictive control (MPC) is a very attractive solution for controlling power electronic converters. The aim of this paper is to present and discuss the latest developments in MPC for power converters and drives, describing the current state of this control strategy and analyzing the new trends and challenges it presents when applied to power electronic systems. The paper revisits the operating principle of MPC and identifies three key elements in the MPC strategies, namely the prediction model, the cost function, and the optimization algorithm. This paper summarizes the most recent research concerning these elements, providing details about the different solutions proposed by the academic and industrial communities.					Norambuena, Margarita/AAE-9266-2021; Rivera, Marco/E-9124-2012; Rodriguez, Jose/A-2534-2013; Franquelo, Leopoldo Garcia/D-5450-2009; Vazquez, Sergio/C-1669-2016; Norambuena, Margarita/B-4882-2019	Rivera, Marco/0000-0002-4353-2088; Rodriguez, Jose/0000-0002-1410-4121; Franquelo, Leopoldo Garcia/0000-0002-1976-9747; Vazquez, Sergio/0000-0002-7438-8904; Norambuena, Margarita/0000-0002-2530-2000													0278-0046	1557-9948				FEB	2017	64	2					935	947		10.1109/TIE.2016.2625238	http://dx.doi.org/10.1109/TIE.2016.2625238													WOS:000395826100006
J	Rodriguez, J; Bernet, S; Steimer, PK; Lizama, IE				Rodriguez, Jose; Bernet, Steffen; Steimer, Peter K.; Lizama, Ignacio E.			A Survey on Neutral-Point-Clamped Inverters	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS												Neutral-point-clamped (NPC) inverters are the most widely used topology of multilevel inverters in high-power applications (several megawatts). This paper presents in a very simple way the basic operation and the most used modulation and control techniques developed to date. Special attention is paid to the loss distribution in semiconductors, and an active NPC inverter is presented to overcome this problem. This paper discusses the main fields of application and presents some technological problems such as capacitor balance and losses.					Bernet, Steffen/B-4609-2010; Rodriguez, Jose/A-2534-2013	Rodriguez, Jose/0000-0002-1410-4121													0278-0046	1557-9948				JUL	2010	57	7					2219	2230		10.1109/TIE.2009.2032430	http://dx.doi.org/10.1109/TIE.2009.2032430													WOS:000278811000004
J	Gross, R; Matthews, I; Cohn, J; Kanade, T; Baker, S				Gross, Ralph; Matthews, Iain; Cohn, Jeffrey; Kanade, Takeo; Baker, Simon			Multi-PIE	IMAGE AND VISION COMPUTING												A close relationship exists between the advancement of face recognition algorithms and the availability of face databases varying factors that affect facial appearance in a controlled manner. The CMU PIE database has been very influential in advancing research in face recognition across pose and illumination. Despite its success the PIE database has several shortcomings: a limited number of subjects, a single recording session and only few expressions captured. To address these issues we collected the CMU Multi-PIE database. It contains 337 subjects, imaged under 15 view points and 19 illumination conditions in up to four recording sessions. In this paper we introduce the database and describe the recording procedure. We furthermore present results from baseline experiments using PCA and LDA classifiers to highlight similarities and differences between PIE and Multi-PIE. (C) 2009 Elsevier B.V. All rights reserved.																			0262-8856	1872-8138				MAY	2010	28	5			SI		807	813		10.1016/j.imavis.2009.08.002	http://dx.doi.org/10.1016/j.imavis.2009.08.002								20490373					WOS:000275849900009
J	Cory, RM; McKnight, DM				Cory, RM; McKnight, DM			Fluorescence spectroscopy reveals ubiquitous presence of oxidized and reduced quinones in dissolved organic matter	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Excitation-emission matrixes (EEMs) of 379 dissolved organic matter (DOM) samples from diverse aquatic environments were modeled by parallel factor analysis (PARAFAC). Thirteen components likely representing groups of similarly fluorescing moieties were found to explain the variation in this data set. Seven of the thirteen components were identified as quinone-like based on comparison of their excitation and emission spectra to spectra of model quinones. These quinone-like fluorophores were found to vary in redox state and degree of conjugation. Two components were identified as amino acid-like based on comparison to tyrosine and tryptophan fluorescence spectra. The other four components are not yet associated with any class of molecules. The quinone-like fluorophores account for about 50% of the fluorescence for every sample analyzed, showing that quinone-like fluorophores are an important and ubiquitous fluorescing moiety and in natural waters. Further, the distribution of the quinone-like fluorophores was evaluated as a function of environmental and laboratory redox gradients. Under reducing conditions, the contribution of the reduced quinone-like fluorophores increased concurrent with a decrease in the oxidized quinone-like fluorophores, indicating that DOM fluorescence is a function of redox state of quinone-like moieties. Lastly, a ratio of two quinone-like fluorophores was found to explain the variation in the fluorescence index. These results provide new insight into the redox reactivity of DOM and have implications for the application of fluorescence spectroscopy as a tool to characterize DOM.					Cory, Rose/C-2277-2009	Cory, Rose/0000-0001-9867-7084; MCKNIGHT, DIANE/0000-0002-4171-1533													0013-936X	1520-5851				NOV 1	2005	39	21					8142	8149		10.1021/es0506962	http://dx.doi.org/10.1021/es0506962								16294847					WOS:000233078000013
J	Boons, F; Lüdeke-Freund, F				Boons, Frank; Luedeke-Freund, Florian			Business models for sustainable innovation: state-of-the-art and steps towards a research agenda	JOURNAL OF CLEANER PRODUCTION												The aim of this paper is to advance research on sustainable innovation by adopting a business model perspective. Through a confrontation of the literature on both topics we find that research on sustainable innovation has tended to neglect the way in which firms need to combine a value proposition, the organization of the upstream and downstream value chain and a financial model in order to bring sustainable innovations to the market. Therefore, we review the current literature on business models in the contexts of technological, organizational and social innovation. As the current literature does not offer a general conceptual definition of sustainable business models, we propose examples of normative requirements that business models should meet in order to support sustainable innovations. Finally, we sketch the outline of a research agenda by formulating a number of guiding questions. (C) 2012 Elsevier Ltd. All rights reserved.					Lüdeke-Freund, Florian/AAI-6175-2020; Boons, Frank/N-1203-2013	Boons, Frank/0000-0001-8743-7800; Ludeke-Freund, Florian/0000-0001-9566-3699													0959-6526	1879-1786				APR	2013	45						9	19		10.1016/j.jclepro.2012.07.007	http://dx.doi.org/10.1016/j.jclepro.2012.07.007													WOS:000318389100002
J	Damnjanovic, A; Montojo, J; Wei, YB; Ji, TF; Luo, T; Vajapeyam, M; Yoo, T; Song, O; Malladi, D				Damnjanovic, Aleksandar; Montojo, Juan; Wei, Yongbin; Ji, Tingfang; Luo, Tao; Vajapeyam, Madhavan; Yoo, Taesang; Song, Osok; Malladi, Durga			A SURVEY ON 3GPP HETEROGENEOUS NETWORKS	IEEE WIRELESS COMMUNICATIONS												As the spectral efficiency of a point-to-point link in cellular networks approaches its theoretical limits, with the forecasted explosion of data traffic, there is a need for an increase in the node density to further improve network capacity. However, in already dense deployments in today's networks, cell splitting gains can be severely limited by high inter-cell interference. Moreover, high capital expenditure cost associated with high power macro nodes further limits viability of such an approach. This article discusses the need for an alternative strategy, where low power nodes are overlaid within a macro network, creating what is referred to as a heterogeneous network. We survey current state of the art in heterogeneous deployments and focus on 3GPP LTE air interface to describe future trends. A high-level overview of the 3GPP LTE air interface, network nodes, and spectrum allocation options is provided, along with the enabling mechanisms for heterogeneous deployments. Interference management techniques that are critical for LTE heterogeneous deployments are discussed in greater detail. Cell range expansion, enabled through cell biasing and adaptive resource partitioning, is seen as an effective method to balance the load among the nodes in the network and improve overall trunking efficiency. An interference cancellation receiver plays a crucial role in ensuring acquisition of weak cells and reliability of control and data reception in the presence of legacy signals.																			1536-1284					JUN	2011	18	3					10	21		10.1109/MWC.2011.5876496	http://dx.doi.org/10.1109/MWC.2011.5876496													WOS:000291820500004
J	Cox, KD; Covernton, GA; Davies, HL; Dower, JF; Juanes, F; Dudas, SE				Cox, Kieran D.; Covernton, Garth A.; Davies, Hailey L.; Dower, John F.; Juanes, Francis; Dudas, Sarah E.			Human Consumption of Microplastics	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Microplastics are ubiquitous across ecosystems, yet the exposure risk to humans is unresolved. Focusing on the American diet, we evaluated the number of microplastic particles in commonly consumed foods in relation to their recommended daily intake. The potential for microplastic inhalation and how the source of drinking water may affect microplastic consumption were also explored. Our analysis used 402 data points from 26 studies, which represents over 3600 processed samples. Evaluating approximately 15% of Americans' caloric intake, we estimate that annual microplastics consumption ranges from 39000 to 52000 particles depending on age and sex. These estimates increase to 74000 and 121000 when inhalation is considered. Additionally, individuals who meet their recommended water intake through only bottled sources may be ingesting an additional 90000 microplastics annually, compared to 4000 microplastics for those who consume only tap water. These estimates are subject to large amounts of variation; however, given methodological and data limitations, these values are likely underestimates.					; Covernton, Garth/AAJ-8381-2020	Davies, Hailey/0000-0002-2110-2861; Cox, Kieran/0000-0001-5626-1048; Covernton, Garth/0000-0003-3814-4918; Juanes, Francis/0000-0001-7397-0014													0013-936X	1520-5851				JUN 18	2019	53	12					7068	7074		10.1021/acs.est.9b01517	http://dx.doi.org/10.1021/acs.est.9b01517								31184127					WOS:000472682900050
J	Barlat, F; Brem, JC; Yoon, JW; Chung, K; Dick, RE; Lege, DJ; Pourgoghrat, F; Choi, SH; Chu, E				Barlat, F; Brem, JC; Yoon, JW; Chung, K; Dick, RE; Lege, DJ; Pourgoghrat, F; Choi, SH; Chu, E			Plane stress yield function for aluminum alloy sheets - part 1: theory	INTERNATIONAL JOURNAL OF PLASTICITY												A new plane stress yield function that well describes the anisotropic behavior of sheet metals, in particular, aluminum alloy sheets, was proposed. The anisotropy of the function was introduced in the formulation using two linear transformations on the Cauchy stress tensor. It was shown that the accuracy of this new function was similar to that of other recently proposed non-quadratic yield functions. Moreover, it was proved that the function is convex in stress space. A new experiment was proposed to obtain one of the anisotropy coefficients. This new formulation is expected to be particularly suitable for finite element (FE) modeling simulations of sheet forming processes for aluminum alloy sheets. (C) 2002 Elsevier Science Ltd. All rights reserved.					Shi-Hoon, Choi/JXO-0233-2024; Pourboghrat, Farhang/AAQ-3058-2021; Barlat, Frederic/C-9294-2009; Yoon, Jeong Whan/N-9471-2015	/0000-0002-4463-3454; Yoon, Jeong Whan/0000-0002-7616-5253													0749-6419	1879-2154					2003	19	9					1297	1319	PII S0749-6419(02)00019-0	10.1016/S0749-6419(02)00019-0	http://dx.doi.org/10.1016/S0749-6419(02)00019-0													WOS:000182756500002
J	Oustaloup, A; Levron, F; Mathieu, B; Nanot, FM				Oustaloup, A; Levron, F; Mathieu, B; Nanot, FM			Frequency-band complex noninteger differentiator: Characterization and synthesis	IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-FUNDAMENTAL THEORY AND APPLICATIONS												The state-of-the-art on generalized (or any order) derivatives in physics and engineering sciences, is outlined for justifying the interest of the noninteger differentiation. The problems subsequent to its use in real-time operations are then set out so as to motivate the idea of synthesizing it by a recursive distribution of zeros and poles. An analysis of the existing work is also proposed to support this idea. A comprehensive study is given of the synthesis of differentiators with integer, noninteger, real or complex orders, and whose action is limited to any given frequency bandwidth. First, a definition, in the operational and frequency domains, of a frequency-band complex noninteger order differentiator, is given in a mathematical space with four dimensions which is a Banach algebra. Then, the determination of its synthesized form, by a recursive distribution of complex zeros and poles characterized by complex recursive factors, is presented, The complex noninteger differentiation order is expressed as a function of these recursive factors. The number of zeros and poles is calculated to he as low as possible while still ensuring the stability of the synthesized differentiator and providing a suitable approximation to the initial differentiator to be synthesized. A time validation is presented. Finally, guidelines are proposed for the conception of the synthesized differentiator.																			1057-7122					JAN	2000	47	1					25	39		10.1109/81.817385	http://dx.doi.org/10.1109/81.817385													WOS:000084926900003
J	Aaron, D; Tsouris, C				Aaron, D; Tsouris, C			Separation of CO<sub>2</sub> from flue gas:: A review	SEPARATION SCIENCE AND TECHNOLOGY					13th Symposium on Separation Science and Technology for Energy Applications	OCT 27-30, 2003	Gatlinburg, TN	Oak Ridge Natl Lab, Argonne Natl Lab, US DOE, Amer Inst Chem Engineers, Separat Div, Amer Chem Soc, Ind & Engn Chem Div, Separat Sci & Technol Subdiv				As a result of human activity, approximately 7 Gt of carbon are emitted to the earth's atmosphere each year. A large portion of this carbon is in the form of gaseous CO2, and approximately 30% of this CO2 Comes from fossil fuel power plants. In addition to rising levels of atmospheric CO2, the earth's temperature is increasing. Since CO2 can act as a trap for heat (similar to the glass in a greenhouse), reduction of CO2 emissions is an important area of research. Separation and sequestration of CO2 are near-term goals for emissions reduction. Better fuel efficiency (in power production, transportation, and other areas) can be considered a mid-term goal. An acceptable long-term goal for reducing emissions is using alternate power sources such as nuclear, solar, and wind power. Because separation and sequestration are short-term goals, they are critical and challenging steps for researchers. Methods that are reviewed in this paper include absorption using solvents or solid sorbents, pressure- and temperature-swing adsorption using various solid sorbents, cryogenic distillation, membranes, and several novel and emerging technologies. Upon completion of this review, it was concluded that the most promising current method for CO2 separation is liquid absorption using monoethanolamine (MEA). While this method is currently most promising, the development of ceramic and metallic membranes for membrane diffusion should produce membranes significantly more efficient at separation than liquid absorption. The other methods investigated in this report are either too new for comparison or appear unlikely to experience significant changes to make them desirable for implementation.					Tsouris, Costas/C-2544-2016	Tsouris, Costas/0000-0002-0522-1027													0149-6395	1520-5754					2005	40	1-3					321	348		10.1081/SS-200042244	http://dx.doi.org/10.1081/SS-200042244													WOS:000227145000021
J	Girard, A				Girard, Antoine			Dynamic Triggering Mechanisms for Event-Triggered Control	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												In this technical note, we present a new class of event triggering mechanisms for event-triggered control systems. This class is characterized by the introduction of an internal dynamic variable, which motivates the proposed name of dynamic event triggering mechanism. The stability of the resulting closed-loop system is proved and the influence of design parameters on the decay rate of the Lyapunov function is discussed. For linear systems, we establish a lower bound on the inter-execution time as a function of the parameters. The influence of these parameters on a quadratic integral performance index is also studied. Some simulation results are provided for illustration of the theoretical claims.						Girard, Antoine/0000-0002-4075-9041													0018-9286	1558-2523				JUL	2015	60	7					1992	1997		10.1109/TAC.2014.2366855	http://dx.doi.org/10.1109/TAC.2014.2366855													WOS:000356871400029
J	Wu, QQ; Zeng, Y; Zhang, R				Wu, Qingqing; Zeng, Yong; Zhang, Rui			Joint Trajectory and Communication Design for Multi-UAV Enabled Wireless Networks	IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS												Due to the high maneuverability, flexible deployment, and low cost, unmanned aerial vehicles (UAVs) have attracted significant interest recently in assisting wireless communication. This paper considers a multi-UAV enabled wireless communication system, where multiple UAV-mounted aerial base stations are employed to serve a group of users on the ground. To achieve fair performance among users, we maximize the minimum throughput over all ground users in the downlink communication by optimizing the multiuser communication scheduling and association jointly with the UAV's trajectory and power control. The formulated problem is a mixed integer nonconvex optimization problem that is challenging to solve. As such, we propose an efficient iterative algorithm for solving it by applying the block coordinate descent and successive convex optimization techniques. Specifically, the user scheduling and association, UAV trajectory, and transmit power are alternately optimized in each iteration. In particular, for the nonconvex UAV trajectory and transmit power optimization problems, two approximate convex optimization problems are solved, respectively. We further show that the proposed algorithm is guaranteed to converge. To speed up the algorithm convergence and achieve good throughput, a low-complexity and systematic initialization scheme is also proposed for the UAV trajectory design based on the simple circular trajectory and the circle packing scheme. Extensive simulation results are provided to demonstrate the significant throughput gains of the proposed design as compared to other benchmark schemes.					Zeng, Yong/AFM-8040-2022; Wu, Qingqing/IAM-7302-2023; Zhang, Rui/C-2657-2011	Wu, Qingqing/0000-0002-0043-3266; Zhang, Rui/0000-0002-8729-8393													1536-1276	1558-2248				MAR	2018	17	3					2109	2121		10.1109/TWC.2017.2789293	http://dx.doi.org/10.1109/TWC.2017.2789293													WOS:000427226500050
J	Boore, DM; Atkinson, GM				Boore, David M.; Atkinson, Gail M.			Ground-motion prediction equations for the average horizontal component of PGA, PGV, and 5%-damped PSA at spectral periods between 0.01 s and 10.0 s	EARTHQUAKE SPECTRA												This paper contains ground-motion prediction equations (GMPEs) for average horizontal-component ground motions as a function of earthquake magnitude, distance from source to site, local average shear-wave velocity, and fault type. Our equations are for peak ground acceleration (PGA), peak ground velocity (PGV), and 5%-damped pseudo-absolute-acceleration spectra (PSA) at periods between 0.01 s and 10 s. They were derived by empirical regression of an extensive strong-motion database compiled by the "PEER NGA" (Pacific Earthquake Engineering Research Center's Next Generation Attenuation) project. For periods less than 1 s, the analysis used 1,574 records from 58 mainshocks in the distance range from 0 km to 400 km (the number of available data decreased as period increased). The primary predictor variables are moment magnitude (M), closest horizontal distance to the surface projection of the fault plane (R-JB), and the time-averaged shear-wave velocity from the surface to 30 m (V-S30). The equations are applicable for M=5-8, R-JB < 200 km, and V-S30=180-1300 m/s.					Boore, David/GWQ-6027-2022														8755-2930					FEB	2008	24	1					99	138		10.1193/1.2830434	http://dx.doi.org/10.1193/1.2830434													WOS:000256935500006
J	Murphy, F; Ewins, C; Carbonnier, F; Quinn, B				Murphy, Fionn; Ewins, Ciaran; Carbonnier, Frederic; Quinn, Brian			Wastewater Treatment Works (WwTW) as a Source of Microplastics in the Aquatic Environment	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Municipal effluent discharged from wastewater treatment works (WwTW) is suspected to be a significant contributor of microplastics (MP) to the environment as many personal care products contain plastic microbeads. A secondary WwTW (population equivalent 650 000) was sampled for microplastics at different stages of the treatment process to ascertain at what stage in the treatment process the MP are being removed. The influent contained on average 15.70 (+/-5.23) MP.L-1. This was reduced to 0.25 (+/-0.04) MP.L-1 in the final effluent, a decrease of 98.41%. Despite this large reduction we calculate that this WwTW is releasing 65 million microplastics into the receiving water every day. A significant proportion of the microplastic accumulated in and was removed during the grease removal stage (19.67 (+/-4.51) MP/2.5 g), it was only in the grease that the much publicised microbeads were found. This study shows that despite the efficient removal rates of MP achieved by this modern treatment plant when dealing with such a large volume of effluent even a modest amount of microplastics being released per liter of effluent could result in significant amounts of microplastics entering the environment. This is the first study to describe in detail the fate of microplastics during the wastewater treatment process.					Quinn, Brian/E-9317-2013	Quinn, Brian/0000-0002-4182-1118; Ewins, Ciaran/0000-0002-7524-7142													0013-936X	1520-5851				JUN 7	2016	50	11					5800	5808		10.1021/acs.est.5b05416	http://dx.doi.org/10.1021/acs.est.5b05416								27191224					WOS:000377629900046
J	Mato, Y; Isobe, T; Takada, H; Kanehiro, H; Ohtake, C; Kaminuma, T				Mato, Y; Isobe, T; Takada, H; Kanehiro, H; Ohtake, C; Kaminuma, T			Plastic resin pellets as a transport medium for toxic chemicals in the marine environment	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Plastic resin pellets (small granules 0.1-0.5 centimeters in diameter) are widely distributed in the ocean all over the world. They are an industrial raw material for the plastic industry and are unintentionally released to the environment both during manufacturing and transport. They are sometimes ingested by seabirds and other marine organisms, and their adverse effects on organisms are a concern. In the present study, PCBs, DDE, and nonylphenols (NP) were detected in polypropylene (PP) resin pellets collected from four Japanese coasts. Concentrations of PCBs (4-117 ng/g), DDE (0.16-3.1 ng/g), and NP (0.13-16 mug/g) varied among the sampling sites. These concentrations were comparable to those for suspended particles and bottom sediments collected from the same area as the pellets. Field adsorption experiments using PP virgin pellets demonstrated significant and steady increase in PCBs and DDE concentrations throughout the six-day experiment, indicating that the source of PCBs and DDE is ambient seawater and that adsorption to pellet surfaces is the mechanism of enrichment. The major source of NP in the marine PP resin pellets was thought to be plastic additives and/or their degradation products. Comparison of PCBs and DDE concentrations in marine PP resin pellets with those in seawater suggests their high degree of accumulation (apparent adsorption coefficient: 10(5)-10(6)). The high accumulation potential suggests that plastic resin pellets serve as both a transport medium and a potential source of toxic chemicals in the marine environment.					Takada, Hideshige/G-1096-2013; Isobe, Tomohiko/P-2114-2015; Isobe, Tomohiko/G-9576-2012	Isobe, Tomohiko/0000-0001-9235-1227													0013-936X	1520-5851				JAN 15	2001	35	2					318	324		10.1021/es0010498	http://dx.doi.org/10.1021/es0010498								11347604					WOS:000166390700011
J	Williams, BM; Hoel, LA				Williams, BM; Hoel, LA			Modeling and forecasting vehicular traffic flow as a seasonal ARIMA process: Theoretical basis and empirical results	JOURNAL OF TRANSPORTATION ENGINEERING												This article presents the theoretical basis for modeling univariate traffic condition data streams as seasonal autoregressive integrated moving average processes. This foundation rests on the Wold decomposition theorem and on the assertion that a one-week lagged first seasonal difference applied to discrete interval traffic condition data will yield a weakly stationary transformation. Moreover, empirical results using actual intelligent transportation system data are presented and found to be consistent with the theoretical hypothesis. Conclusions are given on the implications of these assertions and findings relative to ongoing intelligent transportation systems research, deployment, and operations.					Williams, Billy/I-6122-2012	xiaobing, lv/0009-0002-3773-0595; Williams, Billy/0000-0002-7599-1385													0733-947X	1943-5436				NOV-DEC	2003	129	6					664	672		10.1061/(ASCE)0733-947X(2003)129:6(664)	http://dx.doi.org/10.1061/(ASCE)0733-947X(2003)129:6(664)													WOS:000186059200011
J	Hisamoto, D; Lee, WC; Kedzierski, J; Takeuchi, H; Asano, K; Kuo, C; Anderson, E; King, TJ; Bokor, J; Hu, CM				Hisamoto, D; Lee, WC; Kedzierski, J; Takeuchi, H; Asano, K; Kuo, C; Anderson, E; King, TJ; Bokor, J; Hu, CM			FinFET - A self-aligned double-gate MOSFET scalable to 20 nm	IEEE TRANSACTIONS ON ELECTRON DEVICES												MOSFETs with gate length down to 17 nm are reported. To suppress the short channel effect, a novel self-aligned double-gate MOSFET, FinFET, is proposed, By using boron-doped Si0.4Ge0.6 as a gate material, the desired threshold voltage was achieved for the ultrathin body device. The quasiplanar nature of this new variant of the vertical double-gate MOSFETs can be fabricated relatively easily using the conventional planar MOSFET process technologies.																			0018-9383					DEC	2000	47	12					2320	2325																WOS:000165561900013
J	Rappaport, TS; Xing, YC; Kanhere, O; Ju, SH; Madanayake, A; Mandal, S; Alkhateeb, A; Trichopoulos, GC				Rappaport, Theodore S.; Xing, Yunchou; Kanhere, Ojas; Ju, Shihao; Madanayake, Arjuna; Mandal, Soumyajit; Alkhateeb, Ahmed; Trichopoulos, Georgios C.			Wireless Communications and Applications Above 100 GHz: Opportunities and Challenges for 6G and Beyond	IEEE ACCESS												Frequencies from 100 GHz to 3 THz are promising bands for the next generation of wireless communication systems because of the wide swaths of unused and unexplored spectrum. These frequencies also offer the potential for revolutionary applications that will be made possible by new thinking, and advances in devices, circuits, software, signal processing, and systems. This paper describes many of the technical challenges and opportunities for wireless communication and sensing applications above 100 GHz, and presents a number of promising discoveries, novel approaches, and recent results that will aid in the development and implementation of the sixth generation (6G) of wireless networks, and beyond. This paper shows recent regulatory and standard body rulings that are anticipating wireless products and services above 100 GHz and illustrates the viability of wireless cognition, hyper-accurate position location, sensing, and imaging. This paper also presents approaches and results that show how long distance mobile communications will be supported to above 800 GHz since the antenna gains are able to overcome air-induced attenuation, and present methods that reduce the computational complexity and simplify the signal processing used in adaptive antenna arrays, by exploiting the Special Theory of Relativity to create a cone of silence in over-sampled antenna arrays that improve performance for digital phased array antennas. Also, new results that give insights into power efficient beam steering algorithms, and new propagation and partition loss models above 100 GHz are given, and promising imaging, array processing, and position location results are presented. The implementation of spatial consistency at THz frequencies, an important component of channel modeling that considers minute changes and correlations over space, is also discussed. This paper offers the first in-depth look at the vast applications of THz wireless products and applications and provides approaches for how to reduce power and increase performance across several problem domains, giving early evidence that THz techniques are compelling and available for future wireless communications.					Ju, Shihao/AAG-4317-2020; Xing, Yunchou/ABD-2377-2021; Mandal, Soumyajit/ABD-7076-2021; Kanhere, Ojas/JWA-3564-2024; Alkhateeb, Ahmed/I-8485-2015; Trichopoulos, Georgios/S-4271-2016	Trichopoulos, Georgios/0000-0002-9030-9348; Rappaport, Theodore (Ted)/0000-0001-7449-9957; Kanhere, Ojas/0000-0001-6864-7247; Madanayake, Arjuna/0000-0003-3478-6702; Ju, Shihao/0000-0002-0661-3241													2169-3536						2019	7						78729	78757		10.1109/ACCESS.2019.2921522	http://dx.doi.org/10.1109/ACCESS.2019.2921522													WOS:000473783300001
J	Goring, DG; Nikora, VI				Goring, DG; Nikora, VI			Despiking acoustic Doppler velocimeter data	JOURNAL OF HYDRAULIC ENGINEERING-ASCE												A new method for detecting spikes in acoustic Doppler velocimeter data sequences is suggested. The method combines three concepts: (1) that differentiation enhances the high frequency portion of a signal, (2) that the expected maximum of a random series is given by the Universal threshold, and (3) that good data cluster in a dense cloud in phase space or Poincare maps. These concepts are used to construct an ellipsoid in three-dimensional phase space, then points lying outside the ellipsoid are designated as spikes. The new method is shown to have superior performance to various other methods and it has the added advantage that it requires no parameters. Several methods for replacing sequences of spurious data are presented. A polynomial fitted to good data on either side of the spike event, then interpolated across the event, is preferred by the authors.																			0733-9429					JAN	2002	128	1					117	126		10.1061/(ASCE)0733-9429(2002)128:1(117)	http://dx.doi.org/10.1061/(ASCE)0733-9429(2002)128:1(117)													WOS:000173366700013
J	Kuznetsov, AV; Nield, DA				Kuznetsov, A. V.; Nield, D. A.			Natural convective boundary-layer flow of a nanofluid past a vertical plate	INTERNATIONAL JOURNAL OF THERMAL SCIENCES												The natural convective boundary-layer flow of a nanofluid past a vertical plate is studied analytically. The model used for the nanofluid incorporates the effects of Brownian motion and thermophoresis. A similarity solution is presented. This solution depends on a Lewis number Le, a buoyancy-ratio number Nr, a Brownian motion number Nb, and a thermophoresis number Nt. For various values of Pr and Le, the variation of the reduced Nusselt number with Nr, Nb and Nt is expressed by correlation formulas. It was found that the reduced Nusselt number is a decreasing function of each of Nr, Nb and Nt. (C) 2009 Elsevier Masson SAS. All rights reserved.																			1290-0729	1778-4166				FEB	2010	49	2					243	247		10.1016/j.ijthermalsci.2009.07.015	http://dx.doi.org/10.1016/j.ijthermalsci.2009.07.015													WOS:000273738700002
J	Healey, JA; Picard, RW				Healey, JA; Picard, RW			Detecting stress during real-world driving tasks using physiological sensors	IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS												This paper presents methods for collecting and analyzing physiological data during real-world driving tasks to determine a driver's relative stress level. Electrocardiogram, electromyogram, skin conductance, and respiration were recorded continuously while drivers followed a set route through open roads in the greater Boston area. Data from 24 drives of at least 50-min duration were collected for analysis. The data were analyzed in two ways. Analysis I used features from 5-min intervals of data during the rest, highway, and city driving conditions to distinguish three levels of driver stress with an accuracy of over 97% across multiple drivers and driving days. Analysis II compared continuous features, calculated at 1-s intervals throughout the entire drive, with a metric of observable stressors created by independent coders from videotapes. The results show that for most drivers studied, skin conductivity and heart rate metrics are most closely correlated with driver stress level. These findings indicate that physiological signals can provide a metric of driver stress in future cars capable of physiological monitoring. Such a metric could be used to help manage noncritical in-vehicle information systems and could also provide a continuous measure of how different road and traflic conditions affect drivers.																			1524-9050	1558-0016				JUN	2005	6	2					156	166		10.1109/TITS.2005.848368	http://dx.doi.org/10.1109/TITS.2005.848368													WOS:000229689300004
J	Jayne, JT; Leard, DC; Zhang, XF; Davidovits, P; Smith, KA; Kolb, CE; Worsnop, DR				Jayne, JT; Leard, DC; Zhang, XF; Davidovits, P; Smith, KA; Kolb, CE; Worsnop, DR			Development of an aerosol mass spectrometer for size and composition analysis of submicron particles	AEROSOL SCIENCE AND TECHNOLOGY												The importance of atmospheric aerosols in regulating the Earth's climate and their potential detrimental impact on air quality and human health has stimulated the need for instrumentation which can provide real-time analysis of size resolved aerosol, mass, and chemical composition, We describe here an aerosol mass spectrometer (AMS) which has been developed in response to these aerosol sampling needs and present results which demonstrate quantitative measurement capability for a laboratory-generated pure component NH4NO3 aerosol, The instrument combines standard vacuum and mass spectrometric technologies with recently developed aerosol sampling techniques, A unique aerodynamic aerosol inlet (developed at the University of Minnesota) focuses particles into a narrow beam and efficiently transports them into vacuum where aerodynamic particle size is determined via a particle time-of-flight (TOF) measurement, Time-resolved particle mass detection is performed mass spectrometrically following particle flash vaporization on a resistively heated surface, Calibration data are presented for aerodynamic particle velocity and particle collection efficiency measurements, The capability to measure aerosol size and mass distributions is compared to simultaneous measurements using a differential mobility analyzer (DMA) and condensation particle counter (CPC), Quantitative size classification is demonstrated for pure component NH4NO3 aerosols having mass concentrations > similar to 0.25 mu g m(-3), Results of fluid dynamics calculations illustrating the performance of the aerodynamic lens are also presented and compared to the measured performance, The utility of this AMS as both a laboratory and held portable instrument is discussed.					Kolb, Charles/A-8596-2009; Worsnop, Douglas/D-2817-2009														0278-6826					JUL-AUG	2000	33	1-2					49	70		10.1080/027868200410840	http://dx.doi.org/10.1080/027868200410840													WOS:000087956800005
J	Mont, OK				Mont, OK			Clarifying the concept of product-service system	JOURNAL OF CLEANER PRODUCTION												A new trend of product-service systems (PSSs) that has the potential to minimise environmental impacts of both production and consumption is emerging. This article attempts to build a theoretical framework for PSS and serves as a background for identifying possible investment needs in studying them. There are three main uncertainties regarding the applicability and feasibility of PSSs: the readiness of companies to adopt them, the readiness of consumers to accept them, and their environmental implications.. The main finding is that successful PSSs will require different societal infrastructure, human structures and organisational layouts in order to function in a sustainable manner. (C) 2002 Elsevier Science Ltd. All rights reserved.					Mont, Oksana/B-1587-2015	Mont, Oksana/0000-0002-8063-4294													0959-6526						2002	10	3					237	245	PII S0959-6526(01)00039-7	10.1016/S0959-6526(01)00039-7	http://dx.doi.org/10.1016/S0959-6526(01)00039-7													WOS:000174290300005
J	Elia, N; Mitter, SK				Elia, N; Mitter, SK			Stabilization of linear systems with limited information	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												In this paper, we show that the coarsest, or least dense, quantizer that quadratically stabilizes a single input linear discrete time invariant system is logarithmic, and can be computed by solving a special linear quadratic regulator (LQR) problem. We provide a closed form for the optimal logarithmic base exclusively in terms of the unstable eigenvalues of the system. We show how to design quantized state-feedback controllers, and quantized state estimators. This leads to the design of hybrid output feedback controllers. The theory is then extended to sampling and quantization of continuous time linear systems sampled at constant time intervals. We generalize the definition of density of quantization to the density of sampling and quantization in a natural way, and search for the coarsest sampling and quantization scheme that ensures stability. We show that the resulting optimal sampling time is only function of the sum of the unstable eigenvalues of the continuous time system, and that the associated optimal quantizer is logarithmic with the logarithmic base being a universal constant independent of the system. The coarsest sampling and quantization scheme so obtained is related to the concept of minimal attention control recently introduced by Brockett. Finally, by relaxing the definition of quadratic stability, we show how to construct logarithmic quantizers with only finite number of quantization levels and still achieve practical stability of the closed-loop system. This final result provides a way to practically implement the theory developed in this paper.					Elia, Nicola/B-3636-2011														0018-9286	1558-2523				SEP	2001	46	9					1384	1400		10.1109/9.948466	http://dx.doi.org/10.1109/9.948466													WOS:000170926500004
J	Wang, JZ; Li, J; Wiederhold, G				Wang, JZ; Li, J; Wiederhold, G			SIMPLIcity: Semantics-sensitive integrated matching for picture libraries	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												The need for efficient content-based image retrieval has increased tremendously in many application areas such as biomedicine, military, commerce, education, and Web image classification and searching. We present here SIMPLIcity (Semantics-sensitive Integrated Matching for Picture Libraries), an image retrieval system, which uses semantics classification methods, a wavelet-based approach for feature extraction, and integrated region matching based upon image segmentation. As in other region-based retrieval systems, an image is represented by a set of regions, roughly corresponding to objects, which are characterized by color, texture, shape, and location. The system classifies images into semantic categories, such as textured-nontextured, graph-photograph. Potentially, the categorization enhances retrieval by permitting semantically-adaptive searching methods and narrowing down the searching range in a database. A measure for the overall similarity between images is developed using a region-matching scheme that integrates properties of all the regions in the images. Compared with retrieval based on individual regions, the overall similarity approach 1) reduces the adverse effect of inaccurate segmentation, 2) helps to clarify the semantics of a particular region, and 3) enables a simple querying interface for region-based image retrieval systems. The application of SIMPLIcity to several databases, including a database of about 200,000 general-purpose images, has demonstrated that our system performs significantly better and faster than existing ones. The system is fairly robust to image alterations.						Wang, James/0000-0003-4379-4173													0162-8828	1939-3539				SEP	2001	23	9					947	963		10.1109/34.955109	http://dx.doi.org/10.1109/34.955109													WOS:000170885200002
J	Pfurtscheller, G; Neuper, C				Pfurtscheller, G; Neuper, C			Motor imagery and direct brain-computer communication	PROCEEDINGS OF THE IEEE												Motor imagery can modify the neuronal activity in the primary sensorimotor areas in a very similar way as observable with a real executed movement. One part of EEG-based brain-computer interfaces (BCI) is based on the recording and classification of circumscribed and transient EEG changes during different types of motor imagery such as, e.g., imagination of left-hand, right-hand, or foot movement. Features such as, e.g., band power or adaptive autoregressive parameters are either extracted in bipolar EEG recordings overlaying sensorimotor areas or from an array of electrodes located over central and neighboring areas. For the classification of the features, linear discrimination analysis and neural networks is used. Characteristic for the Graz BCI is that a classifier is set up in a learning session and updated after one or more sessions with online feedback using the procedure of "rapid prototyping. " As a result, a discrimination of two brain states (e.g., left- versus right-hand movement imagination) can be reached within only a few days of training. At this time, a tetraplegic patient is able to operate an EEG-based control of a hand orthosis with nearly 100% classification accuracy, by mental imagination of specific motor commands.																			0018-9219	1558-2256				JUL	2001	89	7			SI		1123	1134		10.1109/5.939829	http://dx.doi.org/10.1109/5.939829													WOS:000170371200010
J	De Jong, WH; Hagens, WI; Krystek, P; Burger, MC; Sips, AJAM; Geertsma, RE				De Jong, Wim H.; Hagens, Werner I.; Krystek, Petra; Burger, Marina C.; Sips, Adrienne J. A. M.; Geertsma, Robert E.			Particle size-dependent organ distribution of gold nanoparticles after intravenous administration	BIOMATERIALS												A kinetic study was performed to determine the influence of particle size on the in vivo tissue distribution of spherical-shaped gold nanoparticles in the rat. Gold nanoparticles were chosen as model substances as they are used in several medical applications. In addition, the detection of the presence of gold is feasible with no background levels in the body in the normal situation. Rats were intravenously injected in the tail vein with gold nanoparticles with a diameter of 10, 50, 100 and 250 nm, respectively. After 24 h, the rats were sacrificed and blood and various organs were collected for gold determination. The presence of gold was measured quantitatively with inductively coupled plasma mass spectrometry (ICP-MS). For all gold nanoparticle sizes the majority of the gold was demonstrated to be present in liver and spleen. A clear difference was observed between the distribution of the 10 rum particles and the larger particles. The 10 rum particles were present in various organ systems including blood, liver, spleen, kidney, testis, thymus, heart, lung and brain, whereas the larger particles were only detected in blood, liver and spleen. The results demonstrate that tissue distribution of gold nartoparticles is size-dependent with the smallest 10 run nanoparticles showing the most widespread organ distribution. (C) 2008 Elsevier Ltd. All rights reserved.					Krystek, Petra/B-7634-2014	Geertsma, Robert/0000-0003-0979-9077													0142-9612	1878-5905				APR	2008	29	12					1912	1919		10.1016/j.biomaterials.2007.12.037	http://dx.doi.org/10.1016/j.biomaterials.2007.12.037								18242692					WOS:000254729800019
J	Xu, F; Wu, K				Xu, F; Wu, K			Guided-wave and leakage characteristics of substrate integrated waveguide	IEEE TRANSACTIONS ON MICROWAVE THEORY AND TECHNIQUES												The substrate integrated waveguide (SIW) technique makes it possible that a complete circuit including planar circuitry, transitions, and rectangular waveguides are fabricated in planar form using a standard printed circuit board or other planar processing techniques. In this paper, guided wave and modes characteristics of such an SIW periodic structure are studied in detail for the first time. A numerical multimode calibration procedure is proposed and developed with a commercial software package on the basis of a full-wave finite-element method for the accurate extraction of complex propagation constants of the SIW structure. Two different lengths of the SIW are numerically simulated under multimode excitation. By means of our proposed technique, the complex propagation constant of each SIW mode can accurately be extracted and the electromagnetic bandstop phenomena of periodic structures are also investigated. Experiments are made to validate our proposed technique. Simple design rules are provided and discussed.																			0018-9480	1557-9670				JAN	2005	53	1					66	73		10.1109/TMTT.2004.839303	http://dx.doi.org/10.1109/TMTT.2004.839303													WOS:000226343600008
J	Durst, J; Siebel, A; Simon, C; Hasché, F; Herranz, J; Gasteiger, HA				Durst, J.; Siebel, A.; Simon, C.; Hasche, F.; Herranz, J.; Gasteiger, H. A.			New insights into the electrochemical hydrogen oxidation and evolution reaction mechanism	ENERGY & ENVIRONMENTAL SCIENCE												The effect of pH on the hydrogen oxidation and evolution reaction (HOR/HER) rates is addressed for the first time for the three most active monometallic surfaces: Pt, Ir, and Pd carbon-supported catalysts. Kinetic data were obtained for a proton exchange membrane fuel cell (PEMFC; pH approximate to 0) using the H-2-pump mode and with a rotating disk electrode (RDE) in 0.1 M NaOH. Our findings point toward: (i) a similar approximate to 100-fold activity decrease on all these surfaces when going from low to high pH; (ii) a reaction rate controlled by the Volmer step on Pt/C; and (iii) the H-binding energy being the unique and sole descriptor for the HOR/HER in alkaline electrolytes. Based on a detailed discussion of our data, we propose a new mechanism for the HOR/HER on Pt-metals in alkaline electrolytes.					Gasteiger, Hubert/Y-8338-2019; Herranz, Juan/C-7744-2013	Hasche, Frederic/0000-0002-9353-0603; Herranz, Juan/0000-0002-5805-6192; Gasteiger, Hubert/0000-0001-8199-8703													1754-5692	1754-5706				JUL	2014	7	7					2255	2260		10.1039/c4ee00440j	http://dx.doi.org/10.1039/c4ee00440j													WOS:000337977600016
J	Yang, XS; Gandomi, AH				Yang, Xin-She; Gandomi, Amir Hossein			Bat algorithm: a novel approach for global engineering optimization	ENGINEERING COMPUTATIONS												Purpose - Nature-inspired algorithms are among the most powerful algorithms for optimization. The purpose of this paper is to introduce a new nature-inspired metaheuristic optimization algorithm, called bat algorithm (BA), for solving engineering optimization tasks. Design/methodology/approach - The proposed BA is based on the echolocation behavior of bats. After a detailed formulation and explanation of its implementation, BA is verified using eight nonlinear engineering optimization problems reported in the specialized literature. Findings - BA has been carefully implemented and carried out optimization for eight well-known optimization tasks; then a comparison has been made between the proposed algorithm and other existing algorithms. Originality/value - The optimal solutions obtained by the proposed algorithm are better than the best solutions obtained by the existing methods. The unique search features used in BA are analyzed, and their implications for future research are also discussed in detail.					Hamza, Mukhtar/V-2602-2019; Gandomi, Amir/J-7595-2013	Gandomi, Amir/0000-0002-2798-0104; Yang, Xin-She/0000-0001-8231-5556; Yang, Xin-She/0000-0002-1689-2002													0264-4401	1758-7077					2012	29	5-6					464	483		10.1108/02644401211235834	http://dx.doi.org/10.1108/02644401211235834													WOS:000309328600001
J	Rugh, WJ; Shamma, JS				Rugh, WJ; Shamma, JS			Research on gain scheduling	AUTOMATICA												Gain scheduling for nonlinear controller design is described in terms of general features of the approach and in terms of early examples of applications in flight control and automotive engine control. Then recent research is discussed, emphasizing work on linearization-based scheduling and work on linear parameter-varying approaches. (C) 2000 Elsevier Science Ltd. All rights reserved.																			0005-1098	1873-2836				OCT	2000	36	10					1401	1425		10.1016/S0005-1098(00)00058-3	http://dx.doi.org/10.1016/S0005-1098(00)00058-3													WOS:000089048000001
J	Donoho, DL; Huo, XM				Donoho, DL; Huo, XM			Uncertainty principles and ideal atomic decomposition	IEEE TRANSACTIONS ON INFORMATION THEORY												Suppose a discrete-time signal S(t), 0 less than or equal to t < N, is a superposition of atoms taken from a combined time-frequency dictionary made of spike sequences 1({t=r}) and sinusoids exp{2 pi iwt/N)/rootN. Can one recover, from knowledge of S alone, the precise collection of atoms going to make up S? Because every discrete-time signal can be represented as a superposition of spikes alone, or as a superposition of sinusoids alone, there is no unique way of writing S as a sum of spikes and sinusoids in general. We prove that if S is representable as a highly sparse superposition of atoms from this time-frequency dictionary, then there is only one such highly sparse representation of S, and it can be obtained by solving the convex optimization problem of minimizing the l(1) norm of the coefficients among all decompositions. Here "highly sparse" means that N-t + N-w < rootN/2 where N-t is the number of time atoms, N, is the number of frequency atoms, and N is the length of the discrete-time signal. Underlying this result is a general l(1) uncertainty principle which says that if two bases are mutually incoherent, no nonzero signal can have a sparse representation in both bases simultaneously. For the above setting, the bases are sinuosids and spikes, and mutual incoherence is measured in terms of the largest inner product between different basis elements. The uncertainty principle holds for a variety of interesting basis pairs, not just sinusoids and spikes. The results have idealized applications to band-limited approximation with gross errors, to error-correcting encryption, and to separation of uncoordinated sources. Related phenomena hold for functions of a real variable, with basis pairs such as sinusoids and wavelets, and for functions of two variables, with basis pairs such as wavelets and ridgelets. In these settings, if a function f is representable by a sufficiently sparse superposition of terms taken from both bases, then there is only one such sparse representation; it may be obtained by minimum l(1) norm atomic decomposition. The condition "sufficiently sparse" becomes a multiscale condition; for example, that the number of wavelets at level j plus the number of sinusoids in the jth dyadic frequency band are together less than a constant times 2(j/2).																			0018-9448	1557-9654				NOV	2001	47	7					2845	2862		10.1109/18.959265	http://dx.doi.org/10.1109/18.959265													WOS:000171700300013
J	Arima, Y; Iwata, H				Arima, Yusuke; Iwata, Hiroo			Effect of wettability and surface functional groups on protein adsorption and cell adhesion using well-defined mixed self-assembled monolayers	BIOMATERIALS												Self-assembled monolayers (SAMs) of alkanethiols, which can provide flat and chemically well-defined surfaces, were employed as model surfaces to understand cellular interaction with artificial materials. SAMs presenting a wide range of wettabilities were prepared by mixing two kinds of alkanethiols carrying terminal methyl (CH3) hydroxyl (OH), carboxylic acid (COOH), or amino (NH2) groups. Adhesion behavior of human umbilical vein endothelial cells (HUVECs) and HeLa cells on these mixed SAMs were examined. The number of adhered HUVECs reached a maximum on CH3/OH mixed SAMs with a water contact angle of 40 degrees, while cell adhesion increased with decreasing water contact angle up to 60-70 degrees and then leveled off on CH3/COOH and CH3/NH2 mixed SAMs. Numbers of adhered HeLa cells showed a maximum on CH3/OH and CH3/COOH mixed SAMs with a water contact angle of 50 degrees. These facts suggest that cell adhesion is mainly determined by surface wettability, but is also affected by the surface functional group, its surface density, and the kinds of cells. The effect of exchange of adsorbed proteins on cell adhesion was also examined. HUVECs were cultured on the mixed SAMs preadsorbed with albumin. Cell adhesion was effectively prohibited on hydrophobic SAMs pretreated with albumin. Albumin strongly adsorbed and resisted replacement by cell adhesive proteins on hydrophobic SAMs. On the other hand, cells adhered to albumin-adsorbed hydrophilic SAW Displacement of preadsorbed albumin with cell adhesive proteins effectively occurs on these hydrophilic SAMs. This effect contributes to induce SAMs with moderate wettability to give suitable surfaces for cell adhesion. (c) 2007 Elsevier Ltd. All rights reserved.						Iwata, Hiroo/0000-0001-6155-3811													0142-9612					JUL	2007	28	20					3074	3082		10.1016/j.biomaterials.2007.03.013	http://dx.doi.org/10.1016/j.biomaterials.2007.03.013								17428532					WOS:000246651300003
J	Weller, D; Moser, A; Folks, L; Best, ME; Lee, W; Toney, MF; Schwickert, M; Thiele, JU; Doerner, MF				Weller, D; Moser, A; Folks, L; Best, ME; Lee, W; Toney, MF; Schwickert, M; Thiele, JU; Doerner, MF			High K<i><sub>u</sub></i> materials approach to 100 Gbits/in<SUP>2</SUP>	IEEE TRANSACTIONS ON MAGNETICS					10th Annual Magnetic Recording Conference on Magnetic Recording Media (TMRC '99)	AUG 09-11, 1999	UNIV CALIF SAN DIEGO, SAN DIEGO, CA	Univ Calif San Diego	UNIV CALIF SAN DIEGO			High K-u, uniaxial magnetocrystalline anisotropy, materials are generally attractive for ultrahigh density magnetic recording applications as they allow smaller, thermally stable media grains. Prominent candidates are rare-earth transition metals (Co5Sm,...) and tetragonal intermetallic compounds (L1(0) phases FePt, CoPtY,...), which have 20-40 times higher K-u than today's hexagonal Co-alloy based media. This allows for about 3 times smaller grain diameters, D, and a potential 10-fold areal density increase (proportional to 1 / D-2), well beyond the currently projected 40-100 Gbits/in(2) mark. Realization of such densities will depend on a large number of factors, not all related to solving media microstructure problems, In particular, it is at present not known how to record into such media, which may require write fields in the order of 10-100 kOe. Despite this unsolved problem, there is considerable interest in high Ku alternative media, both for longitudinal and perpendicular recording. Activities in this area will be reviewed and data on sputtered and evaporated thin FePt films, with coercivities exceeding 10000 Oe will be presented.					Folks, Liesl/C-7611-2016; Toney, Michael/ABD-5429-2021	Toney, Michael/0000-0002-7513-1166; Folks, Liesl/0000-0003-0161-957X													0018-9464	1941-0069				JAN	2000	36	1	1				10	15		10.1109/20.824418	http://dx.doi.org/10.1109/20.824418													WOS:000085569500003
J	Fridrich, J; Kodovsky, J				Fridrich, Jessica; Kodovsky, Jan			Rich Models for Steganalysis of Digital Images	IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY												We describe a novel general strategy for building steganography detectors for digital images. The process starts with assembling a rich model of the noise component as a union of many diverse submodels formed by joint distributions of neighboring samples from quantized image noise residuals obtained using linear and nonlinear high-pass filters. In contrast to previous approaches, we make the model assembly a part of the training process driven by samples drawn from the corresponding cover-and stego-sources. Ensemble classifiers are used to assemble the model as well as the final steganalyzer due to their low computational complexity and ability to efficiently work with high-dimensional feature spaces and large training sets. We demonstrate the proposed framework on three steganographic algorithms designed to hide messages in images represented in the spatial domain: HUGO, edge-adaptive algorithm by Luo et al. [32], and optimally coded ternary 1 embedding. For each algorithm, we apply a simple submodel-selection technique to increase the detection accuracy per model dimensionality and show how the detection saturates with increasing complexity of the rich model. By observing the differences between how different submodels engage in detection, an interesting interplay between the embedding and detection is revealed. Steganalysis built around rich image models combined with ensemble classifiers is a promising direction towards automatizing steganalysis for a wide spectrum of steganographic schemes.																			1556-6013	1556-6021				JUN	2012	7	3					868	882		10.1109/TIFS.2012.2190402	http://dx.doi.org/10.1109/TIFS.2012.2190402													WOS:000304091600002
J	van der Aalst, W; Weijters, T; Maruster, L				van der Aalst, W; Weijters, T; Maruster, L			Workflow mining: Discovering process models from event logs	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING												Contemporary workflow management systems are driven by explicit process models, i.e., a completely specified workflow design is required in order to enact a given workflow process. Creating a workflow design is a complicated time-consuming process and, typically, there are discrepancies between the actual workflow processes and the processes as perceived by the management. Therefore, we have developed techniques for discovering workflow models. The starting point for such techniques is a so-called "workflow log" containing information about the workflow process as it is actually being executed. We present a new algorithm to extract a process model from such a log and represent it in terms of a Petri net. However, we will also demonstrate that it is not possible to discover arbitrary workflow processes. In this paper, we explore a class of workflow processes that can be discovered. We show that the alpha-algorithm can successfully mine any workflow represented by a so-called SWF-net.					weijters, ton/D-1779-2010; van der Aalst, Wil/G-1248-2011	van der Aalst, Wil/0000-0002-0955-6940; Maruster, Laura/0000-0002-6588-7648													1041-4347	1558-2191				SEP	2004	16	9					1128	1142		10.1109/TKDE.2004.47	http://dx.doi.org/10.1109/TKDE.2004.47													WOS:000222767700008
J	Lam, L; Teng, JG				Lam, L; Teng, JG			Design-oriented stress-strain model for FRP-confined concrete	CONSTRUCTION AND BUILDING MATERIALS												External confinement by the wrapping of FRP sheets (or FRP jacketing) provides a very effective method for the retrofit of reinforced concrete (RC) columns subject to either static or seismic loads. For the reliable and cost-effective design of FRP jackets, an accurate stress-strain model is required for FRP-confined concrete. In this paper, a new design-oriented stress-strain model is proposed for concrete confined by FRP wraps with fibres only or predominantly in the hoop direction based on a careful interpretation of existing test data and observations. This model is simple, so it is suitable for direct use in design, but in the meantime, it captures all the main characteristics of the stress-strain behavior of concrete confined by different types of FRP. In addition, for unconfined concrete, this model reduces directly to idealized stress-strain curves in existing design codes. In the development of this model, a number of important issues including the actual hoop strains in FRP jackets at rupture, the sufficiency of FRP confinement for a significant strength enhancement, and the effect of jacket stiffness on the ultimate axial strain, were all carefully examined and appropriately resolved. The predictions of the model are shown to agree well with test data. (C) 2003 Elsevier Ltd. All rights reserved.					Teng, Jin-Guang/D-5636-2011	Teng, Jin-Guang/0000-0003-2306-2004													0950-0618	1879-0526				SEP-OCT	2003	17	6-7					471	489		10.1016/S0950-0618(03)00045-X	http://dx.doi.org/10.1016/S0950-0618(03)00045-X													WOS:000185948900009
J	Jia, F; Lei, YG; Lin, J; Zhou, X; Lu, N				Jia, Feng; Lei, Yaguo; Lin, Jing; Zhou, Xin; Lu, Na			Deep neural networks: A promising tool for fault characteristic mining and intelligent diagnosis of rotating machinery with massive data	MECHANICAL SYSTEMS AND SIGNAL PROCESSING												Aiming to promptly process the massive fault data and automatically provide accurate diagnosis results, numerous studies have been conducted on intelligent fault diagnosis of rotating machinery. Among these studies, the methods based on artificial neural networks (ANNs) are commonly used, which employ signal processing techniques for extracting features and further input the features to ANNs for classifying faults. Though these methods did work in intelligent fault diagnosis of rotating machinery, they still have two deficiencies. (1) The features are manually extracted depending on much prior knowledge about signal processing techniques and diagnostic expertise. In addition, these manual features are extracted according to a specific diagnosis issue and probably unsuitable for other issues. (2) The ANNs adopted in these methods have shallow architectures, which limits the capacity of ANNs to learn the complex non-linear relationships in fault diagnosis issues. As a breakthrough in artificial intelligence, deep learning holds the potential to overcome the aforementioned deficiencies. Through deep learning, deep neural networks (DNNs) with deep architectures, instead of shallow ones, could be established to mine the useful information from raw data and approximate complex non-linear functions. Based on DNNs, a novel intelligent method is proposed in this paper to overcome the deficiencies of the aforementioned intelligent diagnosis methods. The effectiveness of the proposed method is validated using datasets from rolling element bearings and planetary gearboxes. These datasets contain massive measured signals involving different health conditions under various operating conditions. The diagnosis results show that the proposed method is able to not only adaptively mine available fault characteristics from the measured signals, but also obtain superior diagnosis accuracy compared with the existing methods. (C) 2015 Elsevier Ltd. All rights reserved.					Lu, Na/KMA-3229-2024; Lei, Yaguo/N-4891-2014; Lin, Jing/Y-3233-2019														0888-3270					MAY	2016	72-73						303	315		10.1016/j.ymssp.2015.10.025	http://dx.doi.org/10.1016/j.ymssp.2015.10.025													WOS:000369196200017
J	Borden, MJ; Verhoosel, CV; Scott, MA; Hughes, TJR; Landis, CM				Borden, Michael J.; Verhoosel, Clemens V.; Scott, Michael A.; Hughes, Thomas J. R.; Landis, Chad M.			A phase-field description of dynamic brittle fracture	COMPUTER METHODS IN APPLIED MECHANICS AND ENGINEERING												In contrast to discrete descriptions of fracture, phase-field descriptions do not require numerical tracking of discontinuities in the displacement field. This greatly reduces implementation complexity. In this work, we extend a phase-field model for quasi-static brittle fracture to the dynamic case. We introduce a phase-field approximation to the Lagrangian for discrete fracture problems and derive the coupled system of equations that govern the motion of the body and evolution of the phase-field. We study the behavior of the model in one dimension and show how it influences material properties. For the temporal discretization of the equations of motion, we present both a monolithic and staggered time integration scheme. We study the behavior of the dynamic model by performing a number of two and three dimensional numerical experiments. We also introduce a local adaptive refinement strategy and study its performance in the context of locally refined T-splines. We show that the combination of the phase-field model and local adaptive refinement provides an effective method for simulating fracture in three dimensions. (C) 2012 Elsevier B.V. All rights reserved.					Scott, Michael/AAY-3110-2021; Verhoosel, Clemens/IAM-7882-2023; Hughes, Thomas/AAL-8013-2020; Borden, Michael/R-8602-2016; Landis, Chad/C-9156-2013	Borden, Michael/0000-0001-6633-4925; Verhoosel, Clemens/0000-0001-9319-1552; Landis, Chad/0000-0002-1330-3778; Hughes, Thomas J. R./0000-0001-7024-8368													0045-7825	1879-2138					2012	217						77	95		10.1016/j.cma.2012.01.008	http://dx.doi.org/10.1016/j.cma.2012.01.008													WOS:000302971500007
J	Mairal, J; Elad, M; Sapiro, G				Mairal, Julien; Elad, Michael; Sapiro, Guillermo			Sparse representation for color image restoration	IEEE TRANSACTIONS ON IMAGE PROCESSING												Sparse representations of signals have drawn considerable interest in recent years. The assumption that natural signals, such as images, admit a sparse decomposition over a redundant dictionary leads to efficient algorithms for handling such sources of data. In particular, the design of well adapted dictionaries for images has been a major challenge. The K-SVD has been recently proposed for this task [1] and shown to perform very well for various grayscale image processing tasks. In this paper, we address the problem of learning dictionaries for color images and extend the K-SVD-based grayscale image denoising algorithm that appears in [2]. This work puts forward ways for handling nonhomogeneous noise and missing information, paving the way to state-of-the-art results in applications such as color image denoising, demosaicing, and inpainting, as demonstrated in this paper.					Mairal, Julien/AAL-5611-2021; , Miki/AAH-4640-2019	Elad, Michael/0000-0001-8131-6928													1057-7149	1941-0042				JAN	2008	17	1					53	69		10.1109/TIP.2007.911828	http://dx.doi.org/10.1109/TIP.2007.911828								18229804					WOS:000251744700006
J	Peddieson, J; Buchanan, GR; McNitt, RP				Peddieson, J; Buchanan, GR; McNitt, RP			Application of nonlocal continuum models to nanotechnology	INTERNATIONAL JOURNAL OF ENGINEERING SCIENCE					39th Annual Technical Meeting of the Society-of-Engineering-Science	OCT 13-16, 2002	PENNSYLVANIA STATE UNIV, UNIVERSITY PK, PENNSYLVANIA	Soc Engn Sci	PENNSYLVANIA STATE UNIV			A version of nonlocal elasticity theory is employed to develop a nonlocal Benoulli/Euler beam model. Some representative problems are solved to illustrate the magnitude of predicted nonlocal effects. Particular attention is paid to cantilever beams which are often used as actuators in small scale systems. (C) 2002 Elsevier Science Ltd. All rights reserved.																			0020-7225					FEB-MAR	2003	41	3-5					305	312	PII S0020-7225(02)00210-0	10.1016/S0020-7225(02)00210-0	http://dx.doi.org/10.1016/S0020-7225(02)00210-0													WOS:000180982100009
J	Ong, SP; Chevrier, VL; Hautier, G; Jain, A; Moore, C; Kim, S; Ma, XH; Ceder, G				Ong, Shyue Ping; Chevrier, Vincent L.; Hautier, Geoffroy; Jain, Anubhav; Moore, Charles; Kim, Sangtae; Ma, Xiaohua; Ceder, Gerbrand			Voltage, stability and diffusion barrier differences between sodium-ion and lithium-ion intercalation materials	ENERGY & ENVIRONMENTAL SCIENCE												To evaluate the potential of Na-ion batteries, we contrast in this work the difference between Na-ion and Li-ion based intercalation chemistries in terms of three key battery properties-voltage, phase stability and diffusion barriers. The compounds investigated comprise the layered AMO(2) and AMS(2) structures, the olivine and maricite AMPO(4) structures, and the NASICON A(3)V(2)(PO4)(3) structures. The calculated Na voltages for the compounds investigated are 0.18-0.57 V lower than that of the corresponding Li voltages, in agreement with previous experimental data. We believe the observed lower voltages for Na compounds are predominantly a cathodic effect related to the much smaller energy gain from inserting Na into the host structure compared to inserting Li. We also found a relatively strong dependence of battery properties on structural features. In general, the difference between the Na and Li voltage of the same structure, Delta VNa-Li, is less negative for the maricite structures preferred by Na, and more negative for the olivine structures preferred by Li. The layered compounds have the most negative Delta VNa-Li. In terms of phase stability, we found that open structures, such as the layered and NASICON structures, that are better able to accommodate the larger Na+ ion generally have both Na and Li versions of the same compound. For the close-packed AMPO(4) structures, our results show that Na generally prefers the maricite structure, while Li prefers the olivine structure, in agreement with previous experimental work. We also found surprising evidence that the barriers for Na+ migration can potentially be lower than that for Li+ migration in the layered structures. Overall, our findings indicate that Na-ion systems can be competitive with Li-ion systems.					Ong, Shyue/D-7573-2014; ma, xiaohua/E-6417-2012; Hautier, Geoffroy/GQP-2814-2022; Chevrier, Vincent/L-5025-2019; Ceder, Gerbrand/Y-2544-2019; Kim, Sangtae/F-5661-2012; Ong, Shyue Ping/B-4137-2008	Jain, Anubhav/0000-0001-5893-9967; Kim, Sangtae/0000-0002-7959-8249; Ong, Shyue Ping/0000-0001-5726-2587; Chevrier, Vincent/0000-0002-8725-0787													1754-5692	1754-5706				SEP	2011	4	9					3680	3688		10.1039/c1ee01782a	http://dx.doi.org/10.1039/c1ee01782a													WOS:000294306900068
J	Ding, YL; Alias, H; Wen, DS; Williams, RA				Ding, YL; Alias, H; Wen, DS; Williams, RA			Heat transfer of aqueous suspensions of carbon nanotubes (CNT nanofluids)	INTERNATIONAL JOURNAL OF HEAT AND MASS TRANSFER												This paper is mainly concerned about the heat transfer behaviour of aqueous suspensions of multi-walled carbon nanotubes (CNT nanofluids) flowing through a horizontal tube. Significant enhancement of the convective heat transfer is observed and the enhancement depends on the flow conditions (Reynolds number, Re), CNT concentration and the pH, with the effect of pH smallest. Given other conditions, the enhancement is a function of axial distance from the inlet, increasing first, reaching a maximum, and then decreasing with increasing axial distance. The axial position of the maximum enhancement increases with CNT concentration and Re. Given CNT concentration and the pH level, there appears to be a Re above which a big increase in the convective heat transfer coefficient occurs. Such a big increase seems to correspond to the shear thinning behaviour. For nanofluids containing 0.5 wt.% CNTs, the maximum enhancement reaches over 350% at Re = 800, which could not be attributed purely to the enhanced thermal conduction. Particle re-arrangement, shear induced thermal conduction enhancement, reduction of thermal boundary due to the presence of nanoparticles, as well as the very high aspect ratio of CNTs are proposed to be possible mechanisms. (c) 2005 Elsevier Ltd. All rights reserved.					Ding, Yulong/AAA-8358-2019; Williams, Richard/N-3398-2014; Wen, Dongsheng/A-5307-2010	Ding, Yulong/0000-0001-8490-5349; Wen, Dongsheng/0000-0003-3492-7982													0017-9310	1879-2189				JAN	2006	49	1-2					240	250		10.1016/j.ijheatmasstransfer.2005.07.009	http://dx.doi.org/10.1016/j.ijheatmasstransfer.2005.07.009													WOS:000235787600024
J	van de Vrande, V; de Jong, JPJ; Vanhaverbeke, W; de Rochemont, M				van de Vrande, Vareska; de Jong, Jeroen P. J.; Vanhaverbeke, Wim; de Rochemont, Maurice			Open innovation in SMEs: Trends, motives and management challenges	TECHNOVATION												Open innovation has so far been studied mainly in high-tech, Multinational enterprises. This exploratory paper investigates if open innovation practices are also applied by small- and medium-sized enterprises (SMEs). Drawing oil I database collected from 605 innovative SMEs in the Netherlands, we explore the incidence of and apparent trend towards open innovation. The survey furthermore focuses oil the motives and perceived challenges when SMEs adopt open innovation practices. Within the survey, open innovation is measured with eight innovation practices reflecting technology exploration and exploitation in SMEs. We find that the responding SMEs engage in many open innovation practices and have increasingly adopted such practices during the past 7 years. In addition. we find no major differences between manufacturing and services industries, but medium-sized firms are oil average more heavily involved in open innovation than their smaller counterparts. We furthermore find that SMEs Pursue open innovation primarily for market-related motives such as meeting customer demands, or keeping LIP with competitors. Their most important challenges relate to organizational and Cultural issues as a consequence of dealing with increased external contacts. (C) 2008 Elsevier Ltd. All rights reserved.					van de Vrande, Vareska/AAK-1846-2020; de Jong, Peter/E-9095-2014; Vanhaverbeke, Wim/C-6367-2011	van de Vrande, Vareska/0000-0001-9551-2794; de Jong, Jeroen/0000-0002-2369-5744; Vanhaverbeke, Wim/0000-0002-5710-4738													0166-4972	1879-2383				JUN-JUL	2009	29	6-7					423	437		10.1016/j.technovation.2008.10.001	http://dx.doi.org/10.1016/j.technovation.2008.10.001													WOS:000266760900003
J	Win, KY; Feng, SS				Win, KY; Feng, SS			Effects of particle size and surface coating on cellular uptake of polymeric nanoparticles for oral delivery of anticancer drugs	BIOMATERIALS												This study evaluated cellular uptake of polymeric nanoparticles by using Caco-2 cells, a human colon adenocarcinoma cell line, as an in vitro model with the aim to apply nanoparticles of biodegradable polymers for oral chemotherapy. The feasibility was demonstrated by showing the localization and quantification of the cell uptake of fluorescent polystyrene nanoparticles of standard size and poly(lactic-co-glycolic acid) (PLGA) nanoparticles coated with polyvinyl alcohol (PVA) or vitamin E TPGS. Coumarin-6 loaded PLGA nanoparticles were prepared by a modified solvent extraction/evaporation method and characterized by laser light scattering for size and size distribution, scanning electron microscopy (SEM) for surface morphology, zeta-potential for surface charge, and spectrofluorometry for fluorescent molecule release from the nanoparticles. The effects of particle size and particle surface coating on the cellular uptake of the nanoparticles were quantified by spectrofluorometric measurement. Cellular uptake of vitamin E TPGS-coated PLGA nanoparticles showed 1.4 folds higher than that of PVA-coated PLGA nanoparticles and 4-6 folds higher than that of nude polystyrene nanoparticles. Images of confocal laser scanning microscopy, cryo-SEM and transmission electron microscopy clearly evidenced the internalization of nanoparticles by the Caco-2 cells, showing that surface modification of PLGA nanoparticles with vitamin E TPGS notably improved the cellular uptake. It is highly feasible for nanoparticles of biodegradable polymers to be applied to promote oral chemotherapy. (C) 2004 Elsevier Ltd. All rights reserved.						Win, Khin Yin/0000-0002-8306-942X													0142-9612	1878-5905				MAY	2005	26	15					2713	2722		10.1016/j.biomaterials.2004.07.050	http://dx.doi.org/10.1016/j.biomaterials.2004.07.050								15585275					WOS:000226698400055
J	Bartlett, MS; Movellan, JR; Sejnowski, TJ				Bartlett, MS; Movellan, JR; Sejnowski, TJ			Face recognition by independent component analysis	IEEE TRANSACTIONS ON NEURAL NETWORKS												A number of current face recognition algorithms use face representations found by unsupervised statistical methods. Typically these methods find a set of basis images and represent faces as a linear combination of those images. Principal component analysis (PCA) is a popular example of such methods. The basis images found by PCA depend only on pairwise relationships between pixels in the image database. In a task such as face recognition, in which important information may be contained in the high-order relationships among pixels, it seems reasonable to expect that better basis images may be found by methods sensitive to. these high-order statistics. Independent component analysis (ICA), a generalization of PCA, is one such method. We used a version of ICA derived from the principle of optimal information transfer through sigmoidal neurons. ICA was performed on face images in the FERET database under two different architectures, one which treated the images as random variables and the pixels as outcomes, and a second which treated the pixels as random variables and the images as outcomes. The first architecture found spatially local basis images for the faces. The second architecture produced a factorial face code. Both ICA representations were superior to representations based on PCA for recognizing faces across days and changes in expression. A classifier that combined the two ICA representations gave the best performance.					Sejnowski, Terrence/AAV-5558-2021														1045-9227	1941-0093				NOV	2002	13	6					1450	1464		10.1109/TNN.2002.804287	http://dx.doi.org/10.1109/TNN.2002.804287								18244540					WOS:000179415900016
J	Englehart, K; Hudgins, B				Englehart, K; Hudgins, B			A robust, real-time control scheme for multifunction myoelectric control	IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING												This paper represents an ongoing investigation of dexterous and natural control of upper extremity prostheses using the myoelectric signal (MES). The scheme described within uses pattern recognition to process four channels of MES, with the task of discriminating multiple classes of limb movement. The method does not require segmentation of the MES data, allowing a continuous stream of class decisions to be delivered to a prosthetic device. It is shown in this paper that, by exploiting the processing power inherent in current computing systems, substantial gains in classifier accuracy and, response time are possible. Other important characteristics for prosthetic control systems are met as well. Due to the fact that the classifier learns the muscle activation patterns for each desired class for each individual, a natural control actuation results. The continuous decision stream allows complex sequences of manipulation involving multiple joints to be performed without interruption. Finally, minimal storage capacity is required, which is an important factor in embedded control systems.						Englehart, Kevin/0000-0003-4525-1121													0018-9294	1558-2531				JUL	2003	50	7					848	854		10.1109/TBME.2003.813539	http://dx.doi.org/10.1109/TBME.2003.813539								12848352					WOS:000183601100006
J	Hagiwara, M; Akagi, H				Hagiwara, Makoto; Akagi, Hirofumi			Control and Experiment of Pulsewidth-Modulated Modular Multilevel Converters	IEEE TRANSACTIONS ON POWER ELECTRONICS												A modular multilevel converter (MMC) is one of the next-generation multilevel converters intended for high- or medium-voltage power conversion without transformers. The MMC is based on cascade connection of multiple bidirectional chopper-cells per leg, thus requiring voltage-balancing control of the multiple floating dc capacitors. However, no paper has made an explicit discussion on voltage-balancing control with theoretical and experimental verifications. This paper deals with two types of pulsewidth-modulated modular multilevel converters (PWM-MMCs) with focus on their circuit configurations and voltage-balancing control. Combination of averaging and balancing controls enables the PWM-MMCs to achieve voltage balancing without any external circuit. The viability of the PWM-MMCs, as well as the effectiveness of the voltage-balancing control, is confirmed by simulation and experiment.																			0885-8993	1941-0107				JUL	2009	24	7					1737	1746		10.1109/TPEL.2009.2014236	http://dx.doi.org/10.1109/TPEL.2009.2014236													WOS:000268377700008
J	Gandomi, AH; Yang, XS; Alavi, AH				Gandomi, Amir Hossein; Yang, Xin-She; Alavi, Amir Hossein			Cuckoo search algorithm: a metaheuristic approach to solve structural optimization problems	ENGINEERING WITH COMPUTERS												In this study, a new metaheuristic optimization algorithm, called cuckoo search (CS), is introduced for solving structural optimization tasks. The new CS algorithm in combination with L,vy flights is first verified using a benchmark nonlinear constrained optimization problem. For the validation against structural engineering optimization problems, CS is subsequently applied to 13 design problems reported in the specialized literature. The performance of the CS algorithm is further compared with various algorithms representative of the state of the art in the area. The optimal solutions obtained by CS are mostly far better than the best solutions obtained by the existing methods. The unique search features used in CS and the implications for future research are finally discussed in detail.					Gandomi, Amir/J-7595-2013; Hamza, Mukhtar/V-2602-2019; Alavi, Amir H./Q-7017-2019	Yang, Xin-She/0000-0002-1689-2002; Alavi, Amir H./0000-0002-7593-8509													0177-0667	1435-5663				JAN	2013	29	1					17	35		10.1007/s00366-011-0241-y	http://dx.doi.org/10.1007/s00366-011-0241-y													WOS:000313017200002
J	Bhat, SP; Bernstein, DS				Bhat, SP; Bernstein, DS			Geometric homogeneity with applications to finite-time stability	MATHEMATICS OF CONTROL SIGNALS AND SYSTEMS												This paper studies properties of homogeneous systems in a geometric, coordinate-free setting. A key contribution of this paper is a result relating regularity properties of a homogeneous function to its degree of homogeneity and the local behavior of the dilation near the origin. This result makes it possible to extend previous results on homogeneous systems to the geometric framework. As an application of our results, we consider finite-time stability of homogeneous systems. The main result that links homogeneity and finite-time stability is that a homogeneous system is finite-time stable if and only if it is asymptotically stable and has a negative degree of homogeneity. We also show that the assumption of homogeneity leads to stronger properties for finite-time stable systems.						Bhat, Sanjay/0000-0002-8595-6081													0932-4194	1435-568X				JUN	2005	17	2					101	127		10.1007/s00498-005-0151-x	http://dx.doi.org/10.1007/s00498-005-0151-x													WOS:000229940400002
J	Dinh, HT; Lee, C; Niyato, D; Wang, P				Dinh, Hoang T.; Lee, Chonho; Niyato, Dusit; Wang, Ping			A survey of mobile cloud computing: architecture, applications, and approaches	WIRELESS COMMUNICATIONS & MOBILE COMPUTING												Together with an explosive growth of the mobile applications and emerging of cloud computing concept, mobile cloud computing (MCC) has been introduced to be a potential technology for mobile services. MCC integrates the cloud computing into the mobile environment and overcomes obstacles related to the performance (e.g., battery life, storage, and bandwidth), environment (e.g., heterogeneity, scalability, and availability), and security (e.g., reliability and privacy) discussed in mobile computing. This paper gives a survey of MCC, which helps general readers have an overview of the MCC including the definition, architecture, and applications. The issues, existing solutions, and approaches are presented. In addition, the future research directions of MCC are discussed. Copyright (c) 2011 John Wiley & Sons, Ltd.					Dinh, Hoang/I-1910-2018; Niyato, Dusit/Y-2769-2019; Wang, Ping/A-3697-2011	Niyato, Dusit/0000-0002-7442-7416; Dinh, Hoang/0000-0002-9528-0863													1530-8669	1530-8677				DEC 25	2013	13	18					1587	1611		10.1002/wcm.1203	http://dx.doi.org/10.1002/wcm.1203													WOS:000327254900001
J	Goferman, S; Zelnik-Manor, L; Tal, A				Goferman, Stas; Zelnik-Manor, Lihi; Tal, Ayellet			Context-Aware Saliency Detection	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												We propose a new type of saliency-context-aware saliency-which aims at detecting the image regions that represent the scene. This definition differs from previous definitions whose goal is to either identify fixation points or detect the dominant object. In accordance with our saliency definition, we present a detection algorithm which is based on four principles observed in the psychological literature. The benefits of the proposed approach are evaluated in two applications where the context of the dominant objects is just as essential as the objects themselves. In image retargeting, we demonstrate that using our saliency prevents distortions in the important regions. In summarization, we show that our saliency helps to produce compact, appealing, and informative summaries.																			0162-8828	1939-3539				OCT	2012	34	10					1915	1926		10.1109/TPAMI.2011.272	http://dx.doi.org/10.1109/TPAMI.2011.272								22201056					WOS:000307522700004
J	Boucart, K; Ionescu, AM				Boucart, Kathy; Mihai Ionescu, Adrian			Double-gate tunnel FET with high-κ gate dielectric	IEEE TRANSACTIONS ON ELECTRON DEVICES												In this paper, we propose and validate a novel design for a double-gate tunnel field-effect transistor (DG Tunnel FET), for which the simulations show significant improvements compared with single-gate devices using an SiO2 gate dielectric. For the first time, DG Tunnel FET devices, which are using a high-kappa gate dielectric, are explored using realistic design parameters, showing an ON-current as high as 0.23 mA for a gate voltage of 1.8 V, an OFF-current of less than 1 fA (neglecting gate leakage), an improved average subthreshold swing of 57 mV/dec, and a minimum point slope of 11 mV/dec. The 2-D nature of Tunnel FET current flow is studied, demonstrating that the current is not confined to a channel at the gate-dielectric surface. When varying temperature, Tunnel FETs with a high-kappa gate dielectric have a smaller threshold voltage shift than those Using SiO2, while the subthreshold slope for fixed values of V-g remains nearly unchanged, in contrast with the traditional MOSFET. Moreover, an I-on/I-off ratio of more than 2 x 10(11) is shown for simulated devices with a gate length (over the intrinsic region) of 50 nm, which indicates that the Tunnel FET is a promising candidate to achieve better-than-ITRS low-standby-power switch performance.					Ionescu, Adrian/A-9014-2010														0018-9383	1557-9646				JUL	2007	54	7					1725	1733		10.1109/TED.2007.899389	http://dx.doi.org/10.1109/TED.2007.899389													WOS:000247643800019
J	Sheen, DM; McMakin, DL; Hall, TE				Sheen, DM; McMakin, DL; Hall, TE			Three-dimensional millimeter-wave imaging for concealed weapon detection	IEEE TRANSACTIONS ON MICROWAVE THEORY AND TECHNIQUES												Millimeter-wave imaging techniques and systems have been developed at the Pacific Northwest National Laboratory (PNNL), Richland, WA, for the detection of concealed weapons and contraband at airports and other secure locations. These techniques were derived from microwave holography techniques that utilize phase and amplitude information recorded over a two-dimensional aperture to reconstruct a focused image of the target. Millimeter-wave imaging is well suited for the detection of concealed weapons or other contraband carried on personnel since millimeter-waves are nonionizing, readily penetrate common clothing material, and are reflected from the human body and any concealed items. In this paper, a wide-bandwidth three-dimensional holographic microwave imaging technique is described. Practical weapon detection systems for airport or other high-throughput applications require high-speed scanning on the order of 3 to 10 s. To achieve this goal, a prototype imaging system utilizing a 27-33 GHz linear sequentially switched array and a high-speed linear scanner has been developed and tested. This system is described in detail along with numerous imaging results.																			0018-9480					SEP	2001	49	9					1581	1592		10.1109/22.942570	http://dx.doi.org/10.1109/22.942570													WOS:000170643600011
J	Merkel, TC; Lin, HQ; Wei, XT; Baker, R				Merkel, Tim C.; Lin, Haiqing; Wei, Xiaotong; Baker, Richard			Power plant post-combustion carbon dioxide capture: An opportunity for membranes	JOURNAL OF MEMBRANE SCIENCE												Carbon dioxide capture from power plant flue gas and subsequent sequestration is expected to play a key role in mitigating global climate change. Conventional amine technologies being considered for separating CO2 from flue gas are costly, energy intensive, and if implemented, would result in large increases in the cost of producing electricity. Membranes offer potential as an energy-efficient, low-cost CO2 capture option. Recently, working with the U.S. Department of Energy (DOE), we have developed membranes with CO2 permeances of greater than 1000 gpu and a CO2/N-2 selectivity of 50 at 30 degrees C. This permeance is ten times higher than commercial CO2 membranes and the selectivity is among the highest reported for non-facilitated transport materials. These membranes, in combination with a novel process design that uses incoming combustion air as a sweep gas to generate driving force, could meet DOE CO2 capture cost targets. Under these conditions, improving membrane permeance is more important than increasing selectivity to further reduce the cost of CO2 capture from flue gas. Membrane cost and reliability issues will be key to the eventual competitiveness of this technology for flue gas treatment. (C) 2009 Elsevier B.V. All rights reserved.					Lin, Haiqing/K-3181-2013	Lin, Haiqing/0000-0001-8042-154X													0376-7388	1873-3123				SEP 1	2010	359	1-2			SI		126	139		10.1016/j.memsci.2009.10.041	http://dx.doi.org/10.1016/j.memsci.2009.10.041													WOS:000279953300015
J	Cai, HY; Zheng, VW; Chang, KCC				Cai, HongYun; Zheng, Vincent W.; Chang, Kevin Chen-Chuan			A Comprehensive Survey of Graph Embedding: Problems, Techniques, and Applications	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING												Graph is an important data representation which appears in a wide diversity of real-world scenarios. Effective graph analytics provides users a deeper understanding of what is behind the data, and thus can benefit a lot of useful applications such as node classification, node recommendation, link prediction, etc. However, most graph analytics methods suffer the high computation and space cost. Graph embedding is an effective yet efficient way to solve the graph analytics problem. It converts the graph data into a low dimensional space in which the graph structural information and graph properties are maximumly preserved. In this survey, we conduct a comprehensive review of the literature in graph embedding. We first introduce the formal definition of graph embedding as well as the related concepts. After that, we propose two taxonomies of graph embedding which correspond to what challenges exist in different graph embedding problem settings and how the existing work addresses these challenges in their solutions. Finally, we summarize the applications that graph embedding enables and suggest four promising future research directions in terms of computation efficiency, problem settings, techniques, and application scenarios.						Cai, Hongyun/0000-0001-5853-2841													1041-4347	1558-2191				SEP 1	2018	30	9					1616	1637		10.1109/TKDE.2018.2807452	http://dx.doi.org/10.1109/TKDE.2018.2807452													WOS:000440853500001
J	Sigmund, O				Sigmund, Ole			Morphology-based black and white filters for topology optimization	STRUCTURAL AND MULTIDISCIPLINARY OPTIMIZATION												To ensure manufacturability and mesh independence in density-based topology optimization schemes, it is imperative to use restriction methods. This paper introduces a new class of morphology-based restriction schemes that work as density filters; that is, the physical stiffness of an element is based on a function of the design variables of the neighboring elements. The new filters have the advantage that they eliminate grey scale transitions between solid and void regions. Using different test examples, it is shown that the schemes, in general, provide black and white designs with minimum length-scale constraints on either or both minimum hole sizes and minimum structural feature sizes. The new schemes are compared with methods and modified methods found in the literature.					Sigmund, Ole/A-5354-2008	Sigmund, Ole/0000-0003-0344-7249													1615-147X	1615-1488				APR	2007	33	4-5					401	424		10.1007/s00158-006-0087-x	http://dx.doi.org/10.1007/s00158-006-0087-x													WOS:000244689200010
J	Graves, A; Liwicki, M; Fernández, S; Bertolami, R; Bunke, H; Schmidhuber, R				Graves, Alex; Liwicki, Marcus; Fernandez, Santiago; Bertolami, Roman; Bunke, Horst; Schmidhuber, Juergen			A Novel Connectionist System for Unconstrained Handwriting Recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Recognizing lines of unconstrained handwritten text is a challenging task. The difficulty of segmenting cursive or overlapping characters, combined with the need to exploit surrounding context, has led to low recognition rates for even the best current recognizers. Most recent progress in the field has been made either through improved preprocessing or through advances in language modeling. Relatively little work has been done on the basic recognition algorithms. Indeed, most systems rely on the same hidden Markov models that have been used for decades in speech and handwriting recognition, despite their well-known shortcomings. This paper proposes an alternative approach based on a novel type of recurrent neural network, specifically designed for sequence labeling tasks where the data is hard to segment and contains long-range bidirectional interdependencies. In experiments on two large unconstrained handwriting databases, our approach achieves word recognition accuracies of 79.7 percent on online data and 74.1 percent on offline data, significantly outperforming a state-of-the-art HMM-based system. In addition, we demonstrate the network's robustness to lexicon size, measure the individual influence of its hidden layers, and analyze its use of context. Last, we provide an in-depth discussion of the differences between the network and HMMs, suggesting reasons for the network's superior performance.					Liwicki, Marcus/D-5572-2014														0162-8828	1939-3539				MAY	2009	31	5					855	868		10.1109/TPAMI.2008.137	http://dx.doi.org/10.1109/TPAMI.2008.137								19299860					WOS:000264144500007
J	Patwari, N; Hero, AO; Perkins, M; Correal, NS; O'Dea, RJ				Patwari, N; Hero, AO; Perkins, M; Correal, NS; O'Dea, RJ			Relative location estimation in wireless sensor networks	IEEE TRANSACTIONS ON SIGNAL PROCESSING												Self-configuration in wireless sensor networks is a general class of estimation problems that we study via the Cramer-Rao bound (CRB). Specifically, we consider sensor location estimation when sensors measure received signal strength (RSS) or time-of-arrival (TOA) between themselves and neighboring sensors. A small fraction of sensors in the network have a known location, whereas the remaining locations must be estimated. We derive CRBs and maximum-likelihood estimators (MLEs) under Gaussian and log-normal models for the TOA and RSS measurements, respectively. An extensive TOA and RSS measurement campaign in an indoor office area illustrates MLE performance. Finally, relative location estimation algorithms are implemented in a wireless sensor network testbed and deployed in indoor and outdoor environments. The measurements and testbed experiments demonstrate 1-m RMS location errors using TOA, and 1- to 2-m RMS location errors using RSS.					Patwari, Neal/C-7949-2009	Hero, Alfred/0000-0002-2531-9670; Patwari, Neal/0000-0003-3440-2043													1053-587X	1941-0476				AUG	2003	51	8					2137	2148		10.1109/TSP.2003.814469	http://dx.doi.org/10.1109/TSP.2003.814469													WOS:000184090200011
J	Grossglauser, M; Tse, DNC				Grossglauser, M; Tse, DNC			Mobility increases the capacity of ad hoc wireless networks	IEEE-ACM TRANSACTIONS ON NETWORKING												The capacity of ad hoe wireless networks is constrained by the mutual interference of concurrent transmissions between nodes. We study A model of an ad hoe network where n nodes communicate in random, source-destination pairs. These nodes are assumed to be mobile. We examine the per-session throughput for applications with loose delay constraints,. such that the topology changes over the time-scale of packet delivery. Under this assumption, the per-user throughput can increase dramatically when nodes. are mobile rather than fixed. This improvement can be achieved by exploiting a form of multiuser diversity via packet relaying.																			1063-6692					AUG	2002	10	4					477	486		10.1109/TNET.2002.801403	http://dx.doi.org/10.1109/TNET.2002.801403													WOS:000177635200004
J	Xu, X				Xu, Xun			From cloud computing to cloud manufacturing	ROBOTICS AND COMPUTER-INTEGRATED MANUFACTURING												Cloud computing is changing the way industries and enterprises do their businesses in that dynamically scalable and virtualized resources are provided as a service over the Internet. This model creates a brand new opportunity for enterprises. In this paper, some of the essential features of cloud computing are briefly discussed with regard to the end-users, enterprises that use the cloud as a platform, and cloud providers themselves. Cloud computing is emerging as one of the major enablers for the manufacturing industry; it can transform the traditional manufacturing business model, help it to align product innovation with business strategy, and create intelligent factory networks that encourage effective collaboration. Two types of cloud computing adoptions in the manufacturing sector have been suggested, manufacturing with direct adoption of cloud computing technologies and cloud manufacturing the manufacturing version of cloud computing. Cloud computing has been in some of key areas of manufacturing such as IT, pay-as-you-go business models, production scaling up and down per demand, and flexibility in deploying and customizing solutions. In cloud manufacturing, distributed resources are encapsulated into cloud services and managed in a centralized way. Clients can use cloud services according to their requirements. Cloud users can request services ranging from product design, manufacturing, testing, management, and all other stages of a product life cycle. (C) 2011 Elsevier Ltd. All rights reserved.					Xu, Xun/K-7899-2015	Xu, Xun/0000-0001-6294-8153													0736-5845	1879-2537				FEB	2012	28	1					75	86		10.1016/j.rcim.2011.07.002	http://dx.doi.org/10.1016/j.rcim.2011.07.002													WOS:000296117200008
J	Cho, GC; Dodds, J; Santamarina, JC				Cho, GC; Dodds, J; Santamarina, JC			Particle shape effects on packing density, stiffness, and strength: Natural and crushed sands	JOURNAL OF GEOTECHNICAL AND GEOENVIRONMENTAL ENGINEERING												The size and shape of soil particles reflect the formation history of the grains. In turn, the macroscale behavior of the soil mass results from particle level interactions which are affected by particle shape. Sphericity, roundness, and smoothness characterize different scales associated with particle shape. New experimental data and results from published studies are gathered into two databases to explore the effects of particle shape on packing density and on the small-to-large strain mechanical properties of sandy soils. In agreement with previous studies, these data confirm that increased angularity or eccentricity produces an increase in e(max) and e(min). Furthermore, the data show that increasing particle irregularity causes a decrease in stiffness yet heightened sensitivity to the state of stress, an increase in compressibility under zero-lateral strain loading; an increase in the critical state friction angle 4,,; and an increase in the interceptor of the critical state line (there is a weak effect on the slope X). Therefore, particle shape emerges as a significant soil index property that needs to be properly characterized and documented, particularly in clean sands and gravels. The systematic assessment of particle shape will lead to a better understanding of sand behavior.					Cho, Gye-Chun/C-1600-2011; Santamarina, J./ABF-6381-2020	Santamarina, J. Carlos/0000-0001-8708-2827													1090-0241	1943-5606				MAY	2006	132	5					591	602		10.1061/(ASCE)1090-0241(2006)132:5(591)	http://dx.doi.org/10.1061/(ASCE)1090-0241(2006)132:5(591)													WOS:000236988000004
J	Cassman, KG; Dobermann, A; Walters, DT				Cassman, KG; Dobermann, A; Walters, DT			Agroecosystems, nitrogen-use efficiency, and nitrogen management	AMBIO					2nd International Nitrogen Conference	OCT, 2001	POTOMAC, MD					The global challenge of meeting increased food demand and protecting environmental quality will be won or lost in cropping systems that produce maize, rice, and wheat . Achieving synchrony between N supply and crop demand without excess or deficiency is the key to optimizing trade-offs amongst yield, profit, and environmental protection in both large-scale systems in developed countries and small-scale systems in developing countries. Setting the research agenda and developing effective policies to meet this challenge requires quantitative understanding of current levels of N-use efficiency and losses in these systems, the biophysical controls on these factors, and the economic returns from adoption of improved management practices. Although advances in basic biology, ecology, and biogeochemistry can provide answers, the magnitude of the scientific challenge should not be underestimated because it becomes increasingly difficult to control the fate of N in cropping systems that must sustain yield increases on the world's limited supply of productive farm land.					Cassman, Kenneth/C-3646-2019	Dobermann, Achim/0000-0001-5728-5594													0044-7447	1654-7209				MAR	2002	31	2					132	140		10.1639/0044-7447(2002)031[0132:ANUEAN]2.0.CO;2	http://dx.doi.org/10.1639/0044-7447(2002)031[0132:ANUEAN]2.0.CO;2								12078002					WOS:000175937500012
J	Boretti, A; Rosa, L				Boretti, Alberto; Rosa, Lorenzo			Reassessing the projections of the World Water Development Report	NPJ CLEAN WATER												The 2018 edition of the United Nations World Water Development Report stated that nearly 6 billion peoples will suffer from clean water scarcity by 2050. This is the result of increasing demand for water, reduction of water resources, and increasing pollution of water, driven by dramatic population and economic growth. It is suggested that this number may be an underestimation, and scarcity of clean water by 2050 may be worse as the effects of the three drivers of water scarcity, as well as of unequal growth, accessibility and needs, are underrated. While the report promotes the spontaneous adoption of nature-based-solutions within an unconstrained population and economic expansion, there is an urgent need to regulate demography and economy, while enforcing clear rules to limit pollution, preserve aquifers and save water, equally applying everywhere. The aim of this paper is to highlight the inter-linkage in between population and economic growth and water demand, resources and pollution, that ultimately drive water scarcity, and the relevance of these aspects in local, rather than global, perspective, with a view to stimulating debate.					Boretti, Alberto/S-8109-2019; Rosa, Lorenzo/B-7728-2012	Rosa, Lorenzo/0000-0002-9210-5680; /0000-0002-3374-0238													2059-7037					JUL 31	2019	2								15	10.1038/s41545-019-0039-9	http://dx.doi.org/10.1038/s41545-019-0039-9													WOS:000479290500001
J	El Ayadi, M; Kamel, MS; Karray, F				El Ayadi, Moataz; Kamel, Mohamed S.; Karray, Fakhri			Survey on speech emotion recognition: Features, classification schemes, and databases	PATTERN RECOGNITION												Recently, increasing attention has been directed to the study of the emotional content of speech signals, and hence, many systems have been proposed to identify the emotional content of a spoken utterance. This paper is a survey of speech emotion classification addressing three important aspects of the design of a speech emotion recognition system. The first one is the choice of suitable features for speech representation. The second issue is the design of an appropriate classification scheme and the third issue is the proper preparation of an emotional speech database for evaluating system performance. Conclusions about the performance and limitations of current speech emotion recognition systems are discussed in the last section of this survey. This section also suggests possible ways of improving speech emotion recognition systems. (C) 2010 Elsevier Ltd. All rights reserved.					Kamel, Mohamed/D-9323-2011; Karray, Fakhri/A-2824-2010	Kamel, Mohamed/0000-0001-6173-8082													0031-3203	1873-5142				MAR	2011	44	3					572	587		10.1016/j.patcog.2010.09.020	http://dx.doi.org/10.1016/j.patcog.2010.09.020													WOS:000285233300007
J	Stojanovic, M; Preisig, J				Stojanovic, Milica; Preisig, James			Underwater Acoustic Communication Channels: Propagation Models and Statistical Characterization	IEEE COMMUNICATIONS MAGAZINE												Acoustic propagation is characterized by three major factors: attenuation that increases with signal frequency, time-varying multipath propagation, and low speed of sound (1500 m/s). The background noise, although often characterized as Gaussian, is not white, but has a decaying power spectral density. The channel capacity depends on the distance, and may be extremely limited. Because acoustic propagation is best supported at low frequencies, although the total available bandwidth may be low, an acoustic communication system is inherently wideband in the sense that the bandwidth is not negligible with respect to its center frequency. The channel can have a sparse impulse response, where each physical path acts as a time-varying low-pass filter, and motion introduces additional Doppler spreading and shifting. Surface waves, internal turbulence, fluctuations in the sound speed, and other small-scale phenomena contribute to random signal variations. At this time, there are no standardized models for the acoustic channel fading, and experimental measurements are often made to assess the statistical properties of the channel in particular deployment sites.						Preisig, James/0000-0002-7066-8474													0163-6804	1558-1896				JAN	2009	47	1					84	89		10.1109/MCOM.2009.4752682	http://dx.doi.org/10.1109/MCOM.2009.4752682													WOS:000262557400013
J	Digham, FF; Alouini, MS; Simon, MK				Digham, Fadel F.; Alouini, Mohamed-Slim; Simon, Marvin K.			On the energy detection of unknown signals over fading channels	IEEE TRANSACTIONS ON COMMUNICATIONS					IEEE International Conference on Communications (ICC 2003)	MAY 11-15, 2003	ANCHORAGE, AK	IEEE				This letter addresses the problem of energy detection of an unknown signal over a multipath channel. It starts with the no-diversity case, and presents some alternative closed-form expressions for the probability of detection to those recently reported in the literature. Detection capability is boosted by implementing both square-law combining and square-law selection diversity schemes.					Simon, Marvin/GPT-0009-2022; Alouini, Mohamed-Slim/I-2658-2018	Alouini, Mohamed-Slim/0000-0003-4827-1793													0090-6778	1558-0857				JAN	2007	55	1					21	24		10.1109/TCOMM.2006.887483	http://dx.doi.org/10.1109/TCOMM.2006.887483													WOS:000243952900004
J	Liu, T; Yuan, ZJ; Sun, JA; Wang, JD; Zheng, NN; Tang, XO; Shum, HY				Liu, Tie; Yuan, Zejian; Sun, Jian; Wang, Jingdong; Zheng, Nanning; Tang, Xiaoou; Shum, Heung-Yeung			Learning to Detect a Salient Object	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												In this paper, we study the salient object detection problem for images. We formulate this problem as a binary labeling task where we separate the salient object from the background. We propose a set of novel features, including multiscale contrast, center-surround histogram, and color spatial distribution, to describe a salient object locally, regionally, and globally. A conditional random field is learned to effectively combine these features for salient object detection. Further, we extend the proposed approach to detect a salient object from sequential images by introducing the dynamic salient features. We collected a large image database containing tens of thousands of carefully labeled images by multiple users and a video segment database, and conducted a set of experiments over them to demonstrate the effectiveness of the proposed approach.					Liu, Tie/JXX-0080-2024; Wang, Jingdong/E-9920-2017	Wang, Jingdong/0000-0002-4888-4445													0162-8828	1939-3539				FEB	2011	33	2					353	367		10.1109/TPAMI.2010.70	http://dx.doi.org/10.1109/TPAMI.2010.70								21193811					WOS:000285313200011
J	Divya, KC; Ostergaard, J				Divya, K. C.; Ostergaard, Jacob			Battery energy storage technology for power systems-An overview	ELECTRIC POWER SYSTEMS RESEARCH												The penetration of renewable sources (particularly wind power) in to the power system network has been increasing in the recent years. As a result of this, there have been serious concerns over reliable and satisfactory operation of the power systems. One of the solutions being proposed to improve the reliability and performance of these systems is to integrate energy storage devices into the power system network. Further, in the present deregulated markets these storage devices could also be used to increase the profit margins of wind farm owners and even provide arbitrage. This paper discusses the present status of battery energy storage technology and methods of assessing their economic viability and impact on power system operation. Further, a discussion on the role of battery storage systems of electric hybrid vehicles in power system storage technologies had been made. Finally, the paper suggests a likely future outlook for the battery technologies and the electric hybrid vehicles in the context of power system applications. (C) 2008 Elsevier B.V. All rights reserved.					Ostergaard, Jacob/F-4434-2012; Mathiesen, Brian Vad/E-3551-2016	Ostergaard, Jacob/0000-0002-9416-2857; Mathiesen, Brian Vad/0000-0003-3917-1184													0378-7796	1873-2046				APR	2009	79	4					511	520		10.1016/j.epsr.2008.09.017	http://dx.doi.org/10.1016/j.epsr.2008.09.017													WOS:000264009100002
J	Shrestha, S; Kazama, F				Shrestha, S.; Kazama, F.			Assessment of surface water quality using multivariate statistical techniques: A case study of the Fuji river basin, Japan	ENVIRONMENTAL MODELLING & SOFTWARE					International Symposium on Environment Software System	MAY 18-21, 2004	James Madison Univ, Harrisonburg, VA		James Madison Univ			Multivariate statistical techniques, such as cluster analysis (CA), principal component analysis (PCA), factor analysis (FA) and discriminant analysis (DA), were applied for the evaluation of temporal/spatial variations and the interpretation of a large complex water quality data set of the Fuji river basin, generated during 8 years (1995-2002) monitoring of 12 parameters at 13 different sites (14 976 observations). Hierarchical cluster analysis grouped 13 sampling sites into three clusters, i.e., relatively less polluted (LP), medium polluted (MP) and highly polluted (HP) sites, based on the similarity of water quality characteristics. Factor analysis/principal component analysis, applied to the data sets of the three different groups obtained from cluster analysis, resulted in five, five and three latent factors explaining 73.18, 77.61 and 65.39% of the total variance in water quality data sets of LP, MP and HP areas, respectively. The varifactors obtained from factor analysis indicate that the param eters responsible for water quality variations are mainly related to discharge and temperature (natural), organic pollution (point source: domestic wastewater) in relatively less polluted areas; organic pollution (point source: domestic wastewater) and nutrients (non-point sources: agriculture and orchard plantations) in medium polluted areas; and organic pollution and nutrients (point sources: domestic wastewater, wastewater treatment plants and industries) in highly polluted areas in the basin. Discriminant analysis gave the best results for both spatial and temporal analysis. It provided an important data reduction as it uses only six parameters (discharge, temperature, dissolved oxygen, biochemical oxygen demand, electrical conductivity and nitrate nitrogen), affording more than 85% correct assignations in temporal analysis, and seven parameters (discharge, temperature, biochemical oxygen demand, pH, electrical conductivity, nitrate nitrogen and ammonical nitrogen), affording more than 81% correct assignations in spatial analysis, of three different sampling sites of the basin. Therefore, DA allowed a reduction in the dimensionality of the large data set, delineating a few indicator parameters responsible for large variations in water quality. Thus, this study illustrates the usefulness of multivariate statistical techniques for analysis and interpretation of complex data sets, and in water quality assessment, identification of pollution sources/factors and understanding temporal/spatial variations in water quality for effective river water quality management. (c) 2006 Elsevier Ltd. All rights reserved.						Shrestha, Sangam/0000-0002-4972-3969													1364-8152	1873-6726				APR	2007	22	4			SI		464	475		10.1016/j.envsoft.2006.02.001	http://dx.doi.org/10.1016/j.envsoft.2006.02.001													WOS:000243487800008
J	Holmberg, K; Erdemir, A				Holmberg, Kenneth; Erdemir, Ali			Influence of tribology on global energy consumption, costs and emissions	FRICTION					6th World Tribology Congress (WTC)	SEP 17-22, 2017	Chinese Tribol Inst, Beijing, PEOPLES R CHINA	Tsinghua Univ, State Key Lab Tribol	Chinese Tribol Inst			Calculations of the impact of friction and wear on energy consumption, economic expenditure, and CO2 emissions are presented on a global scale. This impact study covers the four main energy consuming sectors: transportation, manufacturing, power generation, and residential. Previously published four case studies on passenger cars, trucks and buses, paper machines and the mining industry were included in our detailed calculations as reference data in our current analyses. The following can be concluded: In total, similar to 23% (119 EJ) of the world's total energy consumption originates from tribological contacts. Of that 20% (103 EJ) is used to overcome friction and 3% (16 EJ) is used to remanufacture worn parts and spare equipment due to wear and wear-related failures. By taking advantage of the new surface, materials, and lubrication technologies for friction reduction and wear protection in vehicles, machinery and other equipment worldwide, energy losses due to friction and wear could potentially be reduced by 40% in the long term (15 years) and by 18% in the short term (8 years). On global scale, these savings would amount to 1.4% of the GDP annually and 8.7% of the total energy consumption in the long term. The largest short term energy savings are envisioned in transportation (25%) and in the power generation (20%) while the potential savings in the manufacturing and residential sectors are estimated to be similar to 10%. In the longer terms, the savings would be 55%, 40%, 25%, and 20%, respectively. Implementing advanced tribological technologies can also reduce the CO2 emissions globally by as much as 1,460 MtCO(2) and result in 450,000 million Euros cost savings in the short term. In the longer term, the reduction can be 3,140 MtCO(2) and the cost savings 970,000 million Euros. Fifty years ago, wear and wear-related failures were a major concern for UK industry and their mitigation was considered to be the major contributor to potential economic savings by as much as 95% in ten years by the development and deployment of new tribological solutions. The corresponding estimated savings are today still of the same orders but the calculated contribution to cost reduction is about 74% by friction reduction and to 26% from better wear protection. Overall, wear appears to be more critical than friction as it may result in catastrophic failures and operational breakdowns that can adversely impact productivity and hence cost.					Erdemir, Ali/AAF-9422-2019; Erdemir, Ali/P-7643-2018	Erdemir, Ali/0000-0002-6489-9620													2223-7690	2223-7704				SEP	2017	5	3			SI		263	284		10.1007/s40544-017-0183-5	http://dx.doi.org/10.1007/s40544-017-0183-5													WOS:000409867800004
J	Krieger, G; Moreira, A; Fiedler, H; Hajnsek, I; Werner, M; Younis, M; Zink, M				Krieger, Gerhard; Moreira, Alberto; Fiedler, Hauke; Hajnsek, Irena; Werner, Marian; Younis, Marwan; Zink, Manfred			TanDEM-X: A satellite formation for high-resolution SAR interferometry	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING					6th European Conference on Synthetic Aperture Radar	MAY 16-18, 2006	Dresden, GERMANY					TanDEMA (TerraSAR-X add-on for Digital Elevation Measurements) is an innovative spaceborne radar interferometer that is based on two TerraSAR-X radar satellites flying in close formation. The primary objective of the TanDEMA mission is the generation of a consistent global digital elevation model (DEM) with an unprecedented accuracy, which is equaling or surpassing the HRTI-3 specification. Beyond that, TanDEM-X provides a highly reconfigurable platform for the demonstration of new radar imaging techniques and applications. This paper gives a detailed overview of the TanDEM-X mission concept which is based on the systematic combination of several innovative technologies. The key elements are the bistatic data acquisition employing an innovative phase synchronization link, a novel satellite formation flying concept allowing for the collection of bistatic data with short along-track baselines, as well as the use of new interferometric modes for system verification and DEM calibration. The interferometric performance is analyzed in detail, taking into account the peculiarities of the bistatic operation. Based on this analysis, an optimized DEM data acquisition plan is derived which employs the combination of multiple data takes with different baselines. Finally, a collection of instructive examples illustrates the capabilities of TanDEM-X for the development and demonstration of new remote sensing applications.					Younis, Marwan/AAD-9345-2021; Hajnsek, Irena/AAH-1504-2021; Krieger, Gerhard/D-5164-2012; Moreira, Alberto/C-1147-2013	Krieger, Gerhard/0000-0002-4548-0285; Younis, Marwan/0000-0002-8563-7371; Moreira, Alberto/0000-0002-3436-9653													0196-2892	1558-0644				NOV	2007	45	11	1				3317	3341		10.1109/TGRS.2007.900693	http://dx.doi.org/10.1109/TGRS.2007.900693													WOS:000250812600003
J	Guo, CX; Ran, JR; Vasileff, A; Qiao, SZ				Guo, Chunxian; Ran, Jingrun; Vasileff, Anthony; Qiao, Shi-Zhang			Rational design of electrocatalysts and photo(electro) catalysts for nitrogen reduction to ammonia (NH<sub>3</sub>) under ambient conditions	ENERGY & ENVIRONMENTAL SCIENCE												As one of the most important chemicals and carbon-free energy carriers, ammonia (NH3) has a worldwide annual production of similar to 150 million tons, and is mainly produced by the traditional high-temperature and high-pressure Haber-Bosch process which consumes massive amounts of energy. Very recently, electrocatalytic and photo(electro) catalytic reduction of N-2 to NH3, which can be performed at ambient conditions using renewable energy, have received tremendous attention. The overall performance of these electrocatalytic and photo(electro) catalytic systems is largely dictated by their core components, catalysts. This perspective for the first time highlights the rational design of electrocatalysts and photo(electro) catalysts for N-2 reduction to NH3 under ambient conditions. Fundamental theory of catalytic reaction pathways for the N-2 reduction reaction and the corresponding material design principles are introduced first. Then, recently developed electrocatalysts and photo(electro) catalysts are summarized, with a special emphasis on the relationship between their physicochemical properties and NH3 production performance. Finally, the opportunities in this emerging research field, in particular, the strategy of combining experimental and theoretical techniques to design efficient and stable catalysts for NH3 production, are outlined.					Vasileff, Anthony/HHS-5489-2022; Guo, Chunxian/S-8207-2019; Qiao, Shi Zhang/A-6057-2010; Guo, Chunxian/B-8259-2019; Ran, Jingrun/D-1219-2016	Qiao, Shi Zhang/0000-0002-4568-8422; Guo, Chunxian/0000-0002-2603-7181; Ran, Jingrun/0000-0002-8840-862X													1754-5692	1754-5706				JAN	2018	11	1					45	56		10.1039/c7ee02220d	http://dx.doi.org/10.1039/c7ee02220d													WOS:000423017000003
J	Dhillon, HS; Ganti, RK; Baccelli, F; Andrews, JG				Dhillon, Harpreet S.; Ganti, Radha Krishna; Baccelli, Francois; Andrews, Jeffrey G.			Modeling and Analysis of <i>K</i>-Tier Downlink Heterogeneous Cellular Networks	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS												Cellular networks are in a major transition from a carefully planned set of large tower-mounted base-stations (BSs) to an irregular deployment of heterogeneous infrastructure elements that often additionally includes micro, pico, and femtocells, as well as distributed antennas. In this paper, we develop a tractable, flexible, and accurate model for a downlink heterogeneous cellular network (HCN) consisting of K tiers of randomly located BSs, where each tier may differ in terms of average transmit power, supported data rate and BS density. Assuming a mobile user connects to the strongest candidate BS, the resulting Signal-to-Interference-plus-Noise-Ratio (SINR) is greater than 1 when in coverage, Rayleigh fading, we derive an expression for the probability of coverage (equivalently outage) over the entire network under both open and closed access, which assumes a strikingly simple closed-form in the high SINR regime and is accurate down to -4 dB even under weaker assumptions. For external validation, we compare against an actual LTE network (for tier 1) with the other K - 1 tiers being modeled as independent Poisson Point Processes. In this case as well, our model is accurate to within 1-2 dB. We also derive the average rate achieved by a randomly located mobile and the average load on each tier of BSs. One interesting observation for interference-limited open access networks is that at a given SINR, adding more tiers and/or BSs neither increases nor decreases the probability of coverage or outage when all the tiers have the same target-SINR.					Dhillon, Harpreet/Q-2237-2017; Baccelli, Francois/IWU-5360-2023; Andrews, Jeffrey/ADW-5995-2022	Ganti, Radha Krishna/0000-0002-5211-5657													0733-8716	1558-0008				APR	2012	30	3					550	560		10.1109/JSAC.2012.120405	http://dx.doi.org/10.1109/JSAC.2012.120405													WOS:000302232000005
J	Boparai, HK; Joseph, M; O'Carroll, DM				Boparai, Hardiljeet K.; Joseph, Meera; O'Carroll, Denis M.			Kinetics and thermodynamics of cadmium ion removal by adsorption onto nano zerovalent iron particles	JOURNAL OF HAZARDOUS MATERIALS												Nano zerovalent iron (nZVI) is an effective adsorbent for removing various organic and inorganic contaminants. In this study. nZVI particles were used to investigate the removal of Cd2+ in the concentration ;range of 25-450 mgL(-1). The effect of temperature on kinetics and equilibrium of cadmium sorption on nZVI particles was thoroughly examined. Consistent with an endothermic reaction, an increase in the temperature resulted in increasing cadmium adsorption rate. The adsorption kinetics well fitted using a pseudo second-order kinetic model. The calculated activation energy for adsorption was 54.8 kJ mol(-1), indicating the adsorption process to be chemisorption. The intraparticle diffusion model described that the intraparticle diffusion was not the only rate-limiting step. The adsorption isotherm data could be well described by the Langmuir as well as Temkin equations. The maximum adsorption capacity of nZVI for Cd2+ was found to be 769.2 mg g(-1) at 297K. Thermodynamic parameters (i.e., change in the free energy (Delta G degrees), the enthalpy (Delta H degrees), and the entropy (Delta S degrees)) were also evaluated. The overall adsorption process was endothermic and spontaneous in nature. EDX analysis indicated the presence of cadmium ions on the nZVI surface. These results suggest that nZVI could be employed as an efficient adsorbent for the removal of cadmium from contaminated water sources. (c) 2010 Elsevier B.V. All rights reserved.					O'Carroll, Denis/E-6382-2013; Boparai, Hardiljeet Kaur/H-5544-2013	O'Carroll, Denis/0000-0001-6557-226X; Boparai, Hardiljeet Kaur/0000-0002-0068-337X													0304-3894	1873-3336				FEB 15	2011	186	1					458	465		10.1016/j.jhazmat.2010.11.029	http://dx.doi.org/10.1016/j.jhazmat.2010.11.029								21130566					WOS:000288102400058
J	Shur, ML; Spalart, PR; Strelets, MK; Travin, AK				Shur, Mikhail L.; Spalart, Philippe R.; Strelets, Mikhail Kh.; Travin, Andrey K.			A hybrid RANS-LES approach with delayed-DES and wall-modelled LES capabilities	INTERNATIONAL JOURNAL OF HEAT AND FLUID FLOW												A CFD strategy is proposed that combines delayed detached-eddy simulation (DDES) with an improved RANS-LES hybrid model aimed at wall modelling in LES (WMLES). The system ensures a different response depending on whether the simulation does or does not have inflow turbulent content. In the first case, it reduces to WMLES: most of the turbulence is resolved except near the wall. Empirical improvements to this model relative to the pure DES equations provide a great increase of the resolved turbulence activity near the wall and adjust the resolved logarithmic layer to the modelled one, thus resolving the issue of "log layer mismatch" which is common in DES and other WMLES methods. An essential new element here is a definition of the subgrid length-scale which depends not only oil the grid spacings, but also on the wall distance. In the case without inflow turbulent content, the proposed model performs as DDES, i.e., it gives a pure RANS solution for attached flows and a DES-like solution for massively separated flows. The coordination of the two branches is carried out by a blending function. The promise of the model is supported by its satisfactory performance in all the three modes it was designed for, namely, in pure WMLES applications (channel flow in a wide Reynolds-number range and flow over a hydrofoil with trailing-edge separation), in a natural DDES application (an airfoil in deep stall), and in a flow where both branches of the model are active in different flow regions (a backward-facing-step, flow). (C) 2008 Elsevier Inc. All rights reserved.					Gargioni, Elisabetta/K-8829-2019; Strelets, Mikhail/N-9418-2013; Shur, Michael/O-1881-2013	Shur, Michael/0000-0002-2752-8759; Shur, Mikhail/0000-0002-9223-1687													0142-727X	1879-2278				DEC	2008	29	6					1638	1649		10.1016/j.ijheatfluidflow.2008.07.001	http://dx.doi.org/10.1016/j.ijheatfluidflow.2008.07.001													WOS:000261859000010
J	Kleindorfer, PR; Saad, GH				Kleindorfer, PR; Saad, GH			Managing disruption risks in supply chains	PRODUCTION AND OPERATIONS MANAGEMENT												There are two broad categories of risk affecting supply chain design and management: (1) risks arising from the problems of coordinating supply and demand, and (2) risks arising from disruptions to normal activities. This paper is concerned with the second category of risks, which may arise from natural disasters, from strikes and economic disruptions, and from acts of purposeful agents, including terrorists. The paper provides a conceptual framework that reflects the joint activities of risk assessment and risk mitigation that are fundamental to disruption risk management in supply chains. We then consider empirical results from a rich data set covering the period 1995-2000 on accidents in the U.S. Chemical Industry. Based on these results and other literature, we discuss the implications for the design of management systems intended to cope with supply chain disruption risks.																			1059-1478	1937-5956				SPR	2005	14	1					53	68		10.1111/j.1937-5956.2005.tb00009.x	http://dx.doi.org/10.1111/j.1937-5956.2005.tb00009.x													WOS:000228773300005
J	Zhao, B; Song, Q; Liu, WH; Sun, YD				Zhao, Biao; Song, Qiang; Liu, Wenhua; Sun, Yandong			Overview of Dual-Active-Bridge Isolated Bidirectional DC-DC Converter for High-Frequency-Link Power-Conversion System	IEEE TRANSACTIONS ON POWER ELECTRONICS												High-frequency-link (HFL) power conversion systems (PCSs) are attracting more and more attentions in academia and industry for high power density, reduced weight, and low noise without compromising efficiency, cost, and reliability. In HFL PCSs, dual-active-bridge (DAB) isolated bidirectional dc-dc converter (IBDC) serves as the core circuit. This paper gives an overview of DAB-IBDC for HFL PCSs. First, the research necessity and development history are introduced. Second, the research subjects about basic characterization, control strategy, soft-switching solution and variant, as well as hardware design and optimization are reviewed and analyzed. On this basis, several typical application schemes of DAB-IBDC for HPL PCSs are presented in a worldwide scope. Finally, design recommendations and future trends are presented. As the core circuit of HFL PCSs, DAB-IBDC has wide prospects. The large-scale practical application of DAB-IBDC for HFL PCSs is expected with the recent advances in solid-state semiconductors, magnetic and capacitive materials, and microelectronic technologies.																			0885-8993	1941-0107				AUG	2014	29	8			SI		4091	4106		10.1109/TPEL.2013.2289913	http://dx.doi.org/10.1109/TPEL.2013.2289913													WOS:000334117900022
J	Maddah-Ali, MA; Niesen, U				Maddah-Ali, Mohammad Ali; Niesen, Urs			Fundamental Limits of Caching	IEEE TRANSACTIONS ON INFORMATION THEORY												Caching is a technique to reduce peak traffic rates by prefetching popular content into memories at the end users. Conventionally, these memories are used to deliver requested content in part from a locally cached copy rather than through the network. The gain offered by this approach, which we term local caching gain, depends on the local cache size (i.e., the memory available at each individual user). In this paper, we introduce and exploit a second, global, caching gain not utilized by conventional caching schemes. This gain depends on the aggregate global cache size (i.e., the cumulative memory available at all users), even though there is no cooperation among the users. To evaluate and isolate these two gains, we introduce an information-theoretic formulation of the caching problem focusing on its basic structure. For this setting, we propose a novel coded caching scheme that exploits both local and global caching gains, leading to a multiplicative improvement in the peak rate compared with previously known schemes. In particular, the improvement can be on the order of the number of users in the network. In addition, we argue that the performance of the proposed scheme is within a constant factor of the information-theoretic optimum for all values of the problem parameters.																			0018-9448	1557-9654				MAY	2014	60	5					2856	2867		10.1109/TIT.2014.2306938	http://dx.doi.org/10.1109/TIT.2014.2306938													WOS:000335151900028
J	Liu, WF; Pokharel, PP; Principe, JC				Liu, Weifeng; Pokharel, Puskal P.; Principe, Jose C.			Correntropy: properties and applications in non-gaussian signal processing	IEEE TRANSACTIONS ON SIGNAL PROCESSING												The optimality of second-order statistics depends heavily on the assumption of Gaussianity. In this paper, we elucidate further the probabilistic and geometric meaning of the recently defined correntropy function as a localized similarity measure. A close relationship between correntropy and M-estimation is established. Connections and differences between correntropy and kernel methods are presented. As such correntropy has vastly different properties compared with second-order statistics that can be very useful in non-Gaussian signal processing, especially in the impulsive noise environment. Examples are presented to illustrate the technique.					principe, jose/N-8099-2014														1053-587X	1941-0476				NOV	2007	55	11					5286	5298		10.1109/TSP.2007.896065	http://dx.doi.org/10.1109/TSP.2007.896065													WOS:000250374300014
J	Mao, YY; Zhang, J; Letaief, KB				Mao, Yuyi; Zhang, Jun; Letaief, Khaled B.			Dynamic Computation Offloading for Mobile-Edge Computing With Energy Harvesting Devices	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS												Mobile-edge computing (MEC) is an emerging paradigm to meet the ever-increasing computation demands from mobile applications. By offloading the computationally intensive workloads to the MEC server, the quality of computation experience, e.g., the execution latency, could be greatly improved. Nevertheless, as the on-device battery capacities are limited, computation would be interrupted when the battery energy runs out. To provide satisfactory computation performance as well as achieving green computing, it is of significant importance to seek renewable energy sources to power mobile devices via energy harvesting (EH) technologies. In this paper, we will investigate a green MEC system with EH devices and develop an effective computation offloading strategy. The execution cost, which addresses both the execution latency and task failure, is adopted as the performance metric. A low-complexity online algorithm is proposed, namely, the Lyapunov optimization-based dynamic computation offloading algorithm, which jointly decides the offloading decision, the CPU-cycle frequencies for mobile execution, and the transmit power for computation offloading. A unique advantage of this algorithm is that the decisions depend only on the current system state without requiring distribution information of the computation task request, wireless channel, and EH processes. The implementation of the algorithm only requires to solve a deterministic problem in each time slot, for which the optimal solution can be obtained either in closed form or by bisection search. Moreover, the proposed algorithm is shown to be asymptotically optimal via rigorous analysis. Sample simulation results shall be presented to corroborate the theoretical analysis as well as validate the effectiveness of the proposed algorithm.					Zhang, Jun/M-8009-2013	Zhang, Jun/0000-0002-5222-1898; MAO, YUYI/0000-0002-5646-8679													0733-8716	1558-0008				DEC	2016	34	12					3590	3605		10.1109/JSAC.2016.2611964	http://dx.doi.org/10.1109/JSAC.2016.2611964													WOS:000392473600037
J	Vaidyanathan, PP; Pal, P				Vaidyanathan, Palghat P.; Pal, Piya			Sparse Sensing With Co-Pprime Samplers and Arrays	IEEE TRANSACTIONS ON SIGNAL PROCESSING												This paper considers the sampling of temporal or spatial wide sense stationary (WSS) signals using a co-prime pair of sparse samplers. Several properties and applications of co-prime samplers are developed. First, for uniform spatial sampling with and sensors where and are co-prime with appropriate interelement spacings, the difference co-array has O(MN) freedoms which can be exploited in beamforming and in direction of arrival estimation. An M-point DFT filter bank and an N-point DFT filter bank can be used at the outputs of the two sensor arrays and their outputs combined in such a way that there are effectively MN bands (i.e., MN narrow beams with beamwidths proportional to 1/MN), a result following from co-primality. The ideas are applicable to both active and passive sensing, though the details and tradeoffs are different. Time domain sparse co-prime samplers also generate a time domain co-array with O(MN) freedoms, which can be used to estimate the autocorrelation at much finer lags than the sample spacings. This allows estimation of power spectrum of an arbitrary signal with a frequency resolution proportional to 2 pi/(MNT) even though the pairs of sampled sequences x(c)(NTn) and x(c)(MTn) in the time domain can be arbitrarily sparse - in fact from the sparse set of samples x(c)(NTn) and x(c)(MTn) one can estimate O(MN) frequencies in the range vertical bar omega vertical bar < pi/T. It will be shown that the co-array based method for estimating sinusoids in noise offers many advantages over methods based on the use of Chinese remainder theorem and its extensions. Examples are presented throughout to illustrate the various concepts.																			1053-587X					FEB	2011	59	2					573	586		10.1109/TSP.2010.2089682	http://dx.doi.org/10.1109/TSP.2010.2089682													WOS:000286111100009
J	Kasprzyk-Hordern, B; Dinsdale, RM; Guwy, AJ				Kasprzyk-Hordern, Barbara; Dinsdale, Richard M.; Guwy, Alan J.			The removal of pharmaceuticals, personal care products, endocrine disruptors and illicit drugs during wastewater treatment and its impact on the quality of receiving waters	WATER RESEARCH												A 5-month monitoring program was undertaken in South Wales in the UK to determine the fate of SS pharmaceuticals, personal care products, endocrine disruptors and illicit drugs (PPCPs) in two contrasting wastewater plants utilising two different wastewater treatment technologies: activated sludge and trickling filter beds. The impact of treated wastewater effluent on the quality of receiving waters was also assessed. PPCPs were found to be present at high loads reaching 10 kg day(-1) in the raw sewage. Concentrations of PPCPs in raw sewage were found to correlate with their usage/consumption patterns in Wales and their metabolism. The efficiency of the removal of PPCPs was found to be strongly dependent on the technology implemented in the wastewater treatment plant (WWTP). In general, the WWTP utilising trickling filter beds resulted in, on average, less than 70% removal of all 55 PPCPs studied, while the WWTP utilising activated sludge treatment gave a much higher removal efficiency of over 85%. The monitoring programme revealed that treated wastewater effluents were the main contributors to PPCPs concentrations (up to 3 kg of PPCPs day(-1)) in the rivers studied. Bearing in mind that in the cases examined here the WWTP effluents were also major contributors to rivers' flows (dilution factor for the studied rivers did not exceed 23 times) the effect of WWTP effluent on the quality of river water is significant and cannot be underestimated. (C) 2008 Elsevier Ltd. All rights reserved.					Guwy, Alan/AAH-5518-2021; Kasprzyk-Hordern, Barbara/D-4351-2011; Guwy, Alan/HKE-3038-2023	Kasprzyk-Hordern, Barbara/0000-0002-6809-2875; Guwy, Alan/0000-0002-7002-9242													0043-1354					FEB	2009	43	2					363	380		10.1016/j.watres.2008.10.047	http://dx.doi.org/10.1016/j.watres.2008.10.047								19022470					WOS:000263595500013
J	Adams, LK; Lyon, DY; Alvarez, PJJ				Adams, Laura K.; Lyon, Delina Y.; Alvarez, Pedro J. J.			Comparative eco-toxicity of nanoscale TiO<sub>2</sub>, SiO<sub>2</sub>, and ZnO water suspensions	WATER RESEARCH												The potential eco-toxicity of nanosized titanium dioxide (TiO2), silicon dioxide (SiO2), and zinc oxide (ZnO) water suspensions was investigated using Gram-positive Bacillus subtilis and Gram-negative Escherichia coli as test organisms. These three photosensitive nanomaterials were harmful to varying degrees, with antibacterial activity increasing with particle concentration. Antibacterial activity generally increased from SiO2 to TiO2 to ZnO, and B. subtilis was most susceptible to their effects. Advertised nanoparticle size did not correspond to true particle size. Apparently, aggregation produced similarly sized particles that had similar antibacterial activity at a given concentration. The presence of light was a significant factor under most conditions tested, presumably due to its role in promoting generation of reactive oxygen species (ROS). However, bacterial growth inhibition was also observed under dark conditions, indicating that undetermined mechanisms additional to photocatalytic ROS production were responsible for toxicity. These results highlight the need for caution during the use and disposal of such manufactured nanomaterials to prevent unintended environmental impacts, as well as the importance of further research on the mechanisms and factors that increase toxicity to enhance risk management. (c) 2006 Elsevier Ltd. All rights reserved.					Lyon, Delina/ABD-7121-2021; Alvarez, Pedro/AAE-7216-2019	Alvarez, Pedro/0000-0002-6725-7199; Lyon, Delina/0000-0002-2291-9048													0043-1354					NOV	2006	40	19					3527	3532		10.1016/j.watres.2006.08.004	http://dx.doi.org/10.1016/j.watres.2006.08.004								17011015					WOS:000241654600006
J	Samarati, P				Samarati, P			Protecting respondents' identities in microdata release	IEEE TRANSACTIONS ON KNOWLEDGE AND DATA ENGINEERING												Today's globally networked society places great demand on the dissemination and sharing of information. While in the past released information was mostly in tabular and statistical form, many situations call today for the release of specific data (microdata). In order to protect the anonymity of the, entities (called respondents) to which information refers, data holders often remove or encrypt explicit identifiers such as names, addresses, and phone numbers. Deidentifying data, however, provides no guarantee of anonymity. Released information often contains other data, such as race, birth date, sex, and ZIP code, that can be linked to publicly available information to reidentify respondents and inferring information that was not intended for disclosure. In this paper we address the problem of releasing microdata while safeguarding the anonymity of the respondents to which the data refer. The approach is based on the definition of k-anonymity. A table provides k-anonymity if attempts to link explicitly identifying information to its content map the information to at least k entities. We illustrate how k-anonymity can be provided without compromising the Integrity (or truthfulness) of the information released by using generalization and suppression techniques. We introduce the concept of minimal generalization that captures the property of the release process not to distort the data more than needed to achieve k-anonymity, and present an algorithm for the computation of such a generalization. We also discuss possible preference policies to choose among different minimal generalizations.						Samarati, Pierangela/0000-0001-7395-4620													1041-4347					NOV-DEC	2001	13	6					1010	1027		10.1109/69.971193	http://dx.doi.org/10.1109/69.971193													WOS:000172574600011
J	Jindal, N				Jindal, Nihar			MIMO broadcast channels with finite-rate feedback	IEEE TRANSACTIONS ON INFORMATION THEORY					IEEE Global Telecommunications Conference (GLOBECOM 05)	NOV 28-DEC 02, 2005	St Louis, MO	IEEE				Mlultiple transmit antennas in a downlink channel can provide tremendous capacity (i.e., multiplexing) gains, even when receivers have only single antennas. However, receiver and transmitter channel state information is generally required. In this correspondence, a system where each receiver has perfect channel knowledge, but the transmitter only receive-s quantized information regarding the channel instantiation is analyzed. The well-known zero-forcing transmission technique is considered, and simple expressions for the throughput degradation due to finite-rate feedback are derived. A key finding is that the feedback rate per mobile must be increased linearly with the signal-to-noise ratio (SNR) (in decibels) in order to achieve the full multiplexing gain. This is in sharp contrast to point-to-point multiple-input multiple-output (MIMO) systems, in which it is not necessary to increase the feedback rate as a function of the SNR.																			0018-9448	1557-9654				NOV	2006	52	11					5045	5060		10.1109/TIT.2006.883550	http://dx.doi.org/10.1109/TIT.2006.883550													WOS:000241805700019
J	Navarro, E; Piccapietra, F; Wagner, B; Marconi, F; Kaegi, R; Odzak, N; Sigg, L; Behra, R				Navarro, Enrique; Piccapietra, Flavio; Wagner, Bettina; Marconi, Fabio; Kaegi, Ralf; Odzak, Niksa; Sigg, Laura; Behra, Renata			Toxicity of Silver Nanoparticles to <i>Chlamydomonas reinhardtii</i>	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Silver nanoparticles (AgNP) are likely to enter the aquatic environment because of their multiple uses. We have examined the short-term toxicity of AgNP and ionic silver (Ag+) to photosynthesis in Chlamydomonas reinhardtii using fluorometry. AgNP ranged in size from 10 to 200 nm with most particles around 25 nm. As determined by DGT (diffusive gradients in thin films), byion-selective electrode, and by centrifugal ultrafiltration, about 1% of the AgNP was present as Ag+ ions. Based on total Ag concentration, toxicity was 18 times higher for AgNO3 than for AgNP (in terms of EC50). However, when compared as a function of the Ag+ concentration, toxicity of AgNP appeared to be much higher than that of AgNO3. The ionic Ag+ measured in the AgNP suspensions could not fully explain the observed toxicity. Cysteine, a strong Ag+ ligand, abolished the inhibitory effects on photosynthesis of both AgNP and Ag+. Together, the results indicate that the interaction of these particles with algae influences the toxicity of AgNP, which is mediated by Ag+. Particles contributed to the toxicity as a source of Ag+ which is formed in presence of algae.					Sigg, Laura/AAI-3504-2020; Navarro, Enrique/A-4869-2009	Navarro, Enrique/0000-0002-3964-4431; Sigg, Laura/0000-0002-2210-2951													0013-936X	1520-5851				DEC 1	2008	42	23					8959	8964		10.1021/es801785m	http://dx.doi.org/10.1021/es801785m								19192825					WOS:000261307200059
J	Ren, W; AtkinS, E				Ren, Wei; Atkins, Ella			Distributed multi-vehicle coordinated control <i>via</i> local information exchange	INTERNATIONAL JOURNAL OF ROBUST AND NONLINEAR CONTROL												This paper describes it distributed coordination scheme with local information exchange for multiple vehicle systems. We introduce second-order consensus protocols that take into account motions of the information states and their derivatives, extending first-order protocols from the literature. We also derive necessary and sufficient conditions under which consensus can be reached in the context of unidirectional information exchange topologies. This work takes into account the general case where information flow may be unidirectional due to sensors with limited fields of view or vehicles with directed, power-constrained communication links. Unlike the first-order case, we show that having a (directed) spanning tree is a necessary rather than a sufficient condition for consensus seeking with second-order dynamics. This work focuses on a formal analysis of information exchange topologies that permit second-order consensus. Given its importance to the stability of the coordinated system, an analysis of the consensus term control gains is also presented, specifically the strength of the information states relative to their derivatives. As an illustrative example, consensus protocols are applied to coordinate the movements of multiple mobile robots. Copyright (C) 2006 John Wiley & Sons, Ltd.					Ren, Wei/G-7369-2011; Atkins, Ella/J-5732-2013														1049-8923	1099-1239				JUL 10	2007	17	10-11					1002	1033		10.1002/rnc.1147	http://dx.doi.org/10.1002/rnc.1147													WOS:000247739000007
J	Dimakis, AG; Godfrey, PB; Wu, YN; Wainwright, MJ; Ramchandran, K				Dimakis, Alexandros G.; Godfrey, P. Brighten; Wu, Yunnan; Wainwright, Martin J.; Ramchandran, Kannan			Network Coding for Distributed Storage Systems	IEEE TRANSACTIONS ON INFORMATION THEORY												Distributed storage systems provide reliable access to data through redundancy spread over individually unreliable nodes. Application scenarios include data centers, peer-to-peer storage systems, and storage in wireless networks. Storing data using an erasure code, in fragments spread across nodes, requires less redundancy than simple replication for the same level of reliability. However, since fragments must be periodically replaced as nodes fail, a key question is how to generate encoded fragments in a distributed way while transferring as little data as possible across the network. For an erasure coded system, a common practice to repair from a single node failure is for a new node to reconstruct the whole encoded data object to generate just one encoded block. We show that this procedure is sub-optimal. We introduce the notion of regenerating codes, which allow a new node to communicate functions of the stored data from the surviving nodes. We show that regenerating codes can significantly reduce the repair bandwidth. Further, we show that there is a fundamental tradeoff between storage and repair bandwidth which we theoretically characterize using flow arguments on an appropriately constructed graph. By invoking constructive results in network coding, we introduce regenerating codes that can achieve any point in this optimal tradeoff.					Dimakis, Alexandros/A-5496-2011	Dimakis, Alexandros/0000-0002-4244-7033; Wainwright, Martin J./0000-0002-8760-2236													0018-9448					SEP	2010	56	9					4539	4551		10.1109/TIT.2010.2054295	http://dx.doi.org/10.1109/TIT.2010.2054295													WOS:000283072400028
J	Carrión, M; Arroyo, JM				Carrion, Miguel; Arroyo, Jose M.			A computationally efficient mixed-integer linear formulation for the thermal unit commitment problem	IEEE TRANSACTIONS ON POWER SYSTEMS												This paper presents a new mixed-integer linear formulation for the unit commitment problem of thermal units. The formulation proposed requires fewer binary variables and constraints than previously reported models, yielding a significant computational saving. Furthermore, the modeling framework provided by the new formulation allows including a precise description of time-dependent startup costs and intertemporal constraints such as ramping limits and minimum up and down times. A commercially available mixed-integer linear programming algorithm has been applied to efficiently solve the unit commitment problem for practical large-scale cases. Simulation results back these conclusions.					Carrion, Miguel/I-3600-2015; ARROYO, JOSE/E-2473-2013	Carrion Ruiz Peinado, Miguel/0000-0001-5764-3996; ARROYO, JOSE/0000-0002-9538-6748													0885-8950					AUG	2006	21	3					1371	1378		10.1109/TPWRS.2006.876672	http://dx.doi.org/10.1109/TPWRS.2006.876672													WOS:000239355300040
J	Zhong, ZL; Li, J; Luo, ZM; Chapman, M				Zhong, Zilong; Li, Jonathan; Luo, Zhiming; Chapman, Michael			Spectral-Spatial Residual Network for Hyperspectral Image Classification: A 3-D Deep Learning Framework	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING												In this paper, we designed an end-to-end spectralspatial residual network (SSRN) that takes raw 3-D cubes as input data without feature engineering for hyperspectral image classification. In this network, the spectral and spatial residual blocks consecutively learn discriminative features from abundant spectral signatures and spatial contexts in hyperspectral imagery (HSI). The proposed SSRN is a supervised deep learning framework that alleviates the declining-accuracy phenomenon of other deep learning models. Specifically, the residual blocks connect every other 3-D convolutional layer through identity mapping, which facilitates the backpropagation of gradients. Furthermore, we impose batch normalization on every convolutional layer to regularize the learning process and improve the classification performance of trained models. Quantitative and qualitative results demonstrate that the SSRN achieved the state-of-the-art HSI classification accuracy in agricultural, rural-urban, and urban data sets: Indian Pines, Kennedy Space Center, and University of Pavia.					Li, Jonathan/AAA-7712-2021	LI, Jonathan/0000-0001-7899-0049; Zhong, Zilong/0000-0003-0104-9116; Luo, Zhiming/0000-0002-3411-9582													0196-2892	1558-0644				FEB	2018	56	2					847	858		10.1109/TGRS.2017.2755542	http://dx.doi.org/10.1109/TGRS.2017.2755542													WOS:000424627500019
J	Yoo, HD; Shterenberg, I; Gofer, Y; Gershinsky, G; Pour, N; Aurbach, D				Yoo, Hyun Deog; Shterenberg, Ivgeni; Gofer, Yosef; Gershinsky, Gregory; Pour, Nir; Aurbach, Doron			Mg rechargeable batteries: an on-going challenge	ENERGY & ENVIRONMENTAL SCIENCE												The first working Mg rechargeable battery prototypes were ready for presentation about 13 years ago after two breakthroughs. The first was the development of non-Grignard Mg complex electrolyte solutions with reasonably wide electrochemical windows in which Mg electrodes are fully reversible. The second breakthrough was attained by demonstrating high-rate Mg cathodes based on Chevrel phases. These prototypes could compete with lead-acid or Ni-Cd batteries in terms of energy density, very low self-discharge, a wide temperature range of operation, and an impressive prolonged cycle life. However, the energy density and rate capability of these Mg battery prototypes were not attractive enough to commercialize them. Since then we have seen gradual progress in the development of better electrolyte solutions, as well as suggestions of new cathodes. In this article we review the recent accumulated experience, understandings, new strategies and materials, in the continuous R&D process of nonaqueous Mg batteries. This paper provides a road-map of this field during the last decade.					Aurbach, Doron/HTS-1256-2023	Yoo, Hyun Deog/0000-0001-5188-481X													1754-5692					AUG	2013	6	8					2265	2279		10.1039/c3ee40871j	http://dx.doi.org/10.1039/c3ee40871j													WOS:000321983800003
J	Yu, W; Lui, R				Yu, Wei; Lui, Raymond			Dual methods for nonconvex spectrum optimization of multicarrier systems	IEEE TRANSACTIONS ON COMMUNICATIONS					IEEE Global Telecommunications Conference (GLOBECOM 04)	NOV 29-DEC 03, 2004	Dallas, TX	IEEE, Strateg Alliance Metroplex Technol, Freescale, IDT, Nokia, Univ Texas, Austin, ECE, Wireless Valley Commun Inc, ALCATEL, ALTERA, Raytheon, SMU Eng, UTA Eng, Univ Texas, Dallas, Erik Jonsson Sch Engn & Comp Sci, Axes Technol				The design and optimization of multicarrier communications systems often involve a maximization of the total throughput subject to system resource constraints. The optimization problem is numerically difficult to solve when the problem does not have a convexity structure. This paper makes progress toward solving optimization problems of this type by showing that under a certain condition called the time-sharing condition, the duality gap of the optimization problem is always zero, regardless of the convexity of the objective function. Further, we show that the time-sharing condition is satisfied for practical multiuser spectrum optimization. problems in multicarrier systems in the limit as the number of carriers goes to infinity. This result leads to efficient numerical algorithms that solve the nonconvex problem in the dual domain. We show that the recently proposed optimal spectrum balancing algorithm for digital subscriber lines can be interpreted as a dual algorithm. This new interpretation gives rise to more efficient dual update methods. It also suggests ways in which the dual objective may be evaluated approximately, further improving the numerical efficiency of the algorithm. We propose a low-complexity iterative spectrum balancing algorithm based on these ideas, and show that the new algorithm achieves near-optimal performance in many practical situations.																			0090-6778	1558-0857				JUL	2006	54	7					1310	1322		10.1109/TCOMM.2006.877962	http://dx.doi.org/10.1109/TCOMM.2006.877962													WOS:000239406200022
J	Paerl, HW; Paul, VJ				Paerl, Hans W.; Paul, Valerie J.			Climate change: Links to global expansion of harmful cyanobacteria	WATER RESEARCH												Cyanobacteria are the Earth's oldest (similar to 3.5 bya) oxygen evolving organisms, and they have had major impacts on shaping our modern-day biosphere. Conversely, biospheric environmental perturbations, including nutrient enrichment and climatic changes (e.g. global warming, hydrologic changes, increased frequencies and intensities of tropical cyclones, more intense and persistent droughts), strongly affect cyanobacterial growth and bloom potentials in freshwater and marine ecosystems. We examined human and climatic controls on harmful (toxic, hypoxia-generating, food web disrupting) bloom-forming cyanobacteria (CyanoHABs) along the freshwater to marine continuum. These changes may act synergistically to promote cyanobacterial dominance and persistence. This synergy is a formidable challenge to water quality, water supply and fisheries managers, because bloom potentials and controls may be altered in response to contemporaneous changes in thermal and hydrologic regimes. In inland waters, hydrologic modifications, including enhanced vertical mixing and, if water supplies permit, increased flushing (reducing residence time) will likely be needed in systems where nutrient input reductions are neither feasible nor possible. Successful control of CyanoHABs by grazers is unlikely except in specific cases. Overall, stricter nutrient management will likely be the most feasible and practical approach to long-term CyanoHAB control in a warmer, stormier and more extreme world. (C) 2011 Elsevier Ltd. All rights reserved.					Paerl, Hans/ACA-9911-2022	Paul, Valerie/0000-0002-4691-1569													0043-1354					APR 1	2012	46	5			SI		1349	1363		10.1016/j.watres.2011.08.002	http://dx.doi.org/10.1016/j.watres.2011.08.002								21893330					WOS:000301018700002
J	Han, LH; Li, W; Bjorhovde, R				Han, Lin-Hai; Li, Wei; Bjorhovde, Reidar			Developments and advanced applications of concrete-filled steel tubular (CFST) structures: Members	JOURNAL OF CONSTRUCTIONAL STEEL RESEARCH												Concrete-filled steel tubular (CFST) structure offers numerous structural benefits, and has been widely used in civil engineering structures. This paper reviews the development of the family of concrete-filled steel tubular structures to date and draws a research framework on CFST members. The research development on CFST structural members in most recent years, particularly in China, is summarized and discussed. The current design approaches from various countries are examined briefly. Some projects in China utilizing CFST members are also introduced. Finally, some concluding remarks are made for CFST members. (C) 2014 Elsevier Ltd. All rights reserved.						HAN, LIN-HAI/0000-0001-8023-3282; Li, Wei/0000-0001-7240-490X													0143-974X	1873-5983				SEP	2014	100						211	228		10.1016/j.jcsr.2014.04.016	http://dx.doi.org/10.1016/j.jcsr.2014.04.016													WOS:000338618300018
J	Lichtsteiner, P; Posch, C; Delbruck, T				Lichtsteiner, Patrick; Posch, Christoph; Delbruck, Tobi			A 128x128 120 dB 15 μs latency asynchronous temporal contrast vision sensor	IEEE JOURNAL OF SOLID-STATE CIRCUITS												This paper describes a 128 x 128 pixel CMOS vision sensor. Each pixel independently and in continuous time quantizes local relative intensity changes to generate spike events. These events appear at the output of the sensor as an asynchronous stream of digital pixel addresses. These address-events signify scene reflectance change and have sub-millisecond timing precision. The output data rate depends on the dynamic content of the scene and is typically orders of magnitude lower than those of conventional frame-based imagers. By combining an active continuous-time front-end logarithmic photoreceptor with a self-timed switched-capacitor differencing circuit, the sensor achieves an array mismatch of 2.1 % in relative intensity event threshold and a pixel bandwidth of 3 kHz under 1 klux scene illumination. Dynamic range is > 120 dB and chip power consumption is 23 mW. Event latency shows weak light dependency with a minimum of 15 mu s at > 1 klux pixel illumination. The sensor is built in a 0.35 mu m 4M2P process. It has 40x40 mu m(2) pixels with 9.4% fill factor. By providing high pixel bandwidth, wide dynamic range, and preciely timed sparse digital output, this silicon retina provides an attractive combination of characteristics for low-latency dynamic vision under uncontrolled illumination with low post-processing requirements.																			0018-9200	1558-173X				FEB	2008	43	2					566	576		10.1109/JSSC.2007.914337	http://dx.doi.org/10.1109/JSSC.2007.914337													WOS:000252813600026
J	Chan, CC				Chan, C. C.			The state of the art of electric, hybrid, and fuel cell vehicles	PROCEEDINGS OF THE IEEE												With the more stringent regulations on emissions and fuel economy, global warming, and constraints on energy resources, the electric, hybrid, and fuel cell vehicles have attracted more and more attention by automakers, governments, and customers. Research and development efforts have been focused on developing novel concepts, low-cost systems, and reliable hybrid electric powertrain. This paper reviews the state of the art of electric, hybrid, and fuel cell vehicles. The topologies for each category and the enabling technologies are discussed.																			0018-9219					APR	2007	95	4					704	718		10.1109/JPROC.2007.892489	http://dx.doi.org/10.1109/JPROC.2007.892489													WOS:000246425200003
J	Chen, VC; Li, FY; Ho, SS; Wechsler, H				Chen, VC; Li, FY; Ho, SS; Wechsler, H			Micro-doppler effect in radar: Phenomenon, model, and simulation study	IEEE TRANSACTIONS ON AEROSPACE AND ELECTRONIC SYSTEMS												When, in addition to the constant Doppler frequency shift induced by the bulk motion of a radar target, the target or any structure on the target undergoes micro-motion dynamics, such as mechanical vibrations or rotations, the micro-motion dynamics induce Doppler modulations on the returned signal, referred to as the micro-Doppler effect. We introduce the micro-Doppler phenomenon in radar, develop a model of Doppler modulations, derive formulas of micro-Doppler induced by targets with vibration, rotation, tumbling and coning motions, and verify them by simulation studies, analyze time-varying micro-Doppler features using high-resolution time-frequency transforms, and demonstrate the micro-Doppler effect observed in real radar data.					Li, Fangyi/HTP-8888-2023; ho, shen shyang/B-7034-2012	ho, shen shyang/0000-0002-0353-7159													0018-9251	1557-9603				JAN	2006	42	1					2	21		10.1109/TAES.2006.1603402	http://dx.doi.org/10.1109/TAES.2006.1603402													WOS:000236288000001
J	Akyildiz, IF; Lo, BF; Balakrishnan, R				Akyildiz, Ian F.; Lo, Brandon F.; Balakrishnan, Ravikumar			Cooperative spectrum sensing in cognitive radio networks: A survey	PHYSICAL COMMUNICATION												Spectrum sensing is a key function of cognitive radio to prevent the harmful interference with licensed users and identify the available spectrum for improving the spectrum's utilization. However, detection performance in practice is often compromised with multipath fading, shadowing and receiver uncertainty issues. To mitigate the impact of these issues, cooperative spectrum sensing has been shown to be an effective method to improve the detection performance by exploiting spatial diversity. While cooperative gain such as improved detection performance and relaxed sensitivity requirement can be obtained, cooperative sensing can incur cooperation overhead. The overhead refers to any extra sensing time, delay, energy, and operations devoted to cooperative sensing and any performance degradation caused by cooperative sensing. In this paper, the state-of-the-art survey of cooperative sensing is provided to address the issues of cooperation method, cooperative gain, and cooperation overhead. Specifically, the cooperation method is analyzed by the fundamental components called the elements of cooperative sensing, including cooperation models, sensing techniques, hypothesis testing, data fusion, control channel and reporting, user selection, and knowledge base. Moreover, the impacting factors of achievable cooperative gain and incurred cooperation overhead are presented. The factors under consideration include sensing time and delay, channel impairments, energy efficiency, cooperation efficiency, mobility, security, and wideband sensing issues. The open research challenges related to each issue in cooperative sensing are also discussed. (C) 2010 Elsevier B.V. All rights reserved.					Akyildiz, Ian/G-7136-2011	Lo, Brandon/0000-0002-1895-6612													1874-4907					MAR	2011	4	1					40	62		10.1016/j.phycom.2010.12.003	http://dx.doi.org/10.1016/j.phycom.2010.12.003													WOS:000213414000005
J	Carballa, M; Omil, F; Lema, JM; Llompart, M; García-Jares, C; Rodríguez, I; Gómez, M; Ternes, T				Carballa, M; Omil, F; Lema, JM; Llompart, M; García-Jares, C; Rodríguez, I; Gómez, M; Ternes, T			Behavior of pharmaceuticals, cosmetics and hormones in a sewage treatment plant	WATER RESEARCH												Two cosmetic ingredients (galaxolide, tonalide), eight pharmaceuticals (carbamazepine, diazepam, diclofenac, ibuprofen, naproxen, roxithromycin, sulfamethoxazole and iopromide) and three hormones (estrone, 17beta-estradiol and 17alpha-ethinylestradiol) have been surveyed along the different units of a municipal Sewage Treatment Plant (STP) in Galicia, NW Spain. Among all the substances considered, significant concentrations in the influent were only found for the two musks (galaxolide and tonalide), two anti-inflammatories (ibuprofen and naproxen), two natural estrogens (estrone, 17beta-estradiol), one antibiotic (sulfaniethoxazole) and the X-ray contrast medium (iopromide), where the other compounds studied were below the limit of quantification. In the primary treatment, only the fragrances (30-50%) and 17beta-estradiol (20%) were partially removed. On the other hand, the aerobic treatment (activated sludges) caused an important reduction in all compounds detected, between 351/4 and 75%, with the exception of iopromide, which remained in the aqueous phase. The overall removal efficiencies within the STP ranged between 70-90% for the fragrances, 40-65% for the anti-inflammatories, around 65% for 17beta-estradiol and 60% for sulfamethoxazole. However, the concentration of estrone increased along the treatment due to the partial oxidation of 17beta-estradiol in the aeration tank. (C) 2004 Elsevier Ltd. All rights reserved.					Garcia-Jares, Carmen/B-4305-2010; Lema, Juan/F-6718-2016; Rodriguez Pereiro, Isaac/H-4771-2015; Omil, Francisco/F-7728-2016; CARBALLA, MARTA/P-7454-2015	Lema, Juan/0000-0001-5616-2584; llompart, maria/0000-0001-5631-9828; Rodriguez Pereiro, Isaac/0000-0002-9693-2042; Omil, Francisco/0000-0003-4042-453X; Garcia-Jares, Carmen/0000-0002-2233-6512; CARBALLA, MARTA/0000-0002-7409-0235													0043-1354					JUL	2004	38	12					2918	2926		10.1016/j.watres.2004.03.029	http://dx.doi.org/10.1016/j.watres.2004.03.029								15223286					WOS:000222647300014
J	Hu, Y; Loizou, PC				Hu, Yi; Loizou, Philipos C.			Evaluation of objective quality measures for speech enhancement	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING												In this paper, we evaluate the performance of several objective measures in terms of predicting the quality of noisy speech enhanced by noise suppression algorithms. The objective measures considered a wide range of distortions introduced by four types of real-world noise at two signal-to-noise ratio levels by four classes of speech enhancement algorithms: spectral subtractive, subspace, statistical-model based, and Wiener algorithms. The subjective quality ratings were obtained using the ITU-T P.835 methodology designed to evaluate the quality of enhanced speech along three dimensions: signal distortion, noise distortion, and overall quality. This paper reports on the evaluation of correlations of several objective measures with these three subjective rating scales. Several new composite objective measures are also proposed by combining the individual objective measures using nonparametric and parametric regression analysis techniques.																			1558-7916	1558-7924				JAN	2008	16	1					229	238		10.1109/TASL.2007.911054	http://dx.doi.org/10.1109/TASL.2007.911054													WOS:000251947000022
J	Witte, F; Fischer, J; Nellesen, J; Crostack, HA; Kaese, V; Pisch, A; Beckmann, F; Windhagen, H				Witte, F; Fischer, J; Nellesen, J; Crostack, HA; Kaese, V; Pisch, A; Beckmann, F; Windhagen, H			In vitro and in vivo corrosion measurements of magnesium alloys	BIOMATERIALS												The in vivo corrosion of magnesium alloys might provide a new mechanism which would allow degradable metal implants to be applied in musculo-skeletal surgery. This would particularly be true if magnesium alloys with controlled in vivo corrosion rates could be developed. Since the magnesium corrosion process depends on its corrosive environment, the corrosion rates of magnesium alloys under standard in vitro environmental conditions were compared to corrosion rates in an in vivo animal model. Two gravity-cast magnesium alloys (AZ91D, LAE442) were used in these investigations. Standardized immersion and electrochemical tests according to ASTM norms were performed. The in vivo corrosion tests were carried out by intramedullar implantation of sample rods of the magnesium alloys in guinea pig femura. The reduction in implant volume was determined by synchrotron-radiation-based microtomography. We found that in vivo corrosion was about four orders of magnitude lower than in vitro corrosion of the tested alloys. Furthermore, the tendency of the corrosion rates obtained from in vitro corrosion tests were in the opposite direction as those obtained from the in vivo study. The results of this study suggest, that the conclusions drawn from current ASTM standard in vitro corrosion tests cannot be used to predict in vivo corrosion rates of magnesium alloys. (c) 2005 Elsevier Ltd. All rights reserved.					Witte, Frank/AFK-1556-2022; Pisch, Alex/AAI-4944-2020; Beckmann, Felix/E-1940-2016; Witte, Frank/D-9294-2014	Beckmann, Felix/0000-0002-2266-9173; Witte, Frank/0000-0001-9154-6217; Pisch, Alexander/0000-0003-3451-5224													0142-9612	1878-5905				OCT	2006	27	7					1013	1018		10.1016/j.biomaterials.2005.07.037	http://dx.doi.org/10.1016/j.biomaterials.2005.07.037								16122786					WOS:000234148300008
J	Smith, MC				Smith, MC			Synthesis of mechanical networks: The inerter	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												This paper is concerned with the problem of synthesis of (passive) mechanical one-port networks. One of the main contributions of this paper is the introduction of a device, which will be called the inerter, which is the true network dual of the spring. This contrasts with the mass element which, by definition, always has one terminal connected to ground. The inerter allows electrical circuits to be translated over to mechanical ones in a completely analogous way. The inerter need not have large mass. This allows any arbitrary positive-real impedance to be synthesized mechanically using physical components which may be assumed to have small mass compared to other structures to which they may be attached. The possible application of the inerter is considered to a vibration absorption problem, a suspension strut design, and as a simulated mass.																			0018-9286	1558-2523				OCT	2002	47	10					1648	1662		10.1109/TAC.2002.803532	http://dx.doi.org/10.1109/TAC.2002.803532													WOS:000178571500006
J	Mahony, R; Hamel, T; Pflimlin, JM				Mahony, Robert; Hamel, Tarek; Pflimlin, Jean-Michel			Nonlinear complementary filters on the special orthogonal group	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												This paper considers the problem of obtaining good attitude estimates from measurements obtained from typical low cost inertial measurement units. The outputs of such systems are characterized by high noise levels and time varying additive biases. We formulate the filtering problem as deterministic observer kinematics posed directly on the special orthogonal group SO (3) driven by reconstructed attitude and angular velocity measurements. Lyapunov analysis results for the proposed observers are derived that ensure almost global stability of the observer error. The approach taken leads to an observer that we term the direct complementary filter. By exploiting the geometry of the special orthogonal group a related observer, termed the passive complementary filter, is derived that decouples the gyro measurements from the reconstructed attitude in the observer inputs. Both the direct and passive filters can be extended to estimate gyro bias online. The passive filter is further developed to provide a formulation in terms of the measurement error that avoids any algebraic reconstruction of the attitude. This leads to an observer on SO(3), termed the explicit complementary filter, that requires only accelerometer and gyro outputs; is suitable for implementation on embedded hardware; and provides good attitude estimates as well as estimating the gyro biases online. The performance of the observers are demonstrated with a set of experiments performed on a robotic test-bed and a radio controlled unmanned aerial vehicle.						Mahony, Robert/0000-0002-7803-2868													0018-9286	1558-2523				JUN	2008	53	5					1203	1218		10.1109/TAC.2008.923738	http://dx.doi.org/10.1109/TAC.2008.923738													WOS:000258868400009
J	Youd, TL; Idriss, IM; Andrus, RD; Arango, I; Castro, G; Christian, JT; Dobry, R; Finn, WDL; Harder, LF; Hynes, ME; Ishihara, K; Koester, JP; Liao, SSC; Marcuson, WF; Martin, GR; Mitchell, JK; Moriwaki, Y; Power, MS; Robertson, PK; Seed, RB; Stokoe, KH				Youd, TL; Idriss, IM; Andrus, RD; Arango, I; Castro, G; Christian, JT; Dobry, R; Finn, WDL; Harder, LF; Hynes, ME; Ishihara, K; Koester, JP; Liao, SSC; Marcuson, WF; Martin, GR; Mitchell, JK; Moriwaki, Y; Power, MS; Robertson, PK; Seed, RB; Stokoe, KH			Liquefaction resistance of soils: Summary report from the 1996 NCEER and 1998 NCEER/NSF Workshops on Evaluation of Liquefaction Resistance of Soils	JOURNAL OF GEOTECHNICAL AND GEOENVIRONMENTAL ENGINEERING												Following disastrous earthquakes in Alaska and in Niigata, Japan in 1964, Professors H. B. Seed and I. M. Idriss developed and published a methodology termed the "simplified procedure" for evaluating liquefaction resistance of soils. This procedure has become a standard of practice throughout North America and much of the world. The methodology which is largely empirical, has evolved over years, primarily through summary papers by H. B. Seed and his colleagues. No general review or update of the procedure has occurred, however, since 1985, the time of the last major paper by Professor Seed and a report from a National Research Council workshop on liquefaction of soils. In 1996 a workshop sponsored by the National Center for Earthquake Engineering Research (NCEER) was convened by Professors T. L. Youd and I. M. Idriss with 20 experts to review developments over the previous 10 years. The purpose was to gain consensus on updates and augmentations to the simplified procedure. The following topics were reviewed and recommendations developed: (1) criteria based on standard penetration tests; (2) criteria based on cone penetration tests; (3) criteria based on shear-wave velocity measurements, (4) use of the Becker penetration test for gravelly soil; (4) magnitude scaling factors; (5) correction factors for overburden pressures and sloping ground; and (6) input values for earthquake magnitude and peak acceleration. Probabilistic and seismic energy analyses were reviewed but no recommendations were formulated.					Koester, Jan-Philipp/AAK-3005-2021														1090-0241					OCT	2001	127	10					817	833		10.1061/(ASCE)1090-0241(2001)127:10(817)	http://dx.doi.org/10.1061/(ASCE)1090-0241(2001)127:10(817)													WOS:000171210000001
J	Laursen, AB; Kegnæs, S; Dahl, S; Chorkendorff, I				Laursen, Anders B.; Kegnaes, Soren; Dahl, Soren; Chorkendorff, Ib			Molybdenum sulfides-efficient and viable materials for electro - and photoelectrocatalytic hydrogen evolution	ENERGY & ENVIRONMENTAL SCIENCE												This perspective covers the use of molybdenum disulfide and related compounds, generally termed MoSx, as electro- or photoelectrocatalysts for the hydrogen evolution reaction (HER). State of the art solutions as well as the most illustrative results from the extensive electro- and photoelectrocatalytic literature are given. The research strategies currently employed in the field are outlined and future challenges pointed out. We suggest that the key to optimising the HER activity of MoS2 is divided into (1) increasing the catalytic activity of the active site, (2) increasing the number of active sites of the catalyst, and (3) improving the electrical contact to these sites. These postulations are substantiated by examples from the existing literature and some new results. To demonstrate the electrocatalytic properties of a highly conductive MoS2 hybrid material, we present the HER activity data for multi-wall MoS2 nanotubes on multi-wall carbon nanotubes (MWMoS2@MWCNTs). This exemplifies the typical data collected for the electrochemical HER. In addition, it demonstrates that the origin of the activity is closely related to the amount of edges in the layered MoS2. The photoelectrocatalytic HER is also discussed, based on examples from literature, with an emphasis on the use of MoSx as either (1) the co-catalyst providing the HER activity for a semiconductor, e. g. Mo3S4+ on Si or (2) MoS2 as the semiconductor with an intrinsic HER activity. Finally, suggestions for future catalyst designs are given.					Dahl, Søren/A-4898-2011; Chorkendorff, Ib/C-7282-2008; Laursen, Anders/F-9575-2011; Kegnaes, Soren/E-1891-2011	Chorkendorff, Ib/0000-0003-2738-0325; Laursen, Anders/0000-0002-1386-9202; Kegnaes, Soren/0000-0002-6933-6931													1754-5692	1754-5706				FEB	2012	5	2					5577	5591		10.1039/c2ee02618j	http://dx.doi.org/10.1039/c2ee02618j													WOS:000299502300009
J	Rodríguez, JD; Pérez, A; Lozano, JA				Diego Rodriguez, Juan; Perez, Aritz; Antonio Lozano, Jose			Sensitivity Analysis of <i>k</i>-Fold Cross Validation in Prediction Error Estimation	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												In the machine learning field, the performance of a classifier is usually measured in terms of prediction error. In most real-world problems, the error cannot be exactly calculated and it must be estimated. Therefore, it is important to choose an appropriate estimator of the error. This paper analyzes the statistical properties, bias and variance, of the k-fold cross-validation classification error estimator (k-cv). Our main contribution is a novel theoretical decomposition of the variance of the k-cv considering its sources of variance: sensitivity to changes in the training set and sensitivity to changes in the folds. The paper also compares the bias and variance of the estimator for different values of k. The experimental study has been performed in artificial domains because they allow the exact computation of the implied quantities and we can rigorously specify the conditions of experimentation. The experimentation has been performed for two classifiers (naive Bayes and nearest neighbor), different numbers of folds, sample sizes, and training sets coming from assorted probability distributions. We conclude by including some practical recommendation on the use of k-fold cross validation.					Lozano, Jose A./F-5120-2010; Perez, Aritz/P-2247-2017	Lozano, Jose A./0000-0002-4683-8111; Perez, Aritz/0000-0002-8128-1099													0162-8828	1939-3539				MAR	2010	32	3					569	575		10.1109/TPAMI.2009.187	http://dx.doi.org/10.1109/TPAMI.2009.187								20075479					WOS:000273609600013
J	Kruth, JP; Froyen, L; Van Vaerenbergh, J; Mercelis, P; Rombouts, M; Lauwers, B				Kruth, JP; Froyen, L; Van Vaerenbergh, J; Mercelis, P; Rombouts, M; Lauwers, B			Selective laser melting of iron-based powder	JOURNAL OF MATERIALS PROCESSING TECHNOLOGY					14th International Symposium on Electromachining	MAR 30-APR 01, 2004	Edinburgh, SCOTLAND	UK, Sci & Engn Res Council, CIRP, Sci & Engn Res Council, Royal Soc Edinburgh				Selective laser melting (SLM) is driven by the need to process near full density objects with mechanical properties comparable to those of bulk materials. During the process the powder particles are completely molten by the laser beam. The resulting high density allows avoiding lengthy post-processing as required with selective laser sintering (SLS) of metal powders. Unlike SLS, SLM is more difficult to control. Because of the large energy input of the laser beam and the complete melting of particles problems like balling, residual stresses and deformation occur. This paper will describe SLM applied to a mixture of different types of particles (Fe, Ni, Cu and Fe3P) specially developed for SLM. The different appearing phenomenons are discussed and the process optimization is described. The latter includes an appropriate process parameter adjustment and the application of special scanning strategies. Resulting parts are characterized by their microstructure, density and mechanical properties. (C) 2004 Elsevier B.V. All rights reserved.																			0924-0136	1873-4774				JUN 10	2004	149	1-3					616	622		10.1016/j.jmatprotec.2003.11.051	http://dx.doi.org/10.1016/j.jmatprotec.2003.11.051													WOS:000222532800102
J	Hutmacher, DW; Schantz, T; Zein, I; Ng, KW; Teoh, SH; Tan, KC				Hutmacher, DW; Schantz, T; Zein, I; Ng, KW; Teoh, SH; Tan, KC			Mechanical properties and cell cultural response of polycaprolactone scaffolds designed and fabricated via fused deposition modeling	JOURNAL OF BIOMEDICAL MATERIALS RESEARCH												A number of different processing techniques have been developed to design and fabricate three-dimensional (3D) scaffolds for tissue-engineering applications. The imperfection of the current techniques has encouraged the use of a rapid prototyping technology known as fused deposition modeling (FDM). Our results show that FDM allows the design and fabrication of highly reproducible bioresorbable 3D scaffolds with a fully interconnected pore network. The mechanical properties and in vitro biocompatibility of polycaprolactone scaffolds with a porosity of 61 +/- 1% and two matrix architectures were studied. The honeycomblike pores had a size falling within the range of 360 x 430 x 620 mum. The scaffolds with a 0/60/120 degrees lay-down pattern had a compressive stiffness and a 1% offset yield strength in air of 41.9 +/- 3.5 and 3.1 +/- 0.1 MPa, respectively, and a compressive stiffness and a 1% offset yield strength in simulated physiological conditions (a saline solution at 37 degreesC) of 29.4 +/- 4.0 and 2.3 +/- 0.2 MPa, respectively. In comparison, the scaffolds with a 0/72/144/36/108 degrees lay-down pattern had a compressive stiffness and a 1% offset yield strength in air of 20.2 +/- 1.7 and 2.4 +/- 0.1 MPa, respectively, and a compressive stiffness and a 1% offset yield strength in simulated physiological conditions (a saline solution at 37 degreesC) of 21.5 +/- 2.9 and 2.0 +/- 0.2 MPa, respectively. Statistical analysis confirmed that the five-angle scaffolds had significantly lower stiffness and 1% offset yield strengths under compression loading than those with a three-angle pattern under both testing conditions (p less than or equal to 0.05). The obtained stress-strain curves for both scaffold architectures demonstrate the typical behavior of a honeycomb structure undergoing deformation. In vitro studies were conducted with primary human fibroblasts and periosteal cells. Light, environmental scanning electron, and confocal laser microscopy as well as immunohistochemistry showed cell proliferation and extracellular matrix production on the polycaprolactone surface in the Ist culturing week. Over a period of 3-4 weeks in a culture, the fully interconnected scaffold architecture was completely 3D-filled by cellular tissue. Our cell culture study shows that fibroblasts and osteoblast-like cells can proliferate, differentiate, and produce a cellular tissue in an entirely interconnected 3D polycaprolactone matrix. (C) 2001 John Wiley & Sons, Inc.					Hutmacher, Dietmar/AEO-9578-2022; Ng, Kee Woei/B-7242-2008	Hutmacher, Dietmar Werner/0000-0001-5678-2134; Ng, Kee Woei/0000-0002-7276-3563													0021-9304					MAY	2001	55	2					203	216		10.1002/1097-4636(200105)55:2<203::AID-JBM1007>3.0.CO;2-7	http://dx.doi.org/10.1002/1097-4636(200105)55:2<203::AID-JBM1007>3.0.CO;2-7								11255172					WOS:000167221200008
J	Zhang, ZX; Liu, QJ; Wang, YH				Zhang, Zhengxin; Liu, Qingjie; Wang, Yunhong			Road Extraction by Deep Residual U-Net	IEEE GEOSCIENCE AND REMOTE SENSING LETTERS												Road extraction from aerial images has been a hot research topic in the field of remote sensing image analysis. In this letter, a semantic segmentation neural network, which combines the strengths of residual learning and U-Net, is proposed for road area extraction. The network is built with residual units and has similar architecture to that of U-Net. The benefits of this model are twofold: first, residual units ease training of deep networks. Second, the rich skip connections within the network could facilitate information propagation, allowing us to design networks with fewer parameters, however, better performance. We test our network on a public road data set and compare it with U-Net and other two state-of-the-art deep-learning-based road extraction methods. The proposed approach outperforms all the comparing methods, which demonstrates its superiority over recently developed state of the arts.					zhang, zhengxin/AAE-2993-2019														1545-598X	1558-0571				MAY	2018	15	5					749	753		10.1109/LGRS.2018.2802944	http://dx.doi.org/10.1109/LGRS.2018.2802944													WOS:000430730200023
J	Hu, M; Mi, BX				Hu, Meng; Mi, Baoxia			Enabling Graphene Oxide Nanosheets as Water Separation Membranes	ENVIRONMENTAL SCIENCE & TECHNOLOGY												We report a novel procedure to synthesize a new type of water separation membrane using graphene oxide (GO) nanosheets such that water can flow through the nanochannels between GO layers while unwanted solutes are rejected by size exclusion and charge effects. The GO membrane was made via layer-by-layer deposition of GO nanosheets, which were cross-linked by 1,3,5-benzenetricarbonyl trichloride, on a polydopamine-coated polysulfone support. The cross-linking not only provided the stacked GO nanosheets with the necessary stability to overcome their inherent dispensability in water environment but also fine-tuned the charges, functionality, and spacing of the GO nanosheets. We then tested the membranes synthesized with different numbers of GO layers to demonstrate their interesting water separation performance. It was found that the GO membrane flux ranged between 80 and 276 LMH/MPa, roughly 4-10 times higher than that of most commercial nanofiltration membranes. Although the GO membrane in the present development stage had a relatively low rejection (6-46%) of monovalent and divalent salts, it exhibited a moderate rejection (46-66%) of Methylene blue and a high rejection (93-95%) of Rhodamine-WT. We conclude the paper by emphasizing that the facile synthesis of a GO membrane exploiting the ideal properties of inexpensive GO materials offers a myriad of opportunities to modify its physicochemical properties, potentially making the GO membrane a next-generation, cost-effective, and sustainable alternative to the long-existing thin-film composite polyamide membranes for water separation applications.					Mi, Baoxia/H-2309-2014	Hu, Meng/0000-0003-3749-6452													0013-936X	1520-5851				APR 16	2013	47	8					3715	3723		10.1021/es400571g	http://dx.doi.org/10.1021/es400571g								23488812					WOS:000317813400023
J	McLellan, BC; Williams, RP; Lay, J; van Riessen, A; Corder, GD				McLellan, Benjamin C.; Williams, Ross P.; Lay, Janine; van Riessen, Arie; Corder, Glen D.			Costs and carbon emissions for geopolymer pastes in comparison to ordinary portland cement	JOURNAL OF CLEANER PRODUCTION												Geopolymer concrete is seen as a potential alternative to standard concrete, and an opportunity to convert a variety of waste streams into useful by-products. One key driver in geopolymer development is the desire to reduce greenhouse gas emissions from the production of concrete products. This paper presents an examination of the lifecycle cost and carbon impacts of Ordinary Portland Cement (OPC) and geopolymers in an Australian context, with an identification of some key challenges for geopolymer development. The results of the examination show that there is wide variation in the calculated financial and environmental "cost" of geopolymers, which can be beneficial or detrimental depending on the source location, the energy source and the mode of transport. Some case study geopolymer concrete mixes based on typical Australian feedstocks indicate potential for a 44-64% reduction in greenhouse gas emissions while the financial costs are 7% lower to 39% higher compared with OPC. (C) 2011 Elsevier Ltd. All rights reserved.					Williams, Ross/G-3791-2010; van Riessen, Arie/C-9519-2009; McLellan, Benjamin/HLH-5239-2023; McLellan, Benjamin/B-7833-2009; Corder, Glen/K-3133-2014	Williams, Ross/0000-0003-3556-0799; McLellan, Benjamin/0000-0002-4802-3864; Corder, Glen/0000-0001-8733-1248													0959-6526	1879-1786				JUN-JUL	2011	19	9-10					1080	1090		10.1016/j.jclepro.2011.02.010	http://dx.doi.org/10.1016/j.jclepro.2011.02.010													WOS:000290702800018
J	Williams, JM; Adewunmi, A; Schek, RM; Flanagan, CL; Krebsbach, PH; Feinberg, SE; Hollister, SJ; Das, S				Williams, JM; Adewunmi, A; Schek, RM; Flanagan, CL; Krebsbach, PH; Feinberg, SE; Hollister, SJ; Das, S			Bone tissue engineering using polycaprolactone scaffolds fabricated via selective laser sintering	BIOMATERIALS												Polycaprolactone (PCL) is a bioresorbable polymer with potential applications for bone and cartilage repair. In this work, porous PCL scaffolds were computationally designed and then fabricated via selective laser sintering (SLS), a rapid prototyping technique. The microstructure and mechanical properties of the fabricated scaffolds were assessed and compared to the designed porous architectures and computationally predicted properties. Scaffolds were then seeded with bone morphogenetic protein-7 (BMP-7) transduced fibroblasts and implanted subcutaneously to evaluate biological properties and to demonstrate tissue in-growth. The work done illustrates the ability to design and fabricate PCL scaffolds with porous architecture that have sufficient mechanical properties for bone tissue engineering applications using SLS. Compressive modulus and yield strength values ranged from 52 to 67 MPa and 2.0 to 3.2 Mpa, respectively, lying within the lower range of properties reported for human trabecular bone. Finite element analysis (FEA) results showed that mechanical properties of scaffold designs and of fabricated scaffolds can be computationally predicted. Histological evaluation and micro-computed tomography (mu CT) analysis of implanted scaffolds showed that bone can be generated in vivo. Finally, to demonstrate the clinical application of this technology, we designed and fabricated a prototype mandibular condyle scaffold based on an actual pig condyle. The integration of scaffold computational design and free-form fabrication techniques presented here could prove highly useful for the construction of scaffolds that have anatomy specific exterior architecture derived from patient CT or MRI data and an interior porous architecture derived from computational design optimization. (C) 2005 Elsevier Ltd. All rights reserved.					Das, Suman/A-7820-2009; Flanagan, Colleen/AAA-3421-2021; Hollister, Scott/ABH-3463-2021; Krebsbach, Paul/AAC-4765-2021	Flanagan, Colleen/0000-0001-8530-5126; Hollister, Scott/0000-0001-7625-892X													0142-9612	1878-5905				AUG	2005	26	23					4817	4827		10.1016/j.biomaterials.2004.11.057	http://dx.doi.org/10.1016/j.biomaterials.2004.11.057								15763261					WOS:000228315900013
J	Intanagonwiwat, C; Govindan, R; Estrin, D; Heidemann, J; Silva, F				Intanagonwiwat, C; Govindan, R; Estrin, D; Heidemann, J; Silva, F			Directed diffusion for wireless sensor networking	IEEE-ACM TRANSACTIONS ON NETWORKING												Advances in processor, memory, and radio technology will enable small and cheap nodes capable of sensing, communication, and computation. Networks of such nodes can coordinate to perform distributed sensing of environmental phenomena. In this paper, we explore the directed-diffusion paradigm for such coordination. Directed diffusion is data-centric in that all communication is for named data. All nodes in a directed-diffusion-based network are application aware. This enables diffusion to achieve energy savings by selecting empirically good paths and by caching and processing data in-network (e.g., data aggregation). We explore and evaluate the use of directed diffusion for a simple remote-surveillance sensor network analytically and experimentally. Our evaluation indicates that directed diffusion can achieve significant energy savings and can outperform idealized traditional schemes (e.g., omniscient multicast) under the investigated scenarios.						Heidemann, John/0000-0002-1225-7562													1063-6692	1558-2566				FEB	2003	11	1					2	16		10.1109/TNET.2002.808417	http://dx.doi.org/10.1109/TNET.2002.808417													WOS:000181934200001
J	Haryanto, A; Fernando, S; Murali, N; Adhikari, S				Haryanto, A; Fernando, S; Murali, N; Adhikari, S			Current status of hydrogen production techniques by steam reforming of ethanol: A review	ENERGY & FUELS												Hydrogen is considered to be the most viable energy carrier for the future. Producing hydrogen from ethanol steam reforming would not only be environmentally friendly but also would open new opportunities for utilization of renewable resources, which are globally available. This paper reviews the current state of the steam reforming process of ethanol, examines different catalysts, and, finally, makes a comparative analysis. Different catalysts have been used for the steam reforming of ethanol. Depending on the type of catalysts, reaction conditions, and the catalyst preparation method, ethanol conversion and hydrogen production vary greatly. It was observed that Co/ZnO, ZnO, Rh/Al2O3, RIVCeO2, and Ni/La2O3-Al2O3 performed the best, in regard to the steam reforming of ethanol. Currently, hydrogen production from ethanol steam reforming is still in the research and development stage.						Adhikari, Sushil/0000-0002-6539-6822													0887-0624	1520-5029				SEP-OCT	2005	19	5					2098	2106		10.1021/ef0500538	http://dx.doi.org/10.1021/ef0500538													WOS:000232067300044
J	Aumann, HH; Chahine, MT; Gautier, C; Goldberg, MD; Kalnay, E; McMillin, LM; Revercomb, H; Rosenkranz, PW; Smith, WL; Staelin, DH; Strow, LL; Susskind, J				Aumann, HH; Chahine, MT; Gautier, C; Goldberg, MD; Kalnay, E; McMillin, LM; Revercomb, H; Rosenkranz, PW; Smith, WL; Staelin, DH; Strow, LL; Susskind, J			AIRS/AMSU/HSB on the aqua mission: Design, science objectives, data products, and processing systems	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING												The Atmospheric Infrared Sounder (AIRS), the Advanced Microwave Sounding Unit (AMSU), and the Humidity Sounder for Brazil (HSB) form an integrated cross-track scanning temperature and humidity sounding system on the Aqua satellite of the Earth Observing System (EOS). AIRS is an infrared spectrometer/radiometer that covers the 3.7-15.4-tim spectral range with 2378 spectral channels. AMSU is a 15-channel microwave radiometer operating between 23 and 89 GHz. HSB is a four-channel microwave radiometer that makes measurements between 150 and 190 GHz. In addition to supporting the National Aeronautics and Space Administration's interest in process study and climate research, AIRS is the first hyperspectral infrared radiometer designed to support the operational requirements for medium-range weather forecasting of the National Ocean and Atmospheric Administration's National Centers for Environmental Prediction (NCEP) and other numerical weather forecasting centers. AIRS, together with the AMSU and HSB microwave radiometers, will achieve global retrieval accuracy of better than 1 K in the lower troposphere under clear and partly cloudy conditions. This paper presents an overview of the science objectives, AIRS/AMSU/HSB data products, retrieval algorithms, and the ground-data processing concepts. The EOS Aqua was launched on May 4, 2002 from Vandenberg AFB, CA, into a 705-km-high, sun-synchronous orbit. Based on the excellent radiometric and spectral performance demonstrated by AIRS during prelaunch testing, which has by now been verified during on-orbit testing, we expect the assimilation of AIRS data into the numerical weather forecast to result in significant forecast range and reliability improvements.					Goldberg, Mitch/F-5589-2010; Kalnay, Eugenia/F-4393-2010	Kalnay, Eugenia/0000-0002-9984-9906													0196-2892					FEB	2003	41	2					253	264		10.1109/TGRS.2002.808356	http://dx.doi.org/10.1109/TGRS.2002.808356													WOS:000182494600009
J	Wang, SQ; Tuor, T; Salonidis, T; Leung, KK; Makaya, C; He, T; Chan, K				Wang, Shiqiang; Tuor, Tiffany; Salonidis, Theodoros; Leung, Kin K.; Makaya, Christian; He, Ting; Chan, Kevin			Adaptive Federated Learning in Resource Constrained Edge Computing Systems	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS												Emerging technologies and applications including Internet of Things, social networking, and crowd-sourcing generate large amounts of data at the network edge. Machine learning models are often built from the collected data, to enable the detection, classification, and prediction of future events. Due to bandwidth, storage, and privacy concerns, it is often impractical to send all the data to a centralized location. In this paper, we consider the problem of learning model parameters from data distributed across multiple edge nodes, without sending raw data to a centralized place. Our focus is on a generic class of machine learning models that are trained using gradient-descent-based approaches. We analyze the convergence bound of distributed gradient descent from a theoretical point of view, based on which we propose a control algorithm that determines the best tradeoff between local update and global parameter aggregation to minimize the loss function under a given resource budget. The performance of the proposed algorithm is evaluated via extensive experiments with real datasets, both on a networked prototype system and in a larger-scale simulated environment. The experimentation results show that our proposed approach performs near to the optimum with various machine learning models and different data distributions.					Covey, Kevin/AAE-3599-2020; Wang, Shiqiang/AAR-4091-2020														0733-8716	1558-0008				JUN	2019	37	6					1205	1221		10.1109/JSAC.2019.2904348	http://dx.doi.org/10.1109/JSAC.2019.2904348													WOS:000468234400003
B	Kim, H; Tadesse, Y; Priya, S		Priya, S; Inman, DJ		Kim, Hyunuk; Tadesse, Yonas; Priya, Shashank			Piezoelectric Energy Harvesting	ENERGY HARVESTING TECHNOLOGIES												This chapter provides the introductory information on piezoelectric energy harvesting covering various aspects such as modeling, selection of materials, vibration harvesting device design using bulk and MEMS approach, and energy harvesting circuits. All these characteristics are illustrated through selective examples. A simple step-by-step procedure is presented to design the cantilever beam based energy harvester by incorporating piezoelectric material at maximum stress points in first and second resonance modes. Suitable piezoelectric material for vibration energy harvesting is characterized by the large magnitude of product of the piezoelectric voltage constant (g) and the piezoelectric strain constant (d) given as (d . g). The condition for obtaining large magnitude of d.g has been shown to be as vertical bar d vertical bar = epsilon(n), where E is the permittivity of the material and n is a material parameter having, lower limit of 0.5. The material can be in the form of polycrystalline ceramics, textured ceramics, thin films, and polymers. A brief coverage of various material systems is provided in all these categories. Using these materials different transducer structures can be fabricated depending upon the desired frequency and vibration amplitude such as multilayer, MFC, bimorph, amplified piezoelectric actuator, QuickPack, rainbow, cymbal, and moonie. The concept of multi modal energy harvesting is introduced at the end of the chapter. This concept provides the opportunity for further enhancement of power density by combining two different energy-harvesting schemes in one system such that one assists the other.					Tadesse, Yonas/K-8916-2013; Priya, S/GQH-7176-2022	Tadesse, Yonas/0000-0001-6606-7089; Priya, Shashank/0000-0003-1367-3434															978-0-387-76463-4				2009							3	39		10.1007/978-0-387-76464-1_1	http://dx.doi.org/10.1007/978-0-387-76464-1_1	10.1007/978-0-387-76464-1												WOS:000268240100001
J	Hessel, V; Löwe, H; Schönfeld, F				Hessel, V; Löwe, H; Schönfeld, F			Micromixers -: a review on passive and active mixing principles	CHEMICAL ENGINEERING SCIENCE					5th International Symposium on Mixing in Industrial Processes	JUN 01-04, 2004	Seville, SPAIN					A review on microstructured mixer devices and their mixing principles concerning miscible liquids (and gases) is given. This is supplemented by the description of typical mixing element designs, methods for mixing characterisation, and application fields. The mixing principles applied can be divided in two classes relying either on the pumping energy or provision of other external energy to achieve mixing, termed passive and active mixing, respectively. As far as passive mixing is concerned, devices and techniques such as Y- and T-type flow-, multi-laminating-, split-and-recombine-, chaotic-, jet colliding-, recirculation flow-mixers and others are discussed. Active mixing can be accomplished by time-pulsing flow owing to a periodical change of pumping energy or electrical fields, acoustic fluid shaking, ultrasound. electrowetting-based droplet shaking, microstirrers, and others. (c) 2005 Elsevier Ltd. All rights reserved.					hessel, ellen/ABB-4007-2021														0009-2509	1873-4405				APR-MAY	2005	60	8-9					2479	2501		10.1016/j.ces.2004.11.033	http://dx.doi.org/10.1016/j.ces.2004.11.033													WOS:000227864000033
J	Jinno, M; Takara, H; Kozicki, B; Tsukishima, Y; Sone, Y; Matsuoka, S				Jinno, Masahiko; Takara, Hidehiko; Kozicki, Bartlomiej; Tsukishima, Yukio; Sone, Yoshiaki; Matsuoka, Shinji			Spectrum-Efficient and Scalable Elastic Optical Path Network: Architecture, Benefits, and Enabling Technologies	IEEE COMMUNICATIONS MAGAZINE												The sustained growth of data traffic volume calls for an introduction of an efficient and scalable transport platform for links of 100 Gb/s and beyond in the future optical network. In this article, after briefly reviewing the existing major technology options, we propose a novel, spectrum-efficient, and scalable optical transport network architecture called SLICE. The SLICE architecture enables sub-wavelength, super-wavelength, and multiple-rate data traffic accommodation in a highly spectrum-efficient manner, thereby providing a fractional bandwidth service. Dynamic bandwidth variation of elastic optical paths provides network operators with new business opportunities offering cost-effective and highly available connectivity services through time-dependent bandwidth sharing, energy-efficient network operation, and highly survivable restoration with bandwidth squeezing. We also discuss an optical orthogonal frequency-division multiplexing-based flexible-rate transponder and a bandwidth-variable wavelength cross-connect as the enabling technologies of SLICE concept. Finally, we present the performance evaluation and technical challenges that arise in this new network architecture.					Jinno, Masahiko/J-4433-2012														0163-6804	1558-1896				NOV	2009	47	11					66	73		10.1109/MCOM.2009.5307468	http://dx.doi.org/10.1109/MCOM.2009.5307468													WOS:000271478300011
J	Hokayem, PF; Spong, MW				Hokayem, Peter F.; Spong, Mark W.			Bilateral teleoperation: An historical survey	AUTOMATICA					16th IFAC World Congress	JUL 03-08, 2005	Prague, CZECH REPUBLIC	IFAC				This survey addresses the subject of bilateral teleoperation, a research stream with more than 50 years of history and one that continues to be a fertile ground for theoretical exploration and many applications. We focus on the control theoretic approaches that have been developed to address inherent control problems such as delays and information loss. Exposure to several concurrent applications is provided, and possible future trends are outlined. (c) 2006 Elsevier Ltd. All rights reserved.																			0005-1098	1873-2836				DEC	2006	42	12					2035	2057		10.1016/j.automatica.2006.06.027	http://dx.doi.org/10.1016/j.automatica.2006.06.027													WOS:000242304700001
J	Baena, JD; Bonache, J; Martín, F; Sillero, RM; Falcone, F; Lopetegi, T; Laso, MAG; García-García, J; Gil, I; Portillo, MF; Sorolla, M				Baena, JD; Bonache, J; Martín, F; Sillero, RM; Falcone, F; Lopetegi, T; Laso, MAG; García-García, J; Gil, I; Portillo, MF; Sorolla, M			Equivalent-circuit models for split-ring resonators and complementary split-ring resonators coupled to planar transmission lines	IEEE TRANSACTIONS ON MICROWAVE THEORY AND TECHNIQUES												In this paper, a new approach for the development of planar metamaterial structures is developed. For this purpose, split-ring resonators (SRRs) and complementary split-ring resonators (CSRRs) coupled to planar transmission lines are investigated. The electromagnetic behavior of these elements, as well as their coupling to the host transmission line, are studied, and analytical equivalent-circuit models are proposed for the isolated and coupled SRRs/CSRRs. From these models, the stopband/passband characteristics of the analyzed SRR/CSRR loaded transmission lines are derived. It is shown that, in the long wavelength limit, these stopbands/passbands can be interpreted as due to the presence of negative/positive values for the effective 6 and mu of the line. The proposed analysis is of interest in the design of compact microwave devices based on the metamaterial concept.					Gil, Ignacio/X-5011-2019; Baena, Juan/HCI-9097-2022; Falcone, Francisco/B-9456-2012; Garcia-Garcia, Joan J/AAI-2779-2021; Laso, Miguel/B-6305-2012; Bonache, Jordi/G-1549-2011; Lopetegi, Txema/L-7597-2014	Garcia-Garcia, Joan J/0000-0002-7825-0224; Laso, Miguel/0000-0003-1371-0610; Bonache, Jordi/0000-0002-7225-5737; Falcone, Francisco/0000-0002-4911-9753; Marques Sillero, Ricardo/0000-0003-0528-384X; Martin, Ferran/0000-0002-1494-9167; Baena Doello, Juan Domingo/0000-0002-8349-3263; Gil, Ignacio/0000-0002-7175-5756; Lopetegi, Txema/0000-0002-8255-3383													0018-9480	1557-9670				APR	2005	53	4	2				1451	1461		10.1109/TMTT.2005.845211	http://dx.doi.org/10.1109/TMTT.2005.845211													WOS:000228365800005
J	Stankovic, JA				Stankovic, John A.			Research Directions for the Internet of Things	IEEE INTERNET OF THINGS JOURNAL												Many technical communities are vigorously pursuing research topics that contribute to the Internet of Things (IoT). Nowadays, as sensing, actuation, communication, and control become even more sophisticated and ubiquitous, there is a significant overlap in these communities, sometimes from slightly different perspectives. More cooperation between communities is encouraged. To provide a basis for discussing open research problems in IoT, a vision for how IoT could change the world in the distant future is first presented. Then, eight key research topics are enumerated and research problems within these topics are discussed.																			2327-4662					FEB	2014	1	1					3	9		10.1109/JIOT.2014.2312291	http://dx.doi.org/10.1109/JIOT.2014.2312291													WOS:000209672000002
J	Lindstrom, AB; Strynar, MJ; Libelo, EL				Lindstrom, Andrew B.; Strynar, Mark J.; Libelo, E. Laurence			Polyfluorinated Compounds: Past, Present, and Future	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Interest and concern about polyfluorinated compounds (PFCs), such as perfluorooctane sulfonate (PFOS), perfluorooctanoic acid (PFOA), and an increasing number of other related compounds is growing as more is learned about these ubiquitous anthropogenic substances. Many of these compounds can be toxic, and they are regularly found in the blood of animals and humans worldwide. A great deal of research has been conducted in this area, but a surprising amount remains unknown about their distribution in the environment and how people ultimately become exposed. The utility of these compounds seems to ensure their continued use in one form or another for the foreseeable future, presenting a long-term challenge to scientists, industry leaders, and public health officials worldwide.						Strynar, Mark/0000-0003-3472-7921													0013-936X	1520-5851				OCT 1	2011	45	19					7954	7961		10.1021/es2011622	http://dx.doi.org/10.1021/es2011622								21866930					WOS:000295245600002
J	Njoku, EG; Jackson, TJ; Lakshmi, V; Chan, TK; Nghiem, SV				Njoku, EG; Jackson, TJ; Lakshmi, V; Chan, TK; Nghiem, SV			Soil moisture retrieval from AMSR-E	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING												The Advanced Microwave Scanning Radiometer (AMSR-E) on the Earth Observing System (EOS) Aqua satellite was launched on May 4, 2002. The AMSR-E instrument provides a potentially improved soil moisture sensing capability over previous spaceborne radiometers such as the Scanning Multichannel Microwave Radiometer and Special Sensor Microwave/Imager due to its combination of low frequency and higher spatial resolution (approximately 60 km at 6.9 GHz). The AMSR-E soil moisture retrieval approach and its implementation are described in this paper. A postlaunch validation program is in progress that will provide evaluations of the retrieved soil moisture and enable improved hydrologic applications of the data. Key aspects of the validation program include assessments of the effects on retrieved soil moisture of variability in vegetation water content, surface temperature, and spatial heterogeneity. Examples of AMSR-E brightness temperature observations over land are shown from the first few months of instrument operation, indicating general features of global vegetation and soil moisture variability. The AMSR-E sensor calibration and extent of radio frequency interference are currently being assessed, to be followed by quantitative assessments of the soil moisture retrievals. The AMSR-E instrument was developed by the National Space Development Agency of Japan (NASDA) and provided to the U.S. National Aeronautics. and Space Administration. A similar instrument was launched in December 2002 on NASDA's ADEOS-II satellite.					Lakshmi, Venkat/I-3078-2016														0196-2892	1558-0644				FEB	2003	41	2					215	229		10.1109/TGRS.2002.808243	http://dx.doi.org/10.1109/TGRS.2002.808243													WOS:000182494600006
J	Govindaraju, RS				Govindaraju, Rao S.		ASCE Task Comm Application Artific	ARTIFICIAL NEURAL NETWORKS IN HYDROLOGY. I: PRELIMINARY CONCEPTS	JOURNAL OF HYDROLOGIC ENGINEERING												In this two-part series, the writers investigate the role of artificial neural networks (ANNs) in hydrology. ANNs are gaining popularity, as is evidenced by the increasing number of papers on this topic appearing in hydrology journals, especially over the last decade. In terms of hydrologic applications, this modeling tool is still in its nascent stages. The practicing hydrologic community is just becoming aware of the potential of ANNs as an alternative modeling tool. This paper is intended to serve as an introduction to ANNs for hydrologists. Apart from descriptions of various aspects of ANNs and some guidelines on their usage, this paper offers a brief comparison of the nature of ANNs and other modeling philosophies in hydrology. A discussion on the strengths and limitations of ANNs brings out the similarities they have with other modeling approaches, such as the physical model.						Govindaraju, Rao/0000-0003-3957-3319													1084-0699	1943-5584				APR	2000	5	2					115	123																WOS:000207775700001
J	Du, PW; Eisenberg, R				Du, Pingwu; Eisenberg, Richard			Catalysts made of earth-abundant elements (Co, Ni, Fe) for water splitting: Recent progress and future challenges	ENERGY & ENVIRONMENTAL SCIENCE												This article reviews recent significant advances in the field of water splitting. Catalysts play very important roles in two half reactions of water splitting - water reduction and water oxidation. Considering potential future applications, catalysts made of cheap and earth abundant element(s) are especially important for economically viable energy conversion. This article focuses only on catalysts made of cobalt (Co), nickel (Ni) and iron (Fe) elements for water reduction and water oxidation. Different series of catalysts that can be applied in electrocatalytic and photocatalytic water spitting are discussed in detail and their catalytic mechanisms are introduced. Finally, the future outlook and perspective of catalysts made of earth abundant elements will be discussed.					Eisenberg, Robert/P-6070-2019; Du, Pingwu/G-3329-2010	Eisenberg, Richard/0000-0003-1762-535X; Du, Pingwu/0000-0002-2715-0979													1754-5692	1754-5706				MAR	2012	5	3					6012	6021		10.1039/c2ee03250c	http://dx.doi.org/10.1039/c2ee03250c													WOS:000300710600009
J	Greene, WH; Hensher, DA				Greene, WH; Hensher, DA			A latent class model for discrete choice analysis: contrasts with mixed logit	TRANSPORTATION RESEARCH PART B-METHODOLOGICAL												The multinomial logit model (MNL) has for many years provided the fundamental platform for the analysis of discrete choice. The basic model's several shortcomings, most notably its inherent assumption of independence from irrelevant alternatives have motivated researchers to develop a variety of alternative formulations. The mixed logit model stands as one of the most significant of these extensions. This paper proposes a semi-parametric extension of the MNL, based on the latent class formulation, which resembles the mixed logit model but which relaxes its requirement that the analyst makes specific assumptions about the distributions of parameters across individuals. An application of the model to the choice of long distance travel by three road types (2-lane, 4-lane without a median and 4-lane with a median) by car in New Zealand is used to compare the MNL latent class model with mixed logit. (C) 2003 Elsevier Science Ltd. All rights reserved.					Hensher, David/C-4145-2011	Hensher, David/0000-0003-0058-2242													0191-2615					SEP	2003	37	8					681	698		10.1016/S0191-2615(02)00046-2	http://dx.doi.org/10.1016/S0191-2615(02)00046-2													WOS:000184488500001
J	Han, J; Bhanu, B				Han, J; Bhanu, B			Individual recognition using Gait Energy Image	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												In this paper, we propose a new spatio-temporal gait representation, called Gait Energy Image (GEI), to characterize human walking properties for individual recognition by gait. To address the problem of the lack of training templates, we also propose a novel approach for human recognition by combining statistical gait features from real and synthetic templates. We directly compute the real templates from training silhouette sequences, while we generate the synthetic templates from training sequences by simulating silhouette distortion. We use a statistical approach for learning effective features from real and synthetic templates. We compare the proposed GEI-based gait recognition approach with other gait recognition approaches on USF HumanID Database. Experimental results show that the proposed GEI is an effective and efficient gait representation for individual recognition, and the proposed approach achieves highly competitive performance with respect to the published gait recognition approaches.																			0162-8828	1939-3539				FEB	2006	28	2					316	322		10.1109/TPAMI.2006.38	http://dx.doi.org/10.1109/TPAMI.2006.38								16468626					WOS:000233824500012
J	Aiken, AC; Decarlo, PF; Kroll, JH; Worsnop, DR; Huffman, JA; Docherty, KS; Ulbrich, IM; Mohr, C; Kimmel, JR; Sueper, D; Sun, Y; Zhang, Q; Trimborn, A; Northway, M; Ziemann, PJ; Canagaratna, MR; Onasch, TB; Alfarra, MR; Prevot, ASH; Dommen, J; Duplissy, J; Metzger, A; Baltensperger, U; Jimenez, JL				Aiken, Allison C.; Decarlo, Peter F.; Kroll, Jesse H.; Worsnop, Douglas R.; Huffman, J. Alex; Docherty, Kenneth S.; Ulbrich, Ingrid M.; Mohr, Claudia; Kimmel, Joel R.; Sueper, Donna; Sun, Yele; Zhang, Qi; Trimborn, Achim; Northway, Megan; Ziemann, Paul J.; Canagaratna, Manjula R.; Onasch, Timothy B.; Alfarra, M. Rami; Prevot, Andre S. H.; Dommen, Josef; Duplissy, Jonathan; Metzger, Axel; Baltensperger, Urs; Jimenez, Jose L.			O/C and OM/OC ratios of primary, secondary, and ambient organic aerosols with high-resolution time-of-flight aerosol mass spectrometry	ENVIRONMENTAL SCIENCE & TECHNOLOGY												A recently developed method to rapidly quantify the elemental composition of bulk organic aerosols (OA) using a high-resolution time-of-flight aerosol mass spectrometer (HR-ToF-AMS) is improved and applied to ambient measurements. Atomic oxygen-to-carbon (O/C) ratios characterize the oxidation state of OA, and O/C from ambient urban OA ranges from 0.2 to 0.8 with a diurnal cycle that decreases with primary emissions and increases because of photochemical processing and secondary OA (SOA) production. Regional O/C approaches similar to 0.9. The hydrogen-to-carbon (H/C, 1.4-1.9) urban diurnal profile increases with primary CIA (POA) as does the nitrogen-to-carbon WC, similar to 0.02). Ambient organic-mass-to-organic-carbon ratios (OM/OC) are directly quantified and correlate well with O/C (R-2 = 0.997) for ambient OA because of low N/C. Ambient O/C and OWN have values consistent with those recently reported from other techniques. Positive matrix factorization applied to ambient OA identifies factors with distinct O/C and OM/OC trends. The highest O/C and OM/OC (1.0 and 2.5, respectively) are observed for aged ambient oxygenated OA, significantly exceeding values for traditional chamber SOA, while laboratory-produced primary biomass burning OA (BBOA) is similar to ambient BBOA, O/C of 0.3-0.4. Hydrocarbon-like OA (HOA), a surrogate for urban combustion POA, has the lowest O/C (0.06-0.10), similar to vehicle exhaust. An approximation for predicting O/C from unit mass resolution data is also presented.					Worsnop, Douglas/D-2817-2009; Ulbrich, Ingrid/AAX-9228-2020; DeCarlo, Peter/AAA-8561-2019; Onasch, Tim/AAY-4998-2020; Tomita, Masaru/C-8380-2014; Baltensperger, Urs/AFM-8080-2022; Zhang, Qi/F-9653-2010; , Dommen/AFN-4491-2022; Alfarra, M./K-2156-2012; Huffman, Alex/A-7449-2010; Aiken, Allison/B-9659-2009; Sun, Yele/F-1314-2010; Mohr, Claudia/D-9857-2011; Jimenez, Jose L/A-5294-2008; Duplissy, Jonathan/A-1723-2010; Prevot, Andre/C-6677-2008	Huffman, Alex/0000-0002-5363-9516; Aiken, Allison/0000-0001-5749-7626; Sun, Yele/0000-0003-2354-0221; Mohr, Claudia/0000-0002-3291-9295; Jimenez, Jose L/0000-0001-6203-1847; DeCarlo, Peter/0000-0001-6385-7149; Duplissy, Jonathan/0000-0001-8819-0264; Alfarra, Rami/0000-0002-3925-3780; Canagaratna, Manjula/0000-0002-8803-4007; Prevot, Andre/0000-0002-9243-8194													0013-936X	1520-5851				JUN 15	2008	42	12					4478	4485		10.1021/es703009q	http://dx.doi.org/10.1021/es703009q								18605574					WOS:000256705600041
J	Harrison, RR; Charles, C				Harrison, RR; Charles, C			A low-power low-noise CMOS amplifier for neural recording applications	IEEE JOURNAL OF SOLID-STATE CIRCUITS												There is a need among scientists and clinicians for low-noise low-power biosignal amplifiers capable of amplifying signals in the millihertz-to-kilohertz range while rejecting large dc offsets generated at the electrode-tissue interface. The advent of fully implantable multielectrode arrays has created the need for fully integrated micropower amplifiers. We designed and tested a novel bioamplifier that uses a MOS-bipolar pseudoresistor element to amplify low-frequency signals down to the millihertz range while rejecting large dc offsets. We derive the theoretical noise-power tradeoff limit-the noise efficiency factor-for this amplifier and demonstrate that our VLSI implementation approaches this limit by selectively operating MOS transistors in either weak or strong inversion. The resulting amplifier, built in a standard 1.5-mum CMOS process, passes signals from 0.025 Hz to 7.2 kHz with an input-referred noise of 2.2 muVrms and a power dissipation of 80 muW while consuming 0.16 mm(2) of chip area. Our design technique was also used to develop an electroencephalogram amplifier having a bandwidth of 30 Hz and a power dissipation of 0.9 muW while maintaining a similar noise-power tradeoff.																			0018-9200	1558-173X				JUN	2003	38	6					958	965		10.1109/JSSC.2003.811979	http://dx.doi.org/10.1109/JSSC.2003.811979													WOS:000183267800013
J	Thompson, MK; Moroni, G; Vaneker, T; Fadel, G; Campbell, RI; Gibson, I; Bernard, A; Schulz, J; Graf, P; Ahuja, B; Martina, F				Thompson, Mary Kathryn; Moroni, Giovanni; Vaneker, Tom; Fadel, Georges; Campbell, R. Ian; Gibson, Ian; Bernard, Alain; Schulz, Joachim; Graf, Patricia; Ahuja, Bhrigu; Martina, Filomeno			Design for Additive Manufacturing: Trends, opportunities, considerations, and constraints	CIRP ANNALS-MANUFACTURING TECHNOLOGY					66th General Assembly of the International-Academy-for-Production-Engineering (CIRP)	AUG 21-27, 2016	Guimaraes, PORTUGAL	Int Acad Prod Engn				The past few decades have seen substantial growth in Additive Manufacturing (AM) technologies. However, this growth has mainly been process-driven. The evolution of engineering design to take advantage of the possibilities afforded by AM and to manage the constraints associated with the technology has lagged behind. This paper presents the major opportunities, constraints, and economic considerations for Design for Additive Manufacturing. It explores issues related to design and redesign for direct and indirect AM production. It also highlights key industrial applications, outlines future challenges, and identifies promising directions for research and the exploitation of AM's full potential in industry. (C) 2016 CIRP.					Moroni, Giovanni/D-2860-2011; Thompson, Mary/M-8952-2014; Gibson, Ian/ABI-8113-2020														0007-8506	1726-0604					2016	65	2					737	760		10.1016/j.cirp.2016.05.004	http://dx.doi.org/10.1016/j.cirp.2016.05.004													WOS:000383928800009
J	Zhang, B; Qin, X; Li, GR; Gao, XP				Zhang, B.; Qin, X.; Li, G. R.; Gao, X. P.			Enhancement of long stability of sulfur cathode by encapsulating sulfur into micropores of carbon spheres	ENERGY & ENVIRONMENTAL SCIENCE												To enhance the long stability of sulfur cathode for a high energy lithium-sulfur battery system, a sulfur-carbon sphere composite was prepared by encapsulating sulfur into micropores of carbon spheres by thermal treatment of a mixture of sublimed sulfur and carbon spheres. The elemental sulfur exists as a highly dispersed state inside the micropores of carbon spheres with a large surface area and a narrow pore distribution, based on the analyses of the X-ray powder diffraction (XRD), transmission electron microscopy (TEM), Brunauer-Emmett-Teller (BET), thermogravimetry (TG) and local element line-scanning. It is demonstrated from galvanostatic discharge-charge process, cyclic voltammetry (CV) and electrochemical impedance spectra (EIS) that the sulfur-carbon sphere composite has a large reversible capacity and an excellent high rate discharge capability as cathode materials. In particular, the sulfur-carbon sphere composite with 42 wt% sulfur presents a long electrochemical stability up to 500 cycles, based on the constrained electrochemical reaction inside the narrow micropores of carbon spheres due to strong adsorption. Therefore, the electrochemical reaction constrained inside the micropores proposed here would be the dominant factor for the enhanced long stability of the sulfur cathode. The knowledge acquired in this study is important not only for the design of efficient new electrode materials, but also for understanding the effect of the micropores on the electrochemical cycle stability.					Li, Guoran/D-5091-2012	Li, Guoran/0000-0002-6380-5725													1754-5692						2010	3	10					1531	1537		10.1039/c002639e	http://dx.doi.org/10.1039/c002639e													WOS:000282314300018
J	Messerges, TS; Dabbish, EA; Sloan, RH				Messerges, TS; Dabbish, EA; Sloan, RH			Examining smart-card security under the threat of power analysis attacks	IEEE TRANSACTIONS ON COMPUTERS												This paper examines how monitoring power consumption signals might breach smart-card security, Both simple power analysis and differential power analysis attacks are investigated. The theory behind these attacks is reviewed. Then, we concentrate on showing how power analysis theory can be applied to attack an actual smart card. We examine the noise characteristics of the power signals and develop an approach to model the signal-to-noise ratio (SNR), We show how this SNR can be significantly improved using a multiple-bit attack. Experimental results against a smart-card implementation of the Data Encryption Standard demonstrate the effectiveness of our multiple-bit attack, Potential countermeasures to these attacks are also discussed.						, Robert/0000-0001-9517-3139													0018-9340	1557-9956				MAY	2002	51	5					541	552		10.1109/TC.2002.1004593	http://dx.doi.org/10.1109/TC.2002.1004593													WOS:000175244500009
J	Subudhi, B; Pradhan, R				Subudhi, Bidyadhar; Pradhan, Raseswari			A Comparative Study on Maximum Power Point Tracking Techniques for Photovoltaic Power Systems	IEEE TRANSACTIONS ON SUSTAINABLE ENERGY												This paper provides a comprehensive review of the maximum power point tracking (MPPT) techniques applied to photovoltaic (PV) power system available until January, 2012. A good number of publications report on different MPPT techniques for a PV system together with implementation. But, confusion lies while selecting a MPPT as every technique has its own merits and demerits. Hence, a proper review of these techniques is essential. Unfortunately, very few attempts have been made in this regard, excepting two latest reviews on MPPT [Salas et al., 2006], [Esram and Chapman, 2007]. Since, MPPT is an essential part of a PV system, extensive research has been revealed in recent years in this field and many new techniques have been reported to the list since then. In this paper, a detailed description and then classification of the MPPT techniques have made based on features, such as number of control variables involved, types of control strategies employed, types of circuitry used suitably for PV system and practical/ commercial applications. This paper is intended to serve as a convenient reference for future MPPT users in PV systems.					Subudhi, Bidyadhar/AAS-7802-2020; Pradhan, Raseswari/AAL-7541-2021; Subudhi, Bidyadhar/F-1361-2018	Subudhi, Bidyadhar/0000-0003-4383-6783													1949-3029					JAN	2013	4	1					89	98		10.1109/TSTE.2012.2202294	http://dx.doi.org/10.1109/TSTE.2012.2202294													WOS:000325435800010
J	Hertwich, EG; Peters, GP				Hertwich, Edgar G.; Peters, Glen P.			Carbon Footprint of Nations: A Global, Trade-Linked Analysis	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Processes causing greenhouse gas (GHG) emissions benefit humans by providing consumer goods and services. This benefit, and hence the responsibility for emissions, varies by purpose or consumption category and is unevenly distributed across and within countries. We quantify greenhouse gas emissions associated with the final consumption of goods and services for 73 nations and 14 aggregate world regions. We analyze the contribution of 8 categories: construction, shelter, food, clothing, mobility, manufactured products, services, and trade. National average per capita footprints vary from 1 tCO(2)e/y in African countries to similar to 30t/y in Luxembourg and the United States. The expenditure elasticity is 0.57. The cross-national expenditure elasticity for just CO2, 0.81, corresponds remarkably well to the cross-sectional elasticities found within nations, Suggesting a global relationship between expenditure and emissions that holds across several orders of magnitude difference. On the global level, 72% of greenhouse gas emissions are related to household consumption, 10% to government consumption, and 18% to investments. Food accounts for 20% of GHG emissions, operation and maintenance of residences is 19%, and mobility is 17%. Food and services are more important in developing countries, while mobility and manufactured goods rise fast with income and dominate in rich countries. The importance of public services and manufactured goods has not yet been sufficiently appreciated in policy. Policy priorities hence depend on development status and country-level characteristics.					Peters, Glen/B-1012-2008; Hertwich, Edgar/D-2169-2011	Peters, Glen/0000-0001-7889-8568; Hertwich, Edgar/0000-0002-4934-3421													0013-936X	1520-5851				AUG 15	2009	43	16					6414	6420		10.1021/es803496a	http://dx.doi.org/10.1021/es803496a								19746745					WOS:000268907700050
J	Palomar, DP; Chiang, M				Palomar, Daniel P.; Chiang, Mung			A tutorial on decomposition methods for network utility maximization	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS												A systematic understanding of the decomposability structures in network utility maximization is key to both resource allocation and functionality allocation. It helps us obtain the most appropriate distributed algorithm for a given network resource allocation problem, and quantifies the comparison across architectural alternatives of modularized network design. Decomposition theory naturally provides the mathematical language to build an analytic foundation for the design of modularized and distributed control of networks. In this tutorial paper, we first review the basics of convexity, Lagrange duality, distributed subgradient method, Jacobi and Gauss-Seidel iterations, and implication of different time scales of variable updates. Then, we introduce primal, dual, indirect, partial, and hierarchical decompositions, focusing on network utility maximization problem formulations and the meanings of primal and dual decompositions in terms of network architectures. Finally, we present recent examples on: systematic search for alternative decompositions; decoupling techniques for coupled objective functions; and decoupling techniques for coupled constraint sets that are not readily decomposable.					Palomar, Daniel/C-5121-2008	Perez palomar, Daniel/0000-0001-5250-4874													0733-8716	1558-0008				AUG	2006	24	8					1439	1451		10.1109/JSAC.2006.879350	http://dx.doi.org/10.1109/JSAC.2006.879350													WOS:000239552800003
J	Daafouz, J; Riedinger, P; Iung, C				Daafouz, J; Riedinger, P; Iung, C			Stability analysis and control synthesis for switched systems: A switched Lyapunov function approach	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												This note addresses the problem of stability analysis and control synthesis of switched systems in the discrete-time domain. The approach followed in this note looks at the existence of a switched quadratic Lyapunov function to check asymptotic stability of the switched system under consideration. Two different linear matrix inequality-based conditions allow to check the existence of such a Lyapunov function. The first one is classical while the second is new and uses a slack variable, which makes it useful for design problems. These two conditions are proved to be equivalent for stability analysis. Investigating the static output feedback control problem, we show that the second condition is, in this case, less conservative. The reduction of the conservatism is illustrated by a numerical evaluation.						Riedinger, Pierre/0000-0002-8221-4736													0018-9286	1558-2523				NOV	2002	47	11					1883	1887		10.1109/TAC.2002.804474	http://dx.doi.org/10.1109/TAC.2002.804474													WOS:000179218000011
J	Westerhoff, P; Yoon, Y; Snyder, S; Wert, E				Westerhoff, P; Yoon, Y; Snyder, S; Wert, E			Fate of endocrine-disruptor, pharmaceutical, and personal care product chemicals during simulated drinking water treatment processes	ENVIRONMENTAL SCIENCE & TECHNOLOGY												The potential occurrence of endocrine-disrupting compounds (EDCs) as well as pharmaceuticals and personal care products (PPCPs) in drinking water supplies raises concern over the removal of these compounds by common drinking water treatment processes, Three drinking water supplies were spiked with 10 to 250 ng/L of 62 different EDC/ PPCPs; one model water containing an NOM isolate was spiked with 49 different EDC/PPCPs. Compounds were detected by LC/MS/MS or GC/MS/MS. These test waters were subjected to bench-scale experimentation to simulate individual treatment processes in a water treatment plant (WTP). Aluminum sulfate and ferric chloride coagulants or chemical lime softening removed some polyaromatic hydrocarbons (PAHs) but removed < 25% of most other EDC/ PPCPs. Addition of 5 mg/L of powder activated carbon (PAC) with a 4-h contact time removed 50% to > 98% of GC/ MS/MS compounds (more volatile) and 10% to > 95% of LC/ MS/MS compounds (more polar); higher PAC dosages improved EDC/PPCP removal. EDC/PPCP percentage removal was independent of the initial compound concentration. Octanol-water partition coefficients served as a reasonable indicator of compound removal under controlled PAC test conditions, except for EDC/PPCPs that were protonated or deprotonated at the test pH and some that contained heterocyclic or aromatic nitrogen. Separate chlorine or ozone experiments decreased the EDC/PPCP initial concentration by < 10% to > 90%; EDC/PPCPs were likely transformed to oxidation byproducts. Ozone oxidized steroids containing phenolic moieties (estradiol, ethynylestradiol, or estrone) more efficiently than those without aromatic or phenolic moieties (androstenedione, progesterone, and testosterone). EDC/PPCP reactivity with oxidants were separated into three general groups: (1) compounds easily oxidized (> 80% reacted) by chlorine are always oxidized at least as efficiently by ozone; (2) 6 of the similar to 60 compounds (TCEP, BHC, chlordane, dieldrin, heptachlor epoxide, musk ketone) were poorly oxidized (< 20% reacted) by chlorine or ozone; (3) compounds (24 of 60) reacting preferentially (higher removals) with ozone rather than chlorine. Conventional treatment (coagulation plus chlorination) would have low removal of many EDC/PPCPs, while addition of PAC and/or ozone could substantially improve their removals. Existing strategies that predict relative removals of herbicides, pesticides, and other organic pollutants by activated carbon or oxidation can be directly applied for the removal of many EDC/PPCPs, but these strategies need to be modified to account for charged (protonated bases or deprotonated acids) and aliphatic species. Some compounds (e.g., DEET, ibuprofen, gemfibrozil) had low removals unless ozonation was used. Other compounds had low removals by all the WTP processes considered (atrazine, iopromide, meprobarnate, TCEP), and removal processes capable of removing these types of compounds should be investigated.					Snyder, Shane/AAE-8252-2021; Yoon, Yeomin/C-3331-2012; Westerhoff, Paul/AAF-1850-2019; Snyder, Shane/A-3302-2011	Snyder, Shane/0000-0003-2709-9840													0013-936X					SEP 1	2005	39	17					6649	6663		10.1021/es0484799	http://dx.doi.org/10.1021/es0484799								16190224					WOS:000231723800052
J	Pabst, R; Walke, BH; Schultz, DC; Herhold, P; Yanikomeroglu, H; Mukherjee, S; Viswanathan, H; Lott, M; Zirwas, W; Dohler, M; Aghvami, H; Falconer, DD; Fettweis, GP; Fettweis, AP				Pabst, R; Walke, BH; Schultz, DC; Herhold, P; Yanikomeroglu, H; Mukherjee, S; Viswanathan, H; Lott, M; Zirwas, W; Dohler, M; Aghvami, H; Falconer, DD; Fettweis, GP; Fettweis, AP			Relay-based deployment concepts for wireless and mobile broadband radio	IEEE COMMUNICATIONS MAGAZINE												In recent years, there has been an upsurge of interest in multihop-augmented infrastructure-based networks in both industry and academia, such as the seed concept in 3GPP, mesh networks in IEEE 802.16, and coverage extension of HiperLAN/2 through relays or user-cooperative diversity mesh networks. This article, a synopsis of numerous contributions to Working Group 4 of the Wireless World Research Forum and other research work, presents an overview of important topics and applications in the context of relaying. It covers different approaches to exploiting the benefits of multihop communications via relays, such as solutions for radio range extension in mobile and wireless broadband cellular networks (trading range for capacity), and solutions to combat shadowing at high radio frequencies. Furthermore, relaying is presented as a means to reduce infrastructure deployment costs. It is also shown that through the exploitation of spatial diversity, multihop relaying can enhance capacity in cellular networks. We wish to emphasize that while this article focuses on fixed relays, many of the concepts presented can also be applied to systems with moving relays.					Viswanathan, Harish/ABG-6710-2020; Dohler, Mischa/G-8670-2012; Yanikomeroglu, Halim/R-2198-2018	Yanikomeroglu, Halim/0000-0003-4776-9354; Dohler, Mischa/0000-0001-9583-2923													0163-6804	1558-1896				SEP	2004	42	9					80	89		10.1109/MCOM.2004.1336724	http://dx.doi.org/10.1109/MCOM.2004.1336724													WOS:000223783000006
J	Gesbert, D; Hanly, S; Huang, H; Shitz, SS; Simeone, O; Yu, W				Gesbert, David; Hanly, Stephen; Huang, Howard; Shitz, Shlomo Shamai; Simeone, Osvaldo; Yu, Wei			Multi-Cell MIMO Cooperative Networks: A New Look at Interference	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS												This paper presents an overview of the theory and currently known techniques for multi-cell MIMO (multiple input multiple output) cooperation in wireless networks. In dense networks where interference emerges as the key capacity-limiting factor, multi-cell cooperation can dramatically improve the system performance. Remarkably, such techniques literally exploit inter-cell interference by allowing the user data to be jointly processed by several interfering base stations, thus mimicking the benefits of a large virtual MIMO array. Multi-cell MIMO cooperation concepts are examined from different perspectives, including an examination of the fundamental information-theoretic limits, a review of the coding and signal processing algorithmic developments, and, going beyond that, consideration of very practical issues related to scalability and system-level integration. A few promising and quite fundamental research avenues are also suggested.					Hanly, Stephen/C-5909-2008; Simeone, Osvaldo/Q-1673-2016	Gesbert, David/0000-0002-4806-704X; Hanly, Stephen/0000-0002-0524-9927; Shamai Shitz, Shlomo/0000-0002-6594-3371; Simeone, Osvaldo/0000-0001-9898-3209													0733-8716	1558-0008				DEC	2010	28	9					1380	1408		10.1109/JSAC.2010.101202	http://dx.doi.org/10.1109/JSAC.2010.101202													WOS:000284852200002
J	Singh, KP; Malik, A; Mohan, D; Sinha, S				Singh, KP; Malik, A; Mohan, D; Sinha, S			Multivariate statistical techniques for the evaluation of spatial and temporal variations in water quality of Gomti River (India) - a case study	WATER RESEARCH												This case study reports different multivariate statistical techniques applied for evaluation of temporal/spatial variations and interpretation of a large complex water-quality data set obtained during monitoring of Gomti River in Northern part of India. Water quality of the Gomti River, a major tributary of the Ganga River was monitored at eight different sites selected in relatively low, moderate and high pollution regions, regularly over a period of 5 years (1994-1998) for 24 parameters. The complex data matrix (17,790 observations) was treated with different multivariate techniques such as cluster analysis, factor analysis/principal component analysis (FA/PCA) and discriminant analysis (DA). Cluster analysis (CA) showed good results rendering three different groups of similarity between the sampling sites reflecting the different water-quality parameters of the river system. FA/PCA identified six factors, which are responsible for the data structure explaining 71% of the total variance of the data set and allowed to group the selected parameters according to common features as well as to evaluate the incidence of each group on the overall variation in water quality. However, significant data reduction was not achieved, as it needed 14 parameters to explain 71% of both the temporal and spatial changes in water quality. Discriminant analysis showed the best results for data reduction and pattern recognition during both temporal and spatial analysis. Discriminant analysis showed five parameters (pH, temperature, conductivity, total alkalinity and magnesium) affording more than 88% right assignations in temporal analysis, while nine parameters (pH, temperature, alkalinity, Ca-hardness, DO, BOD, chloride, sulfate and TKN) to afford 91% right assignations in spatial analysis of three different regions in the basin. Thus, DA allowed reduction in dimensionality of the large data set, delineating a few indicator parameters responsible for large variations in water quality. This study presents necessity and usefulness of multivariate statistical techniques for evaluation and interpretation of large complex data sets with a view to get better information about the water quality and design of monitoring network for effective management of water resources. (C) 2004 Elsevier Ltd. All rights reserved.					Mohan, Dinesh/E-3475-2010; , Amrita Malik/A-9520-2014	Mohan, Dinesh/0000-0002-3251-2946; , Amrita Malik/0000-0003-4269-3469													0043-1354					NOV	2004	38	18					3980	3992		10.1016/j.watres.2004.06.011	http://dx.doi.org/10.1016/j.watres.2004.06.011								15380988					WOS:000224503800016
J	Zhu, XM; Kahn, JM				Zhu, XM; Kahn, JM			Free-space optical communication through atmospheric turbulence channels	IEEE TRANSACTIONS ON COMMUNICATIONS					IEEE Global Telecommunications Conference (GLOBECOM 00)	NOV 27-DEC 01, 2000	SAN FRANCISCO, CALIFORNIA	IEEE, IEEE, Commun Soc, Internet Soc, ICC GLOBECOM, Telesys Software, AT&T, SPIE, Opt Networks Magazine, Net Gen Learning Syst, MathWorks Inc, Kluwer Acad Publishers, John Wiley & Sons				In free-space optical communication links, atmospheric turbulence causes fluctuations in both the intensity and the phase of the received light signal, impairing link performance. In this paper, we describe several communication techniques to mitigate turbulence-induced intensity fluctuations, i.e., signal fading. These techniques are applicable in the regime in which the receiver aperture is smaller than the correlation length of fading and the observation interval is-shorter than the correlation time of fading. We assume that the receiver has no knowledge of the instantaneous fading state. When the receiver knows only the marginal statistics of the fading, a symbol-by-symbol NIL detector can be used to improve detection performance. If the receiver has knowledge of the joint temporal statistics of the fading, maximum-likelihood sequence detection (MLSD) can be employed, yielding a further performance improvement, but at the cost of very high complexity. Spatial diversity reception with multiple receivers can also be used to overcome turbulence-induced fading. We describe the use of NIL detection in spatial diversity reception to reduce the diversity gain penalty caused by correlation between the fading at different receivers. In a companion paper, we describe two reduced-complexity implementations of the MLSD, which make use of a single-step Markov chain model for the fading correlation in conjunction with per-survivor processing.																			0090-6778					AUG	2002	50	8					1293	1300		10.1109/TCOMM.2002.800829	http://dx.doi.org/10.1109/TCOMM.2002.800829													WOS:000177644800016
J	Antoni, J				Antoni, Jerome			Fast computation of the kurtogram for the detection of transient faults	MECHANICAL SYSTEMS AND SIGNAL PROCESSING												The kurtogram is a fourth-order spectral analysis toot recently introduced for detecting and characterising nonstationarities in a signal. The paradigm relies on the assertion that each type of transient is associated with an optimal (frequency/frequency resolution) dyad {f,Delta f} which maximises its kurtosis, and hence its detection. However, the complete exploration of the whole plane (f, Delta f) is a formidable task hardly amenable to on-line industrial applications. In this communication we describe a fast algorithm for computing the kurtograin over a grid that finely samples the (f, Delta f) plane. Its complexity is on the order of N log N, similarly to the FFT. The efficiency of the algorithm is then illustrated on several industrial cases concerned with the detection of incipient transient faults. (c) 2006 Elsevier Ltd. All rights reserved.																			0888-3270					JAN	2007	21	1					108	124		10.1016/j.ymssp.2005.12.002	http://dx.doi.org/10.1016/j.ymssp.2005.12.002													WOS:000242344200007
J	Ho, YS				Ho, YS			Second-order kinetic model for the sorption of cadmium onto tree fern: A comparison of linear and non-linear methods	WATER RESEARCH												A comparison was made of the linear least-squares method and a trial-and-error nonlinear method of the widely used pseudo-second-order kinetic model for the sorption of cadmium onto ground-up tree fern. Four pseudo-second-order kinetic linear equations are discussed. Kinetic parameters obtained from the four kinetic linear equations using the linear method differed but they were the same when using the non-linear method. A type 1 pseudo-second-order linear kinetic model has the highest coefficient of determination. Results show that the non-linear method may be a better way to obtain the desired parameters. (c) 2005 Elsevier Ltd. All rights reserved.					Ho, Yuh-Shan/C-8624-2009														0043-1354					JAN	2006	40	1					119	125		10.1016/j.watres.2005.10.040	http://dx.doi.org/10.1016/j.watres.2005.10.040								16375947					WOS:000235045700015
J	Brockett, RW; Liberzon, D				Brockett, RW; Liberzon, D			Quantized feedback stabilization of linear systems	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												This paper addresses feedback stabilization problems for linear time-invariant control systems with saturating quantized measurements. We propose a new control design methodology, which relies on the possibility of changing the sensitivity of the quantizer while the system evolves. The equation that describes the evolution of the sensitivity with time (discrete rather than continuous in most cases) is interconnected with the given system (either continuous or discrete), resulting in a hybrid system. When applied to systems that are stabilizable by linear time-invariant feedback, this approach yields global asymptotic stability.																			0018-9286					JUL	2000	45	7					1279	1289		10.1109/9.867021	http://dx.doi.org/10.1109/9.867021													WOS:000089311500004
J	Vetury, R; Zhang, NQQ; Keller, S; Mishra, UK				Vetury, R; Zhang, NQQ; Keller, S; Mishra, UK			The impact of surface states on the DC and RF characteristics of A1GaN/GaN HFETs	IEEE TRANSACTIONS ON ELECTRON DEVICES												GaN based HFETs are of tremendous interest in applications requiring high power at microwave frequencies. Although excellent current-voltage (I-V) characteristics and record high output power densities at microwave frequencies have been achieved, the origin of the 2DEG and the factors limiting the output power and reliability of the devices under high power operation remain uncertain. Drain current collapse has been the major obstacle in the development of reliable high power devices, We show that the cause of current collapse is a charging up of a second virtual gate, physically located in the gate drain access region. Due to the large bias voltages present on the device during a microwave power measurement, surface states in the vicinity of the gate trap electrons, thus acting as a negatively charged virtual gate. The maximum current available from a device during a microwave power measurement is limited by the discharging of this virtual gate. Passivated devices located adjacent to unpassivated devices on the same wafer show almost no current collapse, thus demonstrating that proper surface passivation prevents the formation of the virtual gate. The possible mechanisms by which a surface passivant reduces current collapse and the factors affecting reliability and stability of such a passivant are discussed.					Mishra, Upendra/ABF-9593-2021														0018-9383					MAR	2001	48	3					560	566		10.1109/16.906451	http://dx.doi.org/10.1109/16.906451													WOS:000167253000026
J	Khawaji, AD; Kutubkhanah, IK; Wie, JM				Khawaji, Akili D.; Kutubkhanah, Ibrahim K.; Wie, Jong-Mihn			Advances in seawater desalination technologies	DESALINATION					Conference of the European-Desalination-Society and Center-for-Research-and-Technology-Hellas	APR 22-25, 2007	Halkidiki, GREECE	European Desalinat Soc, Ctr Res & Technol				A number of seawater desalination technologies have been developed during the last several decades to augment the supply of water in and regions of the world. Due to the constraints of high desalination costs, many countries are unable to afford these technologies as a fresh water resource. However, the steady increasing usage of seawater desalination has demonstrated that seawater desalination is a feasible water resource free from the variations in rainfall. A seawater desalination process separates saline seawater into two streams: a fresh water stream containing a low concentration of dissolved salts and a concentrated brine stream. The process requires some form of energy to desalinate, and utilizes several different technologies for separation. Two of the most commercially important technologies are based on the multi-stage flash (MSF) distillation and reverse osmosis (RO) processes. Although the desalination technologies are mature enough to be a reliable source for fresh water from the sea, a significant amount of research and development (R&D) has been carried out in order to constantly improve the technologies and reduce the cost of desalination. This paper reviews the current status, practices, and advances that have been made in the realm of seawater desalination technologies. Additionally, this paper provides an overview of R&D activities and outlines future prospects for the state-of-the-art seawater desalination technologies. Overall, the present review is made with special emphasis on the MSF and RO desalination technologies because they are the most successful processes for the commercial production of large quantities of fresh water from seawater.																			0011-9164	1873-4464				MAR 1	2008	221	1-3					47	69		10.1016/j.desal.2007.01.067	http://dx.doi.org/10.1016/j.desal.2007.01.067													WOS:000254377500006
J	Hameed, BH; Din, ATM; Ahmad, AL				Hameed, B. H.; Din, A. T. M.; Ahmad, A. L.			Adsorption of methylene blue onto bamboo-based activated carbon: Kinetics and equilibrium studies	JOURNAL OF HAZARDOUS MATERIALS												Bamboo, an abundant and inexpensive natural resource in Malaysia was used to prepare activated carbon by physiochemical activation with potassium hydroxide (KOH) and carbon dioxide (CO2) as the activating agents at 850 degrees C for 2 h. The adsorption equilibrium and kinetics of methylene blue dye on such carbon were then examined at 30 degrees C. Adsorption isotherm of the methylene blue (MB) on the activated carbon was determined and correlated with common isotherm equations. The equilibrium data for methylene blue adsorption well fitted to the Langmuir equation, with maximum monolayer adsorption capacity of 454.2 mg/g. Two simplified kinetic models including pseudo-first-order and pseudo-second-order equation were selected to follow the adsorption processes. The adsorption of methylene blue could be best described by the pseudo-second-order equation. The kinetic parameters of this best-fit model were calculated and discussed. (c) 2006 Elsevier B.V. All rights reserved.					Ahmad, Abdul/A-3573-2009; Hameed, Bassim H./C-1270-2009; Mohd Din, Azam Taufik/A-4774-2012	Hameed, Bassim H./0000-0001-5171-6189; Mohd Din, Azam Taufik/0000-0002-9075-5989; Ahmad, Abdul Latif/0000-0003-1612-3032													0304-3894	1873-3336				MAR 22	2007	141	3					819	825		10.1016/j.jhazmat.2006.07.049	http://dx.doi.org/10.1016/j.jhazmat.2006.07.049								16956720					WOS:000245487200043
J	Liu, H; Ramnarayanan, R; Logan, BE				Liu, H; Ramnarayanan, R; Logan, BE			Production of electricity during wastewater treatment using a single chamber microbial fuel cell	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Microbial fuel cells (MFCs) have been used to produce electricity from different compounds, including acetate, lactate, and glucose. We demonstrate here that it is also possible to produce electricity in a MFC from domestic wastewater, while at the same time accomplishing biological wastewater treatment (removal of chemical oxygen demand; COD). Tests were conducted using a single chamber microbial fuel cell (SCMFC) containing eight graphite electrodes (anodes) and a single air cathode. The system was operated under continuous flow conditions with primary clarifier effluent obtained from a local wastewater treatment plant. The prototype SCMFC reactor generated electrical power (maximum of 26 MW m(-2)) while removing up to 80% of the COD of the wastewater. Power output was proportional to the hydraulic retention time over a range of 3-33 h and to the influent wastewater strength over a range of 50-220 mg/L of COD. Current generation was controlled primarily by the efficiency of the cathode. Optimal cathode performance was obtained by allowing passive air flow rather than forced air flow (4.5-5.5 L/min). The Coulombic efficiency of the system, based on COD removal and current generation, was < 12% indicating a substantial fraction of the organic matter was lost without current generation. Bioreactors based on power generation in MFCs may represent a completely new approach to wastewater treatment. If power generation in these systems can be increased, MFC technology may provide a new method to offset wastewater treatment plant operating costs, making advanced wastewater treatment more affordable for both developing and industrialized nations.					Liu, Hong/D-5012-2009; Logan, Bruce/E-7063-2012	Ramanathan, Ramnarayanan/0000-0002-3835-5400													0013-936X	1520-5851				APR 1	2004	38	7					2281	2285		10.1021/es034923g	http://dx.doi.org/10.1021/es034923g								15112835					WOS:000220577800060
J	Gaing, ZL				Gaing, ZL			Particle swarm optimization to solving the economic dispatch considering the generator constraints	IEEE TRANSACTIONS ON POWER SYSTEMS												This paper proposes a particle swarm optimization (PSO) method for solving the economic dispatch (ED). problem in power systems. Many nonlinear characteristics of the generator, such as ramp rate limits, prohibited operating zone, and nonsmooth cost functions are considered using the proposed method in practical generator operation. The feasibility of the proposed method is demonstrated for three different systems, and it is compared with the GA method in terms of the solution quality and computation efficiency. The experimental results show that the proposed PSO method was indeed capable of obtaining higher quality solutions efficiently in ED problems.																			0885-8950	1558-0679				AUG	2003	18	3					1187	1195		10.1109/TPWRS.2003.814889	http://dx.doi.org/10.1109/TPWRS.2003.814889													WOS:000184455100028
J	Seaborn, K; Fels, DI				Seaborn, Katie; Fels, Deborah I.			Gamification in theory and action: A survey	INTERNATIONAL JOURNAL OF HUMAN-COMPUTER STUDIES												Gamification has drawn the attention of academics, practitioners and business professionals in domains as diverse as education, information studies, human-computer interaction, and health. As yet, the term remains mired in diverse meanings and contradictory uses, while the concept faces division on its academic worth, underdeveloped theoretical foundations, and a dearth of standardized guidelines for application. Despite widespread commentary on its merits and shortcomings, little empirical work has sought to validate gamification as a meaningful concept and provide evidence of its effectiveness as a tool for motivating and engaging users in non-entertainment contexts. Moreover, no work to date has surveyed gamification as a field of study from a human-computer studies perspective. In this paper, we present a systematic survey on the use of gamification in published theoretical reviews and research papers involving interactive systems and human participants. We outline current theoretical understandings of gamification and draw comparisons to related approaches, including alternate reality games (ARGs), games with a purpose (GWAPs), and gameful design. We present a multidisciplinary review of gamification in action, focusing on empirical findings related to purpose and context, design of systems, approaches and techniques, and user impact. Findings from the survey show that a standard conceptualization of gamification is emerging against a growing backdrop of empirical participants-based research. However, definitional subjectivity, diverse or unstated theoretical foundations, incongruities among empirical findings, and inadequate experimental design remain matters of concern. We discuss how gamification may to be more usefully presented as a subset of a larger effort to improve the user experience of interactive systems through gameful design. We end by suggesting points of departure for continued empirical investigations of gamified practice and its effects. (C) 2014 Elsevier Ltd. All rights reserved.					Seaborn, Katie/JFK-2295-2023	Seaborn, Katie/0000-0002-7812-9096													1071-5819	1095-9300				FEB	2015	74						14	31		10.1016/j.ijhcs.2014.09.006	http://dx.doi.org/10.1016/j.ijhcs.2014.09.006													WOS:000347765000002
J	Ran, JR; Ma, TY; Gao, GP; Du, XW; Qiao, SZ				Ran, Jingrun; Ma, Tian Yi; Gao, Guoping; Du, Xi-Wen; Qiao, Shi Zhang			Porous P-doped graphitic carbon nitride nanosheets for synergistically enhanced visible-light photocatalytic H<sub>2</sub> production	ENERGY & ENVIRONMENTAL SCIENCE												Novel porous P-doped graphitic carbon nitride (g-C3N4) nanosheets were for the first time fabricated by combining P doping and thermal exfoliation strategies. The as-prepared P-doped g-C3N4 nanosheets show a high visible-light photocatalytic H-2-production activity of 1596 mu mol h(-1) g(-1) and an apparent quantum efficiency of 3.56% at 420 nm, representing one of the most highly active metal-free g-C3N4 nanosheet photocatalysts. This outstanding photocatalytic performance originates from the P-doped conjugated system and novel macroporous nanosheet morphology. Particularly, the empty midgap states (-0.16 V vs. standard hydrogen electrode) created by P doping are for the first time found to greatly extend the light-responsive region up to 557 nm by density functional theory and experimental studies, whilst the novel macroporous structure promotes the mass-transfer process and enhances light harvesting. Our study not only demonstrates a facile, eco-friendly and scalable strategy to synthesize highly efficient porous g-C3N4 nanosheet photocatalysts, but also paves a new avenue for the rational design and synthesis of advanced photocatalysts by harnessing the strong synergistic effects through simultaneously tuning and optimizing the electronic, crystallographic, surface and textural structures.					Du, Xi-Wen/A-7347-2011; Ma, Tianyi/J-1868-2019; Ran, Jingrun/D-1219-2016; Qiao, Shi Zhang/A-6057-2010; Gao, Guoping/W-2417-2019	Ran, Jingrun/0000-0002-8840-862X; Qiao, Shi Zhang/0000-0002-4568-8422; Gao, Guoping/0000-0002-6106-7423; Ma, Tianyi/0000-0002-1042-8700													1754-5692	1754-5706					2015	8	12					3708	3717		10.1039/c5ee02650d	http://dx.doi.org/10.1039/c5ee02650d													WOS:000365412300028
J	Thommes, M				Thommes, Matthias			Physical Adsorption Characterization of Nanoporous Materials	CHEMIE INGENIEUR TECHNIK												During recent years, major progress has been made in the understanding of the adsorption, pore condensation and hysteresis behavior of fluids in novel ordered nanoporous materials with well defined pore structure. This has led to major advances in the structural characterization by physical adsorption, also because of the development and availability of advanced theoretical procedures based on statistical mechanics (e.g., density functional theory, molecular simulation) which allows to describe adsorption and phase behavior of fluids in pores on a molecular level. Very recent improvements allow even to take into account surface geometrical in-homogeneity of the pore walls However, there are still many open questions concerning the structural characterization of more complex porous systems. Important aspects of the major underlying mechanisms associated with the adsorption, pore condensation and hysteresis behavior of fluids in micro-mesoporous materials are reviewed and their significance for advanced physical adsorption characterization is discussed.																			0009-286X	1522-2640				JUL	2010	82	7					1059	1073		10.1002/cite.201000064	http://dx.doi.org/10.1002/cite.201000064													WOS:000280430000017
J	Peel, CB; Hochwald, BM; Swindlehurst, AL				Peel, CB; Hochwald, BM; Swindlehurst, AL			A vector-perturbation technique for near-capacity multiantenna multiuser communication - Part I: Channel inversion and regularization	IEEE TRANSACTIONS ON COMMUNICATIONS					41st Annual Allerton Conference on Communication, Control and Computing	OCT 13, 2003	Monticello, IL					Recent theoretical results describing the sum capacity when using multiple antennas to communicate with multiple users in a known rich scattering environment have not yet been followed with practical transmission schemes that achieve this capacity. We introduce a simple encoding algorithm that achieves near-capacity at sum rates of tens of bits/channel use. The algorithm is a variation on channel inversion that regularizes the inverse and uses a "sphere encoder" to perturb the data to reduce the power of the transmitted signal. This paper is comprised of two parts. In this first part, we show that while the sum capacity grows linearly with the minimum of the number of antennas and users, the sum rate of channel inversion does not. This poor performance is due to the large spread in the singular values of the channel matrix. We introduce regularization to improve the condition of the inverse and maximize the signal-to-interference-plus-noise ratio at the receivers. Regularization enables linear growth and works especially well at low signal-to-noise ratios (SNRs), but as we show in the second part, an additional step is needed to achieve near-capacity performance at all SNRs.					Swindlehurst, A. Lee/J-4806-2017	Swindlehurst, A. Lee/0000-0002-0521-3107													0090-6778	1558-0857				JAN	2005	53	1					195	202		10.1109/TCOMM.2004.840638	http://dx.doi.org/10.1109/TCOMM.2004.840638													WOS:000226813200026
J	Auer, G; Giannini, V; Desset, C; Gódor, I; Skillermark, P; Olsson, M; Imran, MA; Sabella, D; Gonzalez, MJ; Blume, O; Fehske, A				Auer, Gunther; Giannini, Vito; Desset, Claude; Godor, Istvan; Skillermark, Per; Olsson, Magnus; Imran, Muhammad Ali; Sabella, Dario; Gonzalez, Manuel J.; Blume, Oliver; Fehske, Albrecht			HOW MUCH ENERGY IS NEEDED TO RUN A WIRELESS NETWORK?	IEEE WIRELESS COMMUNICATIONS												In order to quantify the energy efficiency of a wireless network, the power consumption of the entire system needs to be captured. In this article, the necessary extensions with respect to existing performance evaluation frameworks are discussed. The most important addenda of the proposed energy efficiency evaluation framework ((EF)-F-3) are a sophisticated power model for various base station types, as well as large-scale long-term traffic models. The BS power model maps the RF output power radiated at the antenna elements to the total supply power of a BS site. The proposed traffic model emulates the spatial distribution of the traffic demands over large geographical regions, including urban and rural areas, as well as temporal variations between peak and off-peak hours. Finally, the (EF)-F-3 is applied to quantify the energy efficiency of the downlink of a 3GPP LTE radio access network.					Sabella, Dario/KYQ-0363-2024; Giannini, Vito/I-9040-2019; Imran, Muhammad Ali/I-4832-2012	Giannini, Vito/0000-0003-0508-2642; Imran, Muhammad Ali/0000-0003-4743-9136													1536-1284	1558-0687				OCT	2011	18	5					40	49		10.1109/MWC.2011.6056691	http://dx.doi.org/10.1109/MWC.2011.6056691													WOS:000296242000008
J	Murshed, SMS; Leong, KC; Yang, C				Murshed, SMS; Leong, KC; Yang, C			Enhanced thermal conductivity of TiO<sub>2</sub> -: water based nanofluids	INTERNATIONAL JOURNAL OF THERMAL SCIENCES												Nanofluids are prepared by dispersing TiO2 nanoparticles in rod-shapes of circle divide 10 nm x 40 nm (diameter by length) and in spherical shapes of circle divide 15 nm in deionized water. A transient hot-wire apparatus with an integrated correlation model is used to measure the thermal conductivities of these nanofluids more conveniently. The pH value and viscosity of the nanofluids are also characterized. The experimental results show that the thermal conductivity increases with an increase of particle volume fraction. The particle size and shape also have effects on this enhancement of thermal conductivity. For TiO2 particles of circle divide 10 nm x 40 nm and circle divide 15 nm dimensions with maximum 5% volume fraction, the enhancement is observed to be nearly 33% and close to 30%, respectively over the base fluid. For 5% volumetric loading of rod-shape TiO2 nanoparticles of circle divide 10 nm x 40 nm in deionized water, this enhancement is found to be 12% higher than that predicted by the Hamilton-Crosser model [I & EC Fundamentals 1 (1962) 187]. However, with the same volumetric loading, the maximum enhancement is determined to be about 16% higher than that predicted by the Bruggeman model [Y. Ding, D. Wen, R.A. Williams, in: Proceedings of 6th International Symposium on Heat Transfer, Beijing, 2004, pp. 66-76] for TiO2 nanoparticles of circle divide 15 nm in the same base fluid of deionized water. The measurement error is estimated to be within 2%. (c) 2005 Elsevier SAS. All rights reserved.					Yang, Chun/A-7467-2008; Leong, Kai Choong/A-3823-2011; Murshed, Sohel/E-5931-2010	Yang, Chun/0000-0003-1191-7642; Leong, Kai Choong/0000-0003-2808-7702; Murshed, Sohel/0000-0001-6774-116X													1290-0729	1778-4166				APR	2005	44	4					367	373		10.1016/j.ijthermalsci.2004.12.005	http://dx.doi.org/10.1016/j.ijthermalsci.2004.12.005													WOS:000228314200007
J	Ipakchi, A; Albuyeh, F				Ipakchi, Ali; Albuyeh, Farrokh			Grid of the Future	IEEE POWER & ENERGY MAGAZINE																															1540-7977					MAR-APR	2009	7	2					52	62		10.1109/MPE.2008.931384	http://dx.doi.org/10.1109/MPE.2008.931384													WOS:000263877800008
J	Wu, FC; Tseng, RL; Juang, RS				Wu, Feng-Chin; Tseng, Ru-Ling; Juang, Ruey-Shin			Initial behavior of intraparticle diffusion model used in the description of adsorption kinetics	CHEMICAL ENGINEERING JOURNAL												The intraparticle diffusion model (IPD) proposed by Weber and Morris has been widely applied for the analysis of adsorption kinetics. In this work, the characteristic curves based on this model were plotted with various initial adsorption factors (R-i). Four zones of the initial adsorption according to Ri value from 0 to 1 were classified: that is, approaching completely initial adsorption (zone 4), strongly initial adsorption (zone 3), intermediately initial adsorption (zone 2), and weakly initial adsorption (zone 1). Activated carbons with micropore volume fraction of 0.537 and 0.686 were prepared from oil-palm shells by steam activation. Based on the standard deviations, the kinetics of the adsorption of tannic acid (TA), methylene blue (MB), phenol, and 4-chlorophenol (4-CP) on activated carbons could be best described by intraparticle diffusion model. The initial adsorption of TA and MB belonged to zone 2, and that of phenol and 4-CP mostly belonged to zone 3. Nearly 80% of the 86 adsorption systems surveyed belonged to zones 2 and 3, indicating that the R-i value was smaller when the carbon with smaller particle and steam-activated carbon was used. (C) 2009 Published by Elsevier B.V.					Juang, Ruey-Shin/B-5335-2011	Juang, Ruey-Shin/0000-0002-6373-9668													1385-8947	1873-3212				NOV 1	2009	153	1-3					1	8		10.1016/j.cej.2009.04.042	http://dx.doi.org/10.1016/j.cej.2009.04.042													WOS:000274348600001
J	Levin, A; Lischinski, D; Weiss, Y				Levin, Anat; Lischinski, Dani; Weiss, Yair			A closed-form solution to natural image matting	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Interactive digital matting, the process of extracting a foreground object from an image based on limited user input, is an important task in image and video editing. From a computer vision perspective, this task is extremely challenging because it is massively ill-posed - at each pixel we must estimate the foreground and the background colors, as well as the foreground opacity("alpha matte") from a single color measurement. Current approaches either restrict the estimation to a small part of the image, estimating foreground and background colors based on nearby pixels where they are known, or perform iterative nonlinear estimation by alternating foreground and background color estimation with alpha estimation. In this paper, we present a closed-form solution to natural image matting. We derive a cost function from local smoothness assumptions on foreground and background colors and show that in the resulting expression, it is possible to analytically eliminate the foreground and background colors to obtain a quadratic cost function in alpha. This allows us to find the globally optimal alpha matte by solving a sparse linear system of equations. Furthermore, the closed-form formula allows us to predict the properties of the solution by analyzing the eigenvectors of a sparse matrix, closely related to matrices used in spectral image segmentation algorithms. We show that high-quality mattes for natural images may be obtained from a small amount of user input.						Lischinski, Dani/0000-0002-6191-0361; Levin, Anat/0000-0002-9849-9043													0162-8828	1939-3539				FEB	2008	30	2					228	242		10.1109/TPAMI.2007.1177	http://dx.doi.org/10.1109/TPAMI.2007.1177								18084055					WOS:000251580300003
J	Ju, H; Zhang, R				Ju, Hyungsik; Zhang, Rui			Throughput Maximization in Wireless Powered Communication Networks	IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS												This paper studies the newly emerging wireless powered communication network in which one hybrid access point (H-AP) with constant power supply coordinates the wireless energy/information transmissions to/from a set of distributed users that do not have other energy sources. A "harvest-then-transmit" protocol is proposed where all users first harvest the wireless energy broadcast by the H-AP in the downlink (DL) and then send their independent information to the H-AP in the uplink (UL) by time-division-multiple-access (TDMA). First, we study the sum-throughput maximization of all users by jointly optimizing the time allocation for the DL wireless power transfer versus the users' UL information transmissions given a total time constraint based on the users' DL and UL channels as well as their average harvested energy values. By applying convex optimization techniques, we obtain the closed-form expressions for the optimal time allocations to maximize the sum-throughput. Our solution reveals an interesting "doubly near-far" phenomenon due to both the DL and UL distance-dependent signal attenuation, where a far user from the H-AP, which receives less wireless energy than a nearer user in the DL, has to transmit with more power in the UL for reliable information transmission. As a result, the maximum sum-throughput is shown to be achieved by allocating substantially more time to the near users than the far users, thus resulting in unfair rate allocation among different users. To overcome this problem, we furthermore propose a new performance metric so-called common-throughput with the additional constraint that all users should be allocated with an equal rate regardless of their distances to the H-AP. We present an efficient algorithm to solve the common-throughput maximization problem. Simulation results demonstrate the effectiveness of the common-throughput approach for solving the new doubly near-far problem in wireless powered communication networks.					Hong, Daesik/W-1844-2019; Zhang, Rui/C-2657-2011	Zhang, Rui/0000-0002-8729-8393													1536-1276	1558-2248				JAN	2014	13	1					418	428		10.1109/TWC.2013.112513.130760	http://dx.doi.org/10.1109/TWC.2013.112513.130760													WOS:000330941700038
J	Weingarten, H; Steinberg, Y; Shamai, S				Weingarten, Hanan; Steinberg, Yossef; Shamai, Shlomo			The capacity region of the Gaussian multiple-input multiple-output broadcast channel	IEEE TRANSACTIONS ON INFORMATION THEORY					IEEE International Symposium on Information Theory	JUN 27-JUL 02, 2004	Chicago, IL	IEEE, IEEE Informat Theory Soc, Motorola Labs, Qualcomm, Broadcom, IBM Res, Texas Instruments, Microsoft, DARPA, NSF, ONR, Dept Navy Sci & Technol, Flarion, Caltech, Lee Ctr Adv Network				The Gaussian multiple-input multiple-output (MIMO) broadcast channel (BC) is considered. The dirty-paper coding (DPC) rate region is shown to coincide with the capacity region. To that end, a new notion of an enhanced broadcast channel is introduced and is used jointly with the entropy power inequality, to show that a superposition of Gaussian codes is optimal for the degraded vector broadcast channel and that DPC is optimal for the nondegraded case. Furthermore, the capacity region is characterized under a wide range of input constraints, accounting, as special cases, for the total power and the per-antenna power constraints.						Shamai Shitz, Shlomo/0000-0002-6594-3371; Steinberg, Yossef/0000-0002-1681-1065													0018-9448	1557-9654				SEP	2006	52	9					3936	3964		10.1109/TIT.2006.880064	http://dx.doi.org/10.1109/TIT.2006.880064													WOS:000240076700005
J	Abbaspour, KC; Rouholahnejad, E; Vaghefi, S; Srinivasan, R; Yang, H; Klove, B				Abbaspour, K. C.; Rouholahnejad, E.; Vaghefi, S.; Srinivasan, R.; Yang, H.; Klove, B.			A continental-scale hydrology and water quality model for Europe: Calibration and uncertainty of a high-resolution large-scale SWAT model	JOURNAL OF HYDROLOGY												A combination of driving forces are increasing pressure on local, national, and regional water supplies needed for irrigation, energy production, industrial uses, domestic purposes, and the environment. In many parts of Europe groundwater quantity, and in particular quality, have come under sever degradation and water levels have decreased resulting in negative environmental impacts. Rapid improvements in the economy of the eastern European block of countries and uncertainties with regard to freshwater availability create challenges for water managers. At the same time, climate change adds a new level of uncertainty with regard to freshwater supplies. In this research we build and calibrate an integrated hydrological model of Europe using the Soil and Water Assessment Tool (SWAT) program. Different components of water resources are simulated and crop yield and water quality are considered at the Hydrological Response Unit (HRU) level. The water resources are quantified at subbasin level with monthly time intervals. Leaching of nitrate into groundwater is also simulated at a finer spatial level (HRU). The use of large-scale, high-resolution water resources models enables consistent and comprehensive examination of integrated system behavior through physically-based, data-driven simulation. In this article we discuss issues with data availability, calibration of large-scale distributed models, and outline procedures for model calibration and uncertainty analysis. The calibrated model and results provide information support to the European Water Framework Directive and lay the basis for further assessment of the impact of climate change on water availability and quality. The approach and methods developed are general and can be applied to any large region around the world. (C) 2015 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).					Yang, Hong/AAA-5152-2020; A. Vaghefi, Saeid/N-7632-2016; Srinivasan, Raghavan/D-3937-2009	Freund, Elham/0000-0002-4316-2013; A. Vaghefi, Saeid/0000-0002-3061-6493; Yang, Hong/0000-0002-7810-1624; Srinivasan, Raghavan/0000-0001-8375-6038; Klove, Bjorn/0000-0002-2353-1440													0022-1694	1879-2707				MAY	2015	524						733	752		10.1016/j.jhydrol.2015.03.027	http://dx.doi.org/10.1016/j.jhydrol.2015.03.027													WOS:000354503300057
J	Wang, K; Li, Q; Liu, BS; Cheng, B; Ho, WK; Yu, JG				Wang, Ke; Li, Qin; Liu, Baoshun; Cheng, Bei; Ho, Wingkei; Yu, Jiaguo			Sulfur-doped g-C<sub>3</sub>N<sub>4</sub> with enhanced photocatalytic CO<sub>2</sub>-reduction performance	APPLIED CATALYSIS B-ENVIRONMENTAL												Graphitic carbon nitride (g-C3N4) is the most stable phase of all carbon nitride allotropes under ambient conditions. In this study, sulfur-doped g-C3N4 was fabricated by simply calcinating thiourea at 520 degrees C. Sulfur-doped g-C3N4 (TCN) was found to absorb light up to 475 nm corresponding to a band gap of 2.63 eV, which was narrower than that of un-doped g-C3N4 (MCN) with a band gap of 2.7 eV. First-principle calculations based on spin-polarized density functional theory were utilized to investigate the theoretical partial density of states of the TCN and MCN, indicating that the band gaps of TCN and MCN were the same, but impurities existed in the TCN sample. Consequently, photogenerated electrons could easily jump from the impurity state to the conduction band or from the valence band to the impurity state. Photocatalytic CO2 reduction was further used to evaluate the photoactivity of samples, and the CH3OH yield using TCN and MCN were 1.12 and 0.81 mu mol g(-1), respectively. PL spectrum analysis and transient photocurrent responses were also carried out to verify the suggested photocatalysis mechanism. (C) 2015 Elsevier B.V. All rights reserved.					Cheng, Bei/G-3315-2018; Wing Kei, Ho/K-7617-2018; Li, Qin/AAA-8342-2020; Yu, Jiaguo/G-4317-2010	Wing Kei, Ho/0000-0003-2490-1121; Li, Qin/0000-0002-6850-4884; Yu, Jiaguo/0000-0002-0612-8633													0926-3373	1873-3883				OCT	2015	176						44	52		10.1016/j.apcatb.2015.03.045	http://dx.doi.org/10.1016/j.apcatb.2015.03.045													WOS:000356549200005
J	Furman, OS; Teel, AL; Watts, RJ				Furman, Olha S.; Teel, Amy L.; Watts, Richard J.			Mechanism of Base Activation of Persulfate	ENVIRONMENTAL SCIENCE & TECHNOLOGY												Base is the most commonly used activator of persulfate for the treatment of contaminated groundwater by in situ chemical oxidation (ISCO) A mechanism for the base activation of persulfate is proposed involving the base-catalyzed hydrolysis of persulfate to hydroperoxide anion and sulfate followed by the reduction of another persulfate molecule by hydroperoxide. Reduction by hydroperoxide decomposes persulfate into sulfate radical and sulfate anion, and hydroperoxide is oxidized to superoxide The base-catalyzed hydrolysis of persulfate was supported by kinetic analyses of persulfate decomposition at various base persulfate molar ratios and an increased rate of persulfate decomposition in D2O vs H2O. Stoichiometric analyses confirmed that hydroperoxide reacts with persulfate in a 1.1 molar ratio Addition of hydroperoxide to basic persulfate systems resulted in rapid decomposition of the hydroperoxide and persulfate and decomposition of the superoxide probe hexachloroethane. The presence of superoxide was confirmed with scavenging by Cu(II) Electron spin resonance spectroscopy confirmed the generation of sulfate radical, hydroxyl radical, and superoxide. The results of this research are consistent with the widespread reactivity reported for base-activated persulfate when it is used for ISCO						Teel, Amy/0000-0002-0882-4413; Furman, Olha/0000-0002-6120-4205													0013-936X	1520-5851				AUG 15	2010	44	16					6423	6428		10.1021/es1013714	http://dx.doi.org/10.1021/es1013714								20704244					WOS:000280727400067
J	Candès, EJ; Plan, Y				Candes, Emmanuel J.; Plan, Yaniv			Matrix Completion With Noise	PROCEEDINGS OF THE IEEE												On the heels of compressed sensing, a new field has very recently emerged. This field addresses a broad range of problems of significant practical interest, namely, the recovery of a data matrix from what appears to be incomplete, and perhaps even corrupted, information. In its simplest form, the problem is to recover a matrix from a small sample of its entries. It comes up in many areas of science and engineering, including collaborative filtering, machine learning, control, remote sensing, and computer vision, to name a few. This paper surveys the novel literature on matrix completion, which shows that under some suitable conditions, one can recover an unknown low-rank matrix from a nearly minimal set of entries by solving a simple convex optimization problem, namely, nuclear-norm minimization subject to data constraints. Further, this paper introduces novel results showing that matrix completion is provably accurate even when the few observed entries are corrupted with a small amount of noise. A typical result is that one can recover an unknown n x n matrix of low rank r from just about nr log(2)n noisy samples with an error that is proportional to the noise level. We present numerical results that complement our quantitative analysis and show that, in practice, nuclear-norm minimization accurately fills in the many missing entries of large low-rank matrices from just a few noisy samples. Some analogies between matrix completion and compressed sensing are discussed throughout.																			0018-9219					JUN	2010	98	6					925	936		10.1109/JPROC.2009.2035722	http://dx.doi.org/10.1109/JPROC.2009.2035722													WOS:000277884900005
J	Jia, G; Wang, HF; Yan, L; Wang, X; Pei, RJ; Yan, T; Zhao, YL; Guo, XB				Jia, G; Wang, HF; Yan, L; Wang, X; Pei, RJ; Yan, T; Zhao, YL; Guo, XB			Cytotoxicity of carbon nanomaterials: Single-wall nanotube, multi-wall nanotube, and fullerene	ENVIRONMENTAL SCIENCE & TECHNOLOGY												A cytotoxicity test protocol for single-wall nanotubes (SWNTs), multi-wall nanotubes (with diameters ranging from 10 to 20 nm, MWNT10), and fullerene (C-60) was tested. Profound cytotoxicity of SWNTs was observed in alveolar macrophage (AM) after a 6-h exposure in vitro. The cytotoxicity increases by as high as similar to35% when the dosage of SWNTs was increased by 11.30 mug/cm(2). No significant toxicity was observed for C60 up to a dose of 226.00 mug/CM2. The cytotoxicity apparently follows a sequence order on a mass basis: SWNTs > MWNT10 > quartz > C-60. SWNTs significantly impaired phagocytosis of AM at the low dose of 0.38 mug/cm(2), whereas MWNT10 and C60 induced injury only at the high dose of 3.06 mug/cm(2). The macrophages exposed to SWNTs or MWNT10 of 3.06 mug/cm(2) showed characteristic features of necrosis and degeneration. A sign of apoptotic cell death likely existed. Carbon nanomaterials with different geometric structures exhibit quite different cytotoxicity and bioactivity in vitro, although they may not be accurately reflected in the comparative toxicity in vivo.					Wang, Haifang/I-2776-2014; Wang, Xiang/J-2054-2014	Wang, Xiang/0000-0002-6647-0684													0013-936X	1520-5851				MAR 1	2005	39	5					1378	1383		10.1021/es048729l	http://dx.doi.org/10.1021/es048729l								15787380					WOS:000227257400034
J	Webster, TJ; Ergun, C; Doremus, RH; Siegel, RW; Bizios, R				Webster, TJ; Ergun, C; Doremus, RH; Siegel, RW; Bizios, R			Enhanced functions of osteoblasts on nanophase ceramics	BIOMATERIALS												Select functions of osteoblasts (bone-forming cells) on nanophase (materials with grain sizes less than 100 nm) alumina, titania, and hydroxyapatite (HA) were investigated using in vitro cellular models. Compared to conventional ceramics, surface occupancy of osteoblast colonies was significantly less on all nanophase ceramics tested in the present study after 4 and 6 days of culture. Osteoblast proliferation was significantly greater on nanophase alumina, titania, and HA than on conventional formulations of the same ceramic after 3 and 5 days. More importantly, compared to conventional ceramics, synthesis of alkaline phosphatase and deposition of calcium-containing mineral was significantly greater by osteoblasts cultured on nanophase than on conventional ceramics after 21 and 28 days. The results of the present study provided the first evidence of enhanced long-term ton the order of days to weeks) functions of osteoblasts cultured on nanophase ceramics; in this manner, nanophase ceramics clearly represent a unique and promising class of orthopaedic/dental implant formulations with improved osseointegrative properties. (C) 2000 Elsevier Science Ltd. All rights reserved.					ergun, celaletdin/ABI-6074-2020														0142-9612	1878-5905				SEP	2000	21	17					1803	1810		10.1016/S0142-9612(00)00075-2	http://dx.doi.org/10.1016/S0142-9612(00)00075-2								10905463					WOS:000088014600010
J	Xue, WF; Zhang, L; Mou, XQ; Bovik, AC				Xue, Wufeng; Zhang, Lei; Mou, Xuanqin; Bovik, Alan C.			Gradient Magnitude Similarity Deviation: A Highly Efficient Perceptual Image Quality Index	IEEE TRANSACTIONS ON IMAGE PROCESSING												It is an important task to faithfully evaluate the perceptual quality of output images in many applications, such as image compression, image restoration, and multimedia streaming. A good image quality assessment (IQA) model should not only deliver high quality prediction accuracy, but also be computationally efficient. The efficiency of IQA metrics is becoming particularly important due to the increasing proliferation of high-volume visual data in high-speed networks. We present a new effective and efficient IQA model, called gradient magnitude similarity deviation (GMSD). The image gradients are sensitive to image distortions, while different local structures in a distorted image suffer different degrees of degradations. This motivates us to explore the use of global variation of gradient based local quality map for overall image quality prediction. We find that the pixel-wise gradient magnitude similarity (GMS) between the reference and distorted images combined with a novel pooling strategy-the standard deviation of the GMS map-can predict accurately perceptual image quality. The resulting GMSD algorithm is much faster than most state-of-the-art IQA methods, and delivers highly competitive prediction accuracy. MATLAB source code of GMSD can be downloaded at http://www4.comp.polyu.edu.hk/similar to cslzhang/IQA/GMSD/GMSD.htm.					Xue, Wufeng/C-8790-2015; Zhang, Lei/P-8881-2014; Bovik, Alan/B-6717-2012	Mou, Xuanqin/0000-0003-1381-5260; Bovik, Alan/0000-0001-6067-710X; Xue, Wufeng/0000-0002-9776-0975; Zhang, Lei/0000-0002-2078-4215													1057-7149	1941-0042				FEB	2014	23	2					684	695		10.1109/TIP.2013.2293423	http://dx.doi.org/10.1109/TIP.2013.2293423								26270911					WOS:000329581800016
J	Boore, DM; Stewart, JP; Seyhan, E; Atkinson, GM				Boore, David M.; Stewart, Jonathan P.; Seyhan, Emel; Atkinson, Gail M.			NGA-West2 Equations for Predicting PGA, PGV, and 5% Damped PSA for Shallow Crustal Earthquakes	EARTHQUAKE SPECTRA												We provide ground motion prediction equations for computing medians and standard deviations of average horizontal component intensity measures (IMs) for shallow crustal earthquakes in active tectonic regions. The equations were derived from a global database with M 3.0-7.9 events. We derived equations for the primary M- and distance-dependence of the IMs after fixing the V-S30-based nonlinear site term from a parallel NGA-West2 study. We then evaluated additional effects using mixed effects residuals analysis, which revealed no trends with source depth over the M range of interest, indistinct Class 1 and 2 event IMs, and basin depth effects that increase and decrease long-period IMs for depths larger and smaller, respectively, than means from regional V-S30-depth relations. Our aleatory variability model captures decreasing between-event variability with M, as well as within-event variability that increases or decreases with M depending on period, increases with distance, and decreases for soft sites.					Boore, David/GWQ-6027-2022; Stewart, Jonathan/ADF-5038-2022														8755-2930	1944-8201				AUG	2014	30	3			SI		1057	1085		10.1193/070113EQS184M	http://dx.doi.org/10.1193/070113EQS184M													WOS:000342264100005
J	von Moos, N; Burkhardt-Holm, P; Köhler, A				von Moos, Nadia; Burkhardt-Holm, Patricia; Koehler, Angela			Uptake and Effects of Microplastics on Cells and Tissue of the Blue Mussel <i>Mytilus edulis</i> L. after an Experimental Exposure	ENVIRONMENTAL SCIENCE & TECHNOLOGY												In this study, we investigated if industrial high-density polyethylene (HDPE) particles, a model microplastic free of additives, ranging > 0-80 mu m are ingested and taken up into the cells and tissue of the blue mussel Mytilus edulis L. The effects of exposure (up to 96 h) and plastic ingestion were observed at the cellular and subcellular level. Microplastic uptake into the gills and digestive gland was analyzed by a new method using polarized light microscopy. Mussel health status was investigated incorporating histological assessment and cytochemical biomarkers of toxic effects and early warning. In addition to being drawn into the gills, HDPE particles were taken up into the stomach and transported into the digestive gland where they accumulated in the lysosomal system after 3 h of exposure. Our results show notable histological changes upon uptake and a strong inflammatory response demonstrated by the formation of granulocytomas after 6 h and lysosomal membrane destabilization, which significantly increased with longer exposure times. We provide proof of principle that microplastics are taken up into cells and cause significant effects on the tissue and cellular level, which can be assessed with standard cytochemical biomarkers and polarized light microscopy for microplastic tracking in tissue.						von Moos, Nadia R./0000-0002-6570-0089													0013-936X	1520-5851				OCT 16	2012	46	20					11327	11335		10.1021/es302332w	http://dx.doi.org/10.1021/es302332w								22963286					WOS:000309805000062
J	Mohamed, AR; Dahl, GE; Hinton, G				Mohamed, Abdel-rahman; Dahl, George E.; Hinton, Geoffrey			Acoustic Modeling Using Deep Belief Networks	IEEE TRANSACTIONS ON AUDIO SPEECH AND LANGUAGE PROCESSING												Gaussian mixture models are currently the dominant technique for modeling the emission distribution of hidden Markov models for speech recognition. We show that better phone recognition on the TIMIT dataset can be achieved by replacing Gaussian mixture models by deep neural networks that contain many layers of features and a very large number of parameters. These networks are first pre-trained as a multi-layer generative model of a window of spectral feature vectors without making use of any discriminative information. Once the generative pre-training has designed the features, we perform discriminative fine-tuning using backpropagation to adjust the features slightly to make them better at predicting a probability distribution over the states of monophone hidden Markov models.																			1558-7916	1558-7924				JAN	2012	20	1					14	22		10.1109/TASL.2011.2109382	http://dx.doi.org/10.1109/TASL.2011.2109382													WOS:000298325600005
J	Lowry, PB; Gaskin, J				Lowry, Paul Benjamin; Gaskin, James			Partial Least Squares (PLS) Structural Equation Modeling (SEM) for Building and Testing Behavioral Causal Theory: When to Choose It and How to Use It	IEEE TRANSACTIONS ON PROFESSIONAL COMMUNICATION												Problem: Partial least squares (PLS), a form of structural equation modeling (SEM), can provide much value for causal inquiry in communication-related and behavioral research fields. Despite the wide availability of technical information on PLS, many behavioral and communication researchers often do not use PLS in situations in which it could provide unique theoretical insights. Moreover, complex models comprising formative (causal) and reflective (consequent) constructs are now common in behavioral research, but they are often misspecified in statistical models, resulting in erroneous tests. Key concepts: First-generation (1G) techniques, such as correlations, regressions, or difference of means tests (such as ANOVA or t-tests), offer limited modeling capabilities, particularly in terms of causal modeling. In contrast, second-generation techniques (such as covariance-based SEM or PLS) offer extensive, scalable, and flexible causal-modeling capabilities. Second-generation (2G) techniques do not invalidate the need for 1G techniques however. The key point of 2G techniques is that they are superior for the complex causal modeling that dominates recent communication and behavioral research. Key lessons: For exploratory work, or for studies that include formative constructs, PLS should be selected. For confirmatory work, either covariance-based SEM or PLS may be used. Despite claims that lower sampling requirements exist for PLS, inadequate sample sizes result in the same problems for either technique. Implications: SEM's strength is in modeling. In particular, SEM allows for complex models that include latent (unobserved) variables, formative variables, chains of effects (mediation), and multiple group comparisons of these more complex relationships.					Gaskin, James/AFL-0923-2022; Lowry, Paul/A-2790-2008	Lowry, Paul/0000-0002-0187-5808													0361-1434	1558-1500				JUN	2014	57	2					123	146		10.1109/TPC.2014.2312452	http://dx.doi.org/10.1109/TPC.2014.2312452													WOS:000337135400004
J	Johnston, ID; McCluskey, DK; Tan, CKL; Tracey, MC				Johnston, I. D.; McCluskey, D. K.; Tan, C. K. L.; Tracey, M. C.			Mechanical characterization of bulk Sylgard 184 for microfluidics and microengineering	JOURNAL OF MICROMECHANICS AND MICROENGINEERING					7th International Conference on Microtechnologies in Medicine and Biology (MMB)	APR 10-12, 2013	Marina Del Rey, CA					Polydimethylsiloxane (PDMS) elastomers are extensively used for soft lithographic replication of microstructures in microfluidic and micro-engineering applications. Elastomeric microstructures are commonly required to fulfil an explicit mechanical role and accordingly their mechanical properties can critically affect device performance. The mechanical properties of elastomers are known to vary with both curing and operational temperatures. However, even for the elastomer most commonly employed in microfluidic applications, Sylgard 184, only a very limited range of data exists regarding the variation in mechanical properties of bulk PDMS with curing temperature. We report an investigation of the variation in the mechanical properties of bulk Sylgard 184 with curing temperature, over the range 25 degrees C to 200 degrees C. PDMS samples for tensile and compressive testing were fabricated according to ASTM standards. Data obtained indicates variation in mechanical properties due to curing temperature for Young's modulus of 1.32-2.97 MPa, ultimate tensile strength of 3.51-7.65 MPa, compressive modulus of 117.8-186.9 MPa and ultimate compressive strength of 28.4-51.7 GPa in a range up to 40% strain and hardness of 44-54 Sh(A).					tan, christabel/AAL-6615-2020	Tracey, Mark/0000-0003-2948-8495; McCluskey, Daniel/0000-0001-9199-938X; Johnston, Ian/0000-0001-9696-3191													0960-1317	1361-6439				MAR	2014	24	3							035017	10.1088/0960-1317/24/3/035017	http://dx.doi.org/10.1088/0960-1317/24/3/035017													WOS:000333892700024
J	Chui, HL; Rangarajan, A				Chui, HL; Rangarajan, A			A new point matching algorithm for non-rigid registration	COMPUTER VISION AND IMAGE UNDERSTANDING												Feature-based methods for non-rigid registration frequently encounter the correspondence problem. Regardless of whether points, lines, curves or surface parameterizations are used, feature-based non-rigid matching requires us to automatically solve for correspondences between two sets of features. In addition, there could be many features in either set that have no counterparts in the other. This outlier rejection problem further complicates an already difficult correspondence problem. We formulate feature-based non-rigid registration as a nonrigid point matching problem. After a careful review of the problem and an in-depth examination of two types of methods previously designed for rigid robust point matching (RPM), we propose a new general framework for non-rigid point matching. We consider it a general framework because it does not depend on any particular form of spatial mapping. We have also developed an algorithm-the TPS-RPM algorithm-with the thin-plate spline (TPS) as the parameterization of the non-rigid spatial mapping and the softassign for the correspondence. The performance of the TPS-RPM algorithm is demonstrated and validated in a series of carefully designed synthetic experiments. In each of these experiments, an empirical comparison with the popular iterated closest point (ICP) algorithm is also provided. Finally, we apply the algorithm to the problem of non-rigid registration of cortical anatomical structures which is required in brain mapping. While these results are somewhat preliminary, they clearly demonstrate the applicability of our approach to real world tasks involving feature-based nonrigid registration. (C) 2003 Published by Elsevier Science (USA).					Rangarajan, Anand/A-8652-2009	Rangarajan, Anand/0000-0001-8695-8436													1077-3142	1090-235X				FEB-MAR	2003	89	2-3					114	141		10.1016/S1077-3142(03)00009-2	http://dx.doi.org/10.1016/S1077-3142(03)00009-2													WOS:000182704400002
J	Eskandar, H; Sadollah, A; Bahreininejad, A; Hamdi, M				Eskandar, Hadi; Sadollah, Ali; Bahreininejad, Ardeshir; Hamdi, Mohd			Water cycle algorithm - A novel metaheuristic optimization method for solving constrained engineering optimization problems	COMPUTERS & STRUCTURES												This paper presents a new optimization technique called water cycle algorithm (WCA) which is applied to a number of constrained optimization and engineering design problems. The fundamental concepts and ideas which underlie the proposed method is inspired from nature and based on the observation of water cycle process and how rivers and streams flow to the sea in the real world. A comparative study has been carried out to show the effectiveness of the WCA over other well-known optimizers in terms of computational effort (measures as number of function evaluations) and function value (accuracy) in this paper. (c) 2012 Elsevier Ltd. All rights reserved.					Abd Shukor, Mohd Hamdi/B-9093-2010; Bahreininejad, Ardeshir/O-8986-2019; Sadollah, Ali/H-1199-2011	eskandar, hadi/0000-0002-6717-7893; Bahreininejad, Ardeshir/0000-0002-9370-6234; Sadollah, Ali/0000-0002-7782-4126													0045-7949	1879-2243				NOV	2012	110						151	166		10.1016/j.compstruc.2012.07.010	http://dx.doi.org/10.1016/j.compstruc.2012.07.010													WOS:000310114500011
J	Tress, W; Marinova, N; Moehl, T; Zakeeruddin, SM; Nazeeruddin, MK; Grätzel, M				Tress, W.; Marinova, N.; Moehl, T.; Zakeeruddin, S. M.; Nazeeruddin, Mohammad Khaja; Graetzel, M.			Understanding the rate-dependent <i>J</i>-<i>V</i> hysteresis, slow time component, and aging in CH<sub>3</sub>NH<sub>3</sub>PbI<sub>3</sub> perovskite solar cells: the role of a compensated electric field	ENERGY & ENVIRONMENTAL SCIENCE												In this work we show that the rate-dependent hysteresis seen in current-voltage scans of CH3NH3PbI3 perovskite solar cells is related to a slow field-induced process that tends to cancel the electric field in the device at each applied bias voltage. It is attributed to the build-up of space charge close to the contacts, independent of illumination and most likely due to ionic displacement, which is enhanced when the device undergoes aging. This process can also lead to a reduction of the open-circuit voltage or the steady-state photocurrent and does not directly correlate with the development of the hysteresis if it is measured at a fixed voltage sweep rate.					Zakeeruddin, Mohammed/D-3244-2014; Graetzel, Michael/G-4870-2011; Moehl, Thomas/B-2218-2013; Nazeeruddin, Mohammad/B-1323-2008; Tress, Wolfgang/B-7171-2017; Marinova, Nevena/M-7296-2016	Moehl, Thomas/0000-0002-4733-4839; Tress, Wolfgang/0000-0002-4010-239X; Marinova, Nevena/0000-0002-3055-6267; Nazeeruddin, Mohammad Khaja/0000-0001-5955-4786													1754-5692	1754-5706					2015	8	3					995	1004		10.1039/c4ee03664f	http://dx.doi.org/10.1039/c4ee03664f													WOS:000352274600025
J	Gerstel, O; Jinno, M; Lord, A; Ben Yoo, SJ				Gerstel, Ori; Jinno, Masahiko; Lord, Andrew; Ben Yoo, S. J.			Elastic Optical Networking: A New Dawn for the Optical Layer?	IEEE COMMUNICATIONS MAGAZINE												Optical networks are undergoing significant changes, fueled by the exponential growth of traffic due to multimedia services and by the increased uncertainty in predicting the sources of this traffic due to the ever changing models of content providers over the Internet. The change has already begun: simple on-off modulation of signals, which was adequate for bit rates up to 10 Gb/s, has given way to much more sophisticated modulation schemes for 100 Gb/s and beyond. The next bottleneck is the 10-year-old division of the optical spectrum into a fixed "wavelength grid," which will no longer work for 400 Gb/s and above, heralding the need for a more flexible grid. Once both transceivers and switches become flexible, a whole new elastic optical networking paradigm is born. In this article we describe the drivers, building blocks, architecture, and enabling technologies for this new paradigm, as well as early standardization efforts.					Jinno, Masahiko/J-4433-2012														0163-6804	1558-1896				FEB	2012	50	2					S12	S20		10.1109/MCOM.2012.6146481	http://dx.doi.org/10.1109/MCOM.2012.6146481													WOS:000301419800002
J	Vishwanath, S; Jindal, N; Goldsmith, AG				Vishwanath, S; Jindal, N; Goldsmith, AG			Duality, achievable rates, and sum-rate capacity of Gaussian MIMO broadcast channels	IEEE TRANSACTIONS ON INFORMATION THEORY					IEEE International Conference on Communications	APR 28-MAY 02, 2002	NEW YORK, NY	IEEE Commun Soc, ICC GLOBECOM, IEEE, AT&T Labs, Avaya Labs, Nippon Telegraph & Telephone, Nokia, Polytech Univ, Verizon Commun				We consider a multiuser multiple-input multiple-output (MIMO) Gaussian broadcast channel (BC), where the transmitter and receivers have multiple antennas. Since the MIMO BC is in general a nondegraded BC, its capacity region remains an unsolved problem. In this paper, we establish a duality between what is termed the "dirty paper" achievable region (the Caire-Shamai achievable region) for the MIMO BC and the capacity region of the MIMO multiple-access channel (MAC), which is easy to compute. Using this duality, we greatly reduce the computational complexity required for, obtaining the dirty paper achievable region for the MIMO BC. We also show that the dirty paper achievable region achieves the sum-rate capacity of the MIMO BC by establishing that the maximum sum rate of this region equals an upper bound on the sum rate of the MIMO BC.					Goldsmith, Andrea/F-8335-2010	Goldsmith, Andrea/0000-0001-5686-800X													0018-9448	1557-9654				OCT	2003	49	10					2658	2668		10.1109/TIT.2003.817421	http://dx.doi.org/10.1109/TIT.2003.817421													WOS:000185861400020
J	Eleftheriades, GV; Iyer, AK; Kremer, PC				Eleftheriades, GV; Iyer, AK; Kremer, PC			Planar negative refractive index media using periodically <i>L</i>-<i>C</i> loaded transmission lines	IEEE TRANSACTIONS ON MICROWAVE THEORY AND TECHNIQUES					IEEE Annual Microwave-Theory-and-Techniques-Society International Microwave Symposium (IEEE MTT-S IMS 2002)	JUN 02-07, 2002	SEATTLE, WA	IEEE				Recent demonstrations of negative refraction utilize three-dimensional collections of discrete periodic scatterers to synthesize artificial dielectrics with simultaneously negative permittivity and permeability. In this paper, we propose an alternate perspective on the design and function of such materials that exploits the well-known L-C distributed network representation of homogeneous dielectrics. In the conventional low-pass topology, the quantities L and C represent a positive equivalent permeability and permittivity, respectively. However, in the dual configuration, in which the positions of L and C are simply interchanged, these equivalent material parameters assume simultaneously negative values. Two-dimensional periodic versions of these dual networks are used to demonstrate negative refraction and focusing; phenomena that are manifestations of the fact that such media support a propagating fundamental backward harmonic. We hereby present the characteristics of these artificial transmission-line media and propose a suitable means of implementing them in planar form. We then present circuit and full-wave field simulations illustrating negative refraction and focusing, and the first experimental verification of focusing using such an implementation.					Iyer, Ashwin/AAU-4763-2021														0018-9480	1557-9670				DEC	2002	50	12					2702	2712		10.1109/TMTT.2002.805197	http://dx.doi.org/10.1109/TMTT.2002.805197													WOS:000179713700004
J	Yu, WW; Chen, GR; Cao, M				Yu, Wenwu; Chen, Guanrong; Cao, Ming			Some necessary and sufficient conditions for second-order consensus in multi-agent dynamical systems	AUTOMATICA												This paper studies some necessary and sufficient conditions for second-order consensus in multi-agent dynamical systems. First, basic theoretical analysis is carried out for the case where for each agent the second-order dynamics are governed by the position and velocity terms and the asymptotic velocity is constant. A necessary and sufficient condition is given to ensure second-order consensus and it is found that both the real and imaginary parts of the eigenvalues of the Laplacian matrix of the corresponding network play key roles in reaching consensus. Based on this result, a second-order consensus algorithm is derived for the multi-agent system facing communication delays. A necessary and sufficient condition is provided, which shows that consensus can be achieved in a multi-agent system whose network topology contains a directed spanning tree if and only if the time delay is less than a critical value. Finally, simulation examples are given to verify the theoretical analysis. (C) 2010 Elsevier Ltd. All rights reserved.					Chen, Guanrong/F-6000-2011; Yu, Wenwu/G-5496-2012; Cao, Ming/B-6808-2013; Cao, Ming/L-5257-2016	Chen, Guanrong/0000-0003-1381-7418; Cao, Ming/0000-0001-5472-562X													0005-1098	1873-2836				JUN	2010	46	6					1089	1095		10.1016/j.automatica.2010.03.006	http://dx.doi.org/10.1016/j.automatica.2010.03.006													WOS:000278675500017
J	Torralba, A; Fergus, R; Freeman, WT				Torralba, Antonio; Fergus, Rob; Freeman, William T.			80 million tiny images: A large data set for nonparametric object and scene recognition	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												With the advent of the Internet, billions of images are now freely available online and constitute a dense sampling of the visual world. Using a variety of nonparametric methods, we explore this world with the aid of a large data set of 79,302,017 images collected from the Web. Motivated by psychophysical results showing the remarkable tolerance of the human visual system to degradations in image resolution, the images in the data set are stored as 32 x 32 color images. Each image is loosely labeled with one of the 75,062 nonabstract nouns in English, as listed in the Wordnet lexical database. Hence, the image database gives comprehensive coverage of all object categories and scenes. The semantic information from Wordnet can be used in conjunction with the nearest neighbor methods to perform object classification over a range of semantic levels, minimizing the effects of labeling noise. For certain classes that are particularly prevalent in the data set, such as people, we are able to demonstrate a recognition performance comparable to class-specific Viola-Jones style detectors.						Fergus, Rob/0009-0005-3077-2495													0162-8828	1939-3539				NOV	2008	30	11					1958	1970		10.1109/TPAMI.2008.128	http://dx.doi.org/10.1109/TPAMI.2008.128								18787244					WOS:000259110000009
J	Stenumgaard, P; Persson, D; Larsson, EG; Wiklundh, K				Stenumgaard, Peter; Persson, Daniel; Larsson, Erik G.; Wiklundh, Kia			An Early-Warning Service for Emerging Communication Problems in Security and Safety Applications	IEEE COMMUNICATIONS MAGAZINE												Experience has shown that unpredictable disruption of communications during emergency operations can have severe consequences both for personal safety and for the ability to conduct a successful operation. An early-warning service for emerging communication disruption due to both unintentional interference and jamming, would therefore be a significant contribution for increased safety and security in such operations. We propose a solution for such an early-warning service both on the terminal and on higher system level. The solution is based on historical recorded data of both local and global information such as signal-to-interference ratio, interference classification, and position. We show by an example that with this service implemented, the operator will have increased time to take actions before a disruption occurs on a specific terminal.					Larsson, Erik/ADV-7383-2022														0163-6804					MAY	2013	51	5					186	192		10.1109/MCOM.2013.6515064	http://dx.doi.org/10.1109/MCOM.2013.6515064													WOS:000318998600023
J	Camps-Valls, G; Bruzzone, L				Camps-Valls, G; Bruzzone, L			Kernel-based methods for hyperspectral image classification	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING												This paper presents the framework of kernel-based methods in the context of hyperspectral image classification, illustrating from a general viewpoint the main characteristics of different kernel-based approaches and analyzing their properties in the hyperspectral domain. In particular, we assess performance of regularized radial basis function neural networks (Reg-RBFNN), standard support vector machines (SVMs), kernel Fisher discriminant (KFD) analysis, and regularized AdaBoost (Reg-AB). The novelty of this work consists in: 1) introducing Reg-RBFNN and Reg-AB for hyperspectral image classification; 2) comparing kernel-based methods by taking into account the peculiarities of hyperspectral images; and 3) clarifying their theoretical relationships. To these purposes, we focus on the accuracy of methods when working in noisy environments, high input dimension, and limited training sets. In addition, some other important issues are discussed, such as the sparsity of the solutions, the computational burden,,and the capability of the methods to provide outputs that can be directly interpreted as probabilities.					Bruzzone, Lorenzo/JPL-7703-2023; Camps-Valls, Gustau/A-2532-2011; Bruzzone, Lorenzo/A-2076-2012	Camps-Valls, Gustau/0000-0003-1683-2138; Bruzzone, Lorenzo/0000-0002-6036-459X													0196-2892	1558-0644				JUN	2005	43	6					1351	1362		10.1109/TGRS.2005.846154	http://dx.doi.org/10.1109/TGRS.2005.846154													WOS:000229586900012
J	Benediktsson, JA; Palmason, JA; Sveinsson, JR				Benediktsson, JA; Palmason, JA; Sveinsson, JR			Classification of hyperspectral data from urban areas based on extended morphological profiles	IEEE TRANSACTIONS ON GEOSCIENCE AND REMOTE SENSING					IEEE Workshop on Advances in Techniques for Analysis of Remotely Sensed Data held in Honor of David A Landgrebe	OCT 27-28, 2003	NASA Goddard Space Flight Visitor Ctr, Greenbelt, MD	IEEE	NASA Goddard Space Flight Visitor Ctr			Classification of hyperspectral data with high spatial resolution from urban areas is investigated. A method based on mathematical morphology for preprocessing of the hyperspectral data is proposed. In this approach, opening and closing morphological transforms are used in order to isolate bright (opening) and dark (closing) structures in images, where bright/dark means brighter/darker than the surrounding features in the images. A morphological profile is constructed based on the repeated use of openings and closings with a structuring element, of increasing size, starting with one original image. In order to apply the morphological approach to hyperspectral data, principal components of the hyperspectral imagery are computed. The most significant principal components are used as base images for an extended morphological profile, i.e., a profile based on more than one original image. In experiments, two hyperspectral urban datasets are classified. The proposed method is used as a preprocessing method for a neural network classifier and compared to more conventional classification methods with different types of statistical computations and feature extraction.					Sveinsson, Johannes/B-7038-2017; Benediktsson, Jon Atli/F-2861-2010	Benediktsson, Jon Atli/0000-0003-0621-9647; Sveinsson, Johannes R./0000-0001-6309-3126													0196-2892	1558-0644				MAR	2005	43	3					480	491		10.1109/TGRS.2004.842478	http://dx.doi.org/10.1109/TGRS.2004.842478													WOS:000227130000008
J	Chenite, A; Chaput, C; Wang, D; Combes, C; Buschmann, MD; Hoemann, CD; Leroux, JC; Atkinson, BL; Binette, F; Selmani, A				Chenite, A; Chaput, C; Wang, D; Combes, C; Buschmann, MD; Hoemann, CD; Leroux, JC; Atkinson, BL; Binette, F; Selmani, A			Novel injectable neutral solutions of chitosan form biodegradable gels in situ	BIOMATERIALS												A novel approach to provide, thermally sensitive neutral solutions based on chitosan/polyol salt combinations is described. These formulations possess a physiological pH and can be held liquid below room temperature for encapsulating living cells and therapeutic proteins; they form monolithic gels at body temperature. When injected in vivo the liquid formulations turn into gel implants in situ, This system was used successfully to deliver biologically active growth factors in vivo as well as an encapsulating matrix for living chondrocytes for tissue engineering applications. This study reports for the first time the use of polymer/polyol salt aqueous solutions as gelling systems, suggesting the discovery of a prototype for a new family of thermosetting gels highly compatible with biological compounds. (C) 2000 Elsevier Science Ltd. All rights reserved.					HOEMANN, CAROLINE/J-4972-2012; Leroux, Jean-Christophe/N-4202-2015	Buschmann, Michael/0000-0002-2242-6198; COMBES, Christele/0000-0001-5009-1973; Hoemann, Caroline/0000-0003-3750-7879; Leroux, Jean-Christophe/0000-0001-5601-1292													0142-9612	1878-5905				NOV	2000	21	21					2155	2161		10.1016/S0142-9612(00)00116-2	http://dx.doi.org/10.1016/S0142-9612(00)00116-2								10985488					WOS:000088972500006
J	Bertsimas, D; Litvinov, E; Sun, XA; Zhao, J; Zheng, T				Bertsimas, Dimitris; Litvinov, Eugene; Sun, Xu Andy; Zhao, Jinye; Zheng, Tongxin			Adaptive Robust Optimization for the Security Constrained Unit Commitment Problem	IEEE TRANSACTIONS ON POWER SYSTEMS												Unit commitment, one of the most critical tasks in electric power system operations, faces new challenges as the supply and demand uncertainty increases dramatically due to the integration of variable generation resources such as wind power and price responsive demand. To meet these challenges, we propose a two-stage adaptive robust unit commitment model for the security constrained unit commitment problem in the presence of nodal net injection uncertainty. Compared to the conventional stochastic programming approach, the proposed model is more practical in that it only requires a deterministic uncertainty set, rather than a hard-to-obtain probability distribution on the uncertain data. The unit commitment solutions of the proposed model are robust against all possible realizations of the modeled uncertainty. We develop a practical solution methodology based on a combination of Benders decomposition type algorithm and the outer approximation technique. We present an extensive numerical study on the real-world large scale power system operated by the ISO New England. Computational results demonstrate the economic and operational advantages of our model over the traditional reserve adjustment approach.					sun, xu/JCN-6491-2023	Zheng, Tongxin/0000-0002-3508-2929													0885-8950	1558-0679				FEB	2013	28	1					52	63		10.1109/TPWRS.2012.2205021	http://dx.doi.org/10.1109/TPWRS.2012.2205021													WOS:000313965700006
J	Vamvoudakis, KG; Lewis, FL				Vamvoudakis, Kyriakos G.; Lewis, Frank L.			Online actor-critic algorithm to solve the continuous-time infinite horizon optimal control problem	AUTOMATICA												In this paper we discuss an online algorithm based on policy iteration for learning the continuous-time (CT) optimal control solution with infinite horizon cost for nonlinear systems with known dynamics. That is, the algorithm learns online in real-time the solution to the optimal control design HJ equation. This method finds in real-time suitable approximations of both the optimal cost and the optimal control policy, while also guaranteeing closed-loop stability. We present an online adaptive algorithm implemented as an actor/critic structure which involves simultaneous continuous-time adaptation of both actor and critic neural networks. We call this 'synchronous' policy iteration. A persistence of excitation condition is shown to guarantee convergence of the critic to the actual optimal value function. Novel tuning algorithms are given for both critic and actor networks, with extra nonstandard terms in the actor tuning law being required to guarantee closed-loop dynamical stability. The convergence to the optimal controller is proven, and the stability of the system is also guaranteed. Simulation examples show the effectiveness of the new algorithm. (C) 2010 Elsevier Ltd. All rights reserved.						Vamvoudakis, Kyriakos G./0000-0003-1978-4848													0005-1098	1873-2836				MAY	2010	46	5					878	888		10.1016/j.automatica.2010.02.018	http://dx.doi.org/10.1016/j.automatica.2010.02.018													WOS:000278306600010
J	Oliver, NM; Rosario, B; Pentland, AP				Oliver, NM; Rosario, B; Pentland, AP			A Bayesian computer vision system for modeling human interactions	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												We describe a real-time computer vision and machine learning system for modeling and recognizing human behaviors in a visual surveillance task [1]. The system is particularly concerned with detecting when interactions between people occur and classifying the type of interaction. Examples of interesting interaction behaviors include following another person, altering one's path to meet another, and so forth. Our system combines top-down with bottom-up information in a closed feedback loop, with both components employing a statistical Bayesian approach [2]. We propose and compare two different state-based learning architectures, namely, HMMs and CHMMs for modeling behaviors and interactions. The CHMM model is shown to work much more efficiently and accurately. Finally, to deal with the problem of limited training data, a synthetic "Alife-style" training system is used to develop flexible prior models for recognizing human interactions. We demonstrate the ability to use these a priori models to accurately classify real human behaviors and interactions with no additional tuning or training.					Oliver, Nuria/AAK-6995-2021	Oliver, Nuria/0000-0001-5985-691X													0162-8828	1939-3539				AUG	2000	22	8					831	843		10.1109/34.868684	http://dx.doi.org/10.1109/34.868684													WOS:000089321500009
J	Rodriguez-Mozaz, S; Chamorro, S; Marti, E; Huerta, B; Gros, M; Sànchez-Melsió, A; Borrego, CM; Barceló, D; Balcázar, JL				Rodriguez-Mozaz, Sara; Chamorro, Sara; Marti, Elisabet; Huerta, Belinda; Gros, Meritxell; Sanchez-Melsio, Alexandre; Borrego, Carles M.; Barcelo, Damia; Luis Balcazar, Jose			Occurrence of antibiotics and antibiotic resistance genes in hospital and urban wastewaters and their impact on the receiving river	WATER RESEARCH												Antibiotic resistance has become a major health concern; thus, there is a growing interest in exploring the occurrence of antibiotic resistance genes (ARGs) in the environment as well as the factors that contribute to their emergence. Aquatic ecosystems provide an ideal setting for the acquisition and spread of ARGs due to the continuous pollution by antimicrobial compounds derived from anthropogenic activities. We investigated, therefore, the pollution level of a broad range of antibiotics and ARGs released from hospital and urban wastewaters, their removal through a wastewater treatment plant (WWTP) and their presence in the receiving river. Several antimicrobial compounds were detected in all water samples collected. Among antibiotic families, fluoroquinolones were detected at the highest concentration, especially in hospital effluent samples. Although good removal efficiency by treatment processes was observed for several antimicrobial compounds, most antibiotics were still present in WWTP effluents. The results also revealed that copy numbers of ARGs, such as bla(TEM) (resistance to beta-lactams), qnrS (reduced susceptibility to fluoroquinolones), ermB (resistance to macrolides), sulI (resistance to sulfonamides) and tetW (resistance to tetracyclines), were detected at the highest concentrations in hospital effluent and WWTP influent samples. Although there was a significant reduction in copy numbers of these ARGs in WWTP effluent samples, this reduction was not uniform across analyzed ARGs. Relative concentration of ermB and tetW genes decreased as a result of wastewater treatment, whereas increased in the case of bla(TEM), still and qnrS genes. The incomplete removal of antibiotics and ARGs in WWTP severely affected the receiving river, where both types of emerging pollutants were found at higher concentration in downstream waters than in samples collected upstream from the discharge point. Taken together, our findings demonstrate a widespread occurrence of antibiotics and ARGs in urban and hospital wastewater and how these effluents, even after treatment, contribute to the spread of these emerging pollutants in the aquatic environment. (C) 2014 Elsevier Ltd. All rights reserved.					Huerta, Belinda/GMW-7976-2022; Marti, Elisabet/AAJ-9027-2020; BARCELO, DAMIA/O-4558-2016; Balcazar, Jose Luis/A-8390-2008; Borrego, Carles/M-8094-2014; Rodriguez-Mozaz, Sara/P-6048-2014	Marti, Elisabet/0000-0002-5301-3548; Balcazar, Jose Luis/0000-0002-6866-9347; Huerta, Belinda/0000-0003-4392-4898; Borrego, Carles/0000-0002-2708-3753; Rodriguez-Mozaz, Sara/0000-0003-2962-8144; Sanchez-Melsio, Alexandre/0000-0003-0186-5666; Gros, Meritxell/0000-0002-4365-5299													0043-1354	1879-2448				FEB 1	2015	69						234	242		10.1016/j.watres.2014.11.021	http://dx.doi.org/10.1016/j.watres.2014.11.021								25482914					WOS:000349503600023
J	Teodorescu, R; Blaabjerg, F; Liserre, M; Loh, PC				Teodorescu, R.; Blaabjerg, F.; Liserre, M.; Loh, P. C.			Proportional-resonant controllers and filters for grid-connected voltage-source converters	IEE PROCEEDINGS-ELECTRIC POWER APPLICATIONS												The recently introduced proportional-resonant (PR) controllers and filters, and their suitability for current/voltage control of grid-connected converters, are described. Using the PR controllers, the converter reference tracking performance can be enhanced and previously known shortcomings associated with conventional PI controllers can be alleviated. These shortcomings include steady-state errors in single-phase systems and the need for synchronous d-q transformation in three-phase systems. Based on similar control theory, PR filters can also be used for generating the harmonic command reference precisely in an active power filter, especially for single-phase systems, where d-q transformation theory is not directly applicable. Another advantage associated with the PR controllers and filters is the possibility of implementing selective harmonic compensation without requiring excessive computational resources. Given these advantages and the belief that PR control will find wide-ranging applications in grid-interfaced converters, PR control theory is revised in detail with a number of practical cases that have been implemented previously, described clearly to give a comprehensive reference on PR control and filtering.					Loh, Poh/A-5047-2011; Liserre, Marco/C-2857-2011; Blaabjerg, Frede/A-5008-2008; Teodorescu, Remus/O-5224-2015	Blaabjerg, Frede/0000-0001-8311-7412; Teodorescu, Remus/0000-0002-2617-7168													1350-2352					SEP	2006	153	5					750	762		10.1049/ip-epa:20060008	http://dx.doi.org/10.1049/ip-epa:20060008													WOS:000241396000015
J	Jiang, H; Gu, JX; Zheng, XS; Liu, M; Qiu, XQ; Wang, LB; Li, WZ; Chen, ZF; Ji, XB; Li, J				Jiang, Hao; Gu, Jinxing; Zheng, Xusheng; Liu, Min; Qiu, Xiaoqing; Wang, Liangbing; Li, Wenzhang; Chen, Zhongfang; Ji, Xiaobo; Li, Jie			Defect-rich and ultrathin N doped carbon nanosheets as advanced trifunctional metal-free electrocatalysts for the ORR, OER and HER	ENERGY & ENVIRONMENTAL SCIENCE												Rational design and facile preparation of non-noble trifunctional electrocatalysts with high performance, low cost and strong durability for the oxygen reduction reaction (ORR), oxygen evolution reaction (OER) and hydrogen evolution reaction (HER) are highly demanded, but remain as a big challenge. Herein, we report a spontaneous gas-foaming method to prepare nitrogen doped ultrathin carbon nanosheets (NCNs) by simply pyrolysing a mixture of citric acid and NH4Cl. Under the optimized pyrolysis temperature (carbonized at 1000 degrees C) and mass ratio of precursors (1:1), the synthesized NCN-1000-5 sample possesses an ultrathin sheet structure, an ultrahigh specific surface area (1793 m(2) g(-1)), and rich edge defects, and exhibits low overpotential and robust stability for the ORR, OER and HER. By means of density functional theory (DFT) computations, we revealed that the intrinsic active sites for the ORR, OER and HER are the carbon atoms located at the armchair edge and adjacent to the graphitic N dopants. When practically used as a catalyst in rechargeable Zn-air batteries, a high energy density (806 W h kg(-1)), a low charge/discharge voltage gap (0.77 V) and an ultralong cycle life (over 330 h) were obtained at 10 mA cm(-2) for NCN-1000-5. This work not only presents a versatile strategy to develop advanced carbon materials with ultrahigh specific surface area and abundant edge defects, but also provides useful guidance for designing and developing multifunctional metal-free catalysts for various energy-related electrocatalytic reactions.					Jiang, Hao/HHS-2852-2022; Liu, Min/ABI-4990-2020; Qiu, Xiaoqing/F-9346-2011; Chen, Zhongfang/A-3397-2008; Zheng, Xusheng/AAG-9580-2021; wang, Ling fang/A-2767-2014; Ji, Xiaobo/AFO-0372-2022; Liu, Min/D-6532-2013	Qiu, Xiaoqing/0000-0003-4655-4730; Chen, Zhongfang/0000-0002-1445-9184; Liu, Min/0000-0002-9007-4817; Jiang, Hao/0000-0002-5278-8587; Gu, Jinxing/0000-0003-4805-7017													1754-5692	1754-5706				JAN 1	2019	12	1					322	333		10.1039/c8ee03276a	http://dx.doi.org/10.1039/c8ee03276a													WOS:000457194500021
J	Wang, FW; Lazarov, BS; Sigmund, O				Wang, Fengwen; Lazarov, Boyan Stefanov; Sigmund, Ole			On projection methods, convergence and robust formulations in topology optimization	STRUCTURAL AND MULTIDISCIPLINARY OPTIMIZATION												Mesh convergence and manufacturability of topology optimized designs have previously mainly been assured using density or sensitivity based filtering techniques. The drawback of these techniques has been gray transition regions between solid and void parts, but this problem has recently been alleviated using various projection methods. In this paper we show that simple projection methods do not ensure local mesh-convergence and propose a modified robust topology optimization formulation based on erosion, intermediate and dilation projections that ensures both global and local mesh-convergence.					Lazarov, Boyan/AAI-8566-2020; Wang, Fengwen/AAE-3157-2020; Wang, Fengwen/H-6308-2016; Sigmund, Ole/A-5354-2008	Wang, Fengwen/0000-0002-0565-1465; Lazarov, Boyan Stefanov/0000-0002-3721-5692; Sigmund, Ole/0000-0003-0344-7249													1615-147X	1615-1488				JUN	2011	43	6					767	784		10.1007/s00158-010-0602-y	http://dx.doi.org/10.1007/s00158-010-0602-y													WOS:000291056600004
J	Singhal, AK; Athavale, MM; Li, HY; Jiang, Y				Singhal, AK; Athavale, MM; Li, HY; Jiang, Y			Mathematical basis and validation of the full cavitation model	JOURNAL OF FLUIDS ENGINEERING-TRANSACTIONS OF THE ASME												Cavitating,flows entail phase change and hence very large and steep density variations in the low pressure regions. These are also very, sensitive to: (a) the formation and transport of vapor bubbles, (b) the turbulent fluctuations of pressure and velocity, and (c) the magnitude of noncondensible gases, which are dissolved or ingested in the operating liquid. The presented cavitation model accounts for all these first-order effects, and thus is named as the ''full cavitation model." The phase-change rate expressions are derived,front a reduced form of Rayleigh-Plesset equation for bubble dynamics. These rates depend upon local flow conditions (pressure, velocities. turbulence) as well as fluid properties (saturation pressure, densities, and surface tension). The rate expressions employ two empirical constants, which have been calibrated with experimental data covering a very wide range of flow conditions, and do not require adjustments for different problems. The model has been implemented in an advanced, commercial, general-purpose CFD code, CFD-ACE+. Final validation results are presented for flows over hydrofoils, submerged cylindrical bodies, and sharp-edged orifices. Suggestions for possible extensions of the model implementation, e.g., to nonisothermal flows, for ingestion and mixing of noncondensible gases, and for predictions of noise and surface damage are outlined.																			0098-2202	1528-901X				SEP	2002	124	3					617	624		10.1115/1.1486223	http://dx.doi.org/10.1115/1.1486223													WOS:000178020900007
J	Björnson, E; Hoydis, J; Sanguinetti, L				Bjornson, Emil; Hoydis, Jakob; Sanguinetti, Luca			Massive MIMO Networks: Spectral, Energy, and Hardware Efficiency	FOUNDATIONS AND TRENDS IN SIGNAL PROCESSING												Massive multiple-input multiple-output (MIMO) is one of the most promising technologies for the next generation of wireless communication networks because it has the potential to provide game-changing improvements in spectral efficiency (SE) and energy efficiency (EE). This monograph summarizes many years of research insights in a clear and self-contained way and provides the reader with the necessary knowledge and mathematical tools to carry out independent research in this area. Starting from a rigorous definition of Massive MIMO, the monograph covers the important aspects of channel estimation, SE, EE, hardware efficiency (HE), and various practical deployment considerations. From the beginning, a very general, yet tractable, canonical system model with spatial channel correlation is introduced. This model is used to realistically assess the SE and EE, and is later extended to also include the impact of hardware impairments. Owing to this rigorous modeling approach, a lot of classic "wisdom" about Massive MIMO, based on too simplistic system models, is shown to be questionable. The monograph contains many numerical examples, which can be reproduced using Matlab code that is available online at https://dx.doi.org/10.1561/2000000093_supp.					Hoydis, Jakob/AAG-6646-2020; Björnson, Emil/AAD-4840-2019; Sanguinetti, Luca/B-5063-2018	Bjornson, Emil/0000-0002-5954-434X; Sanguinetti, Luca/0000-0002-2577-4091													1932-8346	1932-8354					2017	11	3-4					154	655		10.1561/2000000093	http://dx.doi.org/10.1561/2000000093													WOS:000419227900001
J	Gu, XN; Zheng, YF; Cheng, Y; Zhong, SP; Xi, TF				Gu, Xuenan; Zheng, Yufeng; Cheng, Yan; Zhong, Shengping; Xi, Tingfei			In vitro corrosion and biocompatibility of binary magnesium alloys	BIOMATERIALS												As bioabsorbable materials, magnesium alloys are expected to be totally degraded in the body and their biocorrosion products not deleterious to the surrounding tissues. it's critical that the alloying elements are carefully selected in consideration of their cytotoxicity and hemocompatibility. In the present study, nine alloying elements Al, Ag, In, Mn, Si, Sn, Y, Zn and Zr were added into magnesium individually to fabricate binary Mg-1X (wt.%) alloys. Pure magnesium was used as control. Their mechanical properties, corrosion properties and in vitro biocompatibilities (cytotoxicity and hemocompatibility) were evaluated by SEM, XRD, tensile test, immersion test, electrochemical corrosion test, cell culture and platelet adhesion test. The results showed that the addition of alloying elements could influence the strength and corrosion resistance of Mg. The cytotoxicity tests indicated that Mg-1Al, Mg-1Sn and Mg-1Zn alloy extracts showed no significant reduced cell viability to fibroblasts (L-929 and NIH3T3) and osteoblasts (MC3T3-E1): Mg-1A1 and Mg-1Zn alloy extracts indicated no negative effect on viabilities of blood vessel related cells, ECV304 and VSMC. It was found that hemolysis and the amount of adhered platelets decreased after alloying for all Mg-1X alloys as compared to the pure magnesium control. The relationship between the corrosion products and the in vitro biocompatibility had been discussed and the suitable alloying elements for the biomedical applications associated with bone and blood vessel had been proposed. (C) 2008 Elsevier Ltd. All rights reserved.					YAN, Zheng-Guang/HGC-8374-2022; Gu, Xuenan/F-5354-2011	Zheng, Y.F./0000-0002-7402-9979													0142-9612	1878-5905				FEB	2009	30	4					484	498		10.1016/j.biomaterials.2008.10.021	http://dx.doi.org/10.1016/j.biomaterials.2008.10.021								19000636					WOS:000262065500008
J	Ren, W				Ren, Wei			On consensus algorithms for double-integrator dynamics	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												This note considers consensus algorithms for double-integrator dynamics. We propose and analyze consensus algorithms for double-integrator dynamics in four cases: 1) with a bounded control input, 2) without relative velocity measurements, 3) with a group reference velocity available to each team member, and 4) with a bounded control input when a group reference state is available to only a subset of the team. We show that consensus is reached asymptotically for the first two cases if the undirected interaction graph is connected. We further show that consensus is reached asymptotically for the third case if the directed interaction graph has a directed spanning tree and the gain for velocity matching with the group reference velocity is above a certain bound. We also show that consensus is reached asymptotically for the fourth case if and only if the group reference state flows directly or indirectly to all of the vehicles in the team.					Ren, Wei/G-7369-2011														0018-9286	1558-2523				JUL	2008	53	6					1503	1509		10.1109/TAC.2008.924961	http://dx.doi.org/10.1109/TAC.2008.924961													WOS:000259192300015
J	Dong, WS; Zhang, L; Shi, GM; Li, X				Dong, Weisheng; Zhang, Lei; Shi, Guangming; Li, Xin			Nonlocally Centralized Sparse Representation for Image Restoration	IEEE TRANSACTIONS ON IMAGE PROCESSING												Sparse representation models code an image patch as a linear combination of a few atoms chosen out from an over-complete dictionary, and they have shown promising results in various image restoration applications. However, due to the degradation of the observed image (e. g., noisy, blurred, and/or down-sampled), the sparse representations by conventional models may not be accurate enough for a faithful reconstruction of the original image. To improve the performance of sparse representation-based image restoration, in this paper the concept of sparse coding noise is introduced, and the goal of image restoration turns to how to suppress the sparse coding noise. To this end, we exploit the image nonlocal self-similarity to obtain good estimates of the sparse coding coefficients of the original image, and then centralize the sparse coding coefficients of the observed image to those estimates. The so-called nonlocally centralized sparse representation (NCSR) model is as simple as the standard sparse representation model, while our extensive experiments on various types of image restoration problems, including denoising, deblurring and super-resolution, validate the generality and state-of-the-art performance of the proposed NCSR algorithm.					Zhang, Lei/P-8881-2014; Shi, Guangming/I-8614-2014; Li, Xin/A-7884-2011	Zhang, Lei/0000-0002-2078-4215; Li, Xin/0000-0003-2067-2763													1057-7149	1941-0042				APR	2013	22	4					1618	1628		10.1109/TIP.2012.2235847	http://dx.doi.org/10.1109/TIP.2012.2235847								23269751					WOS:000318016600030
J	Geng, DS; Chen, Y; Chen, YG; Li, YL; Li, RY; Sun, XL; Ye, SY; Knights, S				Geng, Dongsheng; Chen, Ying; Chen, Yougui; Li, Yongliang; Li, Ruying; Sun, Xueliang; Ye, Siyu; Knights, Shanna			High oxygen-reduction activity and durability of nitrogen-doped graphene	ENERGY & ENVIRONMENTAL SCIENCE												Nitrogen-doped graphene as a metal-free catalyst for oxygen reduction was synthesized by heat-treatment of graphene using ammonia. It was found that the optimum temperature was 900 degrees C. The resulting catalyst had a very high oxygen reduction reaction (ORR) activity through a four-electron transfer process in oxygen-saturated 0.1 M KOH. Most importantly, the electrocatalytic activity and durability of this material are comparable or better than the commercial Pt/C (loading: 4.85 mu g(Pt) cm(-2)). XPS characterization of these catalysts was tested to identify the active N species for ORR.					Ye, Siyu/AAA-7948-2020; Geng, Dongsheng/G-7124-2011; Li, Yongliang/H-3179-2011; Sun, Xueliang/C-7257-2012	Geng, Dongsheng/0000-0003-0910-8985; Li, Yongliang/0000-0002-5008-0868; Sun, Xueliang/0000-0003-0374-1245													1754-5692					MAR	2011	4	3					760	764		10.1039/c0ee00326c	http://dx.doi.org/10.1039/c0ee00326c													WOS:000287924700017
J	Centi, G; Perathoner, S				Centi, Gabriele; Perathoner, Siglinda			Opportunities and prospects in the chemical recycling of carbon dioxide to fuels	CATALYSIS TODAY					10th International Conference on CO2 Utilization (ICCDU-X)	MAY 17-21, 2009	Tianjin, PEOPLES R CHINA					This review analyses the opportunities and prospects in the chemical recycling of carbon dioxide to fuels, as a complementary technology to carbon sequestration and storage (CSS). It is remarked that the requisites for this objective are (i) minimize as much as possible the consumption of hydrogen (or hydrogen sources), (ii) produce fuels that can be easily stored and transported, and (iii) use renewable energy sources. From this perspective, the preferable option is to produce alcohols (preferably >= C2) using solar energy to produce the protons and electrons necessary for the reaction of CO2 reduction. It is evidenced, however, that this is still a long-term objective, even if already some good advances in this direction exist. The different topics discussed in the review include CO2 (i) reverse water-gas shift and (ii) hydrogenation to hydrocarbons, alcohols, dimethyl ether and formic acid, (iii) reaction with hydrocarbons to syngas, (iv) photo- and electrochemical/catalytic conversion, and (v) thermochemical conversion. Other relevant options, such as the use of micro-algae or other bio-catalysis based processes, or the use of microwave and plasma processes are instead not addressed. Therefore. the area of carbon dioxide conversion to fuels and chemicals is a very active R&D sector, and it is anticipated that it represents a challenging possibility for companies to develop complementary strategies to CSS to reduce greenhouse gas emissions. (C) 2009 Elsevier B.V. All rights reserved.					Centi, Gabriele/A-6099-2010; Perathoner, Siglinda/A-6257-2010	Centi, Gabriele/0000-0001-5626-9840; Perathoner, Siglinda/0000-0001-8814-1972													0920-5861	1873-4308				NOV 30	2009	148	3-4			SI		191	205		10.1016/j.cattod.2009.07.075	http://dx.doi.org/10.1016/j.cattod.2009.07.075													WOS:000272972400003
J	Owens, JD; Houston, M; Luebke, D; Green, S; Stone, JE; Phillips, JC				Owens, John D.; Houston, Mike; Luebke, David; Green, Simon; Stone, John E.; Phillips, James C.			GPU computing	PROCEEDINGS OF THE IEEE												The graphics processing unit (GPU) has become an integral part of today's mainstream computing systems. Over the past six years, there has been a marked increase in the performance and capabilities of GPUS. The modern GPU is not only a powerful graphics engine but also a highly parallel programmable processor featuring peak arithmetic and memory bandwidth that substantially outpaces its CPU counterpart. The GPU's rapid increase in both programmability and capability has spawned a research community that has successfully mapped a broad range of computationally demanding, complex problems to the GPU. This effort in general-purpose computing on the GPU, also known as GPU computing, has positioned the GPU as a compelling alternative to traditional microprocessors in high-performance computer systems of the future. We describe the background, hardware, and programming model for GPU computing, summarize the state of the art in tools and techniques, and present four GPIJ computing successes in game physics and computational biophysics that deliver order-of-magnitude performance gains over optimized CPU applications.					Owens, John/A-1256-2012; Phillips, James/R-7100-2019; Stone, John/F-3741-2011	Phillips, James/0000-0002-2296-3591; Stone, John/0000-0001-7215-762X													0018-9219	1558-2256				MAY	2008	96	5					879	899		10.1109/JPROC.2008.917757	http://dx.doi.org/10.1109/JPROC.2008.917757													WOS:000255128200011
J	Marsh, KN; Boxall, JA; Lichtenthaler, R				Marsh, KN; Boxall, JA; Lichtenthaler, R			Room temperature ionic liquids and their mixtures - a review	FLUID PHASE EQUILIBRIA					International Symposium on Molecular Thermodynamics and Molecular Simulation	MAY 27-30, 2003	Akiu, JAPAN					Room temperature ionic liquids are salts that are liquid at room temperature and their use as catalysts and catalytic support has been studied extensively. They are also being considered as "green solvents" for various separation processes. Recent measurements reported on the properties of pure ionic liquids and their mixtures, including gas and liquid solubility in common organic solvents will be reviewed. While some property values are in good agreement, some show large differences. These values will be compared and reasons for the discrepancies will be conjectured. Since traditional approaches to predicting the properties of fluid liquids require extensive LLE and VLE measurements, alternative predictive methods need to be explored. The predictions of the properties of mixtures of ionic liquids using COSMOtherm, an approach based on unimolecular quantum chemical calculations of the individual molecules, will be presented. (C) 2004 Published by Elsevier B.V.																			0378-3812	1879-0224				MAY 10	2004	219	1					93	98		10.1016/j.fluid.2004.02.003	http://dx.doi.org/10.1016/j.fluid.2004.02.003													WOS:000221294000015
J	Hsu, RL; Abdel-Mottaleb, M; Jain, AK				Hsu, RL; Abdel-Mottaleb, M; Jain, AK			Face detection in color images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Human face detection plays an important role in applications such as video surveillance, human computer interface, face recognition, and face image database management. We propose a face detection algorithm for color images in the presence of varying lighting conditions as well as complex backgrounds. Based on a novel lighting compensation technique and a nonlinear color transformation, our method detects skin regions over the entire image and then generates face candidates based on the spatial arrangement of these skin patches. The algorithm constructs eye, mouth, and boundary maps for verifying each face candidate. Experimental results demonstrate successful face detection over a wide range of facial variations in color, position, scale, orientation, 3D pose, and expression in images from several photo collections (both indoors and outdoors).						Abdel-Mottaleb, Mohamed/0000-0002-4163-7230													0162-8828	1939-3539				MAY	2002	24	5					696	706		10.1109/34.1000242	http://dx.doi.org/10.1109/34.1000242													WOS:000175187800010
J	Anantharaj, S; Ede, SR; Karthick, K; Sankar, SS; Sangeetha, K; Karthik, PE; Kundu, S				Anantharaj, S.; Ede, S. R.; Karthick, K.; Sankar, S. Sam; Sangeetha, K.; Karthik, P. E.; Kundu, Subrata			Precision and correctness in the evaluation of electrocatalytic water splitting: revisiting activity parameters with a critical assessment	ENERGY & ENVIRONMENTAL SCIENCE												The number of research reports published in recent years on electrochemical water splitting for hydrogen generation is higher than for many other fields of energy research. In fact, electrochemical water splitting, which is conventionally known as water electrolysis, has the potential to meet primary energy requirements in the near future when coal and hydrocarbons are completely consumed. Due to the sudden and exponentially increasing attention on this field, many researchers across the world, including our group, have been exerting immense efforts to improve the electrocatalytic properties of the materials that catalyze the oxygen evolution reaction (OER) at the anode and the hydrogen evolution reaction (HER) at the cathode, aided by the recent revolutionary discovery of nanomaterials. However, the pressure on the researchers to publish their findings rapidly has caused them to make many unnoticed and unintentional errors, which is mainly due to lack of clear insight on the activity parameters. In this perspective, we have discussed the use and validity of ten important parameters, namely overpotential at a defined current density, iR-corrected overpotential at a defined current density, Tafel slope, exchange current density (j(0)), mass activity, specific activity, faradaic efficiency (FE), turnover frequency (TOF), electrochemically active surface area (ECSA) and measurement of double layer capacitance (C-dl) for different electrocatalytic materials that are frequently employed in both OER and HER. Experimental results have also been provided in support of our discussions wherever required. Using our critical assessments of the activity parameters of water splitting electrocatalysis, researchers can ensure precision and correctness when presenting their data regarding the activity of an electrocatalyst.					Pitchiah, Esakki Karthik/C-4567-2018; kannimuthu, karthick/JQV-6911-2023; kundu, subrata/JRY-0807-2023; Selvasundarasekar, Sam Sankar/HTS-8725-2023; Sengeni, Anantharaj/E-6375-2018; Ede, Sivasankara Rao/K-8115-2015	Selvasundarasekar, Sam Sankar/0000-0003-2262-7739; kannimuthu, karthick/0000-0003-2689-0657; Sengeni, Anantharaj/0000-0002-3265-2455; Ede, Sivasankara Rao/0000-0002-1122-4179													1754-5692	1754-5706				APR 1	2018	11	4					744	771		10.1039/c7ee03457a	http://dx.doi.org/10.1039/c7ee03457a													WOS:000430537000003
J	Chen, H; Zhang, Y; Kalra, MK; Lin, F; Chen, Y; Liao, PX; Zhou, JL; Wang, G				Chen, Hu; Zhang, Yi; Kalra, Mannudeep K.; Lin, Feng; Chen, Yang; Liao, Peixi; Zhou, Jiliu; Wang, Ge			Low-Dose CT With a Residual Encoder-Decoder Convolutional Neural Network	IEEE TRANSACTIONS ON MEDICAL IMAGING												Given the potential risk of X-ray radiation to the patient, low-dose CT has attracted a considerable interest in the medical imaging field. Currently, the main stream low-dose CT methods include vendor-specific sinogram domain filtration and iterative reconstruction algorithms, but they need to access raw data, whose formats are not transparent to most users. Due to the difficulty of modeling the statistical characteristics in the image domain, the existing methods for directly processing reconstructed images cannot eliminate image noise very well while keeping structural details. Inspired by the idea of deep learning, here we combine the autoencoder, deconvolution network, and shortcut connections into the residual encoder-decoder convolutional neural network (RED-CNN) for low-dose CT imaging. After patch-based training, the proposed RED-CNN achieves a competitive performance relative to the-state-of-art methods in both simulated and clinical cases. Especially, our method has been favorably evaluated in terms of noise suppression, structural preservation, and lesion detection.					Wang, Ge/AAH-8592-2020; yi, zhang/KGL-4990-2024; Li, Denghui/KYR-7329-2024	Zhang, Yi/0000-0001-7201-2092; Wang, Ge/0000-0002-2656-7705; Lin, Feng/0000-0001-9929-8721													0278-0062	1558-254X				DEC	2017	36	12					2524	2535		10.1109/TMI.2017.2715284	http://dx.doi.org/10.1109/TMI.2017.2715284								28622671					WOS:000417913600012
J	You, CS; Huang, KB; Chae, H; Kim, BH				You, Changsheng; Huang, Kaibin; Chae, Hyukjin; Kim, Byoung-Hoon			Energy-Efficient Resource Allocation for Mobile-Edge Computation Offloading	IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS												Mobile-edge computation offloading (MECO) offloads intensive mobile computation to clouds located at the edges of cellular networks. Thereby, MECO is envisioned as a promising technique for prolonging the battery lives and enhancing the computation capacities of mobiles. In this paper, we study resource allocation for a multiuser MECO system based on time-division multiple access (TDMA) and orthogonal frequency-division multiple access (OFDMA). First, for the TDMA MECO system with infinite or finite cloud computation capacity, the optimal resource allocation is formulated as a convex optimization problem for minimizing the weighted sum mobile energy consumption under the constraint on computation latency. The optimal policy is proved to have a threshold-based structure with respect to a derived offloading priority function, which yields priorities for users according to their channel gains and local computing energy consumption. As a result, users with priorities above and below a given threshold perform complete and minimum offloading, respectively. Moreover, for the cloud with finite capacity, a sub-optimal resource-allocation algorithm is proposed to reduce the computation complexity for computing the threshold. Next, we consider the OFDMA MECO system, for which the optimal resource allocation is formulated as a mixed-integer problem. To solve this challenging problem and characterize its policy structure, a low-complexity sub-optimal algorithm is proposed by transforming the OFDMA problem to its TDMA counterpart. The corresponding resource allocation is derived by defining an average offloading priority function and shown to have close-to-optimal performance in simulation.					You, Changsheng/ABE-8443-2020; Huang, Kaibin/AAC-6346-2019; /D-5046-2011	/0000-0001-8773-4629													1536-1276	1558-2248				MAR	2017	16	3					1397	1411		10.1109/TWC.2016.2633522	http://dx.doi.org/10.1109/TWC.2016.2633522													WOS:000396404600004
J	DeJong, JT; Mortensen, BM; Martinez, BC; Nelson, DC				DeJong, Jason T.; Mortensen, Brina M.; Martinez, Brian C.; Nelson, Douglas C.			Bio-mediated soil improvement	ECOLOGICAL ENGINEERING					1st International Conference on BioGeoCivil Engineering	JUN 23-25, 2008	Delft Univ Technol, Delft, NETHERLANDS	Deltares	Delft Univ Technol			New, exciting opportunities for utilizing biological processes to modify the engineering properties of the Subsurface (e.g. strength, stiffness, permeability) have recently emerged. Enabled by interdisciplinary research at the confluence of microbiology, geochemistry. and civil engineering. this new field has the potential to meet society's ever-expanding needs for innovative treatment processes that improve Soil Supporting new and existing infrastructure. This paper first presents an overview of bio-mediated improvement systems, identifying the primary components and interplay between different disciplines. Geometric compatibility between soil and microbes that restricts the utility of different systems is identified. Focus is then narrowed to a specific system, namely bio-mediated calcite precipitation of sands. Following an overview of the Process, alternative biological processes for inducing calcite precipitation are identified and various microscopy techniques are used to assess how the pore space Volume is altered by calcite precipitation, the calcite precipitation is distributed spatially within the pore space, and the precipitated calcite degrades during loading. Non-destructive geophysical process monitoring techniques are described and their utility explored. Next, the extent to which various soil engineering properties is identified through experimental examples. Potential advantages and envisioned applications of bio-mediated soil improvement are identified. Finally, the primary challenges that lie ahead, namely optimization and upscaling of the processes and the education/training of researchers/practitioners are briefly discussed. (C) 2009 Elsevier B.V. All rights reserved.					Mortensen, Brina/F-5221-2011	DeJong, Jason/0000-0002-9809-955X													0925-8574	1872-6992				FEB	2010	36	2			SI		197	210		10.1016/j.ecoleng.2008.12.029	http://dx.doi.org/10.1016/j.ecoleng.2008.12.029													WOS:000275003400011
J	Ibarra, LF; Medina, RA; Krawinkler, H				Ibarra, LF; Medina, RA; Krawinkler, H			Hysteretic models that incorporate strength and stiffness deterioration	EARTHQUAKE ENGINEERING & STRUCTURAL DYNAMICS												This paper presents the description, calibration and application of relatively simple hysteretic models that include strength and stiffness deterioration properties, features that are critical for demand predictions as a structural system approaches collapse. Three of the basic hysteretic models used in seismic demand evaluation are modified to include deterioration properties: bilinear, peak-oriented, and pinching. The modified models include most of the sources of deterioration: i.e. various modes of cyclic deterioration and softening of the post-yielding stiffness, and also account for a residual strength after deterioration. The models incorporate an energy-based deterioration parameter that controls four cyclic deterioration modes: basic strength, post-capping strength, unloading stiffness, and accelerated reloading stiffness deterioration. Calibration of the hysteretic models on steel, plywood, and reinforced-concrete components demonstrates that the proposed models are capable of simulating the main characteristics that influence deterioration. An application of a peak-oriented deterioration model in the seismic evaluation of single-degree-of-freedom (SDOF) systems is illustrated. The advantages of using deteriorating hysteretic models for obtaining the response of highly inelastic systems are discussed. Copyright (c) 2005 John Wiley & Sons, Ltd.					Medina, Ricardo/K-8212-2018	Medina, Ricardo/0000-0002-9089-0988													0098-8847					OCT	2005	34	12					1489	1511		10.1002/eqe.495	http://dx.doi.org/10.1002/eqe.495													WOS:000232382600003
J	Kaspar, J; Fornasiero, P; Hickey, N				Kaspar, J; Fornasiero, P; Hickey, N			Automotive catalytic converters: current status and some perspectives	CATALYSIS TODAY					6th Italian Seminar on Catalysis	JUN 18-23, 2001	GRADO, ITALY	Italian Chem Soc, Gruppo Int Catalisi				Automotive three-way catalysts (TWCs) have represented over the last 25 years one of the most successful stories in the development of catalysts. The aim of this paper is to illustrate the technology for abatement of exhaust emissions by analysing the current understanding of TWCs, the specific role of the various components, the achievements and the limitations. The challenges in the development of new automotive catalysts, which can meet future highly demanding pollution abatement requirements, are also discussed. (C) 2002 Elsevier Science B.V. All rights reserved.					Hickey, Neal/J-8519-2012; Kaspar, Jan/LPP-7624-2024; Fornasiero, Paolo/B-7279-2011	Hickey, Neal/0000-0003-1271-5719; Fornasiero, Paolo/0000-0003-1082-9157; KASPAR, JAN/0000-0002-1334-7201													0920-5861	1873-4308				JAN 15	2003	77	4					419	449	PII S0920-5861(02)00384-X	10.1016/S0920-5861(02)00384-X	http://dx.doi.org/10.1016/S0920-5861(02)00384-X													WOS:000181544700012
J	Chan, TH; Jia, K; Gao, SH; Lu, JW; Zeng, ZN; Ma, Y				Chan, Tsung-Han; Jia, Kui; Gao, Shenghua; Lu, Jiwen; Zeng, Zinan; Ma, Yi			PCANet: A Simple Deep Learning Baseline for Image Classification?	IEEE TRANSACTIONS ON IMAGE PROCESSING												In this paper, we propose a very simple deep learning network for image classification that is based on very basic data processing components: 1) cascaded principal component analysis (PCA); 2) binary hashing; and 3) blockwise histograms. In the proposed architecture, the PCA is employed to learn multistage filter banks. This is followed by simple binary hashing and block histograms for indexing and pooling. This architecture is thus called the PCA network (PCANet) and can be extremely easily and efficiently designed and learned. For comparison and to provide a better understanding, we also introduce and study two simple variations of PCANet: 1) RandNet and 2) LDANet. They share the same topology as PCANet, but their cascaded filters are either randomly selected or learned from linear discriminant analysis. We have extensively tested these basic networks on many benchmark visual data sets for different tasks, including Labeled Faces in the Wild (LFW) for face verification; the MultiPIE, Extended Yale B, AR, Facial Recognition Technology (FERET) data sets for face recognition; and MNIST for hand-written digit recognition. Surprisingly, for all tasks, such a seemingly naive PCANet model is on par with the state-of-the-art features either prefixed, highly hand-crafted, or carefully learned [by deep neural networks (DNNs)]. Even more surprisingly, the model sets new records for many classification tasks on the Extended Yale B, AR, and FERET data sets and on MNIST variations. Additional experiments on other public data sets also demonstrate the potential of PCANet to serve as a simple but highly competitive baseline for texture classification and object recognition.					Lu, Jiwen/C-5291-2009	Lu, Jiwen/0000-0002-6121-5529													1057-7149	1941-0042				DEC	2015	24	12					5017	5032		10.1109/TIP.2015.2475625	http://dx.doi.org/10.1109/TIP.2015.2475625								26340772					WOS:000362008200015
J	Holzworth, DP; Huth, NI; Devoil, PG; Zurcher, EJ; Herrmann, NI; McLean, G; Chenu, K; van Oosterom, EJ; Snow, V; Murphy, C; Moore, AD; Brown, H; Whish, JPM; Verrall, S; Fainges, J; Bell, LW; Peake, AS; Poulton, PL; Hochman, Z; Thorburn, PJ; Gaydon, DS; Dalgliesh, NP; Rodriguez, D; Cox, H; Chapman, S; Doherty, A; Teixeira, E; Sharp, J; Cichota, R; Vogeler, I; Li, FY; Wang, EL; Hammer, GL; Robertson, MJ; Dimes, JP; Whitbread, AM; Hunt, J; van Rees, H; McClelland, T; Carberry, PS; Hargreaves, JNG; MacLeod, N; McDonald, C; Harsdorf, J; Wedgwood, S; Keating, BA				Holzworth, Dean P.; Huth, Neil I.; deVoil, Peter G.; Zurcher, Eric J.; Herrmann, Neville I.; McLean, Greg; Chenu, Karine; van Oosterom, Erik J.; Snow, Val; Murphy, Chris; Moore, Andrew D.; Brown, Hamish; Whish, Jeremy P. M.; Verrall, Shaun; Fainges, Justin; Bell, Lindsay W.; Peake, Allan S.; Poulton, Perry L.; Hochman, Zvi; Thorburn, Peter J.; Gaydon, Donald S.; Dalgliesh, Neal P.; Rodriguez, Daniel; Cox, Howard; Chapman, Scott; Doherty, Alastair; Teixeira, Edmar; Sharp, Joanna; Cichota, Rogerio; Vogeler, Iris; Li, Frank Y.; Wang, Enli; Hammer, Graeme L.; Robertson, Michael J.; Dimes, John P.; Whitbread, Anthony M.; Hunt, James; van Rees, Harm; McClelland, Tim; Carberry, Peter S.; Hargreaves, John N. G.; MacLeod, Neil; McDonald, Cam; Harsdorf, Justin; Wedgwood, Sara; Keating, Brian A.			APSIM - Evolution towards a new generation of agricultural systems simulation	ENVIRONMENTAL MODELLING & SOFTWARE												Agricultural systems models worldwide are increasingly being used to explore options and solutions for the food security, climate change adaptation and mitigation and carbon trading problem domains. APSIM (Agricultural Production Systems sIMulator) is one such model that continues to be applied and adapted to this challenging research agenda. From its inception twenty years ago, APSIM has evolved into a framework containing many of the key models required to explore changes in agricultural landscapes with capability ranging from simulation of gene expression through to multi-field farms and beyond. Keating et al. (2003) described many of the fundamental attributes of APSIM in detail. Much has changed in the last decade, and the APSIM community has been exploring novel scientific domains and utilising software developments in social media, web and mobile applications to provide simulation tools adapted to new demands. This paper updates the earlier work by Keating et al. (2003) and chronicles the changing external challenges and opportunities being placed on APSIM during the last decade. It also explores and discusses how APSIM has been evolving to a "next generation" framework with improved features and capabilities that allow its use in many diverse topics. Crown Copyright (C) 2014 Published by Elsevier Ltd. All rights reserved.					Hargreaves, John/G-5458-2010; Snow, Val/S-2106-2019; Fainges, Justin/E-7110-2015; Keating, Brian/ABD-1652-2021; Robertson, Michael/G-1418-2010; Bell, Lindsay/B-9769-2008; Hochman, Zvi/E-8993-2010; Brown, Hamish/IAN-1847-2023; Peake, Allan/C-4906-2011; Dalgliesh, Neal/B-9772-2008; Rodriguez, Daniel/A-7920-2011; Moore, Andrew/D-3418-2009; Gaydon, Donald/F-4608-2012; Wang, Enli/K-7478-2012; McLean, Greg/AAE-9842-2021; Vogeler, Iris/P-2761-2019; Huth, Neil/U-3271-2019; Hunt, James/A-1408-2010; Holzworth, Dean/F-8332-2010; Carberry, Peter/B-9768-2008; Thorburn, Peter/A-6884-2011; McDonald, Cam/AAE-5085-2019; Li, Frank Yonghong/AAN-3093-2020; Chenu, Karine/A-8967-2009; Hammer, Graeme/A-3785-2008; Snow, Val/O-8693-2016; McLean, Gregory/Q-9103-2017; Whish, Jeremy/D-3343-2011; Poulton, Perry/D-7027-2011; Teixeira, Edmar/K-1238-2016; Sharp, Joanna/C-1167-2011; Whitbread, Anthony/F-3068-2010; Chapman, Scott/B-9673-2008	Chenu, Karine/0000-0001-7273-2057; Hammer, Graeme/0000-0002-1180-7374; Li, Frank Yonghong/0000-0002-5137-8017; Van Oosterom, Erik/0000-0003-4886-4038; McDonald, Cam/0000-0003-2265-2299; Robertson, Michael/0000-0003-2905-4347; Snow, Val/0000-0002-6911-8184; McLean, Gregory/0000-0002-8491-2984; Whish, Jeremy/0000-0001-5939-9659; Hunt, James/0000-0003-2884-5622; Poulton, Perry/0000-0003-1341-5056; Vogeler, Iris/0000-0003-2512-7668; Teixeira, Edmar/0000-0002-4835-0590; Zurcher, Eric/0000-0002-7274-9921; Herrmann, Neville/0000-0002-7832-9362; Hochman, Zvi/0000-0002-6217-5231; Sharp, Joanna/0000-0001-5849-868X; Rodriguez, Daniel/0000-0002-4699-0957; Gaydon, Donald/0000-0002-0078-4154; Whitbread, Anthony/0000-0003-4840-7670; Moore, Andrew/0000-0002-5675-4720; Chapman, Scott/0000-0003-4732-8452													1364-8152	1873-6726				DEC	2014	62						327	350		10.1016/j.envsoft.2014.07.009	http://dx.doi.org/10.1016/j.envsoft.2014.07.009													WOS:000346751800027
J	Chen, WH				Chen, WH			Disturbance observer based control for nonlinear systems	IEEE-ASME TRANSACTIONS ON MECHATRONICS												This paper presents a general framework for nonlinear systems subject to disturbances using disturbance observer based control (DOBC) techniques. A two-stage design procedure to improve disturbance attenuation ability of current linear/nonlinear controllers is proposed where the disturbance observer design is separated from the controller design. To facilitate this concept, a nonlinear disturbance observer is developed for disturbances generated by an exogenous system, and global exponential stability is established under certain condition. Furthermore, semiglobal stability condition of the composite controller consisting of a nonlinear controller and the nonlinear disturbance observer is established. The developed method is illustrated by the application to control of a two-link robotic manipulator.					Chen, Wen-Hua/C-5993-2009	Chen, Wen-Hua/0000-0003-3356-2889													1083-4435	1941-014X				DEC	2004	9	4					706	710		10.1109/TMECH.2004.839034	http://dx.doi.org/10.1109/TMECH.2004.839034													WOS:000225909600013
J	Xiao, P; Sk, MA; Thia, L; Ge, XM; Lim, RJ; Wang, JY; Lim, KH; Wang, X				Xiao, Peng; Sk, Mahasin Alam; Thia, Larissa; Ge, Xiaoming; Lim, Rern Jern; Wang, Jing-Yuan; Lim, Kok Hwa; Wang, Xin			Molybdenum phosphide as an efficient electrocatalyst for the hydrogen evolution reaction	ENERGY & ENVIRONMENTAL SCIENCE												Electrochemical production of hydrogen from water has been directed to the search for non-noble metal based and earth-abundant catalysts. In this work, we propose a novel cost-effective catalyst, molybdenum phosphide that exhibits high activity towards the hydrogen evolution reaction (HER) in both acid and alkaline media even in bulk form. Comparative analysis of Mo, Mo3P and MoP as catalysts for HER clearly indicates that phosphorization can potentially modify the properties of the metal and different degrees of phosphorization lead to distinct activities and stabilities. Theoretical calculations by density functional theory also show that a simple phosphorization of molybdenum to form MoP introduces a good 'H delivery' system which attains nearly zero binding to H at a certain H coverage. With the combination of experimental results and theoretical calculations, this work has enlightened a new way of exploring cost-effective catalysts for HER.					Ge, Xiaoming/C-7048-2011; Lim, Kok/AAV-7932-2020; Xiao, Peng/KBA-6524-2024; Wang, Xin/G-6206-2010	Wang, Xin/0000-0003-2686-466X; Lim, kok Hwa/0000-0002-2261-9491													1754-5692	1754-5706				AUG	2014	7	8					2624	2629		10.1039/c4ee00957f	http://dx.doi.org/10.1039/c4ee00957f													WOS:000339861800016
J	Zhang, Y; Kohler, N; Zhang, MQ				Zhang, Y; Kohler, N; Zhang, MQ			Surface modification of superparamagnetic magnetite nanoparticles and their intracellular uptake	BIOMATERIALS												Superparamagnetic magnetite nanoparticles were surface-modified with poly (ethylene glycol) (PEG) and folic acid, respectively, to improve their intracellular uptake and ability to tat-get specific cells. PEG and folic acid were successfully immobilized on the surfaces of magnetite nanoparticles and characterized using fourier transform infrared spectra. The nanoparticle internalization into mouse macrophage (RAW 264.7) and human breast cancer (BT20) cells was visualized using both fluorescence and confocal microscopy, and quantified by inductively coupled plasma emission spectroscopy (ICP). After the cells were cultured for 48 h in the medium containing the nanoparticles modified with PEG or folic acid, the results of fluorescence and confocal microscopy showed that the nanoparticles were internalized into the cells. The ICP measurements indicated that the uptake amount of PEG-modified nanoparticles into macrophage cells was much lower than that of unmodified nanoparticles, while folic acid modification did not change the amount of the uptake. However, for breast cancer cells, both PEG and folic acid modification facilitated the nanoparticle internalization into the cells. Therefore, PEG and folic acid modification of magnetite nanoparticles could be used to resist the protein adsorption and thus avoid the particle recognition by macropliage cells, and to facilitate the nanoparticle uptake to specific cancer cells for cancer therapy and diagnosis. (C) 2002 Elsevier Science Ltd. All rights reserved.					Zhang, Miqin/F-5537-2010; Zhang, Yong/F-2803-2010	Zhang, Miqin/0000-0001-8974-1494; Zhang, Yong/0000-0002-1303-0458; Saracik, Kadriye/0000-0002-1622-9788													0142-9612					APR	2002	23	7					1553	1561	PII S0142-9612(01)00267-8	10.1016/S0142-9612(01)00267-8	http://dx.doi.org/10.1016/S0142-9612(01)00267-8								11922461					WOS:000174196100002
J	Baraniuk, RG; Cevher, V; Duarte, MF; Hegde, C				Baraniuk, Richard G.; Cevher, Volkan; Duarte, Marco F.; Hegde, Chinmay			Model-Based Compressive Sensing	IEEE TRANSACTIONS ON INFORMATION THEORY												Compressive sensing (CS) is an alternative to Shannon/Nyquist sampling for the acquisition of sparse or compressible signals that can be well approximated by just K << N elements from an N-dimensional basis. Instead of taking periodic samples, CS measures inner products with M < N random vectors and then recovers the signal via a sparsity-seeking optimization or greedy algorithm. Standard CS dictates that robust signal recovery is possible from M = O(K log(N/K)) measurements. It is possible to substantially decrease M without sacrificing robustness by leveraging more realistic signal models that go beyond simple sparsity and compressibility by including structural dependencies between the values and locations of the signal coefficients. This paper introduces a model-based CS theory that parallels the conventional theory and provides concrete guidelines on how to create model-based recovery algorithms with provable performance guarantees. A highlight is the introduction of a new class of structured compressible signals along with a new sufficient condition for robust structured compressible signal recovery that we dub the restricted amplification property, which is the natural counterpart to the restricted isometry property of conventional CS. Two examples integrate two relevant signal models-wavelet trees and block sparsity-into two state-of-the-art CS recovery algorithms and prove that they offer robust recovery from just M = O(K) measurements. Extensive numerical simulations demonstrate the validity and applicability of our new theory and algorithms.					Baraniuk, Richard/ABA-1743-2020; Duarte, Marco/G-6906-2012	Duarte, Marco/0000-0001-8410-3266; Cevher, Volkan/0000-0002-5004-201X													0018-9448	1557-9654				APR	2010	56	4					1982	2001		10.1109/TIT.2010.2040894	http://dx.doi.org/10.1109/TIT.2010.2040894													WOS:000275999500039
J	Fishler, E; Haimovich, A; Blum, RS; Cimini, LJ; Chizhik, D; Valenzuela, RA				Fishler, E; Haimovich, A; Blum, RS; Cimini, LJ; Chizhik, D; Valenzuela, RA			Spatial diversity in radars-models and detection performance	IEEE TRANSACTIONS ON SIGNAL PROCESSING												Inspired by recent advances in multiple-input multiple-output (MIMO) communications, this proposal introduces the statistical MIMO radar concept. To the authors' knowledge, this is the first time that the statistical MIMO is being proposed for radar. The fundamental difference between statistical MIMO and other radar array systems is that the latter seek to maximize the coherent processing gain, while statistical MIMO radar capitalizes on the diversity of target scattering to improve radar performance. Coherent processing is made possible by highly correlated signals at the receiver array, whereas in statistical MIMO radar, the signals received by the array elements are uncorrelated. Radar targets generally consist of many small elemental scatterers that are fused by the radar waveform and the processing at the receiver, to result in echoes with fluctuating amplitude and phase. It is well known that in conventional radar, slow fluctuations of the target radar cross section (RCS) result in target fades that degrade radar performance. By spacing the antenna elements at the transmitter and at the receiver such that the target angular spread is manifested, the MIMO radar can exploit the spatial diversity of target scatterers opening the way to a variety of new techniques that can improve radar performance. This paper focuses on the application of the target spatial diversity to improve detection performance. The optimal detector in the Neyman-Pearson sense is developed and analyzed for the statistical MIMO radar. It is shown that the optimal detector consists of noncoherent processing of the receiver sensors' outputs and that for cases of practical interest, detection performance is superior to that obtained through coherent processing. An optimal detector invariant to the signal and noise levels is also developed and analyzed. In this case as well, statistical MIMO radar provides great improvements over other types of array radars.						Blum, Rick S/0000-0002-1024-6771													1053-587X	1941-0476				MAR	2006	54	3					823	838		10.1109/TSP.2005.862813	http://dx.doi.org/10.1109/TSP.2005.862813													WOS:000235557500002
J	Narasimhan, SG; Nayar, SK				Narasimhan, SG; Nayar, SK			Contrast restoration of weather degraded images	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												Images of outdoor scenes captured in bad weather suffer from poor contrast. Under bad weather conditions, the light reaching a camera is severely scattered by the atmosphere. The resulting decay in contrast varies across the scene and is exponential in the depths of scene points. Therefore, traditional space invariant image processing techniques are not sufficient to remove weather effects from images. In this paper, we present a physics-based model that describes the appearances of scenes in uniform bad weather conditions. Changes in intensities of scene points under different weather conditions provide simple constraints to detect depth discontinuities in the scene and also to compute scene structure. Then, a fast algorithm to restore scene contrast is presented. In contrast to previous techniques, our weather removal algorithm does not require any a priori scene structure, distributions of scene reflectances, or detailed knowledge about the particular weather condition. All the methods described in this paper are effective under a wide range of weather conditions including haze, mist, fog, and conditions arising due to other aerosols. Further, our methods can be applied to gray scale, RGB color, multispectral and even IR images. We also extend our techniques to restore contrast of scenes with moving objects, captured using a video camera.						Narasimhan, Srinivasa/0000-0003-0389-1921													0162-8828					JUN	2003	25	6					713	724		10.1109/TPAMI.2003.1201821	http://dx.doi.org/10.1109/TPAMI.2003.1201821													WOS:000182961300006
J	Shakhatreh, H; Sawalmeh, AH; Al-Fuqaha, A; Dou, ZC; Almaita, E; Khalil, I; Othman, NS; Khreishah, A; Guizani, M				Shakhatreh, Hazim; Sawalmeh, Ahmad H.; Al-Fuqaha, Ala; Dou, Zuochao; Almaita, Eyad; Khalil, Issa; Othman, Noor Shamsiah; Khreishah, Abdallah; Guizani, Mohsen			Unmanned Aerial Vehicles (UAVs): A Survey on Civil Applications and Key Research Challenges	IEEE ACCESS												The use of unmanned aerial vehicles (UAVs) is growing rapidly across many civil application domains, including real-time monitoring, providing wireless coverage, remote sensing, search and rescue, delivery of goods, security and surveillance, precision agriculture, and civil infrastructure inspection. Smart UAVs are the next big revolution in the UAV technology promising to provide new opportunities in different applications, especially in civil infrastructure in terms of reduced risks and lower cost. Civil infrastructure is expected to dominate more than $45 Billion market value of UAV usage. In this paper, we present UAV civil applications and their challenges. We also discuss the current research trends and provide future insights for potential UAV uses. Furthermore, we present the key challenges for UAV civil applications, including charging challenges, collision avoidance and swarming challenges, and networking and security-related challenges. Based on our review of the recent literature, we discuss open research challenges and draw high-level insights on how these challenges might be approached.					Sawalmeh, Ahmad/AAZ-9563-2020; Khreishah, Abdallah/IQW-2966-2023; Guizani, Mohsen/AAX-4534-2021; Othman, Noor Shamsiah/GLS-5562-2022; Al-Fuqaha, Ala/IQT-0689-2023	Khreishah, Abdallah/0000-0003-1583-713X; Othman, Noor Shamsiah/0000-0002-1849-6687; Almaita, Eyad/0000-0002-9601-4014; Al-Fuqaha, Ala/0000-0002-0903-1204; Khalil, Issa/0000-0002-7660-9512; Sawalmeh, Ahmad/0000-0002-7040-8963													2169-3536						2019	7						48572	48634		10.1109/ACCESS.2019.2909530	http://dx.doi.org/10.1109/ACCESS.2019.2909530													WOS:000466487100001
J	Xiao, ZG; Bi, C; Shao, YC; Dong, QF; Wang, Q; Yuan, YB; Wang, CG; Gao, YL; Huang, JS				Xiao, Zhengguo; Bi, Cheng; Shao, Yuchuan; Dong, Qingfeng; Wang, Qi; Yuan, Yongbo; Wang, Chenggong; Gao, Yongli; Huang, Jinsong			Efficient, high yield perovskite photovoltaic devices grown by interdiffusion of solution-processed precursor stacking layers	ENERGY & ENVIRONMENTAL SCIENCE												We report on an interdiffusion method to fabricate pin-hole free perovskite films using a low temperature (<105 degrees C) solution process. A high efficiency of 15.4%, with a fill factor of similar to 80%, was achieved for the devices under one sun illumination. The interdiffusion method results in high device yield, with an efficiency of above 14.5% for more than 85% of the devices.					Wang, Chenggong/G-9492-2015; Huang, Jinsong/ABM-9861-2022; Xiao, Zhengguo/Y-3205-2019; Qi, Wang/HDM-5801-2022; Shao, Yuchuan/Y-2831-2019; Dong, Qingfeng/ABD-4925-2021; Xiao, Zhengguo/P-4628-2014; Yuan, Yongbo/Y-2461-2019; Gao, Yongli/N-8392-2015	Huang, Jinsong/0000-0002-0509-8778; Dong, Qingfeng/0000-0002-7618-6249; Xiao, Zhengguo/0000-0001-6646-1166; Yuan, Yongbo/0000-0002-4606-4611; Gao, Yongli/0000-0001-9765-5246; Shao, Yuchuan/0000-0001-7155-456X													1754-5692	1754-5706				AUG	2014	7	8					2619	2623		10.1039/c4ee01138d	http://dx.doi.org/10.1039/c4ee01138d													WOS:000339861800015
J	Gaing, ZL				Gaing, ZL			A particle swarm optimization approach for optimum design of PID controller in AVR system	IEEE TRANSACTIONS ON ENERGY CONVERSION												In this paper, a novel design method for determining the optimal proportional-integral-derivative (PID) controller parameters of an AVR system using the particle swarm optimization (PSO) algorithm is presented. This paper demonstrated in detail how to employ the PSO method to search efficiently the optimal PID controller parameters of an AVR system. The proposed approach had superior features, including easy implementation, stable convergence characteristic, and good computational efficiency. Fast tuning of optimum PID controller parameters yields high-quality solution. In order to assist estimating the performance of the proposed PSO-PID controller, a new time-domain performance criterion function was also defined. Compared with the genetic algorithm (GA), the proposed method was indeed more efficient and robust in improving the step response of an AVR system.																			0885-8969	1558-0059				JUN	2004	19	2					384	391		10.1109/TEC.2003.821821	http://dx.doi.org/10.1109/TEC.2003.821821													WOS:000221578600021
J	Kiranyaz, S; Ince, T; Gabbouj, M				Kiranyaz, Serkan; Ince, Turker; Gabbouj, Moncef			Real-Time Patient-Specific ECG Classification by 1-D Convolutional Neural Networks	IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING												Goal: This paper presents a fast and accurate patient-specific electrocardiogram (ECG) classification and monitoring system. Methods: An adaptive implementation of 1-D convolutional neural networks (CNNs) is inherently used to fuse the two major blocks of the ECG classification into a single learning body: feature extraction and classification. Therefore, for each patient, an individual and simple CNN will be trained by using relatively small common and patient-specific training data, and thus, such patient-specific feature extraction ability can further improve the classification performance. Since this also negates the necessity to extract hand-crafted manual features, once a dedicated CNN is trained for a particular patient, it can solely be used to classify possibly long ECG data stream in a fast and accurate manner or alternatively, such a solution can conveniently be used for real-time ECG monitoring and early alert system on a light-weight wearable device. Results: The results over the MIT-BIH arrhythmia benchmark database demonstrate that the proposed solution achieves a superior classification performance than most of the state-of-the-art methods for the detection of ventricular ectopic beats and supraventricular ectopic beats. Conclusion: Besides the speed and computational efficiency achieved, once a dedicated CNN is trained for an individual patient, it can solely be used to classify his/her long ECG records such as Holter registers in a fast and accurate manner. Significance: Due to its simple and parameter invariant nature, the proposed system is highly generic, and, thus, applicable to any ECG dataset.					Kiranyaz, Serkan/AAK-1416-2021; Ince, Turker/F-1349-2019; Gabbouj, Moncef/G-4293-2014	kiranyaz, serkan/0000-0003-1551-3397; Gabbouj, Moncef/0000-0002-9788-2323; Ince, Turker/0000-0002-8495-8958													0018-9294	1558-2531				MAR	2016	63	3					664	675		10.1109/TBME.2015.2468589	http://dx.doi.org/10.1109/TBME.2015.2468589								26285054					WOS:000371933800022
J	Bai, P; Li, J; Brushett, FR; Bazant, MZ				Bai, Peng; Li, Ju; Brushett, Fikile R.; Bazant, Martin Z.			Transition of lithium growth mechanisms in liquid electrolytes	ENERGY & ENVIRONMENTAL SCIENCE												Next-generation high-energy batteries will require a rechargeable lithium metal anode, but lithium dendrites tend to form during recharging, causing short-circuit risk and capacity loss, by mechanisms that still remain elusive. Here, we visualize lithium growth in a glass capillary cell and demonstrate a change of mechanism from root-growing mossy lithium to tip-growing dendritic lithium at the onset of electrolyte diffusion limitation. In sandwich cells, we further demonstrate that mossy lithium can be blocked by nanoporous ceramic separators, while dendritic lithium can easily penetrate nanopores and short the cell. Our results imply a fundamental design constraint for metal batteries ("Sand's capacity''), which can be increased by using concentrated electrolytes with stiff, permeable, nanoporous separators for improved safety.					Bazant, Martin/AFW-1160-2022; Li, Ju/A-2993-2008; Bai, Peng/H-1043-2011	Bai, Peng/0000-0002-2419-3498; Brushett, Fikile/0000-0002-7361-6637; Li, Ju/0000-0002-7841-8058; Bazant, Martin Zdenek/0000-0002-8200-4501													1754-5692	1754-5706					2016	9	10					3221	3229		10.1039/c6ee01674j	http://dx.doi.org/10.1039/c6ee01674j													WOS:000386336200026
J	Basri, R; Jacobs, DW				Basri, R; Jacobs, DW			Lambertian reflectance and linear subspaces	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												We prove that the set of all Lambertian reflectance functions (the mapping from surface normals to intensities) obtained with arbitrary distant right sources lies close to a 9D linear subspace. This implies that, in general, the set of images of a convex Lambertian object obtained under a wide variety of fighting conditions can be approximated accurately by a low-dimensional linear subspace, explaining prior empirical results. We also provide a simple analytic characterization of this linear space. We obtain these results by representing fighting using spherical harmonics and describing the effects of Lambertian materials as the analog of a convolution. These results allow us to construct algorithms for object recognition based on linear methods as well as algorithms that use convex optimization to enforce nonnegative fighting functions. We also show a simple way to enforce nonnegative Fighting when the images of an object lie near a 4D linear space. We apply these algorithms to perform face recognition by finding the 3D model that best matches a 2D query image.																			0162-8828	1939-3539				FEB	2003	25	2					218	233		10.1109/TPAMI.2003.1177153	http://dx.doi.org/10.1109/TPAMI.2003.1177153													WOS:000180519800006
J	Zhou, Z; Chen, X; Li, E; Zeng, LK; Luo, K; Zhang, JS				Zhou, Zhi; Chen, Xu; Li, En; Zeng, Liekang; Luo, Ke; Zhang, Junshan			Edge Intelligence: Paving the Last Mile of Artificial Intelligence With Edge Computing	PROCEEDINGS OF THE IEEE												With the breakthroughs in deep learning, the recent years have witnessed a booming of artificial intelligence (AI) applications and services, spanning from personal assistant to recommendation systems to video/audio surveillance. More recently, with the proliferation of mobile computing and Internet of Things (IoT), billions of mobile and IoT devices are connected to the Internet, generating zillions bytes of data at the network edge. Driving by this trend, there is an urgent need to push the AI frontiers to the network edge so as to fully unleash the potential of the edge big data. To meet this demand, edge computing, an emerging paradigm that pushes computing tasks and services from the network core to the network edge, has been widely recognized as a promising solution. The resulted new interdiscipline, edge AI or edge intelligence (EI), is beginning to receive a tremendous amount of interest. However, research on EI is still in its infancy stage, and a dedicated venue for exchanging the recent advances of EI is highly desired by both the computer system and AI communities. To this end, we conduct a comprehensive survey of the recent research efforts on EI. Specifically, we first review the background and motivation for AI running at the network edge. We then provide an overview of the overarching architectures, frameworks, and emerging key technologies for deep learning model toward training/inference at the network edge. Finally, we discuss future research opportunities on EI. We believe that this survey will elicit escalating attentions, stimulate fruitful discussions, and inspire further research ideas on EI.					Chen, Xu/GXW-3072-2022; Zhou, Zhi/AAS-1383-2020	Luo, Ke/0000-0003-0118-7236; Zeng, Liekang/0000-0003-4800-8768													0018-9219	1558-2256				AUG	2019	107	8			SI		1738	1762		10.1109/JPROC.2019.2918951	http://dx.doi.org/10.1109/JPROC.2019.2918951													WOS:000497973300015
J	Siegel, PH				Siegel, PH			Terahertz technology in biology and medicine	IEEE TRANSACTIONS ON MICROWAVE THEORY AND TECHNIQUES												Terahertz irradiation and sensing is being applied for the first time to a wide range of fields outside the traditional niches of space science, molecular line spectroscopy, and plasma diagnostics. This paper surveys some of the terahertz measurements and applications of interest in the biological and medical sciences.					Siegel, Peter/F-6795-2012														0018-9480	1557-9670				OCT	2004	52	10					2438	2447		10.1109/TMTT.2004.835916	http://dx.doi.org/10.1109/TMTT.2004.835916													WOS:000224330900014
J	Zhang, JP; Wang, FY; Wang, KF; Lin, WH; Xu, X; Chen, C				Zhang, Junping; Wang, Fei-Yue; Wang, Kunfeng; Lin, Wei-Hua; Xu, Xin; Chen, Cheng			Data-Driven Intelligent Transportation Systems: A Survey	IEEE TRANSACTIONS ON INTELLIGENT TRANSPORTATION SYSTEMS												For the last two decades, intelligent transportation systems (ITS) have emerged as an efficient way of improving the performance of transportation systems, enhancing travel security, and providing more choices to travelers. A significant change in ITS in recent years is that much more data are collected from a variety of sources and can be processed into various forms for different stakeholders. The availability of a large amount of data can potentially lead to a revolution in ITS development, changing an ITS from a conventional technology-driven system into a more powerful multifunctional data-driven intelligent transportation system ((DITS)-I-2): a system that is vision, multisource, and learning algorithm driven to optimize its performance. Furthermore, (DITS)-I-2 is trending to become a privacy-aware people-centric more intelligent system. In this paper, we provide a survey on the development of (DITS)-I-2, discussing the functionality of its key components and some deployment issues associated with (DITS)-I-2. Future research directions for the development of (DITS)-I-2 is also presented.					徐, 昕/JNS-1298-2023	Xu, Xin/0000-0003-3238-745X													1524-9050	1558-0016				DEC	2011	12	4					1624	1639		10.1109/TITS.2011.2158001	http://dx.doi.org/10.1109/TITS.2011.2158001													WOS:000297588500061
J	Beeby, SP; Torah, RN; Tudor, MJ; Glynne-Jones, P; O'Donnell, T; Saha, CR; Roy, S				Beeby, S. P.; Torah, R. N.; Tudor, M. J.; Glynne-Jones, P.; O'Donnell, T.; Saha, C. R.; Roy, S.			A micro electromagnetic generator for vibration energy harvesting	JOURNAL OF MICROMECHANICS AND MICROENGINEERING												Vibration energy harvesting is receiving a considerable amount of interest as a means for powering wireless sensor nodes. This paper presents a small ( component volume 0.1 cm(3), practical volume 0.15 cm(3)) electromagnetic generator utilizing discrete components and optimized for a low ambient vibration level based upon real application data. The generator uses four magnets arranged on an etched cantilever with a wound coil located within the moving magnetic field. Magnet size and coil properties were optimized, with the final device producing 46 mu W in a resistive load of 4 k Omega from just 0.59 m s(-2) acceleration levels at its resonant frequency of 52 Hz. A voltage of 428 mVrms was obtained from the generator with a 2300 turn coil which has proved sufficient for subsequent rectification and voltage step-up circuitry. The generator delivers 30% of the power supplied from the environment to useful electrical power in the load. This generator compares very favourably with other demonstrated examples in the literature, both in terms of normalized power density and efficiency.					Glynne-Jones, Peter/A-3025-2012; Beeby, Stephen/T-6039-2017; Roy, Saibal/C-2217-2013	Beeby, Stephen/0000-0002-0800-1759; Glynne-Jones, Peter/0000-0001-5684-3953; Saha, Chitta/0000-0001-6831-846X; Roy, Saibal/0000-0003-4366-597X; Tudor, Michael/0000-0003-1179-9455; O'Donnell, Terence/0000-0002-2824-7107; Torah, Russel/0000-0002-5598-2860													0960-1317	1361-6439				JUL	2007	17	7					1257	1265		10.1088/0960-1317/17/7/007	http://dx.doi.org/10.1088/0960-1317/17/7/007													WOS:000247924900027
J	Nicol, JF; Humphreys, MA				Nicol, JF; Humphreys, MA			Adaptive thermal comfort and sustainable thermal standards for buildings	ENERGY AND BUILDINGS					Conference on Moving Thermal Comfort Standards into the 21st Century	APR 05-08, 2001	WINDSOR, ENGLAND	Oxford Brooks Univ, Loughborough Univ				The origin and development of the adaptive approach to thermal comfort is explained. A number of recent developments in the application of the theory are considered and the origin of the differences between adaptive thermal comfort and the 'rational' indices is explored. The application of the adaptive approach to thermal comfort standards is considered and recommendations made as to the best comfort temperature, the range of comfortable environments and the maximum rate of change of indoor temperature. The application of criteria of sustainability to thermal standards for buildings is also considered. (C) 2002 Elsevier Science B.V. All rights reserved.																			0378-7788	1872-6178				JUL	2002	34	6					563	572	PII S0378-7788(02)00006-3	10.1016/S0378-7788(02)00006-3	http://dx.doi.org/10.1016/S0378-7788(02)00006-3													WOS:000175492600005
J	Deng, J; Li, HB; Xiao, JP; Tu, YC; Deng, DH; Yang, HX; Tian, HF; Li, JQ; Ren, PJ; Bao, XH				Deng, Jiao; Li, Haobo; Xiao, Jianping; Tu, Yunchuan; Deng, Dehui; Yang, Huaixin; Tian, Huanfang; Li, Jianqi; Ren, Pengju; Bao, Xinhe			Triggering the electrocatalytic hydrogen evolution activity of the inert two-dimensional MoS<sub>2</sub> surface <i>via</i> single-atom metal doping	ENERGY & ENVIRONMENTAL SCIENCE												Electrocatalytic splitting of water is one of the most efficient technologies for hydrogen production, and two-dimensional (2D) MoS2 has been considered as a potential alternative to Pt-based catalysts in the hydrogen evolution reaction (HER). However, the catalytic activity of 2D MoS2 is always contributed from its edge sites, leaving a large number of in-plane domains useless. Herein, we for the first time demonstrated that the catalytic activity of in-plane S atoms of MoS2 can be triggered via single-atom metal doping in HER. In experiments, single Pt atom-doped, few-layer MoS2 nanosheets (Pt-MoS2) showed a significantly enhanced HER activity compared with pure MoS2, originating from the tuned adsorption behavior of H atoms on the in-plane S sites neighboring the doped Pt atoms, according to the density functional theory (DFT) calculations. Furthermore, the HER activity of MoS2 doped with a number of transition metals was screened by virtue of DFT calculations, resulting in a volcano curve along the adsorption free energy of H atoms (Delta G(H)degrees), which was further confirmed in experiment by using non-precious metals such as Co and Ni atoms doping 2D MoS2 as the catalysts.					Li, Haobo/GXG-2873-2022; Deng, Jiao/GZB-2249-2022; Yang, Huaixin/R-3261-2018; Li, Jianqi/R-3908-2018; Bao, Xinhe/P-5373-2014; 肖, 建平/HCI-0998-2022; Tian, huanfang/X-2355-2018; YANG, HUAIXIN/AAH-5599-2020	Xiao, Jianping/0000-0003-1779-6140; Tu, Yunchuan/0009-0005-8013-060X; YANG, HUAIXIN/0000-0002-7857-2442													1754-5692	1754-5706					2015	8	5					1594	1601		10.1039/c5ee00751h	http://dx.doi.org/10.1039/c5ee00751h													WOS:000354192900023
J	Farid, AA; Hranilovic, S				Farid, Ahmed A.; Hranilovic, Steve			Outage capacity optimization for free-space optical links with pointing errors	JOURNAL OF LIGHTWAVE TECHNOLOGY												We investigate the performance and design of free-space optical (FSO) communication links over slow fading channels from an information theory perspective. A statistical model for the optical intensity fluctuation at the receiver due to the combined effects of atmospheric turbulence and pointing errors is derived. Unlike earlier work, our model considers the effect of beam width, detectors size, and jitter variance explicitly. Expressions for the outage probability are derived for a variety of atmospheric conditions. For given weather and misalignment conditions, the beam width is optimized to maximize the channel capacity subject to outage. Large gains in achievable rate are realized versus using a nominal beam width. In light fog, by optimizing the beam width, the achievable rate is increased by 80% over the nominal beam width at an outage probability of 10(-5). Well-known error control codes are then applied to the channel and shown to realize much of the achievable gains.					Hranilovic, Steve/ABI-3065-2020														0733-8724	1558-2213				JUL	2007	25	7					1702	1710		10.1109/JLT.2007.899174	http://dx.doi.org/10.1109/JLT.2007.899174													WOS:000248020400007
J	Boswell, R; Collett, TS				Boswell, Ray; Collett, Timothy S.			Current perspectives on gas hydrate resources	ENERGY & ENVIRONMENTAL SCIENCE												For the past three decades, discussion of naturally-occurring gas hydrates has been framed by a series of assessments that indicate enormous global volumes of methane present within gas hydrate accumulations. At present, these estimates continue to range over several orders of magnitude, creating great uncertainty in assessing those two gas hydrate issues that relate most directly to resource volumes - gas hydrate's potential as an energy resource and its possible role in ongoing climate change. However, a series of recent field expeditions have provided new insights into the nature of gas hydrate occurrence; perhaps most notably, the understanding that gas hydrates occur in a wide variety of geologic settings and modes of occurrence. These fundamental differences - which include gas hydrate concentration, host lithology, distribution within the sediment matrix, burial depth, water depth, and many others - can now be incorporated into evaluations of gas hydrate energy resource and environmental issues. With regard to energy supply potential, field data combined with advanced numerical simulation have identified gas-hydrate-bearing sands as the most feasible initial targets for energy recovery. The first assessments of potential technically-recoverable resources are now occurring, enabling a preliminary estimate of ultimate global recoverable volumes on the order of similar to 3 x 10(13) m(3) (10(15) ft(3); similar to 15 GtC). Other occurrences, such as gas hydrate-filled fractures in clay-dominated reservoirs, may also become potential energy production targets in the future; but as yet, no production concept has been demonstrated. With regard to the climate implications of gas hydrate, an analogous partitioning of global resources to determine that portion most prone to dissociation during specific future warming scenarios is needed. At present, it appears that these two portions of total gas hydrate resources (those that are the most likely targets for gas extraction and those that are the most likely to respond in a meaningful way to climate change) will be largely exclusive, as those deposits that are the most amenable to production (the more deeply buried and localized accumulations) are also those that are the most poorly coupled to oceanic and atmospheric conditions.																			1754-5692					APR	2011	4	4					1206	1215		10.1039/c0ee00203h	http://dx.doi.org/10.1039/c0ee00203h													WOS:000289001400008
J	Keller, AA; Wang, HT; Zhou, DX; Lenihan, HS; Cherr, G; Cardinale, BJ; Miller, R; Ji, ZX				Keller, Arturo A.; Wang, Hongtao; Zhou, Dongxu; Lenihan, Hunter S.; Cherr, Gary; Cardinale, Bradley J.; Miller, Robert; Ji, Zhaoxia			Stability and Aggregation of Metal Oxide Nanoparticles in Natural Aqueous Matrices	ENVIRONMENTAL SCIENCE & TECHNOLOGY												There is a pressing need for information on the mobility of nanoparticles in the complex aqueous matrices found in realistic environmental conditions. We dispersed three different metal oxide nanoparticles (TiO2, ZnO and CeO2) in samples taken from eight different aqueous media associated with seawater, lagoon, river, and groundwater, and measured their electrophoretic mobility, state of aggregation, and rate of sedimentation. The electrophoretic mobility of the particles in a given aqueous media was dominated by the presence of natural organic matter (NOM) and ionic strength, and independent of pH. NOM adsorbed onto these nanoparticles significantly reduces their aggregation, stabilizing them under many conditions. The transition from reaction to diffusion limited aggregation occurs at an electrophoretic mobility from around -2 to -0.8 mu m s(-1) V-1 cm. These results are key for designing and interpreting nanoparticle ecotoxicity studies in various environmental conditions.					Cardinale, Bradley/I-7076-2013; Keller, Arturo/AAB-4155-2022; Zhou, Dongxu/C-1255-2013; Wang, Hongtao/F-3264-2010; Keller, Arturo/I-9119-2016	Miller, Robert/0000-0002-8350-3759; Wang, Hongtao/0000-0002-8066-475X; Keller, Arturo/0000-0002-7638-662X													0013-936X	1520-5851				MAR 15	2010	44	6					1962	1967		10.1021/es902987d	http://dx.doi.org/10.1021/es902987d								20151631					WOS:000275325600015
J	Dong, L; Han, Z; Petropulu, AP; Poor, HV				Dong, Lun; Han, Zhu; Petropulu, Athina P.; Poor, H. Vincent			Improving Wireless Physical Layer Security via Cooperating Relays	IEEE TRANSACTIONS ON SIGNAL PROCESSING												Physical (PHY) layer security approaches for wireless communications can prevent eavesdropping without upper layer data encryption. However, they are hampered by wireless channel conditions: absent feedback, they are typically feasible only when the source-destination channel is better than the source-eavesdropper channel. Node cooperation is a means to overcome this challenge and improve the performance of secure wireless communications. This paper addresses secure communications of one source-destination pair with the help of multiple cooperating relays in the presence of one or more eavesdroppers. Three cooperative schemes are considered: decode-and-forward (DF), amplify-and-forward (AF), and cooperative jamming (CJ). For these schemes, the relays transmit a weighted version of a reencoded noise-free message signal (for DF), a received noisy source signal (for AF), or a common jamming signal (for CJ). Novel system designs are proposed, consisting of the determination of relay weights and the allocation of transmit power, that maximize the achievable secrecy rate subject to a transmit power constraint, or, minimize the transmit power subject to a secrecy rate constraint. For DF in the presence of one eavesdropper, closed-form optimal solutions are derived for the relay weights. For other problems, since the optimal relay weights are difficult to obtain, several criteria are considered leading to suboptimal but simple solutions, i.e., the complete nulling of the message signals at all eavesdroppers (for DF and AF), or the complete nulling of jamming signal at the destination (for CJ). Based on the designed relay weights, for DF in the presence of multiple eavesdroppers, and for CJ in the presence of one eavesdropper, the optimal power allocation is obtained in closed-form; in all other cases the optimal power allocation is obtained via iterative algorithms. Numerical evaluation of the obtained secrecy rate and transmit power results show that the proposed design can significantly improve the performance of secure wireless communications.					Poor, H./S-5027-2016; Han, Zhu/ABG-1222-2021	Poor, H. Vincent/0000-0002-2062-131X													1053-587X	1941-0476				MAR	2010	58	3	2				1875	1888		10.1109/TSP.2009.2038412	http://dx.doi.org/10.1109/TSP.2009.2038412													WOS:000274395000035
J	Baines, TS; Lightfoot, HW; Evans, S; Neely, A; Greenough, R; Peppard, J; Roy, R; Shehab, E; Braganza, A; Tiwari, A; Alcock, JR; Angus, JP; Bastl, M; Cousens, A; Irving, P; Johnson, M; Kingston, J; Lockett, H; Martinez, V; Michele, P; Tranfield, D; Walton, IM; Wilson, H				Baines, T. S.; Lightfoot, H. W.; Evans, S.; Neely, A.; Greenough, R.; Peppard, J.; Roy, R.; Shehab, E.; Braganza, A.; Tiwari, A.; Alcock, J. R.; Angus, J. P.; Bastl, M.; Cousens, A.; Irving, P.; Johnson, M.; Kingston, J.; Lockett, H.; Martinez, V.; Michele, P.; Tranfield, D.; Walton, I. M.; Wilson, H.			State-of-the-art in product-service systems	PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART B-JOURNAL OF ENGINEERING MANUFACTURE												A Product-Service System (PSS) is an integrated combination of products and services. This Western concept embraces a service-led competitive strategy, environmental sustainability, and the basis to differentiate from competitors who simply offer lower priced products. This paper aims to report the state-of-the-art of PSS research by presenting a clinical review of literature currently available on this topic. The literature is classified and the major outcomes of each study are addressed and analysed. On this basis, this paper defines the PSS concept, reports on its origin and features, gives examples of applications along with potential benefits and barriers to adoption, summarizes available tools and methodologies, and identifies future research challenges.					Alcock, Jeffrey/B-9021-2008; Roy, Rajkumar/AAR-5146-2020; Neely, Andy/JTV-7316-2023; Tiwari, Ashutosh/A-9901-2011; Lockett, Helen/AAK-7432-2020; Micheli, Pietro/O-4851-2019; Roy, Rajkumar/A-4111-2010; Shehab, Essam/A-7804-2011	Roy, Rajkumar/0000-0001-5491-7437; Neely, Andrew David/0000-0001-8220-5242; Greenough, Richard/0000-0002-1626-4321; Baines, Timothy/0000-0002-7518-2967; Tiwari, Ashutosh/0000-0002-6197-1519; Lockett, Helen/0000-0002-1405-6633; Shehab, Essam/0000-0003-3593-6944; Martinez, Veronica/0000-0001-8680-5106; Micheli, Pietro/0000-0001-7920-6500													0954-4054	2041-1975				OCT	2007	221	10					1543	1552		10.1243/09544054JEM858	http://dx.doi.org/10.1243/09544054JEM858													WOS:000250849500007
J	Ning, FD; Cong, WL; Qiu, JJ; Wei, JH; Wang, SR				Ning, Fuda; Cong, Weilong; Qiu, Jingjing; Wei, Junhua; Wang, Shiren			Additive manufacturing of carbon fiber reinforced thermoplastic composites using fused deposition modeling	COMPOSITES PART B-ENGINEERING												Additive manufacturing (AM) technologies have been successfully applied in various applications. Fused deposition modeling (FDM), one of the most popular AM techniques, is the most widely used method for fabricating thermoplastic parts those are mainly used as rapid prototypes for functional testing with advantages of low cost, minimal wastage, and ease of material change. Due to the intrinsically limited mechanical properties of pure thermoplastic materials, there is a critical need to improve mechanical properties for FDM-fabricated pure thermoplastic parts. One of the possible methods is adding reinforced materials (such as carbon fibers) into plastic materials to form thermoplastic matrix carbon fiber reinforced plastic (CFRP) composites those could be directly used in the actual application areas, such as aerospace, automotive, and wind energy. This paper is going to present FDM of thermoplastic matrix CFRP composites and test if adding carbon fiber (different content and length) can improve the mechanical properties of FDM-fabricated parts. The CFRP feedstock filaments were fabricated from plastic pellets and carbon fiber powders for FDM process. After FDM fabrication, effects on the tensile properties (including tensile strength, Young's modulus, toughness, yield strength, and ductility) and flexural properties (including flexural stress, flexural modulus, flexural toughness, and flexural yield strength) of specimens were experimentally investigated. In order to explore the parts fracture reasons during tensile and flexural tests, fracture interface of CFRP composite specimens after tensile testing and flexural testing was observed and analyzed using SEM micrograph. (C) 2015 Elsevier Ltd. All rights reserved.					Wei, Junhua/X-4364-2019; Wang, Shiren/B-4357-2015; Ning, Fuda/AAP-3970-2020; Qiu, Jingjing/E-9248-2015	Cong, Weilong/0000-0001-6308-7383; Wang, Shiren/0000-0003-4516-3025; Ning, Fuda/0000-0003-0123-3490; Qiu, Jingjing/0000-0001-9643-5452													1359-8368	1879-1069				OCT	2015	80						369	378		10.1016/j.compositesb.2015.06.013	http://dx.doi.org/10.1016/j.compositesb.2015.06.013													WOS:000358968800039
J	Ding, ZG; Fan, PZ; Poor, HV				Ding, Zhiguo; Fan, Pingzhi; Poor, H. Vincent			Impact of User Pairing on 5G Nonorthogonal Multiple-Access Downlink Transmissions	IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY												Nonorthogonal multiple access (NOMA) represents a paradigm shift from conventional orthogonal multiple-access (MA) concepts and has been recognized as one of the key enabling technologies for fifth-generation mobile networks. In this paper, the impact of user pairing on the performance of two NOMA systems, i.e., NOMA with fixed power allocation (F-NOMA) and cognitive-radio-inspired NOMA (CR-NOMA), is characterized. For F-NOMA, both analytical and numerical results are provided to demonstrate that F-NOMA can offer a larger sum rate than orthogonal MA, and the performance gain of F-NOMA over conventional MA can be further enlarged by selecting users whose channel conditions are more distinctive. For CR-NOMA, the quality of service (QoS) for users with poorer channel conditions can be guaranteed since the transmit power allocated to other users is constrained following the concept of cognitive radio networks. Because of this constraint, CR-NOMA exhibits a different behavior compared with F-NOMA. For example, for the user with the best channel condition, CR-NOMA prefers to pair it with the user with the second best channel condition, whereas the user with the worst channel condition is preferred by F-NOMA.					Poor, H./S-5027-2016; Ding, Zhiguo/B-9805-2017	Ding, Zhiguo/0000-0001-5280-384X; Poor, H. Vincent/0000-0002-2062-131X													0018-9545	1939-9359				AUG	2016	65	8					6010	6023		10.1109/TVT.2015.2480766	http://dx.doi.org/10.1109/TVT.2015.2480766													WOS:000381446200014
J	Norskov, JK; Bligaard, T; Logadottir, A; Bahn, S; Hansen, LB; Bollinger, M; Bengaard, H; Hammer, B; Sljivancanin, Z; Mavrikakis, M; Xu, Y; Dahl, S; Jacobsen, CJH				Norskov, JK; Bligaard, T; Logadottir, A; Bahn, S; Hansen, LB; Bollinger, M; Bengaard, H; Hammer, B; Sljivancanin, Z; Mavrikakis, M; Xu, Y; Dahl, S; Jacobsen, CJH			Universality in heterogeneous catalysis	JOURNAL OF CATALYSIS												Based on an extensive set of density functional theory calculations it is shown that for a class of catalytic reactions there is a universal, reactant independent relation between the reaction activation energy and the stability of reaction intermediates. This leads directly to a universal relationship between adsorption energies and catalytic activity, which is used to pinpoint what it is that determines the best catalyst for a given reaction. The universality principle rationalizes a number of known facts about catalysts and points to new ways of improving them. (C) 2002 Elsevier Science (USA).					Mavrikakis, Manos/D-5702-2012; Sljivancanin, Zeljko/C-5436-2018; Xu, Ye/B-5447-2009; Dahl, Søren/A-4898-2011; Sljivancanin, Zeljko/JPK-7121-2023; Norskov, Jens/D-2539-2017; Hammer, Bjork/C-3701-2013; Bligaard, Thomas/A-6161-2011; Bligaard, Thomas/A-6161-2011	Sljivancanin, Zeljko/0000-0001-8575-2575; Norskov, Jens/0000-0002-4427-7728; Mavrikakis, Manos/0000-0002-5293-5356; Hammer, Bjork/0000-0002-7849-6347; Xu, Ye/0000-0002-6406-7832; Bligaard, Thomas/0000-0001-9834-9179; Bligaard, Thomas/0000-0003-0386-0201													0021-9517	1090-2694				JUL 25	2002	209	2					275	278		10.1006/jcat.2002.3615	http://dx.doi.org/10.1006/jcat.2002.3615													WOS:000176916300001
J	Wang, ZD; Giannakis, GB				Wang, ZD; Giannakis, GB			A simple and general parameterization quantifying performance in fading channels	IEEE TRANSACTIONS ON COMMUNICATIONS					IEEE Global Telecommunication Conference (GLOBECOM 02)	NOV 17-21, 2002	TAIPEI, TAIWAN	IEEE, ICC GLOBECOM				We quantify the performance of wireless transmissions over random fading channels at high signal-to-noise ratio (SNR). The performance criteria we consider are average probability of error and outage probability. We show that as functions of the average SNR, they can both be characterized by two parameters: the diversity and coding gains. They both exhibit identical diversity orders, but their coding gains in decibels differ by a constant. The diversity and coding gains are found to depend on the behavior of the random SNR's probability density function only at the origin, or equivalently, on the decaying order of the corresponding moment generating function (i.e., how fast the moment generating function goes to zero as its argument goes to infinity). Diversity and coding gains for diversity combining systems are expressed in terms of the diversity branches' individual diversity and coding gains, where the branches can come from any diversity technique such as space, time, frequency, or, multipath. The proposed analysis offers a simple and unifying approach to evaluating the performance of uncoded and (possibly space-time) coded transmissions over fading channels, and the method applies to almost all digital modulation schemes, including M-ary phase-shift keying, quadrature amplitude modulation, and frequency-shift keying with coherent or noncoherent detection.					Giannakis, Georgios/Z-4413-2019; Zhang, zs/GXN-3521-2022	Wang, Zhengdao/0000-0002-2972-6580; Giannakis, Georgios/0000-0002-0196-0260													0090-6778					AUG	2003	51	8					1389	1398		10.1109/TCOMM.2003.815053	http://dx.doi.org/10.1109/TCOMM.2003.815053													WOS:000184789600021
J	Khoshelham, K; Elberink, SO				Khoshelham, Kourosh; Elberink, Sander Oude			Accuracy and Resolution of Kinect Depth Data for Indoor Mapping Applications	SENSORS												Consumer-grade range cameras such as the Kinect sensor have the potential to be used in mapping applications where accuracy requirements are less strict. To realize this potential insight into the geometric quality of the data acquired by the sensor is essential. In this paper we discuss the calibration of the Kinect sensor, and provide an analysis of the accuracy and resolution of its depth data. Based on a mathematical model of depth measurement from disparity a theoretical error analysis is presented, which provides an insight into the factors influencing the accuracy of the data. Experimental results show that the random error of depth measurement increases with increasing distance to the sensor, and ranges from a few millimeters up to about 4 cm at the maximum range of the sensor. The quality of the data is also found to be influenced by the low resolution of the depth measurements.					Khoshelham, Kourosh/H-6079-2019; Oude Elberink, Sander/D-3829-2009; Khoshelham, Kourosh/A-3789-2010	Oude Elberink, Sander/0000-0002-4511-2095; Khoshelham, Kourosh/0000-0001-6639-1727														1424-8220				FEB	2012	12	2					1437	1454		10.3390/s120201437	http://dx.doi.org/10.3390/s120201437								22438718					WOS:000300720300016
J	Rodríguez, J; Pontt, J; Silva, CA; Correa, P; Lezana, P; Cortés, P; Ammann, U				Rodriguez, Jose; Pontt, Jorge; Silva, Cesar A.; Correa, Pablo; Lezana, Pablo; Cortes, Patricio; Ammann, Ulrich			Predictive current control of a voltage source inverter	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS												This paper presents a predictive current control method and its application to a voltage source inverter. The method uses a discrete-time model of the system to predict the future value of the load current for all possible voltage vectors generated by the inverter. The voltage vector which minimizes a quality function is selected. The quality function used in this work evaluates the current error at the next sampling time. The performance of the proposed predictive control method is compared with hysteresis and pulsewidth modulation control. The results show that the predictive method controls very effectively the load current and performs very well compared with the classical solutions.					Silva, Cesar/I-5448-2013; Rodriguez, Jose/A-2534-2013; Lezana, Pablo/E-4605-2015	Silva, Cesar/0000-0002-6269-2917; Rodriguez, Jose/0000-0002-1410-4121; Lezana, Pablo/0000-0001-8787-5536													0278-0046	1557-9948				FEB	2007	54	1					495	503		10.1109/TIE.2006.888802	http://dx.doi.org/10.1109/TIE.2006.888802													WOS:000244334100049
J	Wang, CS; Stielau, OH; Covic, GA				Wang, CS; Stielau, OH; Covic, GA			Design considerations for a contactless electric vehicle battery charger	IEEE TRANSACTIONS ON INDUSTRIAL ELECTRONICS												This paper overviews theoretical and practical design issues related to inductive power transfer systems and verifies the developed theory using a practical electric vehicle battery charger. The design focuses on the necessary approaches to ensure power transfer over the complete operating range of the system. As such, a new approach to the design of the primary resonant circuit is proposed, whereby deviations from design expectations due to phase or frequency shift are minimized. Of particular interest are systems that are neither loosely nor tightly coupled. The developed solution depends on the selected primary and secondary. resonant topologies, the magnetic coupling coefficient, and the secondary quality factor.																			0278-0046	1557-9948				OCT	2005	52	5					1308	1314		10.1109/TIE.2005.855672	http://dx.doi.org/10.1109/TIE.2005.855672													WOS:000232237100013
J	Ye, H; Li, GY; Juang, BH				Ye, Hao; Li, Geoffrey Ye; Juang, Biing-Hwang			Power of Deep Learning for Channel Estimation and Signal Detection in OFDM Systems	IEEE WIRELESS COMMUNICATIONS LETTERS												This letter presents our initial results in deep learning for channel estimation and signal detection in orthogonal frequency-division multiplexing (OFDM) systems. In this letter, we exploit deep learning to handle wireless OFDM channels in an end-to-end manner. Different from existing OFDM receivers that first estimate channel state information (CSI) explicitly and then detect/recover the transmitted symbols using the estimated CSI, the proposed deep learning-based approach estimates CSI implicitly and recovers the transmitted symbols directly. To address channel distortion, a deep learning model is first trained offline using the data generated from simulation based on channel statistics and then used for recovering the online transmitted data directly. From our simulation results, the deep learning based approach can address channel distortion and detect the transmitted symbols with performance comparable to the minimum mean-square error estimator. Furthermore, the deep learning-based approach is more robust than conventional methods when fewer training pilots are used, the cyclic prefix is omitted, and nonlinear clipping noise exists. In summary, deep learning is a promising tool for channel estimation and signal detection in wireless communications with complicated channel distortion and interference.					Li, Geoffrey/ABE-8992-2020														2162-2337	2162-2345				FEB	2018	7	1					114	117		10.1109/LWC.2017.2757490	http://dx.doi.org/10.1109/LWC.2017.2757490													WOS:000425620400029
J	Rappaport, TS; MacCartney, GR ; Samimi, MK; Sun, S				Rappaport, Theodore S.; MacCartney, George R., Jr.; Samimi, Mathew K.; Sun, Shu			Wideband Millimeter-Wave Propagation Measurements and Channel Models for Future Wireless Communication System Design	IEEE TRANSACTIONS ON COMMUNICATIONS												The relatively unused millimeter-wave (mmWave) spectrum offers excellent opportunities to increase mobile capacity due to the enormous amount of available raw bandwidth. This paper presents experimental measurements and empirically-based propagation channel models for the 28, 38, 60, and 73 GHz mmWave bands, using a wideband sliding correlator channel sounder with steerable directional horn antennas at both the transmitter and receiver from 2011 to 2013. More than 15,000 power delay profiles were measured across the mmWave bands to yield directional and omnidirectional path loss models, temporal and spatial channel models, and outage probabilities. Models presented here offer side-by-side comparisons of propagation characteristics over a wide range of mmWave bands, and the results and models are useful for the research and standardization process of future mmWave systems. Directional and omnidirectional path loss models with respect to a 1 m close-in free space reference distance over a wide range of mmWave frequencies and scenarios using directional antennas in real-world environments are provided herein, and are shown to simplify mm Wave path loss models, while allowing researchers to globally compare and standardize path loss parameters for emerging mmWave wireless networks. A new channel impulse response modeling framework, shown to agree with extensive mmWave measurements over several bands, is presented for use in link-layer simulations, using the observed fact that spatial lobes contain multipath energy that arrives at many different propagation time intervals. The results presented here may assist researchers in analyzing and simulating the performance of next-generation mmWave wireless networks that will rely on adaptive antennas and multiple-input and multiple-output (MIMO) antenna systems.					Sun, Shu/AAH-1270-2021	Rappaport, Theodore (Ted)/0000-0001-7449-9957													0090-6778	1558-0857				SEP	2015	63	9					3029	3056		10.1109/TCOMM.2015.2434384	http://dx.doi.org/10.1109/TCOMM.2015.2434384													WOS:000361485200001
J	Love, DJ; Heath, RW; Strohmer, T				Love, DJ; Heath, RW; Strohmer, T			Grassmannian beamforming for multiple-input multiple-output wireless systems	IEEE TRANSACTIONS ON INFORMATION THEORY					IEEE International Conference on Communications (ICC 2003)	MAY 11-15, 2003	ANCHORAGE, AK	IEEE				Transmit beamforming and receive combining are simple methods for exploiting the significant diversity that is available in multiple-input multiple-output (MIMO) wireless systems. Unfortunately, optimal performance requires either complete channel knowledge or knowledge of the optimal beamforming vector; both are hard to realize. In this correspondence, a quantized maximum signal-to-noise ratio (SNR) beamforming technique is proposed where the receiver only sends the label of the best beamforming vector in a predetermined codebook to the transmitter. By using the distribution of the optimal beamforming vector in independent and identically distributed Rayleigh fading matrix channels, the codebook design problem is solved and related to the problem of Grassmannian line packing. The proposed design criterion is flexible enough to allow for side constraints on the codebook vectors. Bounds on the codebook size are derived to guarantee fall diversity order. Results on the density of Grassmannian line packings are derived and used to develop bounds on the codebook size given a capacity or SNR loss. Monte Carlo simulations are presented that compare the probability of error for different quantization strategies.					Love, David/B-6205-2011; Heath, Robert/AAY-4148-2020; Heath, Robert/A-5366-2010	Heath, Robert/0000-0002-4666-5628													0018-9448	1557-9654				OCT	2003	49	10					2735	2747		10.1109/TIT.2003.817466	http://dx.doi.org/10.1109/TIT.2003.817466													WOS:000185861400029
J	Bennett, ND; Croke, BFW; Guariso, G; Guillaume, JHA; Hamilton, SH; Jakeman, AJ; Marsili-Libelli, S; Newham, LTH; Norton, JP; Perrin, C; Pierce, SA; Robson, B; Seppelt, R; Voinov, AA; Fath, BD; Andreassian, V				Bennett, Neil D.; Croke, Barry F. W.; Guariso, Giorgio; Guillaume, Joseph H. A.; Hamilton, Serena H.; Jakeman, Anthony J.; Marsili-Libelli, Stefano; Newham, Lachlan T. H.; Norton, John P.; Perrin, Charles; Pierce, Suzanne A.; Robson, Barbara; Seppelt, Ralf; Voinov, Alexey A.; Fath, Brian D.; Andreassian, Vazken			Characterising performance of environmental models	ENVIRONMENTAL MODELLING & SOFTWARE												In order to use environmental models effectively for management and decision-making, it is vital to establish an appropriate level of confidence in their performance. This paper reviews techniques available across various fields for characterising the performance of environmental models with focus on numerical, graphical and qualitative methods. General classes of direct value comparison, coupling real and modelled values, preserving data patterns, indirect metrics based on parameter values, and data transformations are discussed. In practice environmental modelling requires the use and implementation of workflows that combine several methods, tailored to the model purpose and dependent upon the data and information available. A five-step procedure for performance evaluation of models is suggested, with the key elements including: (i) (re)assessment of the model's aim, scale and scope; (ii) characterisation of the data for calibration and testing; (iii) visual and other analysis to detect under- or non-modelled behaviour and to gain an overview of overall performance; (iv) selection of basic performance criteria; and (v) consideration of more advanced methods to handle problems such as systematic divergence between modelled and observed values. (C) 2012 Elsevier Ltd. All rights reserved.					Croke, Barry/A-2275-2008; Andreassian, Vazken/B-6226-2008; Guariso, Giorgio/H-9274-2019; MARSILI-LIBELLI, STEFANO/N-3182-2019; Voinov, Alexey/F-7397-2010; Hamilton, Serena/JAC-6672-2023; Seppelt, Ralf/E-6056-2010; Guillaume, Joseph/I-6019-2014; Jakeman, Anthony/P-6786-2014; Perrin, Charles/J-2486-2014; Pierce, Suzanne A/M-4563-2013; Robson, Barbara/B-8296-2008	Seppelt, Ralf/0000-0002-2723-7150; Andreassian, Vazken/0000-0001-7124-9303; Hamilton, Serena/0000-0001-7454-6127; Guillaume, Joseph/0000-0001-6854-8708; Voinov, Alexey/0000-0002-2985-4574; Jakeman, Anthony/0000-0001-5282-2215; Perrin, Charles/0000-0001-8552-1881; Pierce, Suzanne A/0000-0002-3050-1987; Robson, Barbara/0000-0002-1811-3527; Guariso, Giorgio/0000-0002-1991-6372; MARSILI LIBELLI, STEFANO/0000-0003-4555-7534; Croke, Barry/0000-0001-9216-1554													1364-8152	1873-6726				FEB	2013	40						1	20		10.1016/j.envsoft.2012.09.011	http://dx.doi.org/10.1016/j.envsoft.2012.09.011													WOS:000314074000001
J	Wu, DP; Negi, R				Wu, DP; Negi, R			Effective capacity: A wireless link model for support of quality of service	IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS												To facilitate the efficient support of quality of service (QoS) in next-generation wireless networks, it is essential to model a wireless channel in terms of connection-level QoS metrics such as data rate, delay, and delay-violation probability. However, the existing wireless channel models, i.e., physical-layer channel models, do not explicitly characterize a wireless channel in terms of these QoS metrics. In this paper, we propose and develop a link-layer channel model termed effective capacity (EC). In this approach, we first model a wireless link by two EC functions, namely, the probability of nonempty buffer, and the Qos exponent of a connection. Then, we propose a simple and efficient algorithm to estimate these EC functions. The physical-layer analogs of these two link-layer EC functions are the marginal distribution (e.g., Rayleigh-Ricean distribution) and the Doppler spectrum, respectively. The key advantages of the EC link-layer modeling and estimation are: 1) ease of translation into QoS guarantees, such as delay bounds; 2) simplicity of implementation; and 3) accuracy, and hence, efficiency in admission control and resource reservation. We illustrate the advantage of our approach with a set of simulation experiments, which show that the actual QoS metric is closely approximated by the QoS metric predicted by the EC link-layer model, under a wide range of conditions.						Wu, Dapeng/0000-0003-1755-0183													1536-1276					JUL	2003	2	4					630	643		10.1109/TWC.2003.814353	http://dx.doi.org/10.1109/TWC.2003.814353													WOS:000184215300006
J	Xu, AW; Gao, Y; Liu, HQ				Xu, AW; Gao, Y; Liu, HQ			The preparation, characterization, and their photocatalytic activities of rare-earth-doped TiO<sub>2</sub> nanoparticles	JOURNAL OF CATALYSIS												RE/TiO2 photocatalysts were prepared by the sol-gel method using rare earth (RE = La3+, Ce3+, Er3+, Pr3+, Gd3+, Nd3+, Sm3+) metal salts and tetra-n-butyl titanate as precursors, and were characterized by XRD, IR, UV-vis diffuse reflection, and transient absorption spectra. Their photocatalytic activities were evaluated using nitrite as a decomposition objective. As a result, suitable content of doping rare earth in TiO2 can efficiently extend the light absorption properties to the visible region. At the same time, it is beneficial to NO2- adsorption over the catalysts due to rare earth doping. RE/TiO2 samples can enhance the photocatalytic activity to some extent as compared with naked TiO2. The increase in photoactivity is probably due to the higher adsorption, red shifts to a longer wavelength, and the increase in the interfacial electron transfer rate. Nitrite is almost completely degraded over RE/TiO2 catalysts after longer irradiation, which is different from Degussa P-25 with a plateau of activity after ca. 20 min irradiation. Gd3+-doped TiO2 showed the highest reaction activity among all concerned RE-doped samples because of its specific characteristics. The amount of RE doping was an important factor affecting photocatalytic activity; the optimum amount of RE doping is ca. 0.5 wt%, at which each RE/TiO2 sample shows the most reactivity. The photocatalytic degradation reaction of nitrite over Gd3+-doped samples and P-25 follows apparent first order kinetics, which is different from that of Sm3+, Ce3+, Er3+, Pr3+, La3+, and Nd3+-doped TiO2 catalysts, which obey zero-order kinetics, indicating that these processes were dominated by electron-hole recombination. (C) 2002 Elsevier Science (USA).																			0021-9517					APR 25	2002	207	2					151	157		10.1006/jcat.2002.3539	http://dx.doi.org/10.1006/jcat.2002.3539													WOS:000175354900001
J	Strathmann, H				Strathmann, H.			Electrodialysis, a mature technology with a multitude of new applications	DESALINATION												Electrodialysis is a mature process which is applied since more than 50 years on a large industrial scale for the production of potable water from brackish water sources But more recently electrodialysis in combination with bipolar membranes or with ion-exchange resins has found a large number of new interesting applications in the chemical process industry in the food and drug industry as well as in waste water treatment and the production of high quality industrial water In this paper the principle of electrodialysis is described and its advantages and limitations in various applications are pointed out More recent developments in electrodialysis as well as in related processes such as electrodialytic water dissociation or continuous electrodeionization are discussed and their present and potential future applications are indicated Research needs for a sustainable growth of electrodialysis and related processes are pointed out (C) 2010 Elsevier B V All rights reserved																			0011-9164	1873-4464				DEC 31	2010	264	3			SI		268	288		10.1016/j.desal.2010.04.069	http://dx.doi.org/10.1016/j.desal.2010.04.069													WOS:000285497900014
J	Zmood, DN; Holmes, DG				Zmood, DN; Holmes, DG			Stationary frame current regulation of PWM inverters with zero steady-state error	IEEE TRANSACTIONS ON POWER ELECTRONICS												Current regulators. for ac inverters are commonly categorized as hysteresis, linear PI, or deadbeat predictive regulators, with a further sub-classification into stationary ABC frame and synchronous d-q frame implementations. Synchronous frame regulators are generally accepted to have a better performance, than stationary frame regulators, as they operate on dc quantities and hence can eliminate steady-state errors. This paper establishes a theoretical connection between these two classes of regulators and proposes a new type of stationary frame regulator, the P+Resonant regulator, which achieves the same transient and steady-state performance as a synchronous frame PI regulator. The new regulator is applicable to both single-phase and three phase inverters.																			0885-8993					MAY	2003	18	3					814	822		10.1109/TPEL.2003.810852	http://dx.doi.org/10.1109/TPEL.2003.810852													WOS:000182840700012
J	Lampert, CH; Nickisch, H; Harmeling, S				Lampert, Christoph H.; Nickisch, Hannes; Harmeling, Stefan			Attribute-Based Classification for Zero-Shot Visual Object Categorization	IEEE TRANSACTIONS ON PATTERN ANALYSIS AND MACHINE INTELLIGENCE												We study the problem of object recognition for categories for which we have no training examples, a task also called zero-data or zero-shot learning. This situation has hardly been studied in computer vision research, even though it occurs frequently; the world contains tens of thousands of different object classes, and image collections have been formed and suitably annotated for only a few of them. To tackle the problem, we introduce attribute-based classification: Objects are identified based on a high-level description that is phrased in terms of semantic attributes, such as the object's color or shape. Because the identification of each such property transcends the specific learning task at hand, the attribute classifiers can be prelearned independently, for example, from existing image data sets unrelated to the current task. Afterward, new classes can be detected based on their attribute representation, without the need for a new training phase. In this paper, we also introduce a new data set, Animals with Attributes, of over 30,000 images of 50 animal classes, annotated with 85 semantic attributes. Extensive experiments on this and two more data sets show that attribute-based classification indeed is able to categorize images without access to any training images of the target classes.					Lampert, Christoph H./J-2931-2014; Nickisch, Hannes/I-7049-2017	Lampert, Christoph H./0000-0001-8622-7887; Nickisch, Hannes/0000-0003-1604-6647													0162-8828	1939-3539				MAR	2014	36	3					453	465		10.1109/TPAMI.2013.140	http://dx.doi.org/10.1109/TPAMI.2013.140								24457503					WOS:000331450100005
J	Pinaud, BA; Benck, JD; Seitz, LC; Forman, AJ; Chen, ZB; Deutsch, TG; James, BD; Baum, KN; Baum, GN; Ardo, S; Wang, HL; Miller, E; Jaramillo, TF				Pinaud, Blaise A.; Benck, Jesse D.; Seitz, Linsey C.; Forman, Arnold J.; Chen, Zhebo; Deutsch, Todd G.; James, Brian D.; Baum, Kevin N.; Baum, George N.; Ardo, Shane; Wang, Heli; Miller, Eric; Jaramillo, Thomas F.			Technical and economic feasibility of centralized facilities for solar hydrogen production <i>via</i> photocatalysis and photoelectrochemistry	ENERGY & ENVIRONMENTAL SCIENCE												Photoelectrochemical water splitting is a promising route for the renewable production of hydrogen fuel. This work presents the results of a technical and economic feasibility analysis conducted for four hypothetical, centralized, large-scale hydrogen production plants based on this technology. The four reactor types considered were a single bed particle suspension system, a dual bed particle suspension system, a fixed panel array, and a tracking concentrator array. The current performance of semiconductor absorbers and electrocatalysts were considered to compute reasonable solar-to-hydrogen conversion efficiencies for each of the four systems. The U.S. Department of Energy H2A model was employed to calculate the levelized cost of hydrogen output at the plant gate at 300 psi for a 10 tonne per day production scale. All capital expenditures and operating costs for the reactors and auxiliaries (compressors, control systems, etc.) were considered. The final cost varied from $1.60-$10.40 per kg H-2 with the particle bed systems having lower costs than the panel-based systems. However, safety concerns due to the cogeneration of O-2 and H-2 in a single bed system and long molecular transport lengths in the dual bed system lead to greater uncertainty in their operation. A sensitivity analysis revealed that improvement in the solar-to-hydrogen efficiency of the panel-based systems could substantially drive down their costs. A key finding is that the production costs are consistent with the Department of Energy's targeted threshold cost of $2.00-$4.00 per kg H-2 for dispensed hydrogen, demonstrating that photoelectrochemical water splitting could be a viable route for hydrogen production in the future if material performance targets can be met.					Seitz, Linsey/Y-4345-2019; Deutsch, Todd/AAV-7603-2020; Pinaud, Blaise/D-2241-2012; Chen, Zhebo/E-5771-2011; James, Brian/M-8747-2018; Jaramillo, Thomas/C-4174-2014	Chen, Zhebo/0000-0002-8448-4211; Seitz, Linsey/0000-0001-6831-6747; James, Brian/0000-0003-4728-0380; Jaramillo, Thomas/0000-0001-9900-0622; Deutsch, Todd/0000-0001-6577-1226													1754-5692	1754-5706				JUL	2013	6	7					1983	2002		10.1039/c3ee40831k	http://dx.doi.org/10.1039/c3ee40831k													WOS:000320779700001
J	Duarte, M; Dick, C; Sabharwal, A				Duarte, Melissa; Dick, Chris; Sabharwal, Ashutosh			Experiment-Driven Characterization of Full-Duplex Wireless Systems	IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS												We present an experiment-based characterization of passive suppression and active self-interference cancellation mechanisms in full-duplex wireless communication systems. In particular, we consider passive suppression due to antenna separation at the same node, and active cancellation in analog and/or digital domain. First, we show that the average amount of cancellation increases for active cancellation techniques as the received self-interference power increases. Our characterization of the average cancellation as a function of the self-interference power allows us to show that for a constant signal-to-interference ratio at the receiver antenna (before any active cancellation is applied), the rate of a full-duplex link increases as the self-interference power increases. Second, we show that applying digital cancellation after analog cancellation can sometimes increase the self-interference, and thus digital cancellation is more effective when applied selectively based on measured suppression values. Third, we complete our study of the impact of self-interference cancellation mechanisms by characterizing the probability distribution of the self-interference channel before and after cancellation.						Sabharwal, Ashutosh/0000-0003-1898-5787													1536-1276	1558-2248				DEC	2012	11	12					4296	4307		10.1109/TWC.2012.102612.111278	http://dx.doi.org/10.1109/TWC.2012.102612.111278													WOS:000312836900009
J	Mayne, DQ; Seron, MM; Rakovic, SV				Mayne, DQ; Seron, MM; Rakovic, SV			Robust model predictive control of constrained linear systems with bounded disturbances	AUTOMATICA												This paper provides a novel solution to the problem of robust model predictive control of constrained, linear, discrete-time systems in the presence of bounded disturbances. The optimal control problem that is solved online includes, uniquely, the initial state of the model employed in the problem as a decision variable. The associated value function is zero in a disturbance invariant set that serves as the 'origin' when bounded disturbances are present, and permits a strong stability result, namely robust exponential stability of the disturbance invariant set for the controlled system with bounded disturbances, to be obtained. The resultant online algorithm is a quadratic program of similar complexity to that required in conventional model predictive control. (C) 2004 Elsevier Ltd. All rights reserved.					SERON, MARIA/G-7312-2013	SERON, MARIA/0000-0003-2709-6607													0005-1098	1873-2836				FEB	2005	41	2					219	224		10.1016/j.automatica.2004.08.019	http://dx.doi.org/10.1016/j.automatica.2004.08.019													WOS:000226460100004
J	Gustafsson, F; Gunnarsson, F; Bergman, N; Forssell, U; Jansson, J; Karlsson, R; Nordlund, PJ				Gustafsson, F; Gunnarsson, F; Bergman, N; Forssell, U; Jansson, J; Karlsson, R; Nordlund, PJ			Particle filters for positioning, navigation, and tracking	IEEE TRANSACTIONS ON SIGNAL PROCESSING												A framework for positioning, navigation, and tracking problems using particle filters (sequential Monte Carlo methods) is developed. It consists of a class of motion models and a general nonlinear measurement equation in position. A general algorithm is presented, which is parsimonious with the particle dimension. It is based on marginalization, enabling a Kalman filter to estimate all position derivatives, and the particle filter becomes low dimensional. This is of utmost importance for high-performance real-time applications. Automotive and airborne applications illustrate numerically the advantage over classical Kalman filter-based algorithms. Here, the use of nonlinear models and non-Gaussian noise is the main explanation for the improvement in accuracy. More specifically, we describe how the technique of map matching is used to match an aircraft's elevation profile to a digital elevation map and a car's horizontal driven path to a street map. In both cases, real-time implementations are available, and tests have shown that the accuracy in both cases is comparable with satellite navigation (as GPS) but with higher integrity. Based on simulations, we also argue how the particle filter can be used for positioning based on cellular phone measurements, for integrated navigation in aircraft, and for target tracking in aircraft and cars. Finally, the particle filter enables a promising solution to the combined task of navigation and tracking, with possible application to airborne hunting and collision avoidance systems in cars.					Gunnarsson, Fredrik/B-8728-2012; Jansson, Jonas/F-4855-2019	Gunnarsson, Fredrik/0000-0001-6387-3472; Jansson, Jonas/0000-0002-0822-5701													1053-587X					FEB	2002	50	2					425	437		10.1109/78.978396	http://dx.doi.org/10.1109/78.978396													WOS:000173412600024
J	Kuo, CK; Ma, PX				Kuo, CK; Ma, PX			Ionically crosslinked alginate hydrogels as scaffolds for tissue engineering: Part 1. Structure, gelation rate and mechanical properties	BIOMATERIALS												Alginate gels have been used in both drug delivery and cell encapsulation applications in the bead form usually produced by dripping alginate solution into a CaCl2 bath. The major disadvantages to these systems are that the gelation rate is hard to control, the resulting structure is not uniform, and mechanically strong and complex-shaped 3-D structures are difficult to achieve. In this work controlled gelation rate was achieved with CaCO3-GDL and CaSO4-CaCO3-GDL systems, and homogeneous alginate gels were formulated as scaffolds with defined dimensions for tissue engineering applications. Gelation rate increased with increasing total calcium content, increasing proportion of CaSO4, increasing temperature and decreasing alginate concentration. Mechanical properties of the alginate gels were controlled by the compositional variables. Slower gelation systems generate more uniform and mechanically stronger gels than faster gelation systems. The compressive modulus and strength increased with alginate concentration, total calcium content, molecular weight and guluronic acid (G) content of the alginate. MC3T3-E1 osteoblastic cells were uniformly incorporated in the alginate gels and cultured in vitro. These results demonstrated how alginate gel and gel/cell systems could be Formulated with controlled structure. gelation rate, and mechanical properties for tissue engineering and other biomedical applications. (C) 2001 Elsevier Science Ltd. All rights reserved.					X, Peter/E-4895-2011														0142-9612	1878-5905				MAR	2001	22	6					511	521		10.1016/S0142-9612(00)00201-5	http://dx.doi.org/10.1016/S0142-9612(00)00201-5								11219714					WOS:000166842000001
J	Christ, A; Kainz, W; Hahn, EG; Honegger, K; Zefferer, M; Neufeld, E; Rascher, W; Janka, R; Bautz, W; Chen, J; Kiefer, B; Schmitt, P; Hollenbach, HP; Shen, JX; Oberle, M; Szczerba, D; Kam, A; Guag, JW; Kuster, N				Christ, Andreas; Kainz, Wolfgang; Hahn, Eckhart G.; Honegger, Katharina; Zefferer, Marcel; Neufeld, Esra; Rascher, Wolfgang; Janka, Rolf; Bautz, Werner; Chen, Ji; Kiefer, Berthold; Schmitt, Peter; Hollenbach, Hans-Peter; Shen, Jianxiang; Oberle, Michael; Szczerba, Dominik; Kam, Anthony; Guag, Joshua W.; Kuster, Niels			The Virtual Family-development of surface-based anatomical models of two adults and two children for dosimetric simulations	PHYSICS IN MEDICINE AND BIOLOGY												The objective of this study was to develop anatomically correct whole body human models of an adult male (34 years old), an adult female (26 years old) and two children (an 11-year-old girl and a six-year-old boy) for the optimized evaluation of electromagnetic exposure. These four models are referred to as the Virtual Family. They are based on high resolution magnetic resonance (MR) images of healthy volunteers. More than 80 different tissue types were distinguished during the segmentation. To improve the accuracy and the effectiveness of the segmentation, a novel semi-automated tool was used to analyze and segment the data. All tissues and organs were reconstructed as three-dimensional (3D) unstructured triangulated surface objects, yielding high precision images of individual features of the body. This greatly enhances the meshing flexibility and the accuracy with respect to thin tissue layers and small organs in comparison with the traditional voxel-based representation of anatomical models. Conformal computational techniques were also applied. The techniques and tools developed in this study can be used to more effectively develop future models and further improve the accuracy of the models for various applications. For research purposes, the four models are provided for free to the scientific community.					Kuster, Niels/B-9706-2008; shen, chengshuo/GXA-1891-2022; Neufeld, Ellis/F-9331-2011; Kam, Anthony/JJF-1316-2023	Neufeld, Esra/0000-0001-5528-6147; Janka, Rolf/0000-0003-1698-9741; Kuster, Niels/0000-0002-5827-3728													0031-9155	1361-6560				JAN 21	2010	55	2					N23	N38		10.1088/0031-9155/55/2/N01	http://dx.doi.org/10.1088/0031-9155/55/2/N01								20019402					WOS:000272960400015
J	Martínez, JP; Almeida, R; Olmos, S; Rocha, AP; Laguna, P				Martínez, JP; Almeida, R; Olmos, S; Rocha, AP; Laguna, P			A wavelet-based ECG delineator:: Evaluation on standard databases	IEEE TRANSACTIONS ON BIOMEDICAL ENGINEERING												In this paper, we developed and evaluated a robust single-lead electrocardiogram (ECG) delineation system based on the wavelet transform (WT). In a first step, QRS complexes are detected. Then, each QRS is delineated by detecting and identifying the peaks of the individual waves, as well as the complex onset and end. Finally, the determination of P and T wave peaks, onsets and ends is performed. We evaluated the algorithm on several manually annotated databases, such as MIT-BIH Arrhythmia, QT, European ST-T and CSE databases, developed for validation purposes. The QRS detector obtained a sensitivity of Se = 99.66% and a positive predictivity of P+ = 99.56% over the first lead of the validation databases (more than 980,000 beats), while for the well-known MIT-BIH Arrhythmia Database, Se and P+ over 99.8% were attained. As for the delineation of the ECG waves, the mean and standard deviation of the differences between the automatic and manual annotations were computed. The mean error obtained with the WT approach was found not to exceed one sampling interval, while,the standard deviations were around the accepted tolerances between expert physicians, outperforming the results of other well known algorithms, especially in determining the end of T wave.					Olmos, Salvador/B-6935-2015; Rocha, Ana Paula/D-2813-2012; Martinez, Juan Pablo/A-2759-2009; Almeida, Rute/Q-1621-2019; laguna, Pablo/I-6669-2013	Rocha, Ana Paula/0000-0003-3218-7001; Olmos Gasso, Salvador/0000-0002-1869-7227; Martinez, Juan Pablo/0000-0002-7503-3339; Almeida, Rute/0000-0001-7755-5002; laguna, Pablo/0000-0003-3434-9254													0018-9294	1558-2531				APR	2004	51	4					570	581		10.1109/TBME.2003.821031	http://dx.doi.org/10.1109/TBME.2003.821031								15072211					WOS:000220357100002
J	Schubert, MM; Hackenberg, S; van Veen, AC; Muhler, M; Plzak, V; Behm, RJ				Schubert, MM; Hackenberg, S; van Veen, AC; Muhler, M; Plzak, V; Behm, RJ			CO oxidation over supported gold catalysts-"inert" and "active" support materials and their role for the oxygen supply during reaction	JOURNAL OF CATALYSIS												A thorough comparison of gold catalysts on different support materials as well as activity measurements for Au on mixed oxides (Au/Fe2O3. MgO) reveal enhanced CO oxidation rates for a group of "active" support materials (Fe2O3, TiO2, NiOx, CoOx), For Au/Fe2O3, it is shown that large amounts of oxygen can adsorb on the support, which most likely represents the oxygen supply during reaction. The high mobility of these oxygen species and the absence of oxygen scrambling with labeled O-36(2) in pulse experiments strongly suggest the adsorption in a molecular form on the iron oxide support. From the absence of the doubly marked product (COO)-O-18-O-18, reaction schemes via a carbonate-like intermediate or transition-state can be ruled out. For Au catalysts supported on active materials, the dominant reaction pathway is concluded to involve adsorption of a mobile, molecular oxygen species on the support, dissociation at the interface, and reaction on the gold particles and/or at the interface with CO adsorbed on the gold. The facile supply with reactive oxygen, via the support, serves as a probable explanation for the observed independence of the turnover frequency from the Au particle size on these catalysts, while for Au supported on inert materials, where the oxygen supply most likely proceeds via direct dissociative adsorption on the Au particles, the size of the latter plays a decisive role. (C) 2001 Academic Press.					Behm, Rolf Jürgen/D-9276-2019; Muhler, Martin/D-2766-2017	Muhler, Martin/0000-0001-5343-6922; van Veen, Andre/0000-0003-2627-7713													0021-9517					JAN 1	2001	197	1					113	122		10.1006/jcat.2000.3069	http://dx.doi.org/10.1006/jcat.2000.3069													WOS:000166505500013
J	Li, BY; Ren, WQ; Fu, DP; Tao, DC; Feng, D; Zeng, WJ; Wang, ZY				Li, Boyi; Ren, Wenqi; Fu, Dengpan; Tao, Dacheng; Feng, Dan; Zeng, Wenjun; Wang, Zhangyang			Benchmarking Single-Image Dehazing and Beyond	IEEE TRANSACTIONS ON IMAGE PROCESSING												We present a comprehensive study and evaluation of existing single-image dehazing algorithms, using a new large-scale benchmark consisting of both synthetic and real-world hazy images, called REalistic Single-Image DEhazing (RESIDE). RESIDE highlights diverse data sources and image contents, and is divided into five subsets, each serving different training or evaluation purposes. We further provide a rich variety of criteria for dehazing algorithm evaluation, ranging from full-reference metrics to no-reference metrics and to subjective evaluation, and the novel task-driven evaluation. Experiments on RESIDE shed light on the comparisons and limitations of the state-of-the-art dehazing algorithms, and suggest promising future directions.					Ren, Wenqi/L-8724-2019; wang, ziwei/HQY-9921-2023; Zeng, wenjun/ABE-9737-2021; Tao, Dacheng/A-5449-2012	Zeng, Wenjun/0000-0003-2531-3137; Wang, Zhangyang/0000-0002-2050-5693													1057-7149	1941-0042				JAN	2019	28	1					492	505		10.1109/TIP.2018.2867951	http://dx.doi.org/10.1109/TIP.2018.2867951								30176593					WOS:000446131000009
J	Kleindorfer, PR; Singhal, K; Van Wassenhove, LN				Kleindorfer, PR; Singhal, K; Van Wassenhove, LN			Sustainable operations management	PRODUCTION AND OPERATIONS MANAGEMENT												Operations management researchers and practitioners face new challenges in integrating issues of sustainability with their traditional areas of interest. During the past 20 years, there has been growing pressure on businesses to pay more attention to the environmental and resource consequences of the products and services they offer and the processes they deploy. One symptom of this pressure is the movement towards triple bottom line reporting (3BL) concerning the relationship of profit, people, and the planet. The resulting challenges include integrating environmental, health, and safety concerns with green-product design, lean and green operations, and closed-loop supply chains. We review these and other "sustainability" themes covered in the first 50 issues of Production and Operations Management and conclude with some thoughts on future research challenges in sustainable operations management.																			1059-1478	1937-5956				WIN	2005	14	4					482	492																WOS:000236419500009
J	Hof, AL; Gazendam, MGJ; Sinke, WE				Hof, AL; Gazendam, MGJ; Sinke, WE			The condition for dynamic stability	JOURNAL OF BIOMECHANICS												The well-known condition for standing stability in static situations is that the vertical projection of the centre of mass (CoM) should be within the base of support (BoS). On the basis of a simple inverted pendulum model, an extension of this rule is proposed for dynamical situations: the position of (the vertical projection of) the CoM plus its velocity times a factor rootl/g should be within the BoS, l being leg length and g the acceleration of gravity. It is proposed to name this vector quantity 'extrapolated centre of mass position' (XcoM). The definition suggests as a measure of stability the 'margin of stability' b, the minimum distance from XcoM to the boundaries of the BoS. An alternative measure is the temporal stability margin tau, the time in which the boundary of the BoS would be reached without intervention. Some experimental data of subjects standing on one or two feet, flatfoot and tiptoe, are presented to give an idea of the usual ranges of these margins of stability. Example data on walking are also presented. (C) 2004 Elsevier Ltd. All rights reserved.						Hof, At/0000-0003-4054-0442													0021-9290	1873-2380				JAN	2005	38	1					1	8		10.1016/j.jbiomech.2004.03.025	http://dx.doi.org/10.1016/j.jbiomech.2004.03.025								15519333					WOS:000225198500001
J	Goovaerts, P				Goovaerts, P			Geostatistical approaches for incorporating elevation into the spatial interpolation of rainfall	JOURNAL OF HYDROLOGY												This paper presents three multivariate geostatistical algorithms for incorporating a digital elevation model into the spatial prediction of rainfall: simple kriging with varying local means; kriging with an external drift; and colocated cokriging. The techniques are illustrated using annual and monthly rainfall observations measured at 36 climatic stations in a 5000 km(2) region of Portugal. Cross validation is used to compare the prediction performances of the three geostatistical interpolation algorithms with the straightforward linear regression of rainfall against elevation and three univariate techniques: the Thiessen polygon, inverse square distance; and ordinary kriging. Larger prediction errors are obtained for the two algorithms (inverse square distance, Thiessen polygon) that ignore both the elevation and rainfall records at surrounding stations. The three multivariate geostatistical algorithms outperform other interpolators, in particular the linear regression, which stresses the importance of accounting for spatially dependent rainfall observations in addition to the colocated elevation. Last, ordinary kriging yields more accurate predictions than linear regression when the correlation between rainfall and elevation is moderate (less than 0.75 in the case study). (C) 2000 Elsevier Science B.V. All rights reserved.																			0022-1694					FEB 21	2000	228	1-2					113	129		10.1016/S0022-1694(00)00144-X	http://dx.doi.org/10.1016/S0022-1694(00)00144-X													WOS:000085996300010
J	Cheng, MY; Prayogo, D				Cheng, Min-Yuan; Prayogo, Doddy			Symbiotic Organisms Search: A new metaheuristic optimization algorithm	COMPUTERS & STRUCTURES												This paper applies a new robust and powerful metaheuristic algorithm called Symbiotic Organisms Search (SOS) to numerical optimization and engineering design problems. SOS simulates the symbiotic interaction strategies adopted by organisms to survive and propagate in the ecosystem. Twenty-six unconstrained mathematical problems and four structural engineering design problems are tested and obtained results compared with other well-known optimization methods. Obtained results confirm the excellent performance of the SOS method in solving various complex numerical problems. (C) 2014 Elsevier Ltd. All rights reserved.					Prayogo, Doddy/J-1922-2019; Cheng, Min-Yuan/G-3510-2013	Cheng, Min-Yuan/0000-0003-1312-4822; Prayogo, Doddy/0000-0001-5319-3625													0045-7949	1879-2243				JUL 15	2014	139						98	112		10.1016/j.compstruc.2014.03.007	http://dx.doi.org/10.1016/j.compstruc.2014.03.007													WOS:000337555800009
J	Cui, SG; Goldsmith, AJ; Bahai, A				Cui, SG; Goldsmith, AJ; Bahai, A			Energy-efficiency of MIMO and cooperative MIMO techniques in sensor networks	IEEE JOURNAL ON SELECTED AREAS IN COMMUNICATIONS												We consider radio applications in sensor networks, where the nodes operate on batteries so that energy consumption must be minimized, while satisfying given throughput and delay requirements. In this context, we analyze the best modulation and transmission strategy to minimize the total energy consumption required to send a given number of bits. The total energy consumption includes both the transmission energy and the circuit energy consumption. We first consider multi-input-multi-output (MIMO) systems based on Alamouti diversity schemes, which have good spectral efficiency but also more circuitry that consumes energy. We then extend our energy-efficiency analysis Of MIMO systems to individual single-antenna nodes that cooperate to form multiple-antenna transmitters or receivers. By transmitting and/or receiving information jointly, we show that tremendous energy saving is possible for transmission distances larger than a given threshold, even When we take into account the local energy cost necessary for joint information transmission and reception. We also show that over some distance ranges, cooperative MIMO transmission and reception can simultaneously achieve both energy savings and delay reduction.					Cui, Shuguang/D-4677-2014; Goldsmith, Andrea/F-8335-2010	Goldsmith, Andrea/0000-0001-5686-800X													0733-8716	1558-0008				AUG	2004	22	6					1089	1098		10.1109/JSAC.2004.830916	http://dx.doi.org/10.1109/JSAC.2004.830916													WOS:000223150700014
J	Liao, YX; Deschamps, F; Loures, EDR; Ramos, LFP				Liao, Yongxin; Deschamps, Fernando; Rocha Loures, Eduardo de Freitas; Pierin Ramos, Luiz Felipe			Past, present and future of Industry 4.0-a systematic literature review and research agenda proposal	INTERNATIONAL JOURNAL OF PRODUCTION RESEARCH												Over the last few years, the fourth industrial revolution has attracted more and more attentions all around the world. In the current literature, there is still a lack of efforts to systematically review the state of the art of this new industrial revolution wave. The aim of this study is to address this gap by investigating the academic progresses in Industry 4.0. A systematic literature review was carried out to analyse the academic articles within the Industry 4.0 topic that were published online until the end of June 2016. In this paper, the obtained results from both the general data analysis of included papers (e.g. relevant journals, their subject areas and categories, conferences, keywords) and the specific data analysis corresponding to four research sub-questions are illustrated and discussed. These results not only summarise the current research activities (e.g. main research directions, applied standards, employed software and hardware), but also indicate existing deficiencies and potential research directions through proposing a research agenda. Findings of this review can be used as the basis for future research in Industry 4.0 and related topics.					Deschamps, Fernando/R-2558-2018	Deschamps, Fernando/0000-0002-5269-3721; liao, Yongxin/0000-0001-5379-1481													0020-7543	1366-588X					2017	55	12					3609	3629		10.1080/00207543.2017.1308576	http://dx.doi.org/10.1080/00207543.2017.1308576													WOS:000400005900017
J	Spencer, BF; Nagarajaiah, S				Spencer, BF; Nagarajaiah, S			State of the art of structural control	JOURNAL OF STRUCTURAL ENGINEERING																	Spencer, Billie/G-8439-2013; Nagarajaiah, Satish/E-6291-2012	Nagarajaiah, Satish/0000-0003-0088-1656													0733-9445	1943-541X				JUL	2003	129	7					845	856		10.1061/(ASCE)0733-9445(2003)129:7(845)	http://dx.doi.org/10.1061/(ASCE)0733-9445(2003)129:7(845)													WOS:000183672300001
J	Vorobyov, SA; Gershman, AB; Luo, ZQ				Vorobyov, SA; Gershman, AB; Luo, ZQ			Robust adaptive beamforming using worst-case performance optimization: A solution to the signal mismatch problem	IEEE TRANSACTIONS ON SIGNAL PROCESSING												Adaptive beamforming methods are known to degrade if some of underlying assumptions on the environment, sources, or sensor array become violated. In particular, if the desired signal is present in training snapshots, the adaptive array performance may be quite sensitive even to slight mismatches between the presumed and actual signal steering vectors (spatial signatures). Such mismatches can occur as a result of environmental nonstationarities, look direction errors, imperfect array calibration, distorted antenna shape, as well as distortions caused by medium inhomogeneities, near-far mismatch, source spreading, and local scattering. The similar type of performance degradation can occur when the signal steering vector is known exactly but the training sample size is small. In this paper, we develop a new approach to robust adaptive beamforming in the presence of an arbitrary unknown signal steering vector mismatch. Our approach is based oil the optimization of worst-case performance. It turns out that the natural formulation of this adaptive beamforming problem involves minimization of a quadratic function subject to infinitely many nonconvex quadratic constraints. We show that this (originally intractable) problem can be reformulated in a convex form as the so-called second-order cone (SOC) program and solved efficiently (in polynomial time) using the well-established interior point method. It is also shown that the proposed technique can be interpreted in terms of diagonal loading where the optimal value of the diagonal loading factor is computed based on the known level of uncertainty of the signal steering vector. Computer simulations with several frequently encountered types of signal steering vector mismatches show better performance of our robust beamformer as compared with existing adaptive beamforming algorithms.					Vorobyov, Sergiy/G-2478-2013	Vorob'ev, Sergei/0000-0003-2547-9663													1053-587X	1941-0476				FEB	2003	51	2					313	324		10.1109/TSP.2002.806865	http://dx.doi.org/10.1109/TSP.2002.806865													WOS:000181323700002
J	Di Renzo, M; Haas, H; Ghrayeb, A; Sugiura, S; Hanzo, L				Di Renzo, Marco; Haas, Harald; Ghrayeb, Ali; Sugiura, Shinya; Hanzo, Lajos			Spatial Modulation for Generalized MIMO: Challenges, Opportunities, and Implementation	PROCEEDINGS OF THE IEEE												A key challenge of future mobile communication research is to strike an attractive compromise between wireless network's area spectral efficiency and energy efficiency. This necessitates a clean-slate approach to wireless system design, embracing the rich body of existing knowledge, especially on multiple-input-multiple-ouput (MIMO) technologies. This motivates the proposal of an emerging wireless communications concept conceived for single-radio-frequency (RF) large-scale MIMO communications, which is termed as SM. The concept of SM has established itself as a beneficial transmission paradigm, subsuming numerous members of the MIMO system family. The research of SM has reached sufficient maturity to motivate its comparison to state-of-the-art MIMO communications, as well as to inspire its application to other emerging wireless systems such as relay-aided, cooperative, small-cell, optical wireless, and power-efficient communications. Furthermore, it has received sufficient research attention to be implemented in testbeds, and it holds the promise of stimulating further vigorous interdisciplinary research in the years to come. This tutorial paper is intended to offer a comprehensive state-of-the-art survey on SM-MIMO research, to provide a critical appraisal of its potential advantages, and to promote the discussion of its beneficial application areas and their research challenges leading to the analysis of the technological issues associated with the implementation of SM-MIMO. The paper is concluded with the description of the world's first experimental activities in this vibrant research field.					Haas, Harald/AAD-1660-2019; Sugiura, Shinya/A-5358-2013	Haas, Harald/0000-0001-9705-2701; Sugiura, Shinya/0000-0001-7736-8696; Hanzo, Lajos/0000-0002-2636-5214; Ghrayeb, Ali/0000-0002-6808-5886													0018-9219	1558-2256				JAN	2014	102	1					56	103		10.1109/JPROC.2013.2287851	http://dx.doi.org/10.1109/JPROC.2013.2287851													WOS:000328966000008
J	Wennerberg, A; Albrektsson, T				Wennerberg, Ann; Albrektsson, Tomas			Effects of titanium surface topography on bone integration: a systematic review	CLINICAL ORAL IMPLANTS RESEARCH					2nd EAO Consensus Conference 2009	FEB 19-22, 2009	Pfaffikon, SWITZERLAND					Aim To analyse possible effects of titanium surface topography on bone integration. Materials and methods Our analyses were centred on a PubMed search that identified 1184 publications of assumed relevance; of those, 1064 had to be disregarded because they did not accurately present in vivo data on bone response to surface topography. The remaining 120 papers were read and analysed, after removal of an additional 20 papers that mainly dealt with CaP-coated and Zr implants; 100 papers remained and formed the basis for this paper. The bone response to differently configurated surfaces was mainly evaluated by histomorphometry (bone-to-implant contact), removal torque and pushout/pullout tests. Results and discussion A huge number of the experimental investigations have demonstrated that the bone response was influenced by the implant surface topography; smooth (S-a < 0.5 mu m) and minimally rough (S-a 0.5-1 mu m) surfaces showed less strong bone responses than rougher surfaces. Moderately rough (S-a > 1-2 mu m) surfaces showed stronger bone responses than rough (S-a > 2 mu m) in some studies. One limitation was that it was difficult to compare many studies because of the varying quality of surface evaluations; a surface termed 'rough' in one study was not uncommonly referred to as 'smooth' in another; many investigators falsely assumed that surface preparation per se identified the roughness of the implant; and many other studies used only qualitative techniques such as SEM. Furthermore, filtering techniques differed or only height parameters (S-a, R-a) were reported. Conclusions center dot Surface topography influences bone response at the micrometre level. center dot Some indications exist that surface topography influences bone response at the nanometre level. center dot The majority of published papers present an inadequate surface characterization. center dot Measurement and evaluation techniques need to be standardized. center dot Not only height descriptive parameters but also spatial and hybrid ones should be used. To cite this article:Wennerberg A, Albrektsson T. Effects of titanium surface topography on bone integration: a systematic review.Clin. Oral Impl. Res. 20 (Suppl. 4), 2009; 172-184.doi: 10.1111/j.1600-0501.2009.01775.x.																			0905-7161	1600-0501				SEP	2009	20			4			172	184		10.1111/j.1600-0501.2009.01775.x	http://dx.doi.org/10.1111/j.1600-0501.2009.01775.x								19663964					WOS:000268296200017
J	Vachon, S; Klassen, RD				Vachon, Stephan; Klassen, Robert D.			Environmental management and manufacturing performance: The role of collaboration in the supply chain	INTERNATIONAL JOURNAL OF PRODUCTION ECONOMICS												As corporations attempt to move toward environmental sustainability, management must extend their efforts to improve environmental practices across their supply chain. The literature characterizing environmental management within the supply chain has been slowly building, but remains sparse. Using a survey of North American manufacturers, this paper examines the impact of environmental collaborative activities on manufacturing performance. Environmental collaboration was defined specifically to focus on inter-organizational interactions between supply chain members, including such aspects as joint environmental goal setting, shared environmental planning, and working together to reduce pollution or other environmental impacts. These practices can be directed either upstream toward suppliers or downstream toward customers. The influence of collaboration in each direction was empirically assessed for multiple objective and perceptual measures of manufacturing performance using a sample of plants in the package printing industry. Generally, the benefits of collaborative green practices with suppliers were broadest. In contrast, collaboration with customers yielded mixed outcomes. Overall, evidence emerged that upstream practices were more closely linked with process-based performance, while downstream collaboration was associated with product-based performance. (c) 2007 Elsevier B.V. All rights reserved.					Klassen, Robert/I-2178-2012	Klassen, Robert/0000-0002-8650-137X													0925-5273					FEB	2008	111	2					299	315		10.1016/j.ijpe.2006.11.030	http://dx.doi.org/10.1016/j.ijpe.2006.11.030													WOS:000252981900009
J	Lopez, N; Janssens, TVW; Clausen, BS; Xu, Y; Mavrikakis, M; Bligaard, T; Norskov, JK				Lopez, N; Janssens, TVW; Clausen, BS; Xu, Y; Mavrikakis, M; Bligaard, T; Norskov, JK			On the origin of the catalytic activity of gold nanoparticles for low-temperature CO oxidation	JOURNAL OF CATALYSIS												It is Suggested that there may be several effects contributing to the special catalytic properties of supported nanosized gold particles, and that it is useful to order them in a hierarchy. The most important effect is related to the availability of many low-coordinated gold atoms on the small particles. Effects related to the interaction with the Support may also contribute, but to a considerably smaller extent. We base the analysis on a new set of experimental results comparing the CO oxidation rates over gold supported on different reducible and nonreducible oxides, on an analysis of a large number of published activity data, and on an analysis of density-functional calculations of the effect of metal coordination numbers in comparison to the role of charge transfer, layer thickness, and interactions with the support. (C) 2004 Elsevier Inc. All rights reserved.					Xu, Ye/B-5447-2009; Janssens, Ton/AAD-2368-2020; Mavrikakis, Manos/D-5702-2012; Bligaard, Thomas/A-6161-2011; Norskov, Jens/D-2539-2017; Bligaard, Thomas/A-6161-2011; Lopez, Nuria/I-5453-2012	Janssens, Ton V.W./0000-0002-1225-0942; Bligaard, Thomas/0000-0001-9834-9179; Mavrikakis, Manos/0000-0002-5293-5356; Xu, Ye/0000-0002-6406-7832; Norskov, Jens/0000-0002-4427-7728; Bligaard, Thomas/0000-0003-0386-0201; Lopez, Nuria/0000-0001-9150-5941													0021-9517	1090-2694				APR 1	2004	223	1					232	235		10.1016/j.jcat.2004.01.001	http://dx.doi.org/10.1016/j.jcat.2004.01.001													WOS:000220726900024
J	Hutmacher, DW				Hutmacher, DW			Scaffold design and fabrication technologies for engineering tissues - state of the art and future perspectives	JOURNAL OF BIOMATERIALS SCIENCE-POLYMER EDITION												Today, tissue engineers are attempting to engineer virtually every human tissue. Potential tissue-engineered products include cartilage, bone. heart valves, nerves. muscle, bladder, liver, etc. Tissue engineering techniques generally require the use of a porous scaffold, which serves as a three-dimensional template for initial cell attachment and subsequent tissue formation both in vitro and in vivo. The scaffold provides the necessary support for cells to attach, proliferate, and maintain their differentiated function. Its architecture defines the ultimate shape of the new grown soft or hard tissue. In the early days of tissue engineering, clinically established materials such as collagen and polyglycolide were primarily considered as the material of choice for scaffolds. The challenge for more advanced scaffold systems is to arrange cells/tissue in an appropriate 3D configuration and present molecular signals in an appropriate spatial and temporal fashion so that the individual cells will grow and form the desired tissue structures - and do so in a way that can be carried out reproducibly, economically, and on a large scale. This paper is not intended to provide a general review of tissue engineering, but specifically concentrate on the design and processing of synthetic polymeric scaffolds. The material properties and design requirements are discussed. An overview of the various fabrication techniques of scaffolds is presented, beginning with the basic and conventional techniques to the more recent, novel methods that combine both scaffold design and fabrication capabilities.					Hutmacher, Dietmar/AEO-9578-2022	Hutmacher, Dietmar Werner/0000-0001-5678-2134													0920-5063	1568-5624					2001	12	1					107	124		10.1163/156856201744489	http://dx.doi.org/10.1163/156856201744489								11334185					WOS:000168204200008
J	Manjunath, BS; Ohm, JR; Vasudevan, VV; Yamada, A				Manjunath, BS; Ohm, JR; Vasudevan, VV; Yamada, A			Color and texture descriptors	IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY												This paper presents an overview of color and texture descriptors that have been approved for the Final Committee Draft of the MPEG-7 standard, The color and texture descriptors that are described in this paper have undergone extensive evaluation and development during the past two years, Evaluation criteria include effectiveness of the descriptors in similarity retrieval, as well as extraction, storage, and representation complexities, The color descriptors in the standard include a histogram descriptor that is coded using the Haar transform, a color structure histogram, a dominant color descriptor, and a color layout descriptor, The three texture descriptors include one that characterizes homogeneous texture regions and another that represents the local edge distribution. A compact descriptor that facilitates texture browsing is also defined, Each of the descriptors is explained in detail by their semantics, extraction and usage. Effectiveness is documented by experimental results.					Manjunath, B/AAM-8190-2020														1051-8215					JUN	2001	11	6					703	715		10.1109/76.927424	http://dx.doi.org/10.1109/76.927424													WOS:000169216200004
J	Zhang, SX; Zhang, XN; Zhao, CL; Li, JA; Song, Y; Xie, CY; Tao, HR; Zhang, Y; He, YH; Jiang, Y; Bian, YJ				Zhang, Shaoxiang; Zhang, Xiaonong; Zhao, Changli; Li, Jianan; Song, Yang; Xie, Chaoying; Tao, Hairong; Zhang, Yan; He, Yaohua; Jiang, Yao; Bian, Yujun			Research on an Mg-Zn alloy as a degradable biomaterial	ACTA BIOMATERIALIA												In this study a binary Mg-Zn magnesium alloy was researched as a degradable biomedical material. An Mg-Zn alloy fabricated with high-purity raw materials and using a clean melting process had very low levels of impurities. After solid solution treatment and hot working the grain size of the Mg-Zn alloy was finer and a uniform single phase was gained. The mechanical properties of this Mg-Zn alloy were suitable for implant applications, i.e. the tensile strength and elongation achieved were similar to 279.5 MPa and 18.8%, respectively. The results of in vitro degradation experiments including electrochemical measurements and immersion tests revealed that the zinc could elevate the corrosion potential of Mg in simulated body fluid (SBF) and reduce the degradation rate. The corrosion products on the surface of Mg-Zn were hydroxyapatite (HA) and other Mg/Ca phosphates in SBF. In addition, the influence caused by in vitro degradation on mechanical properties was studied, and the results showed that the bending strength of Mg-Zn alloy dropped sharply in the earlier stage of degradation, while smoothly during the later period. The in vitro cytotoxicity of Mg-Zn was examined. The result 0-1 grade revealed that the Mg-Zn alloy was harmless to L-929 cells. For in vivo experiments, Mg-Zn rods were implanted into the femoral shaft of rabbits. The radiographs illustrated that the magnesium alloy could be gradually absorbed in vivo at about 2.32 mm/yr degradation rate obtained by weight loss method. Hematoxylin and eosin (HE) stained section around Mg-Zn rods suggested that there were newly formed bone surrounding the implant. HE stained tissue (containing heart, liver, kidney and spleen tissues) and the biochemical measurements, including serum magnesium, serum creatinine (CREA), blood urea nitrogen (BUN), glutamic-pyruvic transaminase (GPT) and creatine kinase (CK) proved that the in vivo degradation of Mg-Zn did not harm the important organs. Moreover, no adverse effects of hydrogen generated by degradation had been observed and also no negative effects caused by the release of zinc were detected. These results suggested that the novel Mg-Zn binary alloy had good biocompatibility in vivo. (C) 2009 Acta Materialia Inc. Published by Elsevier Ltd. All rights reserved.					song, yang/HOF-4505-2023	Zhao, Changli/0000-0003-1350-8682													1742-7061	1878-7568				FEB	2010	6	2					626	640		10.1016/j.actbio.2009.06.028	http://dx.doi.org/10.1016/j.actbio.2009.06.028								19545650					WOS:000274277800036
J	Qian, CJ; Lin, W				Qian, CJ; Lin, W			A continuous feedback approach to global strong stabilization of nonlinear systems	IEEE TRANSACTIONS ON AUTOMATIC CONTROL												We present in this paper a continuous feedback approach to the problem of global strong stabilization, for genuinely nonlinear systems that may not be stabilized, even locally, by any smooth feedback. We describe conditions under which it is possible to prove, while no smooth controllers exist, the existence of continuous state feedback control laws that achieve global strong stability (GSS) in the sense of Kurzweil, The proof is constructive and carried out by developing a machinery, which combines the theory of homogeneous systems with the idea of adding a power integrator, for the explicit construction of globally stabilizing continuous controllers. We then illustrate, by means of examples, how this machinery can be used to overcome the topological obstruction caused by smooth feedback, and hence resulting in new solutions to a variety of open control problems, including global stabilization of an underactuated unstable two degree of freedom mechanical system.					Qian, Chunjiang/AAE-9170-2020	Qian, Chunjiang/0000-0002-3897-8149													0018-9286	1558-2523				JUL	2001	46	7					1061	1079		10.1109/9.935058	http://dx.doi.org/10.1109/9.935058													WOS:000169945500005
J	Ng, KS; Moo, CS; Chen, YP; Hsieh, YC				Ng, Kong Soon; Moo, Chin-Sien; Chen, Yi-Ping; Hsieh, Yao-Ching			Enhanced coulomb counting method for estimating state-of-charge and state-of-health of lithium-ion batteries	APPLIED ENERGY												The coulomb counting method is expedient for state-of-charge (SOC) estimation of lithium-ion batteries with high charging and discharging efficiencies. The charging and discharging characteristics are investigated and reveal that the coulomb counting method is convenient and accurate for estimating the SOC of lithium-ion batteries. A smart estimation method based on coulomb counting is proposed to improve the estimation accuracy. The corrections are made by considering the charging and operating efficiencies. Furthermore, the state-of-health (SOH) is evaluated by the maximum releasable capacity. Through the experiments that emulate practical operations, the SOC estimation method is verified to demonstrate the effectiveness and accuracy. (C) 2008 Elsevier Ltd. All rights reserved.					Hsieh, Yao-Ching/AFK-2983-2022														0306-2619	1872-9118				SEP	2009	86	9					1506	1511		10.1016/j.apenergy.2008.11.021	http://dx.doi.org/10.1016/j.apenergy.2008.11.021													WOS:000265735300018
J	Elliott, DC				Elliott, Douglas C.			Historical developments in hydroprocessing bio-oils	ENERGY & FUELS												This paper is a review of the developments in the field of catalytic hydroprocessing of biomass-derived liquefaction conversion products (bio-oil) over the past 25 years. Work has been underway, primarily in the U.S. and Europe, in catalytic hydrotreating and hydrocracking of bio-oil in both batch-fed and continuous-flow bench-scale reactor systems. A range of heterogeneous catalyst materials have been tested, including conventional sulfided catalysts developed for petroleum hydroprocessing and precious metal catalysts. The important processing differences have been identified, which required adjustments to conventional hydroprocessing as applied to petroleum feedstocks. This application of hydroprocessing is seen as an extension of petroleum processing and system requirements are not far outside the range of conventional hydroprocessing. The technology is still under development but can play a significant role in supplementing increasingly expensive petroleum. This paper is a review of the developments in the field of catalytic hydroprocessing of biomass-derived liquefaction conversion products (bio-oil) over the past 25 years. Work has been underway, primarily in the U.S. and Europe, in catalytic hydrotreating and hydrocracking of bio-oil in both batch-fed and continuous-flow bench-scale reactor systems. A range of heterogeneous catalyst materials have been tested, including conventional sulfided catalysts developed for petroleum hydroprocessing and precious metal catalysts. The important processing differences have been identified, which required adjustments to conventional hydroprocessing as applied to petroleum feedstocks. This application of hydroprocessing is seen as an extension of petroleum processing and system requirements are not far outside the range of conventional hydroprocessing. The technology is still under development but can play a significant role in supplementing increasingly expensive petroleum.						Elliott, Douglas/0000-0002-2807-4648													0887-0624					MAY-JUN	2007	21	3					1792	1815		10.1021/ef070044u	http://dx.doi.org/10.1021/ef070044u													WOS:000246486100080
