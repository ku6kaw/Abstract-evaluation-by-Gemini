ID,Abstract,rule1,rule2,rule3,rule4,rule5,rule6,rule7,rule8,rule9,rule10,rule11,rule12,rule13,rule14,rule15,rule16,rule17,rule18,rule19,rule20,rule21,rule22,rule23,rule24,rule25,rule26,rule27,rule28,rule29,rule30,rule31,rule32,rule33
0,"Optical networks are undergoing significant changes, fueled by the exponential growth of traffic due to multimedia services and by the increased uncertainty in predicting the sources of this traffic due to the ever changing models of content providers over the Internet. The change has already begun: simple on-off modulation of signals, which was adequate for bit rates up to 10 Gb/s, has given way to much more sophisticated modulation schemes for 100 Gb/s and beyond. The next bottleneck is the 10-year-old division of the optical spectrum into a fixed ""wavelength grid,"" which will no longer work for 400 Gb/s and above, heralding the need for a more flexible grid. Once both transceivers and switches become flexible, a whole new elastic optical networking paradigm is born. In this article we describe the drivers, building blocks, architecture, and enabling technologies for this new paradigm, as well as early standardization efforts.",yes,no,no,yes,no,no,yes,no,no,no,yes,yes,no,no,no,no,yes,yes,yes,no,no,no,no,no,yes,yes,yes,yes,no,yes,no,yes,yes
1,"We consider a multiuser multiple-input multiple-output (MIMO) Gaussian broadcast channel (BC), where the transmitter and receivers have multiple antennas. Since the MIMO BC is in general a nondegraded BC, its capacity region remains an unsolved problem. In this paper, we establish a duality between what is termed the ""dirty paper"" achievable region (the Caire-Shamai achievable region) for the MIMO BC and the capacity region of the MIMO multiple-access channel (MAC), which is easy to compute. Using this duality, we greatly reduce the computational complexity required for, obtaining the dirty paper achievable region for the MIMO BC. We also show that the dirty paper achievable region achieves the sum-rate capacity of the MIMO BC by establishing that the maximum sum rate of this region equals an upper bound on the sum rate of the MIMO BC.",yes,no,no,yes,yes,no,yes,yes,no,yes,yes,yes,no,no,no,no,yes,yes,yes,no,yes,no,yes,no,yes,yes,yes,yes,yes,no,yes,yes,yes
2,"Recent demonstrations of negative refraction utilize three-dimensional collections of discrete periodic scatterers to synthesize artificial dielectrics with simultaneously negative permittivity and permeability. In this paper, we propose an alternate perspective on the design and function of such materials that exploits the well-known L-C distributed network representation of homogeneous dielectrics. In the conventional low-pass topology, the quantities L and C represent a positive equivalent permeability and permittivity, respectively. However, in the dual configuration, in which the positions of L and C are simply interchanged, these equivalent material parameters assume simultaneously negative values. Two-dimensional periodic versions of these dual networks are used to demonstrate negative refraction and focusing; phenomena that are manifestations of the fact that such media support a propagating fundamental backward harmonic. We hereby present the characteristics of these artificial transmission-line media and propose a suitable means of implementing them in planar form. We then present circuit and full-wave field simulations illustrating negative refraction and focusing, and the first experimental verification of focusing using such an implementation.",yes,no,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,no,yes,yes,yes,no,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,no,yes,yes
3,"This paper studies some necessary and sufficient conditions for second-order consensus in multi-agent dynamical systems. First, basic theoretical analysis is carried out for the case where for each agent the second-order dynamics are governed by the position and velocity terms and the asymptotic velocity is constant. A necessary and sufficient condition is given to ensure second-order consensus and it is found that both the real and imaginary parts of the eigenvalues of the Laplacian matrix of the corresponding network play key roles in reaching consensus. Based on this result, a second-order consensus algorithm is derived for the multi-agent system facing communication delays. A necessary and sufficient condition is provided, which shows that consensus can be achieved in a multi-agent system whose network topology contains a directed spanning tree if and only if the time delay is less than a critical value. Finally, simulation examples are given to verify the theoretical analysis. (C) 2010 Elsevier Ltd. All rights reserved.",yes,no,no,no,yes,no,yes,no,yes,no,yes,yes,no,no,no,no,yes,yes,yes,no,yes,no,yes,no,yes,yes,no,yes,no,no,no,yes,no
4,"With the advent of the Internet, billions of images are now freely available online and constitute a dense sampling of the visual world. Using a variety of nonparametric methods, we explore this world with the aid of a large data set of 79,302,017 images collected from the Web. Motivated by psychophysical results showing the remarkable tolerance of the human visual system to degradations in image resolution, the images in the data set are stored as 32 x 32 color images. Each image is loosely labeled with one of the 75,062 nonabstract nouns in English, as listed in the Wordnet lexical database. Hence, the image database gives comprehensive coverage of all object categories and scenes. The semantic information from Wordnet can be used in conjunction with the nearest neighbor methods to perform object classification over a range of semantic levels, minimizing the effects of labeling noise. For certain classes that are particularly prevalent in the data set, such as people, we are able to demonstrate a recognition performance comparable to class-specific Viola-Jones style detectors.",yes,no,no,no,no,no,yes,no,no,no,yes,yes,yes,no,yes,no,yes,yes,yes,no,yes,no,yes,yes,no,yes,yes,yes,no,no,no,yes,yes
5,"Experience has shown that unpredictable disruption of communications during emergency operations can have severe consequences both for personal safety and for the ability to conduct a successful operation. An early-warning service for emerging communication disruption due to both unintentional interference and jamming, would therefore be a significant contribution for increased safety and security in such operations. We propose a solution for such an early-warning service both on the terminal and on higher system level. The solution is based on historical recorded data of both local and global information such as signal-to-interference ratio, interference classification, and position. We show by an example that with this service implemented, the operator will have increased time to take actions before a disruption occurs on a specific terminal.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6,"This paper presents the framework of kernel-based methods in the context of hyperspectral image classification, illustrating from a general viewpoint the main characteristics of different kernel-based approaches and analyzing their properties in the hyperspectral domain. In particular, we assess performance of regularized radial basis function neural networks (Reg-RBFNN), standard support vector machines (SVMs), kernel Fisher discriminant (KFD) analysis, and regularized AdaBoost (Reg-AB). The novelty of this work consists in: 1) introducing Reg-RBFNN and Reg-AB for hyperspectral image classification; 2) comparing kernel-based methods by taking into account the peculiarities of hyperspectral images; and 3) clarifying their theoretical relationships. To these purposes, we focus on the accuracy of methods when working in noisy environments, high input dimension, and limited training sets. In addition, some other important issues are discussed, such as the sparsity of the solutions, the computational burden,,and the capability of the methods to provide outputs that can be directly interpreted as probabilities.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7,"Classification of hyperspectral data with high spatial resolution from urban areas is investigated. A method based on mathematical morphology for preprocessing of the hyperspectral data is proposed. In this approach, opening and closing morphological transforms are used in order to isolate bright (opening) and dark (closing) structures in images, where bright/dark means brighter/darker than the surrounding features in the images. A morphological profile is constructed based on the repeated use of openings and closings with a structuring element, of increasing size, starting with one original image. In order to apply the morphological approach to hyperspectral data, principal components of the hyperspectral imagery are computed. The most significant principal components are used as base images for an extended morphological profile, i.e., a profile based on more than one original image. In experiments, two hyperspectral urban datasets are classified. The proposed method is used as a preprocessing method for a neural network classifier and compared to more conventional classification methods with different types of statistical computations and feature extraction.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8,"A novel approach to provide, thermally sensitive neutral solutions based on chitosan/polyol salt combinations is described. These formulations possess a physiological pH and can be held liquid below room temperature for encapsulating living cells and therapeutic proteins; they form monolithic gels at body temperature. When injected in vivo the liquid formulations turn into gel implants in situ, This system was used successfully to deliver biologically active growth factors in vivo as well as an encapsulating matrix for living chondrocytes for tissue engineering applications. This study reports for the first time the use of polymer/polyol salt aqueous solutions as gelling systems, suggesting the discovery of a prototype for a new family of thermosetting gels highly compatible with biological compounds. (C) 2000 Elsevier Science Ltd. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9,"Unit commitment, one of the most critical tasks in electric power system operations, faces new challenges as the supply and demand uncertainty increases dramatically due to the integration of variable generation resources such as wind power and price responsive demand. To meet these challenges, we propose a two-stage adaptive robust unit commitment model for the security constrained unit commitment problem in the presence of nodal net injection uncertainty. Compared to the conventional stochastic programming approach, the proposed model is more practical in that it only requires a deterministic uncertainty set, rather than a hard-to-obtain probability distribution on the uncertain data. The unit commitment solutions of the proposed model are robust against all possible realizations of the modeled uncertainty. We develop a practical solution methodology based on a combination of Benders decomposition type algorithm and the outer approximation technique. We present an extensive numerical study on the real-world large scale power system operated by the ISO New England. Computational results demonstrate the economic and operational advantages of our model over the traditional reserve adjustment approach.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
10,"In this paper we discuss an online algorithm based on policy iteration for learning the continuous-time (CT) optimal control solution with infinite horizon cost for nonlinear systems with known dynamics. That is, the algorithm learns online in real-time the solution to the optimal control design HJ equation. This method finds in real-time suitable approximations of both the optimal cost and the optimal control policy, while also guaranteeing closed-loop stability. We present an online adaptive algorithm implemented as an actor/critic structure which involves simultaneous continuous-time adaptation of both actor and critic neural networks. We call this 'synchronous' policy iteration. A persistence of excitation condition is shown to guarantee convergence of the critic to the actual optimal value function. Novel tuning algorithms are given for both critic and actor networks, with extra nonstandard terms in the actor tuning law being required to guarantee closed-loop dynamical stability. The convergence to the optimal controller is proven, and the stability of the system is also guaranteed. Simulation examples show the effectiveness of the new algorithm. (C) 2010 Elsevier Ltd. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
11,"We describe a real-time computer vision and machine learning system for modeling and recognizing human behaviors in a visual surveillance task [1]. The system is particularly concerned with detecting when interactions between people occur and classifying the type of interaction. Examples of interesting interaction behaviors include following another person, altering one's path to meet another, and so forth. Our system combines top-down with bottom-up information in a closed feedback loop, with both components employing a statistical Bayesian approach [2]. We propose and compare two different state-based learning architectures, namely, HMMs and CHMMs for modeling behaviors and interactions. The CHMM model is shown to work much more efficiently and accurately. Finally, to deal with the problem of limited training data, a synthetic ""Alife-style"" training system is used to develop flexible prior models for recognizing human interactions. We demonstrate the ability to use these a priori models to accurately classify real human behaviors and interactions with no additional tuning or training.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
12,"Antibiotic resistance has become a major health concern; thus, there is a growing interest in exploring the occurrence of antibiotic resistance genes (ARGs) in the environment as well as the factors that contribute to their emergence. Aquatic ecosystems provide an ideal setting for the acquisition and spread of ARGs due to the continuous pollution by antimicrobial compounds derived from anthropogenic activities. We investigated, therefore, the pollution level of a broad range of antibiotics and ARGs released from hospital and urban wastewaters, their removal through a wastewater treatment plant (WWTP) and their presence in the receiving river. Several antimicrobial compounds were detected in all water samples collected. Among antibiotic families, fluoroquinolones were detected at the highest concentration, especially in hospital effluent samples. Although good removal efficiency by treatment processes was observed for several antimicrobial compounds, most antibiotics were still present in WWTP effluents. The results also revealed that copy numbers of ARGs, such as bla(TEM) (resistance to beta-lactams), qnrS (reduced susceptibility to fluoroquinolones), ermB (resistance to macrolides), sulI (resistance to sulfonamides) and tetW (resistance to tetracyclines), were detected at the highest concentrations in hospital effluent and WWTP influent samples. Although there was a significant reduction in copy numbers of these ARGs in WWTP effluent samples, this reduction was not uniform across analyzed ARGs. Relative concentration of ermB and tetW genes decreased as a result of wastewater treatment, whereas increased in the case of bla(TEM), still and qnrS genes. The incomplete removal of antibiotics and ARGs in WWTP severely affected the receiving river, where both types of emerging pollutants were found at higher concentration in downstream waters than in samples collected upstream from the discharge point. Taken together, our findings demonstrate a widespread occurrence of antibiotics and ARGs in urban and hospital wastewater and how these effluents, even after treatment, contribute to the spread of these emerging pollutants in the aquatic environment. (C) 2014 Elsevier Ltd. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
13,"The recently introduced proportional-resonant (PR) controllers and filters, and their suitability for current/voltage control of grid-connected converters, are described. Using the PR controllers, the converter reference tracking performance can be enhanced and previously known shortcomings associated with conventional PI controllers can be alleviated. These shortcomings include steady-state errors in single-phase systems and the need for synchronous d-q transformation in three-phase systems. Based on similar control theory, PR filters can also be used for generating the harmonic command reference precisely in an active power filter, especially for single-phase systems, where d-q transformation theory is not directly applicable. Another advantage associated with the PR controllers and filters is the possibility of implementing selective harmonic compensation without requiring excessive computational resources. Given these advantages and the belief that PR control will find wide-ranging applications in grid-interfaced converters, PR control theory is revised in detail with a number of practical cases that have been implemented previously, described clearly to give a comprehensive reference on PR control and filtering.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
14,"Rational design and facile preparation of non-noble trifunctional electrocatalysts with high performance, low cost and strong durability for the oxygen reduction reaction (ORR), oxygen evolution reaction (OER) and hydrogen evolution reaction (HER) are highly demanded, but remain as a big challenge. Herein, we report a spontaneous gas-foaming method to prepare nitrogen doped ultrathin carbon nanosheets (NCNs) by simply pyrolysing a mixture of citric acid and NH4Cl. Under the optimized pyrolysis temperature (carbonized at 1000 degrees C) and mass ratio of precursors (1:1), the synthesized NCN-1000-5 sample possesses an ultrathin sheet structure, an ultrahigh specific surface area (1793 m(2) g(-1)), and rich edge defects, and exhibits low overpotential and robust stability for the ORR, OER and HER. By means of density functional theory (DFT) computations, we revealed that the intrinsic active sites for the ORR, OER and HER are the carbon atoms located at the armchair edge and adjacent to the graphitic N dopants. When practically used as a catalyst in rechargeable Zn-air batteries, a high energy density (806 W h kg(-1)), a low charge/discharge voltage gap (0.77 V) and an ultralong cycle life (over 330 h) were obtained at 10 mA cm(-2) for NCN-1000-5. This work not only presents a versatile strategy to develop advanced carbon materials with ultrahigh specific surface area and abundant edge defects, but also provides useful guidance for designing and developing multifunctional metal-free catalysts for various energy-related electrocatalytic reactions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
15,"Mesh convergence and manufacturability of topology optimized designs have previously mainly been assured using density or sensitivity based filtering techniques. The drawback of these techniques has been gray transition regions between solid and void parts, but this problem has recently been alleviated using various projection methods. In this paper we show that simple projection methods do not ensure local mesh-convergence and propose a modified robust topology optimization formulation based on erosion, intermediate and dilation projections that ensures both global and local mesh-convergence.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
16,"Cavitating,flows entail phase change and hence very large and steep density variations in the low pressure regions. These are also very, sensitive to: (a) the formation and transport of vapor bubbles, (b) the turbulent fluctuations of pressure and velocity, and (c) the magnitude of noncondensible gases, which are dissolved or ingested in the operating liquid. The presented cavitation model accounts for all these first-order effects, and thus is named as the ''full cavitation model."" The phase-change rate expressions are derived,front a reduced form of Rayleigh-Plesset equation for bubble dynamics. These rates depend upon local flow conditions (pressure, velocities. turbulence) as well as fluid properties (saturation pressure, densities, and surface tension). The rate expressions employ two empirical constants, which have been calibrated with experimental data covering a very wide range of flow conditions, and do not require adjustments for different problems. The model has been implemented in an advanced, commercial, general-purpose CFD code, CFD-ACE+. Final validation results are presented for flows over hydrofoils, submerged cylindrical bodies, and sharp-edged orifices. Suggestions for possible extensions of the model implementation, e.g., to nonisothermal flows, for ingestion and mixing of noncondensible gases, and for predictions of noise and surface damage are outlined.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
17,"Massive multiple-input multiple-output (MIMO) is one of the most promising technologies for the next generation of wireless communication networks because it has the potential to provide game-changing improvements in spectral efficiency (SE) and energy efficiency (EE). This monograph summarizes many years of research insights in a clear and self-contained way and provides the reader with the necessary knowledge and mathematical tools to carry out independent research in this area. Starting from a rigorous definition of Massive MIMO, the monograph covers the important aspects of channel estimation, SE, EE, hardware efficiency (HE), and various practical deployment considerations. From the beginning, a very general, yet tractable, canonical system model with spatial channel correlation is introduced. This model is used to realistically assess the SE and EE, and is later extended to also include the impact of hardware impairments. Owing to this rigorous modeling approach, a lot of classic ""wisdom"" about Massive MIMO, based on too simplistic system models, is shown to be questionable. The monograph contains many numerical examples, which can be reproduced using Matlab code that is available online at https://dx.doi.org/10.1561/2000000093_supp.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
18,"As bioabsorbable materials, magnesium alloys are expected to be totally degraded in the body and their biocorrosion products not deleterious to the surrounding tissues. it's critical that the alloying elements are carefully selected in consideration of their cytotoxicity and hemocompatibility. In the present study, nine alloying elements Al, Ag, In, Mn, Si, Sn, Y, Zn and Zr were added into magnesium individually to fabricate binary Mg-1X (wt.%) alloys. Pure magnesium was used as control. Their mechanical properties, corrosion properties and in vitro biocompatibilities (cytotoxicity and hemocompatibility) were evaluated by SEM, XRD, tensile test, immersion test, electrochemical corrosion test, cell culture and platelet adhesion test. The results showed that the addition of alloying elements could influence the strength and corrosion resistance of Mg. The cytotoxicity tests indicated that Mg-1Al, Mg-1Sn and Mg-1Zn alloy extracts showed no significant reduced cell viability to fibroblasts (L-929 and NIH3T3) and osteoblasts (MC3T3-E1): Mg-1A1 and Mg-1Zn alloy extracts indicated no negative effect on viabilities of blood vessel related cells, ECV304 and VSMC. It was found that hemolysis and the amount of adhered platelets decreased after alloying for all Mg-1X alloys as compared to the pure magnesium control. The relationship between the corrosion products and the in vitro biocompatibility had been discussed and the suitable alloying elements for the biomedical applications associated with bone and blood vessel had been proposed. (C) 2008 Elsevier Ltd. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
19,"This note considers consensus algorithms for double-integrator dynamics. We propose and analyze consensus algorithms for double-integrator dynamics in four cases: 1) with a bounded control input, 2) without relative velocity measurements, 3) with a group reference velocity available to each team member, and 4) with a bounded control input when a group reference state is available to only a subset of the team. We show that consensus is reached asymptotically for the first two cases if the undirected interaction graph is connected. We further show that consensus is reached asymptotically for the third case if the directed interaction graph has a directed spanning tree and the gain for velocity matching with the group reference velocity is above a certain bound. We also show that consensus is reached asymptotically for the fourth case if and only if the group reference state flows directly or indirectly to all of the vehicles in the team.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
20,"Sparse representation models code an image patch as a linear combination of a few atoms chosen out from an over-complete dictionary, and they have shown promising results in various image restoration applications. However, due to the degradation of the observed image (e. g., noisy, blurred, and/or down-sampled), the sparse representations by conventional models may not be accurate enough for a faithful reconstruction of the original image. To improve the performance of sparse representation-based image restoration, in this paper the concept of sparse coding noise is introduced, and the goal of image restoration turns to how to suppress the sparse coding noise. To this end, we exploit the image nonlocal self-similarity to obtain good estimates of the sparse coding coefficients of the original image, and then centralize the sparse coding coefficients of the observed image to those estimates. The so-called nonlocally centralized sparse representation (NCSR) model is as simple as the standard sparse representation model, while our extensive experiments on various types of image restoration problems, including denoising, deblurring and super-resolution, validate the generality and state-of-the-art performance of the proposed NCSR algorithm.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
21,"Nitrogen-doped graphene as a metal-free catalyst for oxygen reduction was synthesized by heat-treatment of graphene using ammonia. It was found that the optimum temperature was 900 degrees C. The resulting catalyst had a very high oxygen reduction reaction (ORR) activity through a four-electron transfer process in oxygen-saturated 0.1 M KOH. Most importantly, the electrocatalytic activity and durability of this material are comparable or better than the commercial Pt/C (loading: 4.85 mu g(Pt) cm(-2)). XPS characterization of these catalysts was tested to identify the active N species for ORR.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
22,"This review analyses the opportunities and prospects in the chemical recycling of carbon dioxide to fuels, as a complementary technology to carbon sequestration and storage (CSS). It is remarked that the requisites for this objective are (i) minimize as much as possible the consumption of hydrogen (or hydrogen sources), (ii) produce fuels that can be easily stored and transported, and (iii) use renewable energy sources. From this perspective, the preferable option is to produce alcohols (preferably >= C2) using solar energy to produce the protons and electrons necessary for the reaction of CO2 reduction. It is evidenced, however, that this is still a long-term objective, even if already some good advances in this direction exist. The different topics discussed in the review include CO2 (i) reverse water-gas shift and (ii) hydrogenation to hydrocarbons, alcohols, dimethyl ether and formic acid, (iii) reaction with hydrocarbons to syngas, (iv) photo- and electrochemical/catalytic conversion, and (v) thermochemical conversion. Other relevant options, such as the use of micro-algae or other bio-catalysis based processes, or the use of microwave and plasma processes are instead not addressed. Therefore. the area of carbon dioxide conversion to fuels and chemicals is a very active R&D sector, and it is anticipated that it represents a challenging possibility for companies to develop complementary strategies to CSS to reduce greenhouse gas emissions. (C) 2009 Elsevier B.V. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
23,"The graphics processing unit (GPU) has become an integral part of today's mainstream computing systems. Over the past six years, there has been a marked increase in the performance and capabilities of GPUS. The modern GPU is not only a powerful graphics engine but also a highly parallel programmable processor featuring peak arithmetic and memory bandwidth that substantially outpaces its CPU counterpart. The GPU's rapid increase in both programmability and capability has spawned a research community that has successfully mapped a broad range of computationally demanding, complex problems to the GPU. This effort in general-purpose computing on the GPU, also known as GPU computing, has positioned the GPU as a compelling alternative to traditional microprocessors in high-performance computer systems of the future. We describe the background, hardware, and programming model for GPU computing, summarize the state of the art in tools and techniques, and present four GPIJ computing successes in game physics and computational biophysics that deliver order-of-magnitude performance gains over optimized CPU applications.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
24,"Room temperature ionic liquids are salts that are liquid at room temperature and their use as catalysts and catalytic support has been studied extensively. They are also being considered as ""green solvents"" for various separation processes. Recent measurements reported on the properties of pure ionic liquids and their mixtures, including gas and liquid solubility in common organic solvents will be reviewed. While some property values are in good agreement, some show large differences. These values will be compared and reasons for the discrepancies will be conjectured. Since traditional approaches to predicting the properties of fluid liquids require extensive LLE and VLE measurements, alternative predictive methods need to be explored. The predictions of the properties of mixtures of ionic liquids using COSMOtherm, an approach based on unimolecular quantum chemical calculations of the individual molecules, will be presented. (C) 2004 Published by Elsevier B.V.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
25,"Human face detection plays an important role in applications such as video surveillance, human computer interface, face recognition, and face image database management. We propose a face detection algorithm for color images in the presence of varying lighting conditions as well as complex backgrounds. Based on a novel lighting compensation technique and a nonlinear color transformation, our method detects skin regions over the entire image and then generates face candidates based on the spatial arrangement of these skin patches. The algorithm constructs eye, mouth, and boundary maps for verifying each face candidate. Experimental results demonstrate successful face detection over a wide range of facial variations in color, position, scale, orientation, 3D pose, and expression in images from several photo collections (both indoors and outdoors).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
26,"The number of research reports published in recent years on electrochemical water splitting for hydrogen generation is higher than for many other fields of energy research. In fact, electrochemical water splitting, which is conventionally known as water electrolysis, has the potential to meet primary energy requirements in the near future when coal and hydrocarbons are completely consumed. Due to the sudden and exponentially increasing attention on this field, many researchers across the world, including our group, have been exerting immense efforts to improve the electrocatalytic properties of the materials that catalyze the oxygen evolution reaction (OER) at the anode and the hydrogen evolution reaction (HER) at the cathode, aided by the recent revolutionary discovery of nanomaterials. However, the pressure on the researchers to publish their findings rapidly has caused them to make many unnoticed and unintentional errors, which is mainly due to lack of clear insight on the activity parameters. In this perspective, we have discussed the use and validity of ten important parameters, namely overpotential at a defined current density, iR-corrected overpotential at a defined current density, Tafel slope, exchange current density (j(0)), mass activity, specific activity, faradaic efficiency (FE), turnover frequency (TOF), electrochemically active surface area (ECSA) and measurement of double layer capacitance (C-dl) for different electrocatalytic materials that are frequently employed in both OER and HER. Experimental results have also been provided in support of our discussions wherever required. Using our critical assessments of the activity parameters of water splitting electrocatalysis, researchers can ensure precision and correctness when presenting their data regarding the activity of an electrocatalyst.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
27,"Given the potential risk of X-ray radiation to the patient, low-dose CT has attracted a considerable interest in the medical imaging field. Currently, the main stream low-dose CT methods include vendor-specific sinogram domain filtration and iterative reconstruction algorithms, but they need to access raw data, whose formats are not transparent to most users. Due to the difficulty of modeling the statistical characteristics in the image domain, the existing methods for directly processing reconstructed images cannot eliminate image noise very well while keeping structural details. Inspired by the idea of deep learning, here we combine the autoencoder, deconvolution network, and shortcut connections into the residual encoder-decoder convolutional neural network (RED-CNN) for low-dose CT imaging. After patch-based training, the proposed RED-CNN achieves a competitive performance relative to the-state-of-art methods in both simulated and clinical cases. Especially, our method has been favorably evaluated in terms of noise suppression, structural preservation, and lesion detection.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
28,"Mobile-edge computation offloading (MECO) offloads intensive mobile computation to clouds located at the edges of cellular networks. Thereby, MECO is envisioned as a promising technique for prolonging the battery lives and enhancing the computation capacities of mobiles. In this paper, we study resource allocation for a multiuser MECO system based on time-division multiple access (TDMA) and orthogonal frequency-division multiple access (OFDMA). First, for the TDMA MECO system with infinite or finite cloud computation capacity, the optimal resource allocation is formulated as a convex optimization problem for minimizing the weighted sum mobile energy consumption under the constraint on computation latency. The optimal policy is proved to have a threshold-based structure with respect to a derived offloading priority function, which yields priorities for users according to their channel gains and local computing energy consumption. As a result, users with priorities above and below a given threshold perform complete and minimum offloading, respectively. Moreover, for the cloud with finite capacity, a sub-optimal resource-allocation algorithm is proposed to reduce the computation complexity for computing the threshold. Next, we consider the OFDMA MECO system, for which the optimal resource allocation is formulated as a mixed-integer problem. To solve this challenging problem and characterize its policy structure, a low-complexity sub-optimal algorithm is proposed by transforming the OFDMA problem to its TDMA counterpart. The corresponding resource allocation is derived by defining an average offloading priority function and shown to have close-to-optimal performance in simulation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
29,"New, exciting opportunities for utilizing biological processes to modify the engineering properties of the Subsurface (e.g. strength, stiffness, permeability) have recently emerged. Enabled by interdisciplinary research at the confluence of microbiology, geochemistry. and civil engineering. this new field has the potential to meet society's ever-expanding needs for innovative treatment processes that improve Soil Supporting new and existing infrastructure. This paper first presents an overview of bio-mediated improvement systems, identifying the primary components and interplay between different disciplines. Geometric compatibility between soil and microbes that restricts the utility of different systems is identified. Focus is then narrowed to a specific system, namely bio-mediated calcite precipitation of sands. Following an overview of the Process, alternative biological processes for inducing calcite precipitation are identified and various microscopy techniques are used to assess how the pore space Volume is altered by calcite precipitation, the calcite precipitation is distributed spatially within the pore space, and the precipitated calcite degrades during loading. Non-destructive geophysical process monitoring techniques are described and their utility explored. Next, the extent to which various soil engineering properties is identified through experimental examples. Potential advantages and envisioned applications of bio-mediated soil improvement are identified. Finally, the primary challenges that lie ahead, namely optimization and upscaling of the processes and the education/training of researchers/practitioners are briefly discussed. (C) 2009 Elsevier B.V. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
30,"This paper presents the description, calibration and application of relatively simple hysteretic models that include strength and stiffness deterioration properties, features that are critical for demand predictions as a structural system approaches collapse. Three of the basic hysteretic models used in seismic demand evaluation are modified to include deterioration properties: bilinear, peak-oriented, and pinching. The modified models include most of the sources of deterioration: i.e. various modes of cyclic deterioration and softening of the post-yielding stiffness, and also account for a residual strength after deterioration. The models incorporate an energy-based deterioration parameter that controls four cyclic deterioration modes: basic strength, post-capping strength, unloading stiffness, and accelerated reloading stiffness deterioration. Calibration of the hysteretic models on steel, plywood, and reinforced-concrete components demonstrates that the proposed models are capable of simulating the main characteristics that influence deterioration. An application of a peak-oriented deterioration model in the seismic evaluation of single-degree-of-freedom (SDOF) systems is illustrated. The advantages of using deteriorating hysteretic models for obtaining the response of highly inelastic systems are discussed. Copyright (c) 2005 John Wiley & Sons, Ltd.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
31,"Automotive three-way catalysts (TWCs) have represented over the last 25 years one of the most successful stories in the development of catalysts. The aim of this paper is to illustrate the technology for abatement of exhaust emissions by analysing the current understanding of TWCs, the specific role of the various components, the achievements and the limitations. The challenges in the development of new automotive catalysts, which can meet future highly demanding pollution abatement requirements, are also discussed. (C) 2002 Elsevier Science B.V. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
32,"In this paper, we propose a very simple deep learning network for image classification that is based on very basic data processing components: 1) cascaded principal component analysis (PCA); 2) binary hashing; and 3) blockwise histograms. In the proposed architecture, the PCA is employed to learn multistage filter banks. This is followed by simple binary hashing and block histograms for indexing and pooling. This architecture is thus called the PCA network (PCANet) and can be extremely easily and efficiently designed and learned. For comparison and to provide a better understanding, we also introduce and study two simple variations of PCANet: 1) RandNet and 2) LDANet. They share the same topology as PCANet, but their cascaded filters are either randomly selected or learned from linear discriminant analysis. We have extensively tested these basic networks on many benchmark visual data sets for different tasks, including Labeled Faces in the Wild (LFW) for face verification; the MultiPIE, Extended Yale B, AR, Facial Recognition Technology (FERET) data sets for face recognition; and MNIST for hand-written digit recognition. Surprisingly, for all tasks, such a seemingly naive PCANet model is on par with the state-of-the-art features either prefixed, highly hand-crafted, or carefully learned [by deep neural networks (DNNs)]. Even more surprisingly, the model sets new records for many classification tasks on the Extended Yale B, AR, and FERET data sets and on MNIST variations. Additional experiments on other public data sets also demonstrate the potential of PCANet to serve as a simple but highly competitive baseline for texture classification and object recognition.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
33,"Agricultural systems models worldwide are increasingly being used to explore options and solutions for the food security, climate change adaptation and mitigation and carbon trading problem domains. APSIM (Agricultural Production Systems sIMulator) is one such model that continues to be applied and adapted to this challenging research agenda. From its inception twenty years ago, APSIM has evolved into a framework containing many of the key models required to explore changes in agricultural landscapes with capability ranging from simulation of gene expression through to multi-field farms and beyond. Keating et al. (2003) described many of the fundamental attributes of APSIM in detail. Much has changed in the last decade, and the APSIM community has been exploring novel scientific domains and utilising software developments in social media, web and mobile applications to provide simulation tools adapted to new demands. This paper updates the earlier work by Keating et al. (2003) and chronicles the changing external challenges and opportunities being placed on APSIM during the last decade. It also explores and discusses how APSIM has been evolving to a ""next generation"" framework with improved features and capabilities that allow its use in many diverse topics. Crown Copyright (C) 2014 Published by Elsevier Ltd. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
34,"This paper presents a general framework for nonlinear systems subject to disturbances using disturbance observer based control (DOBC) techniques. A two-stage design procedure to improve disturbance attenuation ability of current linear/nonlinear controllers is proposed where the disturbance observer design is separated from the controller design. To facilitate this concept, a nonlinear disturbance observer is developed for disturbances generated by an exogenous system, and global exponential stability is established under certain condition. Furthermore, semiglobal stability condition of the composite controller consisting of a nonlinear controller and the nonlinear disturbance observer is established. The developed method is illustrated by the application to control of a two-link robotic manipulator.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
35,"Electrochemical production of hydrogen from water has been directed to the search for non-noble metal based and earth-abundant catalysts. In this work, we propose a novel cost-effective catalyst, molybdenum phosphide that exhibits high activity towards the hydrogen evolution reaction (HER) in both acid and alkaline media even in bulk form. Comparative analysis of Mo, Mo3P and MoP as catalysts for HER clearly indicates that phosphorization can potentially modify the properties of the metal and different degrees of phosphorization lead to distinct activities and stabilities. Theoretical calculations by density functional theory also show that a simple phosphorization of molybdenum to form MoP introduces a good 'H delivery' system which attains nearly zero binding to H at a certain H coverage. With the combination of experimental results and theoretical calculations, this work has enlightened a new way of exploring cost-effective catalysts for HER.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
36,"Superparamagnetic magnetite nanoparticles were surface-modified with poly (ethylene glycol) (PEG) and folic acid, respectively, to improve their intracellular uptake and ability to tat-get specific cells. PEG and folic acid were successfully immobilized on the surfaces of magnetite nanoparticles and characterized using fourier transform infrared spectra. The nanoparticle internalization into mouse macrophage (RAW 264.7) and human breast cancer (BT20) cells was visualized using both fluorescence and confocal microscopy, and quantified by inductively coupled plasma emission spectroscopy (ICP). After the cells were cultured for 48 h in the medium containing the nanoparticles modified with PEG or folic acid, the results of fluorescence and confocal microscopy showed that the nanoparticles were internalized into the cells. The ICP measurements indicated that the uptake amount of PEG-modified nanoparticles into macrophage cells was much lower than that of unmodified nanoparticles, while folic acid modification did not change the amount of the uptake. However, for breast cancer cells, both PEG and folic acid modification facilitated the nanoparticle internalization into the cells. Therefore, PEG and folic acid modification of magnetite nanoparticles could be used to resist the protein adsorption and thus avoid the particle recognition by macropliage cells, and to facilitate the nanoparticle uptake to specific cancer cells for cancer therapy and diagnosis. (C) 2002 Elsevier Science Ltd. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
37,"Compressive sensing (CS) is an alternative to Shannon/Nyquist sampling for the acquisition of sparse or compressible signals that can be well approximated by just K << N elements from an N-dimensional basis. Instead of taking periodic samples, CS measures inner products with M < N random vectors and then recovers the signal via a sparsity-seeking optimization or greedy algorithm. Standard CS dictates that robust signal recovery is possible from M = O(K log(N/K)) measurements. It is possible to substantially decrease M without sacrificing robustness by leveraging more realistic signal models that go beyond simple sparsity and compressibility by including structural dependencies between the values and locations of the signal coefficients. This paper introduces a model-based CS theory that parallels the conventional theory and provides concrete guidelines on how to create model-based recovery algorithms with provable performance guarantees. A highlight is the introduction of a new class of structured compressible signals along with a new sufficient condition for robust structured compressible signal recovery that we dub the restricted amplification property, which is the natural counterpart to the restricted isometry property of conventional CS. Two examples integrate two relevant signal models-wavelet trees and block sparsity-into two state-of-the-art CS recovery algorithms and prove that they offer robust recovery from just M = O(K) measurements. Extensive numerical simulations demonstrate the validity and applicability of our new theory and algorithms.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
38,"Inspired by recent advances in multiple-input multiple-output (MIMO) communications, this proposal introduces the statistical MIMO radar concept. To the authors' knowledge, this is the first time that the statistical MIMO is being proposed for radar. The fundamental difference between statistical MIMO and other radar array systems is that the latter seek to maximize the coherent processing gain, while statistical MIMO radar capitalizes on the diversity of target scattering to improve radar performance. Coherent processing is made possible by highly correlated signals at the receiver array, whereas in statistical MIMO radar, the signals received by the array elements are uncorrelated. Radar targets generally consist of many small elemental scatterers that are fused by the radar waveform and the processing at the receiver, to result in echoes with fluctuating amplitude and phase. It is well known that in conventional radar, slow fluctuations of the target radar cross section (RCS) result in target fades that degrade radar performance. By spacing the antenna elements at the transmitter and at the receiver such that the target angular spread is manifested, the MIMO radar can exploit the spatial diversity of target scatterers opening the way to a variety of new techniques that can improve radar performance. This paper focuses on the application of the target spatial diversity to improve detection performance. The optimal detector in the Neyman-Pearson sense is developed and analyzed for the statistical MIMO radar. It is shown that the optimal detector consists of noncoherent processing of the receiver sensors' outputs and that for cases of practical interest, detection performance is superior to that obtained through coherent processing. An optimal detector invariant to the signal and noise levels is also developed and analyzed. In this case as well, statistical MIMO radar provides great improvements over other types of array radars.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
39,"Images of outdoor scenes captured in bad weather suffer from poor contrast. Under bad weather conditions, the light reaching a camera is severely scattered by the atmosphere. The resulting decay in contrast varies across the scene and is exponential in the depths of scene points. Therefore, traditional space invariant image processing techniques are not sufficient to remove weather effects from images. In this paper, we present a physics-based model that describes the appearances of scenes in uniform bad weather conditions. Changes in intensities of scene points under different weather conditions provide simple constraints to detect depth discontinuities in the scene and also to compute scene structure. Then, a fast algorithm to restore scene contrast is presented. In contrast to previous techniques, our weather removal algorithm does not require any a priori scene structure, distributions of scene reflectances, or detailed knowledge about the particular weather condition. All the methods described in this paper are effective under a wide range of weather conditions including haze, mist, fog, and conditions arising due to other aerosols. Further, our methods can be applied to gray scale, RGB color, multispectral and even IR images. We also extend our techniques to restore contrast of scenes with moving objects, captured using a video camera.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
40,"The use of unmanned aerial vehicles (UAVs) is growing rapidly across many civil application domains, including real-time monitoring, providing wireless coverage, remote sensing, search and rescue, delivery of goods, security and surveillance, precision agriculture, and civil infrastructure inspection. Smart UAVs are the next big revolution in the UAV technology promising to provide new opportunities in different applications, especially in civil infrastructure in terms of reduced risks and lower cost. Civil infrastructure is expected to dominate more than $45 Billion market value of UAV usage. In this paper, we present UAV civil applications and their challenges. We also discuss the current research trends and provide future insights for potential UAV uses. Furthermore, we present the key challenges for UAV civil applications, including charging challenges, collision avoidance and swarming challenges, and networking and security-related challenges. Based on our review of the recent literature, we discuss open research challenges and draw high-level insights on how these challenges might be approached.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
41,"We report on an interdiffusion method to fabricate pin-hole free perovskite films using a low temperature (<105 degrees C) solution process. A high efficiency of 15.4%, with a fill factor of similar to 80%, was achieved for the devices under one sun illumination. The interdiffusion method results in high device yield, with an efficiency of above 14.5% for more than 85% of the devices.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
42,"In this paper, a novel design method for determining the optimal proportional-integral-derivative (PID) controller parameters of an AVR system using the particle swarm optimization (PSO) algorithm is presented. This paper demonstrated in detail how to employ the PSO method to search efficiently the optimal PID controller parameters of an AVR system. The proposed approach had superior features, including easy implementation, stable convergence characteristic, and good computational efficiency. Fast tuning of optimum PID controller parameters yields high-quality solution. In order to assist estimating the performance of the proposed PSO-PID controller, a new time-domain performance criterion function was also defined. Compared with the genetic algorithm (GA), the proposed method was indeed more efficient and robust in improving the step response of an AVR system.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
43,"Goal: This paper presents a fast and accurate patient-specific electrocardiogram (ECG) classification and monitoring system. Methods: An adaptive implementation of 1-D convolutional neural networks (CNNs) is inherently used to fuse the two major blocks of the ECG classification into a single learning body: feature extraction and classification. Therefore, for each patient, an individual and simple CNN will be trained by using relatively small common and patient-specific training data, and thus, such patient-specific feature extraction ability can further improve the classification performance. Since this also negates the necessity to extract hand-crafted manual features, once a dedicated CNN is trained for a particular patient, it can solely be used to classify possibly long ECG data stream in a fast and accurate manner or alternatively, such a solution can conveniently be used for real-time ECG monitoring and early alert system on a light-weight wearable device. Results: The results over the MIT-BIH arrhythmia benchmark database demonstrate that the proposed solution achieves a superior classification performance than most of the state-of-the-art methods for the detection of ventricular ectopic beats and supraventricular ectopic beats. Conclusion: Besides the speed and computational efficiency achieved, once a dedicated CNN is trained for an individual patient, it can solely be used to classify his/her long ECG records such as Holter registers in a fast and accurate manner. Significance: Due to its simple and parameter invariant nature, the proposed system is highly generic, and, thus, applicable to any ECG dataset.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
44,"Next-generation high-energy batteries will require a rechargeable lithium metal anode, but lithium dendrites tend to form during recharging, causing short-circuit risk and capacity loss, by mechanisms that still remain elusive. Here, we visualize lithium growth in a glass capillary cell and demonstrate a change of mechanism from root-growing mossy lithium to tip-growing dendritic lithium at the onset of electrolyte diffusion limitation. In sandwich cells, we further demonstrate that mossy lithium can be blocked by nanoporous ceramic separators, while dendritic lithium can easily penetrate nanopores and short the cell. Our results imply a fundamental design constraint for metal batteries (""Sand's capacity''), which can be increased by using concentrated electrolytes with stiff, permeable, nanoporous separators for improved safety.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
45,"We prove that the set of all Lambertian reflectance functions (the mapping from surface normals to intensities) obtained with arbitrary distant right sources lies close to a 9D linear subspace. This implies that, in general, the set of images of a convex Lambertian object obtained under a wide variety of fighting conditions can be approximated accurately by a low-dimensional linear subspace, explaining prior empirical results. We also provide a simple analytic characterization of this linear space. We obtain these results by representing fighting using spherical harmonics and describing the effects of Lambertian materials as the analog of a convolution. These results allow us to construct algorithms for object recognition based on linear methods as well as algorithms that use convex optimization to enforce nonnegative fighting functions. We also show a simple way to enforce nonnegative Fighting when the images of an object lie near a 4D linear space. We apply these algorithms to perform face recognition by finding the 3D model that best matches a 2D query image.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
46,"With the breakthroughs in deep learning, the recent years have witnessed a booming of artificial intelligence (AI) applications and services, spanning from personal assistant to recommendation systems to video/audio surveillance. More recently, with the proliferation of mobile computing and Internet of Things (IoT), billions of mobile and IoT devices are connected to the Internet, generating zillions bytes of data at the network edge. Driving by this trend, there is an urgent need to push the AI frontiers to the network edge so as to fully unleash the potential of the edge big data. To meet this demand, edge computing, an emerging paradigm that pushes computing tasks and services from the network core to the network edge, has been widely recognized as a promising solution. The resulted new interdiscipline, edge AI or edge intelligence (EI), is beginning to receive a tremendous amount of interest. However, research on EI is still in its infancy stage, and a dedicated venue for exchanging the recent advances of EI is highly desired by both the computer system and AI communities. To this end, we conduct a comprehensive survey of the recent research efforts on EI. Specifically, we first review the background and motivation for AI running at the network edge. We then provide an overview of the overarching architectures, frameworks, and emerging key technologies for deep learning model toward training/inference at the network edge. Finally, we discuss future research opportunities on EI. We believe that this survey will elicit escalating attentions, stimulate fruitful discussions, and inspire further research ideas on EI.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
47,"Terahertz irradiation and sensing is being applied for the first time to a wide range of fields outside the traditional niches of space science, molecular line spectroscopy, and plasma diagnostics. This paper surveys some of the terahertz measurements and applications of interest in the biological and medical sciences.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
48,"For the last two decades, intelligent transportation systems (ITS) have emerged as an efficient way of improving the performance of transportation systems, enhancing travel security, and providing more choices to travelers. A significant change in ITS in recent years is that much more data are collected from a variety of sources and can be processed into various forms for different stakeholders. The availability of a large amount of data can potentially lead to a revolution in ITS development, changing an ITS from a conventional technology-driven system into a more powerful multifunctional data-driven intelligent transportation system ((DITS)-I-2): a system that is vision, multisource, and learning algorithm driven to optimize its performance. Furthermore, (DITS)-I-2 is trending to become a privacy-aware people-centric more intelligent system. In this paper, we provide a survey on the development of (DITS)-I-2, discussing the functionality of its key components and some deployment issues associated with (DITS)-I-2. Future research directions for the development of (DITS)-I-2 is also presented.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
49,"Vibration energy harvesting is receiving a considerable amount of interest as a means for powering wireless sensor nodes. This paper presents a small ( component volume 0.1 cm(3), practical volume 0.15 cm(3)) electromagnetic generator utilizing discrete components and optimized for a low ambient vibration level based upon real application data. The generator uses four magnets arranged on an etched cantilever with a wound coil located within the moving magnetic field. Magnet size and coil properties were optimized, with the final device producing 46 mu W in a resistive load of 4 k Omega from just 0.59 m s(-2) acceleration levels at its resonant frequency of 52 Hz. A voltage of 428 mVrms was obtained from the generator with a 2300 turn coil which has proved sufficient for subsequent rectification and voltage step-up circuitry. The generator delivers 30% of the power supplied from the environment to useful electrical power in the load. This generator compares very favourably with other demonstrated examples in the literature, both in terms of normalized power density and efficiency.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
50,"The origin and development of the adaptive approach to thermal comfort is explained. A number of recent developments in the application of the theory are considered and the origin of the differences between adaptive thermal comfort and the 'rational' indices is explored. The application of the adaptive approach to thermal comfort standards is considered and recommendations made as to the best comfort temperature, the range of comfortable environments and the maximum rate of change of indoor temperature. The application of criteria of sustainability to thermal standards for buildings is also considered. (C) 2002 Elsevier Science B.V. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
51,"Electrocatalytic splitting of water is one of the most efficient technologies for hydrogen production, and two-dimensional (2D) MoS2 has been considered as a potential alternative to Pt-based catalysts in the hydrogen evolution reaction (HER). However, the catalytic activity of 2D MoS2 is always contributed from its edge sites, leaving a large number of in-plane domains useless. Herein, we for the first time demonstrated that the catalytic activity of in-plane S atoms of MoS2 can be triggered via single-atom metal doping in HER. In experiments, single Pt atom-doped, few-layer MoS2 nanosheets (Pt-MoS2) showed a significantly enhanced HER activity compared with pure MoS2, originating from the tuned adsorption behavior of H atoms on the in-plane S sites neighboring the doped Pt atoms, according to the density functional theory (DFT) calculations. Furthermore, the HER activity of MoS2 doped with a number of transition metals was screened by virtue of DFT calculations, resulting in a volcano curve along the adsorption free energy of H atoms (Delta G(H)degrees), which was further confirmed in experiment by using non-precious metals such as Co and Ni atoms doping 2D MoS2 as the catalysts.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
52,"We investigate the performance and design of free-space optical (FSO) communication links over slow fading channels from an information theory perspective. A statistical model for the optical intensity fluctuation at the receiver due to the combined effects of atmospheric turbulence and pointing errors is derived. Unlike earlier work, our model considers the effect of beam width, detectors size, and jitter variance explicitly. Expressions for the outage probability are derived for a variety of atmospheric conditions. For given weather and misalignment conditions, the beam width is optimized to maximize the channel capacity subject to outage. Large gains in achievable rate are realized versus using a nominal beam width. In light fog, by optimizing the beam width, the achievable rate is increased by 80% over the nominal beam width at an outage probability of 10(-5). Well-known error control codes are then applied to the channel and shown to realize much of the achievable gains.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
53,"For the past three decades, discussion of naturally-occurring gas hydrates has been framed by a series of assessments that indicate enormous global volumes of methane present within gas hydrate accumulations. At present, these estimates continue to range over several orders of magnitude, creating great uncertainty in assessing those two gas hydrate issues that relate most directly to resource volumes - gas hydrate's potential as an energy resource and its possible role in ongoing climate change. However, a series of recent field expeditions have provided new insights into the nature of gas hydrate occurrence; perhaps most notably, the understanding that gas hydrates occur in a wide variety of geologic settings and modes of occurrence. These fundamental differences - which include gas hydrate concentration, host lithology, distribution within the sediment matrix, burial depth, water depth, and many others - can now be incorporated into evaluations of gas hydrate energy resource and environmental issues. With regard to energy supply potential, field data combined with advanced numerical simulation have identified gas-hydrate-bearing sands as the most feasible initial targets for energy recovery. The first assessments of potential technically-recoverable resources are now occurring, enabling a preliminary estimate of ultimate global recoverable volumes on the order of similar to 3 x 10(13) m(3) (10(15) ft(3); similar to 15 GtC). Other occurrences, such as gas hydrate-filled fractures in clay-dominated reservoirs, may also become potential energy production targets in the future; but as yet, no production concept has been demonstrated. With regard to the climate implications of gas hydrate, an analogous partitioning of global resources to determine that portion most prone to dissociation during specific future warming scenarios is needed. At present, it appears that these two portions of total gas hydrate resources (those that are the most likely targets for gas extraction and those that are the most likely to respond in a meaningful way to climate change) will be largely exclusive, as those deposits that are the most amenable to production (the more deeply buried and localized accumulations) are also those that are the most poorly coupled to oceanic and atmospheric conditions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
54,"There is a pressing need for information on the mobility of nanoparticles in the complex aqueous matrices found in realistic environmental conditions. We dispersed three different metal oxide nanoparticles (TiO2, ZnO and CeO2) in samples taken from eight different aqueous media associated with seawater, lagoon, river, and groundwater, and measured their electrophoretic mobility, state of aggregation, and rate of sedimentation. The electrophoretic mobility of the particles in a given aqueous media was dominated by the presence of natural organic matter (NOM) and ionic strength, and independent of pH. NOM adsorbed onto these nanoparticles significantly reduces their aggregation, stabilizing them under many conditions. The transition from reaction to diffusion limited aggregation occurs at an electrophoretic mobility from around -2 to -0.8 mu m s(-1) V-1 cm. These results are key for designing and interpreting nanoparticle ecotoxicity studies in various environmental conditions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
55,"Physical (PHY) layer security approaches for wireless communications can prevent eavesdropping without upper layer data encryption. However, they are hampered by wireless channel conditions: absent feedback, they are typically feasible only when the source-destination channel is better than the source-eavesdropper channel. Node cooperation is a means to overcome this challenge and improve the performance of secure wireless communications. This paper addresses secure communications of one source-destination pair with the help of multiple cooperating relays in the presence of one or more eavesdroppers. Three cooperative schemes are considered: decode-and-forward (DF), amplify-and-forward (AF), and cooperative jamming (CJ). For these schemes, the relays transmit a weighted version of a reencoded noise-free message signal (for DF), a received noisy source signal (for AF), or a common jamming signal (for CJ). Novel system designs are proposed, consisting of the determination of relay weights and the allocation of transmit power, that maximize the achievable secrecy rate subject to a transmit power constraint, or, minimize the transmit power subject to a secrecy rate constraint. For DF in the presence of one eavesdropper, closed-form optimal solutions are derived for the relay weights. For other problems, since the optimal relay weights are difficult to obtain, several criteria are considered leading to suboptimal but simple solutions, i.e., the complete nulling of the message signals at all eavesdroppers (for DF and AF), or the complete nulling of jamming signal at the destination (for CJ). Based on the designed relay weights, for DF in the presence of multiple eavesdroppers, and for CJ in the presence of one eavesdropper, the optimal power allocation is obtained in closed-form; in all other cases the optimal power allocation is obtained via iterative algorithms. Numerical evaluation of the obtained secrecy rate and transmit power results show that the proposed design can significantly improve the performance of secure wireless communications.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
56,"A Product-Service System (PSS) is an integrated combination of products and services. This Western concept embraces a service-led competitive strategy, environmental sustainability, and the basis to differentiate from competitors who simply offer lower priced products. This paper aims to report the state-of-the-art of PSS research by presenting a clinical review of literature currently available on this topic. The literature is classified and the major outcomes of each study are addressed and analysed. On this basis, this paper defines the PSS concept, reports on its origin and features, gives examples of applications along with potential benefits and barriers to adoption, summarizes available tools and methodologies, and identifies future research challenges.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
57,"Additive manufacturing (AM) technologies have been successfully applied in various applications. Fused deposition modeling (FDM), one of the most popular AM techniques, is the most widely used method for fabricating thermoplastic parts those are mainly used as rapid prototypes for functional testing with advantages of low cost, minimal wastage, and ease of material change. Due to the intrinsically limited mechanical properties of pure thermoplastic materials, there is a critical need to improve mechanical properties for FDM-fabricated pure thermoplastic parts. One of the possible methods is adding reinforced materials (such as carbon fibers) into plastic materials to form thermoplastic matrix carbon fiber reinforced plastic (CFRP) composites those could be directly used in the actual application areas, such as aerospace, automotive, and wind energy. This paper is going to present FDM of thermoplastic matrix CFRP composites and test if adding carbon fiber (different content and length) can improve the mechanical properties of FDM-fabricated parts. The CFRP feedstock filaments were fabricated from plastic pellets and carbon fiber powders for FDM process. After FDM fabrication, effects on the tensile properties (including tensile strength, Young's modulus, toughness, yield strength, and ductility) and flexural properties (including flexural stress, flexural modulus, flexural toughness, and flexural yield strength) of specimens were experimentally investigated. In order to explore the parts fracture reasons during tensile and flexural tests, fracture interface of CFRP composite specimens after tensile testing and flexural testing was observed and analyzed using SEM micrograph. (C) 2015 Elsevier Ltd. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
58,"Nonorthogonal multiple access (NOMA) represents a paradigm shift from conventional orthogonal multiple-access (MA) concepts and has been recognized as one of the key enabling technologies for fifth-generation mobile networks. In this paper, the impact of user pairing on the performance of two NOMA systems, i.e., NOMA with fixed power allocation (F-NOMA) and cognitive-radio-inspired NOMA (CR-NOMA), is characterized. For F-NOMA, both analytical and numerical results are provided to demonstrate that F-NOMA can offer a larger sum rate than orthogonal MA, and the performance gain of F-NOMA over conventional MA can be further enlarged by selecting users whose channel conditions are more distinctive. For CR-NOMA, the quality of service (QoS) for users with poorer channel conditions can be guaranteed since the transmit power allocated to other users is constrained following the concept of cognitive radio networks. Because of this constraint, CR-NOMA exhibits a different behavior compared with F-NOMA. For example, for the user with the best channel condition, CR-NOMA prefers to pair it with the user with the second best channel condition, whereas the user with the worst channel condition is preferred by F-NOMA.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
59,"Based on an extensive set of density functional theory calculations it is shown that for a class of catalytic reactions there is a universal, reactant independent relation between the reaction activation energy and the stability of reaction intermediates. This leads directly to a universal relationship between adsorption energies and catalytic activity, which is used to pinpoint what it is that determines the best catalyst for a given reaction. The universality principle rationalizes a number of known facts about catalysts and points to new ways of improving them. (C) 2002 Elsevier Science (USA).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
60,"We quantify the performance of wireless transmissions over random fading channels at high signal-to-noise ratio (SNR). The performance criteria we consider are average probability of error and outage probability. We show that as functions of the average SNR, they can both be characterized by two parameters: the diversity and coding gains. They both exhibit identical diversity orders, but their coding gains in decibels differ by a constant. The diversity and coding gains are found to depend on the behavior of the random SNR's probability density function only at the origin, or equivalently, on the decaying order of the corresponding moment generating function (i.e., how fast the moment generating function goes to zero as its argument goes to infinity). Diversity and coding gains for diversity combining systems are expressed in terms of the diversity branches' individual diversity and coding gains, where the branches can come from any diversity technique such as space, time, frequency, or, multipath. The proposed analysis offers a simple and unifying approach to evaluating the performance of uncoded and (possibly space-time) coded transmissions over fading channels, and the method applies to almost all digital modulation schemes, including M-ary phase-shift keying, quadrature amplitude modulation, and frequency-shift keying with coherent or noncoherent detection.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
61,"Consumer-grade range cameras such as the Kinect sensor have the potential to be used in mapping applications where accuracy requirements are less strict. To realize this potential insight into the geometric quality of the data acquired by the sensor is essential. In this paper we discuss the calibration of the Kinect sensor, and provide an analysis of the accuracy and resolution of its depth data. Based on a mathematical model of depth measurement from disparity a theoretical error analysis is presented, which provides an insight into the factors influencing the accuracy of the data. Experimental results show that the random error of depth measurement increases with increasing distance to the sensor, and ranges from a few millimeters up to about 4 cm at the maximum range of the sensor. The quality of the data is also found to be influenced by the low resolution of the depth measurements.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
62,This paper presents a predictive current control method and its application to a voltage source inverter. The method uses a discrete-time model of the system to predict the future value of the load current for all possible voltage vectors generated by the inverter. The voltage vector which minimizes a quality function is selected. The quality function used in this work evaluates the current error at the next sampling time. The performance of the proposed predictive control method is compared with hysteresis and pulsewidth modulation control. The results show that the predictive method controls very effectively the load current and performs very well compared with the classical solutions.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
63,"This paper overviews theoretical and practical design issues related to inductive power transfer systems and verifies the developed theory using a practical electric vehicle battery charger. The design focuses on the necessary approaches to ensure power transfer over the complete operating range of the system. As such, a new approach to the design of the primary resonant circuit is proposed, whereby deviations from design expectations due to phase or frequency shift are minimized. Of particular interest are systems that are neither loosely nor tightly coupled. The developed solution depends on the selected primary and secondary. resonant topologies, the magnetic coupling coefficient, and the secondary quality factor.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
64,"This letter presents our initial results in deep learning for channel estimation and signal detection in orthogonal frequency-division multiplexing (OFDM) systems. In this letter, we exploit deep learning to handle wireless OFDM channels in an end-to-end manner. Different from existing OFDM receivers that first estimate channel state information (CSI) explicitly and then detect/recover the transmitted symbols using the estimated CSI, the proposed deep learning-based approach estimates CSI implicitly and recovers the transmitted symbols directly. To address channel distortion, a deep learning model is first trained offline using the data generated from simulation based on channel statistics and then used for recovering the online transmitted data directly. From our simulation results, the deep learning based approach can address channel distortion and detect the transmitted symbols with performance comparable to the minimum mean-square error estimator. Furthermore, the deep learning-based approach is more robust than conventional methods when fewer training pilots are used, the cyclic prefix is omitted, and nonlinear clipping noise exists. In summary, deep learning is a promising tool for channel estimation and signal detection in wireless communications with complicated channel distortion and interference.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
65,"The relatively unused millimeter-wave (mmWave) spectrum offers excellent opportunities to increase mobile capacity due to the enormous amount of available raw bandwidth. This paper presents experimental measurements and empirically-based propagation channel models for the 28, 38, 60, and 73 GHz mmWave bands, using a wideband sliding correlator channel sounder with steerable directional horn antennas at both the transmitter and receiver from 2011 to 2013. More than 15,000 power delay profiles were measured across the mmWave bands to yield directional and omnidirectional path loss models, temporal and spatial channel models, and outage probabilities. Models presented here offer side-by-side comparisons of propagation characteristics over a wide range of mmWave bands, and the results and models are useful for the research and standardization process of future mmWave systems. Directional and omnidirectional path loss models with respect to a 1 m close-in free space reference distance over a wide range of mmWave frequencies and scenarios using directional antennas in real-world environments are provided herein, and are shown to simplify mm Wave path loss models, while allowing researchers to globally compare and standardize path loss parameters for emerging mmWave wireless networks. A new channel impulse response modeling framework, shown to agree with extensive mmWave measurements over several bands, is presented for use in link-layer simulations, using the observed fact that spatial lobes contain multipath energy that arrives at many different propagation time intervals. The results presented here may assist researchers in analyzing and simulating the performance of next-generation mmWave wireless networks that will rely on adaptive antennas and multiple-input and multiple-output (MIMO) antenna systems.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
66,"Transmit beamforming and receive combining are simple methods for exploiting the significant diversity that is available in multiple-input multiple-output (MIMO) wireless systems. Unfortunately, optimal performance requires either complete channel knowledge or knowledge of the optimal beamforming vector; both are hard to realize. In this correspondence, a quantized maximum signal-to-noise ratio (SNR) beamforming technique is proposed where the receiver only sends the label of the best beamforming vector in a predetermined codebook to the transmitter. By using the distribution of the optimal beamforming vector in independent and identically distributed Rayleigh fading matrix channels, the codebook design problem is solved and related to the problem of Grassmannian line packing. The proposed design criterion is flexible enough to allow for side constraints on the codebook vectors. Bounds on the codebook size are derived to guarantee fall diversity order. Results on the density of Grassmannian line packings are derived and used to develop bounds on the codebook size given a capacity or SNR loss. Monte Carlo simulations are presented that compare the probability of error for different quantization strategies.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
67,"In order to use environmental models effectively for management and decision-making, it is vital to establish an appropriate level of confidence in their performance. This paper reviews techniques available across various fields for characterising the performance of environmental models with focus on numerical, graphical and qualitative methods. General classes of direct value comparison, coupling real and modelled values, preserving data patterns, indirect metrics based on parameter values, and data transformations are discussed. In practice environmental modelling requires the use and implementation of workflows that combine several methods, tailored to the model purpose and dependent upon the data and information available. A five-step procedure for performance evaluation of models is suggested, with the key elements including: (i) (re)assessment of the model's aim, scale and scope; (ii) characterisation of the data for calibration and testing; (iii) visual and other analysis to detect under- or non-modelled behaviour and to gain an overview of overall performance; (iv) selection of basic performance criteria; and (v) consideration of more advanced methods to handle problems such as systematic divergence between modelled and observed values. (C) 2012 Elsevier Ltd. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
68,"To facilitate the efficient support of quality of service (QoS) in next-generation wireless networks, it is essential to model a wireless channel in terms of connection-level QoS metrics such as data rate, delay, and delay-violation probability. However, the existing wireless channel models, i.e., physical-layer channel models, do not explicitly characterize a wireless channel in terms of these QoS metrics. In this paper, we propose and develop a link-layer channel model termed effective capacity (EC). In this approach, we first model a wireless link by two EC functions, namely, the probability of nonempty buffer, and the Qos exponent of a connection. Then, we propose a simple and efficient algorithm to estimate these EC functions. The physical-layer analogs of these two link-layer EC functions are the marginal distribution (e.g., Rayleigh-Ricean distribution) and the Doppler spectrum, respectively. The key advantages of the EC link-layer modeling and estimation are: 1) ease of translation into QoS guarantees, such as delay bounds; 2) simplicity of implementation; and 3) accuracy, and hence, efficiency in admission control and resource reservation. We illustrate the advantage of our approach with a set of simulation experiments, which show that the actual QoS metric is closely approximated by the QoS metric predicted by the EC link-layer model, under a wide range of conditions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
69,"RE/TiO2 photocatalysts were prepared by the sol-gel method using rare earth (RE = La3+, Ce3+, Er3+, Pr3+, Gd3+, Nd3+, Sm3+) metal salts and tetra-n-butyl titanate as precursors, and were characterized by XRD, IR, UV-vis diffuse reflection, and transient absorption spectra. Their photocatalytic activities were evaluated using nitrite as a decomposition objective. As a result, suitable content of doping rare earth in TiO2 can efficiently extend the light absorption properties to the visible region. At the same time, it is beneficial to NO2- adsorption over the catalysts due to rare earth doping. RE/TiO2 samples can enhance the photocatalytic activity to some extent as compared with naked TiO2. The increase in photoactivity is probably due to the higher adsorption, red shifts to a longer wavelength, and the increase in the interfacial electron transfer rate. Nitrite is almost completely degraded over RE/TiO2 catalysts after longer irradiation, which is different from Degussa P-25 with a plateau of activity after ca. 20 min irradiation. Gd3+-doped TiO2 showed the highest reaction activity among all concerned RE-doped samples because of its specific characteristics. The amount of RE doping was an important factor affecting photocatalytic activity; the optimum amount of RE doping is ca. 0.5 wt%, at which each RE/TiO2 sample shows the most reactivity. The photocatalytic degradation reaction of nitrite over Gd3+-doped samples and P-25 follows apparent first order kinetics, which is different from that of Sm3+, Ce3+, Er3+, Pr3+, La3+, and Nd3+-doped TiO2 catalysts, which obey zero-order kinetics, indicating that these processes were dominated by electron-hole recombination. (C) 2002 Elsevier Science (USA).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
70,Electrodialysis is a mature process which is applied since more than 50 years on a large industrial scale for the production of potable water from brackish water sources But more recently electrodialysis in combination with bipolar membranes or with ion-exchange resins has found a large number of new interesting applications in the chemical process industry in the food and drug industry as well as in waste water treatment and the production of high quality industrial water In this paper the principle of electrodialysis is described and its advantages and limitations in various applications are pointed out More recent developments in electrodialysis as well as in related processes such as electrodialytic water dissociation or continuous electrodeionization are discussed and their present and potential future applications are indicated Research needs for a sustainable growth of electrodialysis and related processes are pointed out (C) 2010 Elsevier B V All rights reserved,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
71,"Current regulators. for ac inverters are commonly categorized as hysteresis, linear PI, or deadbeat predictive regulators, with a further sub-classification into stationary ABC frame and synchronous d-q frame implementations. Synchronous frame regulators are generally accepted to have a better performance, than stationary frame regulators, as they operate on dc quantities and hence can eliminate steady-state errors. This paper establishes a theoretical connection between these two classes of regulators and proposes a new type of stationary frame regulator, the P+Resonant regulator, which achieves the same transient and steady-state performance as a synchronous frame PI regulator. The new regulator is applicable to both single-phase and three phase inverters.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
72,"We study the problem of object recognition for categories for which we have no training examples, a task also called zero-data or zero-shot learning. This situation has hardly been studied in computer vision research, even though it occurs frequently; the world contains tens of thousands of different object classes, and image collections have been formed and suitably annotated for only a few of them. To tackle the problem, we introduce attribute-based classification: Objects are identified based on a high-level description that is phrased in terms of semantic attributes, such as the object's color or shape. Because the identification of each such property transcends the specific learning task at hand, the attribute classifiers can be prelearned independently, for example, from existing image data sets unrelated to the current task. Afterward, new classes can be detected based on their attribute representation, without the need for a new training phase. In this paper, we also introduce a new data set, Animals with Attributes, of over 30,000 images of 50 animal classes, annotated with 85 semantic attributes. Extensive experiments on this and two more data sets show that attribute-based classification indeed is able to categorize images without access to any training images of the target classes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
73,"Photoelectrochemical water splitting is a promising route for the renewable production of hydrogen fuel. This work presents the results of a technical and economic feasibility analysis conducted for four hypothetical, centralized, large-scale hydrogen production plants based on this technology. The four reactor types considered were a single bed particle suspension system, a dual bed particle suspension system, a fixed panel array, and a tracking concentrator array. The current performance of semiconductor absorbers and electrocatalysts were considered to compute reasonable solar-to-hydrogen conversion efficiencies for each of the four systems. The U.S. Department of Energy H2A model was employed to calculate the levelized cost of hydrogen output at the plant gate at 300 psi for a 10 tonne per day production scale. All capital expenditures and operating costs for the reactors and auxiliaries (compressors, control systems, etc.) were considered. The final cost varied from $1.60-$10.40 per kg H-2 with the particle bed systems having lower costs than the panel-based systems. However, safety concerns due to the cogeneration of O-2 and H-2 in a single bed system and long molecular transport lengths in the dual bed system lead to greater uncertainty in their operation. A sensitivity analysis revealed that improvement in the solar-to-hydrogen efficiency of the panel-based systems could substantially drive down their costs. A key finding is that the production costs are consistent with the Department of Energy's targeted threshold cost of $2.00-$4.00 per kg H-2 for dispensed hydrogen, demonstrating that photoelectrochemical water splitting could be a viable route for hydrogen production in the future if material performance targets can be met.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
74,"We present an experiment-based characterization of passive suppression and active self-interference cancellation mechanisms in full-duplex wireless communication systems. In particular, we consider passive suppression due to antenna separation at the same node, and active cancellation in analog and/or digital domain. First, we show that the average amount of cancellation increases for active cancellation techniques as the received self-interference power increases. Our characterization of the average cancellation as a function of the self-interference power allows us to show that for a constant signal-to-interference ratio at the receiver antenna (before any active cancellation is applied), the rate of a full-duplex link increases as the self-interference power increases. Second, we show that applying digital cancellation after analog cancellation can sometimes increase the self-interference, and thus digital cancellation is more effective when applied selectively based on measured suppression values. Third, we complete our study of the impact of self-interference cancellation mechanisms by characterizing the probability distribution of the self-interference channel before and after cancellation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
75,"This paper provides a novel solution to the problem of robust model predictive control of constrained, linear, discrete-time systems in the presence of bounded disturbances. The optimal control problem that is solved online includes, uniquely, the initial state of the model employed in the problem as a decision variable. The associated value function is zero in a disturbance invariant set that serves as the 'origin' when bounded disturbances are present, and permits a strong stability result, namely robust exponential stability of the disturbance invariant set for the controlled system with bounded disturbances, to be obtained. The resultant online algorithm is a quadratic program of similar complexity to that required in conventional model predictive control. (C) 2004 Elsevier Ltd. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
76,"A framework for positioning, navigation, and tracking problems using particle filters (sequential Monte Carlo methods) is developed. It consists of a class of motion models and a general nonlinear measurement equation in position. A general algorithm is presented, which is parsimonious with the particle dimension. It is based on marginalization, enabling a Kalman filter to estimate all position derivatives, and the particle filter becomes low dimensional. This is of utmost importance for high-performance real-time applications. Automotive and airborne applications illustrate numerically the advantage over classical Kalman filter-based algorithms. Here, the use of nonlinear models and non-Gaussian noise is the main explanation for the improvement in accuracy. More specifically, we describe how the technique of map matching is used to match an aircraft's elevation profile to a digital elevation map and a car's horizontal driven path to a street map. In both cases, real-time implementations are available, and tests have shown that the accuracy in both cases is comparable with satellite navigation (as GPS) but with higher integrity. Based on simulations, we also argue how the particle filter can be used for positioning based on cellular phone measurements, for integrated navigation in aircraft, and for target tracking in aircraft and cars. Finally, the particle filter enables a promising solution to the combined task of navigation and tracking, with possible application to airborne hunting and collision avoidance systems in cars.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
77,"Alginate gels have been used in both drug delivery and cell encapsulation applications in the bead form usually produced by dripping alginate solution into a CaCl2 bath. The major disadvantages to these systems are that the gelation rate is hard to control, the resulting structure is not uniform, and mechanically strong and complex-shaped 3-D structures are difficult to achieve. In this work controlled gelation rate was achieved with CaCO3-GDL and CaSO4-CaCO3-GDL systems, and homogeneous alginate gels were formulated as scaffolds with defined dimensions for tissue engineering applications. Gelation rate increased with increasing total calcium content, increasing proportion of CaSO4, increasing temperature and decreasing alginate concentration. Mechanical properties of the alginate gels were controlled by the compositional variables. Slower gelation systems generate more uniform and mechanically stronger gels than faster gelation systems. The compressive modulus and strength increased with alginate concentration, total calcium content, molecular weight and guluronic acid (G) content of the alginate. MC3T3-E1 osteoblastic cells were uniformly incorporated in the alginate gels and cultured in vitro. These results demonstrated how alginate gel and gel/cell systems could be Formulated with controlled structure. gelation rate, and mechanical properties for tissue engineering and other biomedical applications. (C) 2001 Elsevier Science Ltd. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
78,"The objective of this study was to develop anatomically correct whole body human models of an adult male (34 years old), an adult female (26 years old) and two children (an 11-year-old girl and a six-year-old boy) for the optimized evaluation of electromagnetic exposure. These four models are referred to as the Virtual Family. They are based on high resolution magnetic resonance (MR) images of healthy volunteers. More than 80 different tissue types were distinguished during the segmentation. To improve the accuracy and the effectiveness of the segmentation, a novel semi-automated tool was used to analyze and segment the data. All tissues and organs were reconstructed as three-dimensional (3D) unstructured triangulated surface objects, yielding high precision images of individual features of the body. This greatly enhances the meshing flexibility and the accuracy with respect to thin tissue layers and small organs in comparison with the traditional voxel-based representation of anatomical models. Conformal computational techniques were also applied. The techniques and tools developed in this study can be used to more effectively develop future models and further improve the accuracy of the models for various applications. For research purposes, the four models are provided for free to the scientific community.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
79,"In this paper, we developed and evaluated a robust single-lead electrocardiogram (ECG) delineation system based on the wavelet transform (WT). In a first step, QRS complexes are detected. Then, each QRS is delineated by detecting and identifying the peaks of the individual waves, as well as the complex onset and end. Finally, the determination of P and T wave peaks, onsets and ends is performed. We evaluated the algorithm on several manually annotated databases, such as MIT-BIH Arrhythmia, QT, European ST-T and CSE databases, developed for validation purposes. The QRS detector obtained a sensitivity of Se = 99.66% and a positive predictivity of P+ = 99.56% over the first lead of the validation databases (more than 980,000 beats), while for the well-known MIT-BIH Arrhythmia Database, Se and P+ over 99.8% were attained. As for the delineation of the ECG waves, the mean and standard deviation of the differences between the automatic and manual annotations were computed. The mean error obtained with the WT approach was found not to exceed one sampling interval, while,the standard deviations were around the accepted tolerances between expert physicians, outperforming the results of other well known algorithms, especially in determining the end of T wave.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
80,"A thorough comparison of gold catalysts on different support materials as well as activity measurements for Au on mixed oxides (Au/Fe2O3. MgO) reveal enhanced CO oxidation rates for a group of ""active"" support materials (Fe2O3, TiO2, NiOx, CoOx), For Au/Fe2O3, it is shown that large amounts of oxygen can adsorb on the support, which most likely represents the oxygen supply during reaction. The high mobility of these oxygen species and the absence of oxygen scrambling with labeled O-36(2) in pulse experiments strongly suggest the adsorption in a molecular form on the iron oxide support. From the absence of the doubly marked product (COO)-O-18-O-18, reaction schemes via a carbonate-like intermediate or transition-state can be ruled out. For Au catalysts supported on active materials, the dominant reaction pathway is concluded to involve adsorption of a mobile, molecular oxygen species on the support, dissociation at the interface, and reaction on the gold particles and/or at the interface with CO adsorbed on the gold. The facile supply with reactive oxygen, via the support, serves as a probable explanation for the observed independence of the turnover frequency from the Au particle size on these catalysts, while for Au supported on inert materials, where the oxygen supply most likely proceeds via direct dissociative adsorption on the Au particles, the size of the latter plays a decisive role. (C) 2001 Academic Press.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
81,"We present a comprehensive study and evaluation of existing single-image dehazing algorithms, using a new large-scale benchmark consisting of both synthetic and real-world hazy images, called REalistic Single-Image DEhazing (RESIDE). RESIDE highlights diverse data sources and image contents, and is divided into five subsets, each serving different training or evaluation purposes. We further provide a rich variety of criteria for dehazing algorithm evaluation, ranging from full-reference metrics to no-reference metrics and to subjective evaluation, and the novel task-driven evaluation. Experiments on RESIDE shed light on the comparisons and limitations of the state-of-the-art dehazing algorithms, and suggest promising future directions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
82,"Operations management researchers and practitioners face new challenges in integrating issues of sustainability with their traditional areas of interest. During the past 20 years, there has been growing pressure on businesses to pay more attention to the environmental and resource consequences of the products and services they offer and the processes they deploy. One symptom of this pressure is the movement towards triple bottom line reporting (3BL) concerning the relationship of profit, people, and the planet. The resulting challenges include integrating environmental, health, and safety concerns with green-product design, lean and green operations, and closed-loop supply chains. We review these and other ""sustainability"" themes covered in the first 50 issues of Production and Operations Management and conclude with some thoughts on future research challenges in sustainable operations management.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
83,"The well-known condition for standing stability in static situations is that the vertical projection of the centre of mass (CoM) should be within the base of support (BoS). On the basis of a simple inverted pendulum model, an extension of this rule is proposed for dynamical situations: the position of (the vertical projection of) the CoM plus its velocity times a factor rootl/g should be within the BoS, l being leg length and g the acceleration of gravity. It is proposed to name this vector quantity 'extrapolated centre of mass position' (XcoM). The definition suggests as a measure of stability the 'margin of stability' b, the minimum distance from XcoM to the boundaries of the BoS. An alternative measure is the temporal stability margin tau, the time in which the boundary of the BoS would be reached without intervention. Some experimental data of subjects standing on one or two feet, flatfoot and tiptoe, are presented to give an idea of the usual ranges of these margins of stability. Example data on walking are also presented. (C) 2004 Elsevier Ltd. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
84,"This paper presents three multivariate geostatistical algorithms for incorporating a digital elevation model into the spatial prediction of rainfall: simple kriging with varying local means; kriging with an external drift; and colocated cokriging. The techniques are illustrated using annual and monthly rainfall observations measured at 36 climatic stations in a 5000 km(2) region of Portugal. Cross validation is used to compare the prediction performances of the three geostatistical interpolation algorithms with the straightforward linear regression of rainfall against elevation and three univariate techniques: the Thiessen polygon, inverse square distance; and ordinary kriging. Larger prediction errors are obtained for the two algorithms (inverse square distance, Thiessen polygon) that ignore both the elevation and rainfall records at surrounding stations. The three multivariate geostatistical algorithms outperform other interpolators, in particular the linear regression, which stresses the importance of accounting for spatially dependent rainfall observations in addition to the colocated elevation. Last, ordinary kriging yields more accurate predictions than linear regression when the correlation between rainfall and elevation is moderate (less than 0.75 in the case study). (C) 2000 Elsevier Science B.V. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
85,This paper applies a new robust and powerful metaheuristic algorithm called Symbiotic Organisms Search (SOS) to numerical optimization and engineering design problems. SOS simulates the symbiotic interaction strategies adopted by organisms to survive and propagate in the ecosystem. Twenty-six unconstrained mathematical problems and four structural engineering design problems are tested and obtained results compared with other well-known optimization methods. Obtained results confirm the excellent performance of the SOS method in solving various complex numerical problems. (C) 2014 Elsevier Ltd. All rights reserved.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
86,"We consider radio applications in sensor networks, where the nodes operate on batteries so that energy consumption must be minimized, while satisfying given throughput and delay requirements. In this context, we analyze the best modulation and transmission strategy to minimize the total energy consumption required to send a given number of bits. The total energy consumption includes both the transmission energy and the circuit energy consumption. We first consider multi-input-multi-output (MIMO) systems based on Alamouti diversity schemes, which have good spectral efficiency but also more circuitry that consumes energy. We then extend our energy-efficiency analysis Of MIMO systems to individual single-antenna nodes that cooperate to form multiple-antenna transmitters or receivers. By transmitting and/or receiving information jointly, we show that tremendous energy saving is possible for transmission distances larger than a given threshold, even When we take into account the local energy cost necessary for joint information transmission and reception. We also show that over some distance ranges, cooperative MIMO transmission and reception can simultaneously achieve both energy savings and delay reduction.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
87,"Over the last few years, the fourth industrial revolution has attracted more and more attentions all around the world. In the current literature, there is still a lack of efforts to systematically review the state of the art of this new industrial revolution wave. The aim of this study is to address this gap by investigating the academic progresses in Industry 4.0. A systematic literature review was carried out to analyse the academic articles within the Industry 4.0 topic that were published online until the end of June 2016. In this paper, the obtained results from both the general data analysis of included papers (e.g. relevant journals, their subject areas and categories, conferences, keywords) and the specific data analysis corresponding to four research sub-questions are illustrated and discussed. These results not only summarise the current research activities (e.g. main research directions, applied standards, employed software and hardware), but also indicate existing deficiencies and potential research directions through proposing a research agenda. Findings of this review can be used as the basis for future research in Industry 4.0 and related topics.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
88,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
89,"Adaptive beamforming methods are known to degrade if some of underlying assumptions on the environment, sources, or sensor array become violated. In particular, if the desired signal is present in training snapshots, the adaptive array performance may be quite sensitive even to slight mismatches between the presumed and actual signal steering vectors (spatial signatures). Such mismatches can occur as a result of environmental nonstationarities, look direction errors, imperfect array calibration, distorted antenna shape, as well as distortions caused by medium inhomogeneities, near-far mismatch, source spreading, and local scattering. The similar type of performance degradation can occur when the signal steering vector is known exactly but the training sample size is small. In this paper, we develop a new approach to robust adaptive beamforming in the presence of an arbitrary unknown signal steering vector mismatch. Our approach is based oil the optimization of worst-case performance. It turns out that the natural formulation of this adaptive beamforming problem involves minimization of a quadratic function subject to infinitely many nonconvex quadratic constraints. We show that this (originally intractable) problem can be reformulated in a convex form as the so-called second-order cone (SOC) program and solved efficiently (in polynomial time) using the well-established interior point method. It is also shown that the proposed technique can be interpreted in terms of diagonal loading where the optimal value of the diagonal loading factor is computed based on the known level of uncertainty of the signal steering vector. Computer simulations with several frequently encountered types of signal steering vector mismatches show better performance of our robust beamformer as compared with existing adaptive beamforming algorithms.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
90,"A key challenge of future mobile communication research is to strike an attractive compromise between wireless network's area spectral efficiency and energy efficiency. This necessitates a clean-slate approach to wireless system design, embracing the rich body of existing knowledge, especially on multiple-input-multiple-ouput (MIMO) technologies. This motivates the proposal of an emerging wireless communications concept conceived for single-radio-frequency (RF) large-scale MIMO communications, which is termed as SM. The concept of SM has established itself as a beneficial transmission paradigm, subsuming numerous members of the MIMO system family. The research of SM has reached sufficient maturity to motivate its comparison to state-of-the-art MIMO communications, as well as to inspire its application to other emerging wireless systems such as relay-aided, cooperative, small-cell, optical wireless, and power-efficient communications. Furthermore, it has received sufficient research attention to be implemented in testbeds, and it holds the promise of stimulating further vigorous interdisciplinary research in the years to come. This tutorial paper is intended to offer a comprehensive state-of-the-art survey on SM-MIMO research, to provide a critical appraisal of its potential advantages, and to promote the discussion of its beneficial application areas and their research challenges leading to the analysis of the technological issues associated with the implementation of SM-MIMO. The paper is concluded with the description of the world's first experimental activities in this vibrant research field.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
91,"Aim To analyse possible effects of titanium surface topography on bone integration. Materials and methods Our analyses were centred on a PubMed search that identified 1184 publications of assumed relevance; of those, 1064 had to be disregarded because they did not accurately present in vivo data on bone response to surface topography. The remaining 120 papers were read and analysed, after removal of an additional 20 papers that mainly dealt with CaP-coated and Zr implants; 100 papers remained and formed the basis for this paper. The bone response to differently configurated surfaces was mainly evaluated by histomorphometry (bone-to-implant contact), removal torque and pushout/pullout tests. Results and discussion A huge number of the experimental investigations have demonstrated that the bone response was influenced by the implant surface topography; smooth (S-a < 0.5 mu m) and minimally rough (S-a 0.5-1 mu m) surfaces showed less strong bone responses than rougher surfaces. Moderately rough (S-a > 1-2 mu m) surfaces showed stronger bone responses than rough (S-a > 2 mu m) in some studies. One limitation was that it was difficult to compare many studies because of the varying quality of surface evaluations; a surface termed 'rough' in one study was not uncommonly referred to as 'smooth' in another; many investigators falsely assumed that surface preparation per se identified the roughness of the implant; and many other studies used only qualitative techniques such as SEM. Furthermore, filtering techniques differed or only height parameters (S-a, R-a) were reported. Conclusions center dot Surface topography influences bone response at the micrometre level. center dot Some indications exist that surface topography influences bone response at the nanometre level. center dot The majority of published papers present an inadequate surface characterization. center dot Measurement and evaluation techniques need to be standardized. center dot Not only height descriptive parameters but also spatial and hybrid ones should be used. To cite this article:Wennerberg A, Albrektsson T. Effects of titanium surface topography on bone integration: a systematic review.Clin. Oral Impl. Res. 20 (Suppl. 4), 2009; 172-184.doi: 10.1111/j.1600-0501.2009.01775.x.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
92,"As corporations attempt to move toward environmental sustainability, management must extend their efforts to improve environmental practices across their supply chain. The literature characterizing environmental management within the supply chain has been slowly building, but remains sparse. Using a survey of North American manufacturers, this paper examines the impact of environmental collaborative activities on manufacturing performance. Environmental collaboration was defined specifically to focus on inter-organizational interactions between supply chain members, including such aspects as joint environmental goal setting, shared environmental planning, and working together to reduce pollution or other environmental impacts. These practices can be directed either upstream toward suppliers or downstream toward customers. The influence of collaboration in each direction was empirically assessed for multiple objective and perceptual measures of manufacturing performance using a sample of plants in the package printing industry. Generally, the benefits of collaborative green practices with suppliers were broadest. In contrast, collaboration with customers yielded mixed outcomes. Overall, evidence emerged that upstream practices were more closely linked with process-based performance, while downstream collaboration was associated with product-based performance. (c) 2007 Elsevier B.V. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
93,"It is Suggested that there may be several effects contributing to the special catalytic properties of supported nanosized gold particles, and that it is useful to order them in a hierarchy. The most important effect is related to the availability of many low-coordinated gold atoms on the small particles. Effects related to the interaction with the Support may also contribute, but to a considerably smaller extent. We base the analysis on a new set of experimental results comparing the CO oxidation rates over gold supported on different reducible and nonreducible oxides, on an analysis of a large number of published activity data, and on an analysis of density-functional calculations of the effect of metal coordination numbers in comparison to the role of charge transfer, layer thickness, and interactions with the support. (C) 2004 Elsevier Inc. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
94,"Today, tissue engineers are attempting to engineer virtually every human tissue. Potential tissue-engineered products include cartilage, bone. heart valves, nerves. muscle, bladder, liver, etc. Tissue engineering techniques generally require the use of a porous scaffold, which serves as a three-dimensional template for initial cell attachment and subsequent tissue formation both in vitro and in vivo. The scaffold provides the necessary support for cells to attach, proliferate, and maintain their differentiated function. Its architecture defines the ultimate shape of the new grown soft or hard tissue. In the early days of tissue engineering, clinically established materials such as collagen and polyglycolide were primarily considered as the material of choice for scaffolds. The challenge for more advanced scaffold systems is to arrange cells/tissue in an appropriate 3D configuration and present molecular signals in an appropriate spatial and temporal fashion so that the individual cells will grow and form the desired tissue structures - and do so in a way that can be carried out reproducibly, economically, and on a large scale. This paper is not intended to provide a general review of tissue engineering, but specifically concentrate on the design and processing of synthetic polymeric scaffolds. The material properties and design requirements are discussed. An overview of the various fabrication techniques of scaffolds is presented, beginning with the basic and conventional techniques to the more recent, novel methods that combine both scaffold design and fabrication capabilities.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
95,"This paper presents an overview of color and texture descriptors that have been approved for the Final Committee Draft of the MPEG-7 standard, The color and texture descriptors that are described in this paper have undergone extensive evaluation and development during the past two years, Evaluation criteria include effectiveness of the descriptors in similarity retrieval, as well as extraction, storage, and representation complexities, The color descriptors in the standard include a histogram descriptor that is coded using the Haar transform, a color structure histogram, a dominant color descriptor, and a color layout descriptor, The three texture descriptors include one that characterizes homogeneous texture regions and another that represents the local edge distribution. A compact descriptor that facilitates texture browsing is also defined, Each of the descriptors is explained in detail by their semantics, extraction and usage. Effectiveness is documented by experimental results.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
96,"In this study a binary Mg-Zn magnesium alloy was researched as a degradable biomedical material. An Mg-Zn alloy fabricated with high-purity raw materials and using a clean melting process had very low levels of impurities. After solid solution treatment and hot working the grain size of the Mg-Zn alloy was finer and a uniform single phase was gained. The mechanical properties of this Mg-Zn alloy were suitable for implant applications, i.e. the tensile strength and elongation achieved were similar to 279.5 MPa and 18.8%, respectively. The results of in vitro degradation experiments including electrochemical measurements and immersion tests revealed that the zinc could elevate the corrosion potential of Mg in simulated body fluid (SBF) and reduce the degradation rate. The corrosion products on the surface of Mg-Zn were hydroxyapatite (HA) and other Mg/Ca phosphates in SBF. In addition, the influence caused by in vitro degradation on mechanical properties was studied, and the results showed that the bending strength of Mg-Zn alloy dropped sharply in the earlier stage of degradation, while smoothly during the later period. The in vitro cytotoxicity of Mg-Zn was examined. The result 0-1 grade revealed that the Mg-Zn alloy was harmless to L-929 cells. For in vivo experiments, Mg-Zn rods were implanted into the femoral shaft of rabbits. The radiographs illustrated that the magnesium alloy could be gradually absorbed in vivo at about 2.32 mm/yr degradation rate obtained by weight loss method. Hematoxylin and eosin (HE) stained section around Mg-Zn rods suggested that there were newly formed bone surrounding the implant. HE stained tissue (containing heart, liver, kidney and spleen tissues) and the biochemical measurements, including serum magnesium, serum creatinine (CREA), blood urea nitrogen (BUN), glutamic-pyruvic transaminase (GPT) and creatine kinase (CK) proved that the in vivo degradation of Mg-Zn did not harm the important organs. Moreover, no adverse effects of hydrogen generated by degradation had been observed and also no negative effects caused by the release of zinc were detected. These results suggested that the novel Mg-Zn binary alloy had good biocompatibility in vivo. (C) 2009 Acta Materialia Inc. Published by Elsevier Ltd. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
97,"We present in this paper a continuous feedback approach to the problem of global strong stabilization, for genuinely nonlinear systems that may not be stabilized, even locally, by any smooth feedback. We describe conditions under which it is possible to prove, while no smooth controllers exist, the existence of continuous state feedback control laws that achieve global strong stability (GSS) in the sense of Kurzweil, The proof is constructive and carried out by developing a machinery, which combines the theory of homogeneous systems with the idea of adding a power integrator, for the explicit construction of globally stabilizing continuous controllers. We then illustrate, by means of examples, how this machinery can be used to overcome the topological obstruction caused by smooth feedback, and hence resulting in new solutions to a variety of open control problems, including global stabilization of an underactuated unstable two degree of freedom mechanical system.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
98,"The coulomb counting method is expedient for state-of-charge (SOC) estimation of lithium-ion batteries with high charging and discharging efficiencies. The charging and discharging characteristics are investigated and reveal that the coulomb counting method is convenient and accurate for estimating the SOC of lithium-ion batteries. A smart estimation method based on coulomb counting is proposed to improve the estimation accuracy. The corrections are made by considering the charging and operating efficiencies. Furthermore, the state-of-health (SOH) is evaluated by the maximum releasable capacity. Through the experiments that emulate practical operations, the SOC estimation method is verified to demonstrate the effectiveness and accuracy. (C) 2008 Elsevier Ltd. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
99,"This paper is a review of the developments in the field of catalytic hydroprocessing of biomass-derived liquefaction conversion products (bio-oil) over the past 25 years. Work has been underway, primarily in the U.S. and Europe, in catalytic hydrotreating and hydrocracking of bio-oil in both batch-fed and continuous-flow bench-scale reactor systems. A range of heterogeneous catalyst materials have been tested, including conventional sulfided catalysts developed for petroleum hydroprocessing and precious metal catalysts. The important processing differences have been identified, which required adjustments to conventional hydroprocessing as applied to petroleum feedstocks. This application of hydroprocessing is seen as an extension of petroleum processing and system requirements are not far outside the range of conventional hydroprocessing. The technology is still under development but can play a significant role in supplementing increasingly expensive petroleum. This paper is a review of the developments in the field of catalytic hydroprocessing of biomass-derived liquefaction conversion products (bio-oil) over the past 25 years. Work has been underway, primarily in the U.S. and Europe, in catalytic hydrotreating and hydrocracking of bio-oil in both batch-fed and continuous-flow bench-scale reactor systems. A range of heterogeneous catalyst materials have been tested, including conventional sulfided catalysts developed for petroleum hydroprocessing and precious metal catalysts. The important processing differences have been identified, which required adjustments to conventional hydroprocessing as applied to petroleum feedstocks. This application of hydroprocessing is seen as an extension of petroleum processing and system requirements are not far outside the range of conventional hydroprocessing. The technology is still under development but can play a significant role in supplementing increasingly expensive petroleum.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
