Publication Type,Authors,Title,Abstract,DOI,ID,rule1,rule2,rule3,rule4,rule5,rule6,rule7,rule8,rule9,rule10,rule11,rule12,rule13,rule14,rule15,rule16,rule17,rule18,rule19,rule20,rule21,rule22,rule23,rule24,rule25,rule26,rule27,rule28,rule29,rule30,rule31
J,"Kundur, P; Paserba, J; Ajjarapu, V; Andersson, G; Bose, A; Canizares, C; Hatziargyriou, N; Hill, D; Stankovic, A; Taylor, C; Van Cutsem, T; Vittal, V",Definition and classification of power system stability,"The problem of defining and classifying power system stability has been addressed by several previous CIGRE and IEEE Task Force reports. These earlier efforts, however, do not completely reflect current industry needs, experiences and understanding. In particular, the definitions are not precise and the classifications do not encompass all practical instability scenarios. This report developed by a Task Force, set up jointly by the CIGRE Study Committee 38 and the IEEE Power System Dynamic Performance Committee, addresses the issue of stability definition and classification in power systems from a fundamental viewpoint and closely examines the practical ramifications. The report aims to define power system stability more precisely, provide a systematic basis for its classification, and discuss linkages to related issues such as power system reliability and security.",10.1109/TPWRS.2004.825981,0,yes,yes,no,yes,yes,no,yes,no,yes,yes,yes,yes,no,no,no,no,no,no,no,yes,no,no,no,no,no,no,no,no,no,yes,yes
J,"Satyanarayanan, M; Bahl, P; CÃ¡ceres, R; Davies, N",The Case for VM-Based Cloudlets in Mobile Computing,,10.1109/MPRV.2009.82,1,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
J,"Scrosati, B; Hassoun, J; Sun, YK",Lithium-ion batteries. A look into the future,"A critical overview of the latest developments in the lithium ion batteries technology is reported. We first describe the evolution in the electrolyte area with particular attention to ionic liquids, discussing the expected application of these room temperature molten salts and listing the issues that still prevent their practical implementation. The attention is then focused on the electrode materials presently considered the most promising for enhancing the energy density of the batteries. At the anode side a discussion is provided on the status of development of high capacity tin and silicon lithium alloys. We show that the morphology that is the most likely to ensure commercial exploitation of these alloy electrodes is that involving carbon-based nanocomposites. We finally touch on super-high-capacity batteries, discussing the key cases of lithium-sulfur and lithium-air and attempting to forecast their chances to eventually reach the status of practically appealing energy storage systems. We conclude with a brief reflection on the amount of lithium reserves in view of its large use in the case of global conversion from gasoline-powered cars to hybrid and electric cars.",10.1039/c1ee01388b,2,yes,yes,no,yes,yes,yes,yes,no,yes,no,yes,yes,no,no,no,no,no,no,no,no,yes,no,no,no,no,yes,yes,no,yes,yes,yes
J,"Arasaratnam, I; Haykin, S",Cubature Kalman Filters,"In this paper, we present a new nonlinear filter for high-dimensional state estimation, which we have named the cubature Kalman filter (CKF). The heart of the CKF is a spherical-radial cubature rule, which makes it possible to numerically compute multivariate moment integrals encountered in the nonlinear Bayesian filter. Specifically, we derive a third-degree spherical-radial cubature rule that provides a set of cubature points scaling linearly with the state-vector dimension. The CKF may therefore provide a systematic solution for high-dimensional nonlinear filtering problems. The paper also includes the derivation of a square-root version of the CKF for improved numerical stability. The CKF is tested experimentally in two nonlinear state estimation problems. In the first problem, the proposed cubature rule is used to compute the second-order statistics of a nonlinearly transformed Gaussian random variable. The second problem addresses the use of the CKF for tracking a maneuvering aircraft. The results of both experiments demonstrate the improved performance of the CKF over conventional nonlinear filters.",10.1109/TAC.2009.2019800,3,yes,yes,no,yes,yes,no,yes,no,yes,no,yes,yes,yes,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,no,no,yes,yes
J,"Czernik, S; Bridgwater, AV",Overview of applications of biomass fast pyrolysis oil,"Fast pyrolysis of biomass is one of the most recent renewable energy processes to have been introduced. It offers the advantages of a liquid product, bio-oil that can be readily stored and transported. Bio-oil is a renewable liquid fuel and can also be used for production of chemicals. Fast pyrolysis has now achieved a commercial success for production of chemicals and is being actively developed for producing liquid fuels. Bio-oils have been successfully tested in engines, turbines, and boilers, and have been upgraded to high-quality hydrocarbon fuels, although at a presently unacceptable energetic and financial cost. The paper critically reviews scientific and technical developments in applications of bio-oil to date and concludes with some suggestions for research and strategic developments.",10.1021/ef034067u,4,yes,yes,no,yes,no,no,no,no,yes,no,yes,yes,no,no,no,no,no,no,no,yes,no,no,no,no,no,yes,no,no,yes,yes,no
J,"Konak, A; Coit, DW; Smith, AE",Multi-objective optimization using genetic algorithms: A tutorial,"Multi-objective formulations are realistic models for many complex engineering optimization problems. In many real-life problems, objectives under consideration conflict with each other, and optimizing a particular solution with respect to a single objective can result in unacceptable results with respect to the other objectives. A reasonable solution to a multi-objective problem is to investigate a set of solutions, each of which satisfies the objectives at an acceptable level without being dominated by any other solution. In this paper, an overview and tutorial is presented describing genetic algorithms (GA) developed specifically for problems with multiple objectives. They differ primarily from traditional GA by using specialized fitness functions and introducing methods to promote solution diversity. (C) 2005 Elsevier Ltd. All rights reserved.",10.1016/j.ress.2005.11.018,5,yes,no,no,no,yes,no,yes,yes,no,no,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no
J,"Xuan, YM; Roetzel, W",Conceptions for heat transfer correlation of nanofluids,"The nanofluid is a solid-liquid mixture in which metallic or nonmetallic nanoparticles are suspended. The suspended ultrafine particles change transport properties and heat transfer performance of the nanofluid, which exhibits a great potential in enhancing heat transfer. The mechanism of heat transfer enhancement of the nanofluid is investigated. Based on the assumption that the nanofluid behaves more like a fluid rather than a conventional solid-fluid mixture, this article proposes two different approaches for deriving heat transfer correlation of the nanofluid. The effects of transport properties of the nanofluid and thermal dispersion are included. (C) 2000 Elsevier Science Ltd, All rights reserved.",10.1016/S0017-9310(99)00369-5,6,yes,no,yes,no,yes,no,yes,no,yes,no,yes,yes,no,no,no,no,no,no,no,yes,no,no,no,no,no,no,no,no,no,yes,no
J,"Spencer, QH; Swindlehurst, AL; Haardt, M",Zero-forcing methods for downlink spatial multiplexing in multiuser MIMO channels,"The use of space-division multiple access (SDMA) in the downlink of a multiuser multiple-input, multiple-output (MIMO) wireless communications network can provide a substantial gain in system throughput. The challenge in such, multiuser systems is designing transmit vectors while considering the co-channel interference of other users. Typical optimization problems of interest include the capacity problem-maximizing the sum information rate subject to a power constraint-or the power control problem-minimizing transmitted power such that a certain quality-of-service metric for each user is met. Neither of these problems possess closed-form solutions for the general multiuser MIMO channel, but the imposition of certain constraints can lead to closed-form solutions. This paper presents two such constrained solutions. The first, referred to as ""block-diagonalization,"" is a generalization of channel inversion when there are multiple antennas at each receiver. It is easily adapted to optimize for either maximum transmission rate or minimum power and approaches the optimal solution at high SNR. The second, known as ""successive optimization,"" is an alternative method for solving the power minimization problem one user at a time, and it yields superior results in some (e.g., low SNR) situations. Both of these algorithms are limited to cases where the transmitter has more antennas than all receive antennas combined. In order to accommodate more general scenarios, we also propose a framework for coordinated transmitter-receiver processing that generalizes the two algorithms to cases involving more receive than transmit antennae. While the proposed algorithms are suboptimal, they lead to simpler transmitter and receiver structures and allow for a reasonable tradeoff between performance and complexity.",10.1109/TSP.2003.821107,7,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
J,"Park, P; Ko, JW; Jeong, C",Reciprocally convex approach to stability of systems with time-varying delays,"Whereas the upper bound lemma for matrix cross-product, introduced by Park (1999) and modified by Moon, Park, Kwon, and Lee (2001), plays a key role in guiding various delay-dependent criteria for delayed systems, the Jensen inequality has become an alternative as a way of reducing the number of decision variables. It directly relaxes the integral term of quadratic quantities into the quadratic term of the integral quantities, resulting in a linear combination of positive functions weighted by the inverses of convex parameters. This paper suggests the lower bound lemma for such a combination, which achieves performance behavior identical to approaches based on the integral inequality lemma but with much less decision variables, comparable to those based on the Jensen inequality lemma. (C) 2010 Elsevier Ltd. All rights reserved.",10.1016/j.automatica.2010.10.014,8,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,no,no,yes
J,"Keiluweit, M; Nico, PS; Johnson, MG; Kleber, M",Dynamic Molecular Structure of Plant Biomass-Derived Black Carbon (Biochar),"Char black carbon (BC), the solid residue of incomplete combustion, is continuously being added to soils and sediments due to natural vegetation fires, anthropogenic pollution, and new strategies for carbon sequestration (""biochar""). Here we present a molecular-level assessment of the physical organization and chemical complexity of biomass-derived chars and, specifically, that of aromatic carbon in char structures. Brunauer-Emmett-Teller (BET)-N-2 surface area (SA), X-ray diffraction (XRD), synchrotron-based near-edge X-ray absorption fine structure (NEXAFS), and Fourier transform infrared (FT-IR) spectroscopy are used to show how two plant materials (wood and grass) undergo analogous but quantitatively different physical-chemical transitions as charring temperature increases from 100 to 700 degrees C. These changes suggest the existence of four distinct categories of char consisting of a unique mixture of chemical phases and physical states: (i) in transition chars,the crystalline character of the precursor materials is preserved; (ii) in amorphous chars, the heat-altered molecules and incipient aromatic polycondensates are randomly mixed; (iii) composite chars consist of poorly ordered graphene stacks embedded in amorphous phases; and (iv) turbostratic chars are dominated by disordered graphitic crystallites. Molecular variations among the different char categories likely translate into differences in their ability to persist in the environment and function as environmental sorbents.",10.1021/es9031419,9,yes,yes,no,no,yes,no,yes,yes,no,no,yes,no,no,yes,no,yes,yes,yes,yes,no,yes,no,no,yes,yes,yes,no,no,yes,yes,
J,"Cadambe, VR; Jafar, SA",Interference alignment and degrees of freedom of the <i>K</i>-user interference channel,"For the fully connected K user wireless interference channel where the channel coefficients are time-varying and are drawn from a continuous distribution, the sum capacity is characterized as C(SNR) = K/2 log(SNR) + o(log(SNR)). Thus, the K user time-varying interference channel almost surely has K/2 degrees of freedom. Achievability is based on the idea of interference alignment. Examples are also provided of fully connected K user interference channels with constant (not time-varying) coefficients where the capacity is exactly achieved by interference alignment at all SNR values.",10.1109/TIT.2008.926344,10,yes,yes,no,no,yes,no,no,yes,no,no,yes,no,yes,no,no,no,no,no,yes,no,no,no,yes,yes,no,no,no,no,yes,yes,
J,"Zhou, BL; Lapedriza, A; Khosla, A; Oliva, A; Torralba, A",Places: A 10 Million Image Database for Scene Recognition,"The rise of multi-million-item dataset initiatives has enabled data-hungry machine learning algorithms to reach near-human semantic classification performance at tasks such as visual object and scene recognition. Here we describe the Places Database, a repository of 10 million scene photographs, labeled with scene semantic categories, comprising a large and diverse list of the types of environments encountered in the world. Using the state-of-the-art Convolutional Neural Networks (CNNs), we provide scene classification CNNs (Places-CNNs) as baselines, that significantly outperform the previous approaches. Visualization of the CNNs trained on Places shows that object detectors emerge as an intermediate representation of scene classification. With its high-coverage and high-diversity of exemplars, the Places Database along with the Places-CNNs offer a novel resource to guide future progress on scene recognition problems.",10.1109/TPAMI.2017.2723009,11,yes,yes,no,no,yes,no,yes,yes,no,no,yes,yes,yes,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,yes,yes,yes
J,"Xuan, YM; Li, Q",Heat transfer enhancement of nanofluids,"This paper presents a procedure for preparing a nanofluid which is a suspension consisting of nanophase powders and a base liquid. By means of the procedure, some sample nanofluids are prepared. Their TEM photographs are given to illustrate the stability and evenness of suspension. The theoretical study of the thermal conductivity of nanofluids is introduced. The hot-wire apparatus is used to measure the thermal conductivity of nanofluids with suspended copper nanophase powders. Some factors such as the volume fraction, dimensions, shapes and properties of the nanoparticles are discussed. A theoretical model is proposed to describe heat transfer performance of the nanofluid flowing in a tube, with accounting for dispersion of solid particles; (C) 2000 Elsevier Science Inc. All rights reserved.",10.1016/S0142-727X(99)00067-3,12,yes,yes,no,no,no,no,no,no,yes,no,yes,yes,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,yes,no,no,no,no,yes,no
J,"Peng, FZ",Z-source inverter,"This paper presents an impedance-source (or impedance-fed) power converter (abbreviated as Z-source converter) and its control method for implementing dc-to-ac, ac-to-dc, ac-to-ac, and dc-to-dc power conversion. The Z-source converter employs a unique impedance network (or circuit) to couple the converter main circuit to the power source, thus providing unique features that cannot be obtained in the traditional voltage-source (or voltage-fed) and current-source (or current-fed) converters where a capacitor and inductor are used, respectively. The Z-source converter overcomes the conceptual and theoretical barriers and limitations of the traditional voltage-source converter (abbreviated as V-source converter) and current-source converter (abbreviated as I-source converter) and provides a,novel power conversion concept. The Z-source concept can be applied to all dc-to-ac, ac-to-dc, ac-to-ac, and dc-to-dc power conversion. To describe the operating principle and control, this paper focuses on an example: a Z-source inverter for dc-ac power conversion needed in fuel cell applications. Simulation and experimental results will be presented to demonstrate the new features.",10.1109/TIA.2003.808920,13,yes,yes,no,yes,yes,yes,yes,yes,no,no,yes,no,no,no,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,yes,yes,no
J,"Mirjalili, S",The Ant Lion Optimizer,"This paper proposes a novel nature-inspired algorithm called Ant Lion Optimizer (ALO). The ALO algorithm mimics the hunting mechanism of antlions in nature. Five main steps of hunting prey such as the random walk of ants, building traps, entrapment of ants in traps, catching preys, and re-building traps are implemented. The proposed algorithm is benchmarked in three phases. Firstly, a set of 19 mathematical functions is employed to test different characteristics of ALO. Secondly, three classical engineering problems (three-bar truss design, cantilever beam design, and gear train design) are solved by ALO. Finally, the shapes of two ship propellers are optimized by ALO as challenging constrained real problems. In the first two test phases, the ALO algorithm is compared with a variety of algorithms in the literature. The results of the test functions prove that the proposed algorithm is able to provide very competitive results in terms of improved exploration, local optima avoidance, exploitation, and convergence. The ALO algorithm also finds superior optimal designs for the majority of classical engineering problems employed, showing that this algorithm has merits in solving constrained problems with diverse search spaces. The optimal shapes obtained for the ship propellers demonstrate the applicability of the proposed algorithm in solving real problems with unknown search spaces as well. Note that the source codes of the proposed ALO algorithm are publicly available at http://www.alimirjalili.com/ALO.html. (C) 2015 Elsevier Ltd. All rights reserved.",10.1016/j.advengsoft.2015.01.010,14,yes,yes,no,no,yes,yes,yes,no,no,no,yes,yes,yes,no,no,yes,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,no,no,no,no
J,"Bemporad, A; Morari, M; Dua, V; Pistikopoulos, EN",The explicit linear quadratic regulator for constrained systems,"For discrete-time linear time invariant systems with constraints on inputs and states, we develop an algorithm to determine explicitly, the state feedback control law which minimizes a quadratic performance criterion. We show that the control law is piece-wise linear and continuous for both the finite horizon problem (model predictive control) and the usual infinite time measure (constrained linear quadratic regulation). Thus, the on-line control computation reduces to the simple evaluation of an explicitly defined piecewise linear function. By computing the inherent underlying controller structure, we also solve the equivalent of the Hamilton-Jacobi-Bellman equation for discrete-time linear constrained systems. Control based on on-line optimization has long been recognized as a superior alternative for constrained systems, The technique proposed in this paper is attractive for a wide range of practical problems where the computational complexity of on-line optimization is prohibitive. It also provides an insight into the structure underlying optimization-based controllers. (C) 2001 Elsevier Science Ltd. All rights reserved.",10.1016/S0005-1098(01)00174-1,15,yes,yes,no,no,yes,yes,yes,yes,no,yes,yes,yes,no,no,no,yes,yes,yes,yes,no,yes,no,no,yes,yes,yes,yes,yes,yes,yes,
J,"Elhamifar, E; Vidal, R","Sparse Subspace Clustering: Algorithm, Theory, and Applications","Many real-world problems deal with collections of high-dimensional data, such as images, videos, text, and web documents, DNA microarray data, and more. Often, such high-dimensional data lie close to low-dimensional structures corresponding to several classes or categories to which the data belong. In this paper, we propose and study an algorithm, called sparse subspace clustering, to cluster data points that lie in a union of low-dimensional subspaces. The key idea is that, among the infinitely many possible representations of a data point in terms of other points, a sparse representation corresponds to selecting a few points from the same subspace. This motivates solving a sparse optimization program whose solution is used in a spectral clustering framework to infer the clustering of the data into subspaces. Since solving the sparse optimization program is in general NP-hard, we consider a convex relaxation and show that, under appropriate conditions on the arrangement of the subspaces and the distribution of the data, the proposed minimization program succeeds in recovering the desired sparse representations. The proposed algorithm is efficient and can handle data points near the intersections of subspaces. Another key advantage of the proposed algorithm with respect to the state of the art is that it can deal directly with data nuisances, such as noise, sparse outlying entries, and missing entries, by incorporating the model of the data into the sparse optimization program. We demonstrate the effectiveness of the proposed algorithm through experiments on synthetic data as well as the two real-world problems of motion segmentation and face clustering.",10.1109/TPAMI.2013.57,16,yes,no,yes,no,yes,no,yes,yes,no,no,yes,no,yes,no,no,no,yes,yes,yes,no,no,no,no,no,yes,yes,yes,no,no,yes,yes
J,"Wong, HSP; Lee, HY; Yu, SM; Chen, YS; Wu, Y; Chen, PS; Lee, B; Chen, FT; Tsai, MJ",Metal-Oxide RRAM,"In this paper, recent progress of binary metal-oxide resistive switching random access memory (RRAM) is reviewed. The physical mechanism, material properties, and electrical characteristics of a variety of binary metal-oxide RRAM are discussed, with a focus on the use of RRAM for nonvolatile memory application. A review of recent development of large-scale RRAM arrays is given. Issues such as uniformity, endurance, retention, multibit operation, and scaling trends are discussed.",10.1109/JPROC.2012.2190369,17,yes,yes,no,yes,no,no,no,no,no,no,yes,no,no,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,no
J,"Herrera, F; MartÃ­nez, L",A 2-tuple fuzzy linguistic representation model for computing with words,"The fuzzy linguistic approach has been applied successfully to many problems, However, there is a limitation of this approach imposed by its information representation model and the computation methods used when fusion processes are performed on linguistic values, This limitation is the loss of information caused by the need to express the results in the initial expression domain that is discrete via an approximate process. This loss of information implies a lack of precision in the final results from the fusion of linguistic information. In this paper, we present tools for overcoming this limitation, The linguistic information will be expressed by means of 2-tuples, which are composed by a linguistic term and a numeric value assessed in [-0.5, 0.5), This model allows a continuous representation of the linguistic information on its domain, therefore, it-can represent any counting of information obtained in a aggregation process. Together with the 2-tuple representation model we shall develop a computational technique for computing with words (CW) without any loss of information. Finally, different classical aggregation operators will be extended to deal with the 2-tuple linguistic model.",10.1109/91.890332,18,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,no,yes,yes,yes
J,"Bletsas, A; Khisti, A; Reed, DP; Lippman, A",A simple cooperative diversity method based on network path selection,"Cooperative diversity has been recently proposed as a way to form virtual antenna arrays that provide dramatic gains in slow fading wireless environments. However, most of the proposed solutions require distributed space-time coding algorithms, the careful design of which is left for future investigation if there is more than one cooperative relay. We propose a novel scheme that alleviates these problems and provides diversity gains on the order of the number of relays in the network. Our scheme first selects the best relay from a set of M available relays and then uses this ""best"" relay for cooperation between the source and the destination. We develop and analyze a distributed method to select the best relay that requires no topology information and is based on local measurements of the instantaneous channel conditions. This method also requires no explicit communication among the relays. The success (or failure) to select the best available path depends on the statistics of the wireless channel, and a methodology to evaluate performance for any kind of wireless channel statistics, is provided. Information theoretic analysis of outage probability shows that our scheme achieves the same diversity-multiplexing tradeoff as achieved by more complex protocols, where coordination and distributed space-time coding for M relay nodes is required, such as those proposed by Laneman and Wornell (2003). The simplicity of the technique allows for immediate implementation in existing radio hardware and its adoption could provide for improved flexibility, reliability, and efficiency in future 4G wireless systems.",10.1109/JSAC.2005.862417,19,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,yes,yes,yes,yes,no,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,yes
J,"Huang, CW; Zappone, A; Alexandropoulos, GC; Debbah, M; Yuen, C",Reconfigurable Intelligent Surfaces for Energy Efficiency in Wireless Communication,"The adoption of a reconfigurahle intelligent surface (RIS) for downlink multi-user communication from a multi-antenna base station is investigated in this paper. We develop energy-efficient designs for both the transmit power allocation and the phase shifts of the surface reflecting elements subject to individual link budget guarantees for the mobile users. This leads to non-convex design optimization problems for which to tackle we propose two computationally affordable approaches, capitalizing on alternating maximization, gradient descent search, and sequential fractional programming. Specifically, one algorithm employs gradient descent for obtaining the RIS phase coefficients, and fractional programming for optimal transmit power allocation. Instead, the second algorithm employs sequential fractional programming for the optimization of the RIS phase shifts. In addition, a realistic power consumption model for RIS-based systems is presented, and the performance of the proposed methods is analyzed in a realistic outdoor environment. In particular, our results show that the proposed RIS-based resource allocation methods are able to provide up to 300% higher energy efficiency in comparison with the use of regular multi-antenna amplify-and-forward relaying.",10.1109/TWC.2019.2922609,20,yes,yes,no,no,yes,yes,yes,no,no,no,yes,no,no,no,no,yes,yes,yes,yes,no,yes,no,yes,yes,yes,yes,yes,yes,no,yes,yes
J,"Sze, V; Chen, YH; Yang, TJ; Emer, JS",Efficient Processing of Deep Neural Networks: A Tutorial and Survey,"Deep neural networks (DNNs) are currently widely used for many artificial intelligence (AI) applications including computer vision, speech recognition, and robotics. While DNNs deliver state-of-the-art accuracy on many AI tasks, it comes at the cost of high computational complexity. Accordingly, techniques that enable efficient processing of DNNs to improve energy efficiency and throughput without sacrificing application accuracy or increasing hardware cost are critical to the wide deployment of DNNs in AI systems. This article aims to provide a comprehensive tutorial and survey about the recent advances toward the goal of enabling efficient processing of DNNs. Specifically, it will provide an overview of DNNs, discuss various hardware platforms and architectures that support DNNs, and highlight key trends in reducing the computation cost of DNNs either solely via hardware design changes or via joint hardware design and DNN algorithm changes. It will also summarize various development resources that enable researchers and practitioners to quickly get started in this field, and highlight important benchmarking metrics and design considerations that should be used for evaluating the rapidly growing number of DNN hardware designs, optionally including algorithmic codesigns, being proposed in academia and industry. The reader will take away the following concepts from this article: understand the key design considerations for DNNs; be able to evaluate different DNN hardware implementations with benchmarks and comparison metrics; understand the tradeoffs between various hardware architectures and platforms; be able to evaluate the utility of various DNN design techniques for efficient processing; and understand recent implementation trends and opportunities.",10.1109/JPROC.2017.2761740,21,yes,no,no,no,yes,no,yes,yes,no,yes,yes,no,no,no,no,yes,no,no,no,no,no,no,no,no,no,yes,no,no,yes,yes,no
J,"Christidis, K; Devetsikiotis, M",Blockchains and Smart Contracts for the Internet of Things,"Motivated by the recent explosion of interest around blockchains, we examine whether they make a good fit for the Internet of Things (IoT) sector. Blockchains allow us to have a distributed peer-to-peer network where non-trusting members can interact with each other without a trusted intermediary, in a verifiable manner. We review how this mechanism works and also look into smart contracts-scripts that reside on the blockchain that allow for the automation of multi-step processes. We then move into the IoT domain, and describe how a blockchain-IoT combination: 1) facilitates the sharing of services and resources leading to the creation of a marketplace of services between devices and 2) allows us to automate in a cryptographically verifiable manner several existing, time-consuming workflows. We also point out certain issues that should be considered before the deployment of a blockchain network in an IoT setting: from transactional privacy to the expected value of the digitized assets traded on the network. Wherever applicable, we identify solutions and workarounds. Our conclusion is that the blockchain-IoT combination is powerful and can cause significant transformations across several industries, paving the way for new business models and novel, distributed applications.",10.1109/ACCESS.2016.2566339,22,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,no,no,no,yes,no,no,no,no,no,yes,yes,yes,yes,yes,yes,
J,"Al-Karaki, JN; Kamal, AE",Routing techniques in wireless sensor networks: A survey,"Wireless sensor networks consist of small nodes with sensing, computation, and wireless communications capabilities. Many routing, power management, and data dissemination protocols have been specifically designed for WSNs where energy awareness is an essential design issue. Routing protocols in WSNs might differ depending on the application and network architecture. In this article we present a survey of state-of-the-art routing techniques in WSNs. We first outline the design challenges for routing protocols in WSNs followed by a comprehensive survey of routing techniques. Overall, the routing techniques are classified into three categories based on the underlying network structure: flit, hierarchical, and location-based routing. Furthermore, these protocols can be classified into multipath-based, query-based, negotiation-based, QoS-based, and coherent-based depending on the protocol operation. We study the design trade-offs between energy and communication overhead savings in every routing paradigm. We also highlight the advantages and performance issues of each routing technique. The article concludes with possible future research areas.",10.1109/MWC.2004.1368893,23,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,yes,no,no,no,no,no,no,no,no,yes,yes,no,yes,yes,yes,
J,"Kamnitsas, K; Ledig, C; Newcombe, VFJ; Sirnpson, JP; Kane, AD; Menon, DK; Rueckert, D; Glocker, B",Efficient multi-scale 3D CNN with fully connected CRF for accurate brain lesion segmentation,"We propose a dual pathway, 11-layers deep, three-dimensional Convolutional Neural Network for the challenging task of brain lesion segmentation. The devised architecture is the result of an in-depth analysis of the limitations of current networks proposed for similar applications. To overcome the computational burden of processing 3D medical scans, we have devised an efficient and effective dense training scheme which joins the processing of adjacent image patches into one pass through the network while automatically adapting to the inherent class imbalance present in the data. Further, we analyze the development of deeper, thus more discriminative 3D CNNs. In order to incorporate both local and larger contextual information, we employ a dual pathway architecture that processes the input images at multiple scales simultaneously. For post-processing of the network's soft segmentation, we use a 3D fully connected Conditional Random Field which effectively removes false positives. Our pipeline is extensively evaluated on three challenging tasks of lesion segmentation in multi-channel MRI patient data with traumatic brain injuries, brain tumours, and ischemic stroke. We improve on the state-of-the-art for all three applications, with top ranking performance on the public benchmarks BRATS 2015 and ISLES 2015. Our method is computationally efficient, which allows its adoption in a variety of research and clinical settings. The source code of our implementation is made publicly available. (C) 2016 The Authors. Published by Elsevier B.V.",10.1016/j.media.2016.10.004,24,yes,no,no,yes,yes,no,yes,yes,no,no,yes,yes,yes,no,no,no,yes,yes,yes,no,no,no,yes,yes,yes,yes,yes,yes,yes,yes,yes
J,"Roundy, S; Wright, PK; Rabaey, J",A study of low level vibrations as a power source for wireless sensor nodes,"Advances in low power VLSI design, along with the potentially low duty cycle of wireless sensor nodes open up the possibility of powering small wireless computing devices from scavenged ambient power. A broad review of potential power scavenging technologies and conventional energy sources is first presented. Low-level vibrations occurring in common household and office environments as a potential power source are studied in depth. The goal of this paper is not to suggest that the conversion of vibrations is the best or most versatile method to scavenge ambient power, but to study its potential as a viable power source for applications where vibrations are present. Different conversion mechanisms are investigated and evaluated leading to specific optimized designs for both capacitive MicroElectroMechancial Systems (MEMS) and piezoelectric converters. Simulations show that the potential power density from piezoelectric conversion is significantly higher. Experiments using an off-the-shelf PZT piezoelectric bimorph verify the accuracy of the models for piezoelectric converters. A power density of 70 muW/cm(3) has been demonstrated with the PZT bimorph. Simulations show that an optimized design would be capable of 250 muW/cm(3) from a vibration source with an acceleration amplitude of 2.5 m/s(2) at 120 Hz. (C) 2002 Elsevier Science B.V.. All rights reserved.",10.1016/S0140-3664(02)00248-7,25,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,yes,no,yes,no,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,no,yes,yes,no
J,"Richardson, TJ; Shokrollahi, MA; Urbanke, RL",Design of capacity-approaching irregular low-density parity-check codes,"We design low-density parity-check (LDPC) codes that perform at rates extremely close to the Shannon capacity The codes are built from highly irregular bipartite graphs with carefully chosen degree patterns on both sides. Our theoretical analysis of the codes is based on [1], Assuming that the underlying communication channel is symmetric, we prove that the probability densities at the message nodes of the graph possess a certain symmetry, Using this symmetry property we then show that, under the assumption of no cycles, the message densities always converge as the number of iterations tends to infinity. Furthermore, we prove a stability condition which implies an upper bound on the fraction of errors that a belief-propagation decoder can correct when applied to a code induced from a bipartite graph with a given degree distribution. Our codes are found by optimizing the degree structure of the underlying graphs. We develop several strategies to perform this optimization. We also present some simulation results for the codes found which show that the performance of the codes is very close to the asymptotic theoretical bounds.",10.1109/18.910578,26,yes,yes,no,yes,yes,yes,yes,yes,no,no,yes,yes,no,no,no,no,yes,yes,yes,no,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,yes
J,"Liang, YC; Zeng, YH; Peh, ECY; Hoang, AT",Sensing-throughput tradeoff for cognitive radio networks,"In a cognitive radio. network, the secondary users are allowed to utilize the frequency bands of primary users when these bands are not currently being used. To support this spectrum reuse functionality, the secondary users are required to sense the radio frequency environment, and once the prmiary users are found to be active, the secondary users are required to vacate the channel within a certain amount of time. Therefore, spectrum sensing is of significant importance in cognitive radio networks. There are two parameters associated with spectrum sensing: probability of detection and probability of false alarm. The higher the probability of detection, the better the primary users are protected. However, from the secondary users' perspective, the lower the probability of false alarm, the more chances the channel can be reused when it is available, thus the higher the achievable throughput for the secondary network. In this paper, we study the problem of designing the sensing duration to maximize the achievable throughput for the secondary network under the constraint that the primary users are sufficiently protected. We formulate the sensing-throughput tradeoff problem mathematically, and use energy detection sensing scheme to prove that the formulated problem indeed has one optimal sensing time which yields the highest throughput for the secondary network. Cooperative sensing using multiple mini-slots or multiple secondary users are also studied using the methodology proposed in this paper. Computer simulations have shown that for a 6MHz channel, when the frame duration is 100ms, and the signal-to-noise ratio of primary user at the secondary receiver is -20dB, the optimal sensing time achieving the highest throughput while maintaining 90% detection probability is 14.2ms. This optimal sensing time decreases when distributed spectrum sensing is applied.",10.1109/TWC.2008.060869,27,yes,no,no,no,yes,no,yes,no,yes,yes,yes,yes,no,no,no,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,no,no,yes,yes,
J,"Li, SYR; Yeung, RW; Cai, N",Linear network coding,"Consider a communication network. in which certain source nodes multicast information to other nodes on the network in the multihop fashion where every node can pass on any of its received data to others. We are interested in how fast each node can receive the complete information, or equivalently, what the information rate arriving at each node is. Allowing a node to encode its received data before passing it on, the question involves optimization of the multicast mechanisms at the nodes. Among the simplest coding schemes is linear coding, which regards a block of data as a vector over a certain base field and allows a node to apply a linear transformation to a vector before passing it on. We formulate this multicast problem and prove that linear coding suffices to achieve the optimum, which is the max-flow from the source to each receiving node.",10.1109/TIT.2002.807285,28,yes,yes,no,no,yes,no,yes,yes,no,no,yes,no,no,no,no,no,yes,no,yes,no,no,no,no,no,no,no,no,no,no,yes,yes
J,"Bioucas-Dias, JM; Plaza, A; Dobigeon, N; Parente, M; Du, Q; Gader, P; Chanussot, J","Hyperspectral Unmixing Overview: Geometrical, Statistical, and Sparse Regression-Based Approaches","Imaging spectrometers measure electromagnetic energy scattered in their instantaneous field view in hundreds or thousands of spectral channels with higher spectral resolution than multispectral cameras. Imaging spectrometers are therefore often referred to as hyperspectral cameras (HSCs). Higher spectral resolution enables material identification via spectroscopic analysis, which facilitates countless applications that require identifying materials in scenarios unsuitable for classical spectroscopic analysis. Due to low spatial resolution of HSCs, microscopic material mixing, and multiple scattering, spectra measured by HSCs are mixtures of spectra of materials in a scene. Thus, accurate estimation requires unmixing. Pixels are assumed to be mixtures of a few materials, called endmembers. Unmixing involves estimating all or some of: the number of endmembers, their spectral signatures, and their abundances at each pixel. Unmixing is a challenging, ill-posed inverse problem because of model inaccuracies, observation noise, environmental conditions, endmember variability, and data set size. Researchers have devised and investigated many models searching for robust, stable, tractable, and accurate unmixing algorithms. This paper presents an overview of unmixing methods from the time of Keshava and Mustard's unmixing tutorial [1] to the present. Mixing models are first discussed. Signal-subspace, geometrical, statistical, sparsity-based, and spatial-contextual unmixing algorithms are described. Mathematical problems and potential solutions are described. Algorithm characteristics are illustrated experimentally.",10.1109/JSTARS.2012.2194696,29,yes,no,no,yes,yes,no,yes,yes,no,no,yes,yes,no,no,no,no,yes,no,yes,no,no,no,no,no,no,no,no,no,no,yes,no
J,"Topcuoglu, H; Hariri, S; Wu, MY",Performance-effective and low-complexity task scheduling for heterogeneous computing,"Efficient application scheduling is critical for achieving high performance in heterogeneous computing environments. The application scheduling problem has been shown to be NP-complete in general cases as well as in several restricted cases. Because of its key importance, this problem has been extensively studied and various algorithms have been proposed in the literature which are mainly for systems with homogeneous processors. Although there are a few algorithms in the literature for heterogeneous processors, they usually require significantly high scheduling costs and they may not deliver good quality schedules with lower costs. In this paper, we present two novel scheduling algorithms for a bounded number of heterogeneous processors with an objective to simultaneously meet high performance and fast scheduling time, which are called the Heterogeneous Earliest-Finish-Time (HEFT) algorithm and the Critical-Path-on-a-Processor (CPOP) algorithm. The HEFT algorithm selects the task with the highest upward rank value at each step and assigns the selected task to the processor, which minimizes its earliest finish time with an insertion-based approach. On the other hand, the CPOP algorithm uses the summation of upward and downward rank values for prioritizing tasks. Another difference is in the processor selection phase, which schedules the critical tasks onto the processor that minimizes the total execution time of the critical tasks. In order to provide a robust and unbiased comparison with the related work, a parametric graph generator was designed to generate weighted directed acyclic graphs with various characteristics. The comparison study, based on both randomly generated graphs and the graphs of some real applications, shows that our scheduling algorithms significantly surpass previous approaches in terms of both quality and cost of schedules, which are mainly presented with schedule length ratio, speedup, frequency of best results, and average scheduling time metrics.",10.1109/71.993206,30,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,no,yes,no,no,yes,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,yes,yes,
J,"Zhang, R; Ho, CK",MIMO Broadcasting for Simultaneous Wireless Information and Power Transfer,"Wireless power transfer (WPT) is a promising new solution to provide convenient and perpetual energy supplies to wireless networks. In practice, WPT is implementable by various technologies such as inductive coupling, magnetic resonate coupling, and electromagnetic (EM) radiation, for short-/mid-/long-range applications, respectively. In this paper, we consider the EM or radio signal enabled WPT in particular. Since radio signals can carry energy as well as information at the same time, a unified study on simultaneous wireless information and power transfer (SWIPT) is pursued. Specifically, this paper studies a multiple-input multiple-output (MIMO) wireless broadcast system consisting of three nodes, where one receiver harvests energy and another receiver decodes information separately from the signals sent by a common transmitter, and all the transmitter and receivers may be equipped with multiple antennas. Two scenarios are examined, in which the information receiver and energy receiver are separated and see different MIMO channels from the transmitter, or co-located and see the identical MIMO channel from the transmitter. For the case of separated receivers, we derive the optimal transmission strategy to achieve different tradeoffs for maximal information rate versus energy transfer, which are characterized by the boundary of a so-called rate-energy (R-E) region. For the case of co-located receivers, we show an outer bound for the achievable R-E region due to the potential limitation that practical energy harvesting receivers are not yet able to decode information directly. Under this constraint, we investigate two practical designs for the co-located receiver case, namely time switching and power splitting, and characterize their achievable R-E regions in comparison to the outer bound.",10.1109/TWC.2013.031813.120224,31,yes,no,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,yes,yes,yes,yes,no,yes,no,no,no,no,yes,yes,yes,yes,yes,yes
J,"Cha, YJ; Choi, W; BÃ¼yÃ¼kÃ¶ztÃ¼rk, O",Deep Learning-Based Crack Damage Detection Using Convolutional Neural Networks,"A number of image processing techniques (IPTs) have been implemented for detecting civil infrastructure defects to partially replace human-conducted onsite inspections. These IPTs are primarily used to manipulate images to extract defect features, such as cracks in concrete and steel surfaces. However, the extensively varying real-world situations (e.g., lighting and shadow changes) can lead to challenges to the wide adoption of IPTs. To overcome these challenges, this article proposes a vision-based method using a deep architecture of convolutional neural networks (CNNs) for detecting concrete cracks without calculating the defect features. As CNNs are capable of learning image features automatically, the proposed method works without the conjugation of IPTs for extracting features. The designed CNN is trained on 40 K images of 256 x 256 pixel resolutions and, consequently, records with about 98% accuracy. The trained CNN is combined with a sliding window technique to scan any image size larger than 256 x 256 pixel resolutions. The robustness and adaptability of the proposed approach are tested on 55 images of 5,888 x 3,584 pixel resolutions taken from a different structure which is not used for training and validation processes under various conditions (e.g., strong light spot, shadows, and very thin cracks). Comparative studies are conducted to examine the performance of the proposed CNN using traditional Canny and Sobel edge detection methods. The results show that the proposed method shows quite better performances and can indeed find concrete cracks in realistic situations.",10.1111/mice.12263,32,yes,no,no,yes,yes,no,yes,yes,no,yes,yes,yes,yes,no,no,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,no,yes,yes,no
J,"Pogaku, N; Prodanovic, M; Green, TC","Modeling, analysis and testing of autonomous operation of an inverter-based microgrid","The analysis of the small-signal stability of conventional power systems is well established, but for inverter based microgrids there is a need to establish how circuit and control features give rise to particular oscillatory modes and which of these have poor damping. This paper develops the modeling and analysis of autonomous operation of inverter-based microgrids. Each sub-module is modeled in state-space form and all are combined together on a common reference frame. The model captures the detail of the control loops of the inverter but not the switching action. Some inverter modes are found at relatively high frequency and so a full dynamic model of the network (rather than an algebraic impedance model) is used. The complete model is linearized around an operating point and the resulting system matrix is used to derive the eigenvalues. The eigenvalues (termed ""modes"") indicate the frequency and damping of oscillatory components in the transient response. A sensitivity analysis is also presented which helps identifying the origin of each of the modes and identify possible feedback signals for design of controllers to improve the system stability. With experience it is possible to simplify the model (reduce the order) if particular modes are not of interest as is the case with synchronous machine models. Experimental results from a microgrid of three 10-kW inverters are used to verify the results obtained from the model.",10.1109/TPEL.2006.890003,33,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
J,"Xu, ZS",Intuitionistic fuzzy aggregation operators,"An intuitionistic fuzzy set, characterized by a membership function and a non-membership function, is a generalization of fuzzy set. In this paper, based on score function,and accuracy function, we introduce a method for the comparison between two intuitionistic fuzzy values and then develop some aggregation operators, such as the intuitionistic fuzzy weighted averaging operator, intuitionistic fuzzy ordered weighted averaging operator, and intuitionistic fuzzy hybrid aggregation operator, for aggregating intuitionistic fuzzy values and establish various properties of these operators.",10.1109/TFUZZ.2006.890678,34,yes,yes,no,no,yes,no,yes,yes,no,no,yes,yes,no,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes
J,"Tee, KP; Ge, SS; Tay, EH",Barrier Lyapunov Functions for the control of output-constrained nonlinear systems,"In this paper, we present control designs for single-input single-output (SISO) nonlinear systems in strict feedback form with an output constraint. To prevent constraint violation, we employ a Barrier Lyapunov Function, which grows to infinity when its arguments approach some limits. By ensuring boundedness of the Barrier Lyapunov Function in the closed loop, we ensure that those limits are not transgressed. Besides the nominal case where full knowledge of the plant is available, we also tackle scenarios wherein parametric uncertainties are present. Asymptotic tracking is achieved without violation of the constraint, and all closed loop signals remain bounded, under a mild condition on the initial output. Furthermore, we explore the use of an Asymmetric Barrier Lyapunov Function as a generalized approach that relaxes the requirements on the initial conditions. We also compare our control with one that is based on a Quadratic Lyapunov Function, and we show that our control requires less restrictive initial conditions. A numerical example is provided to illustrate the performance of the proposed control. (C) 2008 Elsevier Ltd. All rights reserved.",10.1016/j.automatica.2008.11.017,35,yes,yes,no,no,yes,no,yes,yes,no,yes,yes,yes,no,no,no,no,yes,no,yes,no,no,no,no,no,yes,yes,no,no,yes,yes,
J,"Criminisi, A; PÃ©rez, P; Toyama, K",Region filling and object removal by exemplar-based image inpainting,"A new algorithm is proposed for removing large objects from digital images. The challenge is to fill in the hole that is left behind in a visually plausible way. In the past, this problem has been addressed by two classes of algorithms: 1) ""texture synthesis"" algorithms for generating large image regions from sample textures and 2) ""inpainting"" techniques for filling in small image gaps. The former has been demonstrated for ""textures""-repeating two-dimensional patterns with some stochasticity; the latter focus on linear ""structures"" which can be thought of as one-dimensional patterns, such as lines and object contours. This paper presents a novel and efficient algorithm that combines the advantages of these two approaches. We first note that exemplar-based texture synthesis contains the essential process required to replicate both texture and structure; the success of structure propagation, however, is highly dependent on the order in which the filling proceeds. We propose a best-first algorithm in which the confidence in the synthesized pixel values is propagated in a manner similar to the propagation of information in inpainting. The actual color values are computed using exemplar-based synthesis. In this paper, the simultaneous propagation of texture and structure information is achieved by a single, efficient algorithm. Computational efficiency is achieved by a block-based sampling process. A number of examples on real and synthetic images demonstrate the effectiveness of our algorithm in removing large occluding objects, as well as thin scratches. Robustness with respect to the shape of the manually selected target region is also demonstrated. Our results compare favorably to those obtained by existing techniques.",10.1109/TIP.2004.833105,36,yes,no,yes,yes,yes,no,yes,no,yes,yes,yes,no,yes,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,no,yes,yes
J,"Lin, H; Antsaklis, PJ",Stability and Stabilizability of Switched Linear Systems: A Survey of Recent Results,"During the past several years, there have been increasing research activities in the field of stability analysis and switching stabilization for switched systems. This paper aims to briefly survey recent results in this field. First, the stability analysis for switched systems is reviewed. We focus on the stability analysis for switched linear systems under arbitrary switching, and we highlight necessary and sufficient conditions for asymptotic stability. After a brief review of the stability analysis under restricted switching and the multiple Lyapunov function theory, the switching stabilization problem is studied, and a variety of switching stabilization methods found in the literature are outlined. Then the switching stabilizability problem is investigated, that is under what condition it is possible to stabilize a switched system by properly designing switching control laws. Note that the switching stabilizability problem has been one of the most elusive problems in the switched systems literature. A necessary and sufficient condition for asymptotic stabilizability of switched linear systems is described here.",10.1109/TAC.2008.2012009,37,yes,yes,no,yes,yes,yes,yes,no,no,no,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,no,no,no,yes,yes
J,"DollÃ¡r, P; Wojek, C; Schiele, B; Perona, P",Pedestrian Detection: An Evaluation of the State of the Art,"Pedestrian detection is a key problem in computer vision, with several applications that have the potential to positively impact quality of life. In recent years, the number of approaches to detecting pedestrians in monocular images has grown steadily. However, multiple data sets and widely varying evaluation protocols are used, making direct comparisons difficult. To address these shortcomings, we perform an extensive evaluation of the state of the art in a unified framework. We make three primary contributions: 1) We put together a large, well-annotated, and realistic monocular pedestrian detection data set and study the statistics of the size, position, and occlusion patterns of pedestrians in urban scenes, 2) we propose a refined per-frame evaluation methodology that allows us to carry out probing and informative comparisons, including measuring performance in relation to scale and occlusion, and 3) we evaluate the performance of sixteen pretrained state-of-the-art detectors across six data sets. Our study allows us to assess the state of the art and provides a framework for gauging future efforts. Our experiments show that despite significant progress, performance still has much room for improvement. In particular, detection is disappointing at low resolutions and for partially occluded pedestrians.",10.1109/TPAMI.2011.155,38,yes,no,yes,yes,yes,no,yes,no,yes,yes,yes,yes,yes,no,no,yes,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,no,yes,yes
J,"Giesy, JP; Kannan, K",Global distribution of perfluorooctane sulfonate in wildlife,"Here we report, for the first time, on the global distribution of perfluorooctanesulfonate (PFOS), a fluorinated organic contaminant. PFOS was measured in the tissues of wildlife, including, fish, birds, and marine mammals. Some of the species studied include bald eagles, polar bears, albatrosses, and various species of seals. Samples were collected from urbanized areas in North America, especially the Great Lakes region and coastal marine areas and rivers, and Europe. Samples were also collected from a number of more remote, less urbanized locations such as the Arctic and the North Pacific Oceans. The results demonstrated that PFOS is widespread in the environment. Concentrations of PFOS in animals from relatively more populated and industrialized regions, such as the North American Great Lakes, Baltic Sea, and Mediterranean Sea, were greater than those in animals from remote marine locations. Fish-eating, predatory animals such as mink and bald eagles contained concentrations of PFOS that were greater than the concentrations in their diets. This suggests that PFOS can bioaccumulate to higher trophic levels of the food chain. Currently available data indicate that the concentrations of PFOS in wildlife are less than those required to cause adverse effects in laboratory animals.",10.1021/es001834k,39,yes,yes,no,no,yes,yes,yes,no,yes,no,yes,yes,yes,no,yes,no,yes,yes,no,yes,no,no,yes,yes,yes,yes,no,no,yes,yes,no
J,"Yu, SH; Yu, XH; Shirinzadeh, B; Man, ZH",Continuous finite-time control for robotic manipulators with terminal sliding mode,A continuous finite-time control scheme for rigid robotic manipulators is proposed using a new form of terminal sliding modes. The robustness of the controller is established using the Lyapunov stability theory. Theoretical analysis and simulation results show that faster and high-precision tracking performance is obtained compared with the conventional continuous sliding mode control method. (c) 2005 Elsevier Ltd. All rights reserved.,10.1016/j.automatica.2005.07.001,40,no,no,no,yes,yes,yes,yes,no,yes,no,yes,yes,no,no,no,yes,yes,yes,no,yes,yes,yes,no,yes,yes,yes,no,yes,no,yes,yes
J,"Stauffer, C; Grimson, WEL",Learning patterns of activity using real-time tracking,"Our goal is to develop a visual monitoring system that passively observes moving objects in a site and learns patterns of activity from those observations. For extended sites, the system will require multiple cameras. Thus, key elements of the system are motion tracking, camera coordination, activity classification, and event detection. In this paper, we focus on motion tracking and show how one can use observed motion to learn patterns of activity in a site. Motion segmentation is based on an adaptive background subtraction method that models each pixel as a mixture of Gaussians and uses an on-line approximation to update the model. The Gaussian distributions are then evaluated to determine which are most likely to result from a background process. This yields a stable. real-time outdoor tracker that reliably deals with lighting changes, repetitive motions from clutter, and long-term scene changes. While a tracking system is unaware of the identity of any object it tracks, the identity remains the same for the entire tracking sequence. Our system leverages this information by accumulating joint co-occurrences of the representations within a sequence. These joint cooccurrence statistics are then used to create a hierarchical binary-tree classification of the representations. This method is useful for classifying sequences, as well as individual instances of activities in a site.",10.1109/34.868677,41,yes,yes,no,no,yes,yes,yes,yes,no,no,yes,no,no,no,no,no,no,no,yes,no,no,no,no,no,yes,no,no,no,no,yes,yes
J,"Thackeray, MM; Wolverton, C; Isaacs, ED","Electrical energy storage for transportation-approaching the limits of, and going beyond, lithium-ion batteries","The escalating and unpredictable cost of oil, the concentration of major oil resources in the hands of a few politically sensitive nations, and the long-term impact of CO2 emissions on global climate constitute a major challenge for the 21st century. They also constitute a major incentive to harness alternative sources of energy and means of vehicle propulsion. Today's lithium-ion batteries, although suitable for small-scale devices, do not yet have sufficient energy or life for use in vehicles that would match the performance of internal combustion vehicles. Energy densities 2 and 5 times greater are required to meet the performance goals of a future generation of plug-in hybrid-electric vehicles (PHEVs) with a 40-80 mile all-electric range, and all-electric vehicles (EVs) with a 300-400 mile range, respectively. Major advances have been made in lithium-battery technology over the past two decades by the discovery of new materials and designs through intuitive approaches, experimental and predictive reasoning, and meticulous control of surface structures and chemical reactions. Further improvements in energy density of factors of two to three may yet be achievable for current day lithium-ion systems; factors of five or more may be possible for lithium-oxygen systems, ultimately leading to our ability to confine extremely high potential energy in a small volume without compromising safety, but only if daunting technological barriers can be overcome.",10.1039/c2ee21892e,42,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,no,no,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,yes,no,no
J,"Sheikh, HR; Sabir, MF; Bovik, AC",A statistical evaluation of recent full reference image quality assessment algorithms,"Measurement of visual quality is of fundamental importance for numerous image and video processing applications, where the goal of quality assessment (QA) algorithms is to automatically assess the quality of images or videos in agreement with human quality judgments. Over the years, many researchers have taken different approaches to the problem and have contributed significant research in this area and claim to have made progress in their respective domains. It is important to evaluate the performance of these algorithms in a comparative setting and analyze the strengths and weaknesses of these methods. In this paper, we present results of an extensive subjective quality assessment study in which a total of 779 distorted images were evaluated by about two dozen human subjects. The ""ground truth"" image quality data obtained from about 25 000 individual human quality judgments is used to evaluate the performance of several prominent full-reference image quality assessment algorithms. To the best of our knowledge, apart from video quality studies conducted by the Video Quality Experts Group, the study presented in this paper is the largest subjective image quality study in the literature in terms of number of images, distortion types, and number of human judgments per image. Moreover, we have made the data from the study freely available to the research community [1]. This would allow other researchers to easily report comparative results in the future.",10.1109/TIP.2006.881959,43,yes,no,no,yes,yes,no,yes,no,yes,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,no,no,no,yes,yes,yes,yes,yes,yes,yes,yes,yes
J,"Dai, LL; Wang, BC; Yuan, YF; Han, SF; Chih-Lin, ; Wang, ZC","Non-Orthogonal Multiple Access for 5G: Solutions, Challenges, Opportunities, and Future Research Trends","The increasing demand of mobile Internet and the Internet of Things poses challenging requirements for 5G wireless communications, such as high spectral efficiency and massive connectivity. In this article, a promising technology, non-orthogonal multiple access (NOMA), is discussed, which can address some of these challenges for 5G. Different from conventional orthogonal multiple access technologies, NOMA can accommodate much more users via non-orthogonal resource allocation. We divide existing dominant NOMA schemes into two categories: power-domain multiplexing and code-domain multiplexing, and the corresponding schemes include power-domain NOMA, multiple access with low-density spreading, sparse code multiple access, multi-user shared access, pattern division multiple access, and so on. We discuss their principles, key features, and pros/cons, and then provide a comprehensive comparison of these solutions from the perspective of spectral efficiency, system performance, receiver complexity, and so on. In addition, challenges, opportunities, and future research trends for NOMA design are highlighted to provide some insight on the potential future work for researchers in this field. Finally, to leverage different multiple access schemes including both conventional OMA and new NOMA, we propose the concept of software defined multiple access (SoDeMA), which enables adaptive configuration of available multiple access schemes to support diverse services and applications in future 5G networks.",10.1109/mcom.2015.7263349,44,yes,yes,no,yes,yes,no,yes,yes,no,yes,yes,no,no,no,no,yes,yes,yes,yes,no,no,no,no,no,yes,yes,yes,yes,yes,yes,
J,"Noel, NK; Stranks, SD; Abate, A; Wehrenfennig, C; Guarnera, S; Haghighirad, AA; Sadhanala, A; Eperon, GE; Pathak, SK; Johnston, MB; Petrozza, A; Herz, LM; Snaith, HJ",Lead-free organic-inorganic tin halide perovskites for photovoltaic applications,"Already exhibiting solar to electrical power conversion efficiencies of over 17%, organic-inorganic lead halide perovskite solar cells are one of the most promising emerging contenders in the drive to provide a cheap and clean source of energy. One concern however, is the potential toxicology issue of lead, a key component in the archetypical material. The most likely substitute is tin, which like lead, is also a group 14 metal. While organic-inorganic tin halide perovskites have shown good semiconducting behaviour, the instability of tin in its 2+ oxidation state has thus far proved to be an overwhelming challenge. Here, we report the first completely lead-free, CH3NH3SnI3 perovskite solar cell processed on a mesoporous TiO2 scaffold, reaching efficiencies of over 6% under 1 sun illumination. Remarkably, we achieve open circuit voltages over 0.88 V from a material which has a 1.23 eV band gap.",10.1039/c4ee01076k,45,yes,no,yes,yes,no,no,no,no,no,no,yes,yes,no,yes,no,yes,yes,yes,yes,no,no,no,yes,yes,no,no,no,no,yes,yes,
J,"Lai, LF; Potts, JR; Zhan, D; Wang, L; Poh, CK; Tang, CH; Gong, H; Shen, ZX; Jianyi, LY; Ruoff, RS",Exploration of the active center structure of nitrogen-doped graphene-based catalysts for oxygen reduction reaction,"We present two different ways to fabricate nitrogen-doped graphene (N-graphene) and demonstrate its use as a metal-free catalyst to study the catalytic active center for the oxygen reduction reaction (ORR). N-graphene was produced by annealing of graphene oxide (G-O) under ammonia or by annealing of a N-containing polymer/reduced graphene oxide (RG-O) composite (polyaniline/RG-O or polypyrrole/RG-O). The effects of the N precursors and annealing temperature on the performance of the catalyst were investigated. The bonding state of the N atom was found to have a significant effect on the selectivity and catalytic activity for ORR. Annealing of G-O with ammonia preferentially formed graphitic N and pyridinic N centers, while annealing of polyaniline/RG-O and polypyrrole/RG-O tended to generate pyridinic and pyrrolic N moieties, respectively. Most importantly, the electrocatalytic activity of the catalyst was found to be dependent on the graphitic N content which determined the limiting current density, while the pyridinic N content improved the onset potential for ORR. However, the total N content in the graphene-based non-precious metal catalyst does not play an important role in the ORR process.",10.1039/c2ee21802j,46,yes,no,no,no,yes,yes,yes,yes,no,no,yes,yes,no,no,no,yes,yes,yes,no,yes,no,no,no,yes,yes,yes,no,no,yes,yes,
J,"Vincent, E; Gribonval, R; FÃ©votte, C",Performance measurement in blind audio source separation,"In this paper, we discuss the evaluation of blind audio source separation (BASS) algorithms. Depending on the exact application, different distortions can be allowed between an estimated source and the wanted true source. We consider four different sets of such allowed distortions, from time-invariant gains to time-varying filters. In each case, we decompose the estimated source into a true source part plus error terms corresponding to interferences, additive noise, and algorithmic artifacts. Then, we derive a global performance measure using an energy ratio, plus a separate performance,measure for each error term. These measures are computed and discussed on the results of several BASS problems with various difficulty levels.",10.1109/TSA.2005.858005,47,yes,yes,no,no,yes,no,yes,yes,no,no,yes,yes,no,no,no,yes,yes,no,yes,no,no,no,no,no,no,no,no,no,no,yes,yes
J,"Chen, YS; Jiang, HL; Li, CY; Jia, XP; Ghamisi, P",Deep Feature Extraction and Classification of Hyperspectral Images Based on Convolutional Neural Networks,"Due to the advantages of deep learning, in this paper, a regularized deep feature extraction (FE) method is presented for hyperspectral image (HSI) classification using a convolutional neural network (CNN). The proposed approach employs several convolutional and pooling layers to extract deep features from HSIs, which are nonlinear, discriminant, and invariant. These features are useful for image classification and target detection. Furthermore, in order to address the common issue of imbalance between high dimensionality and limited availability of training samples for the classification of HSI, a few strategies such as L2 regularization and dropout are investigated to avoid overfitting in class data modeling. More importantly, we propose a 3-D CNN-based FE model with combined regularization to extract effective spectral-spatial features of hyperspectral imagery. Finally, in order to further improve the performance, a virtual sample enhanced method is proposed. The proposed approaches are carried out on three widely used hyperspectral data sets: Indian Pines, University of Pavia, and Kennedy Space Center. The obtained results reveal that the proposed models with sparse constraints provide competitive results to state-of-the-art methods. In addition, the proposed deep FE opens a new window for further research.",10.1109/TGRS.2016.2584107,48,yes,no,no,no,yes,no,yes,yes,no,yes,yes,no,yes,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,no,yes,yes,yes
J,"Li, WJ; Laurencin, CT; Caterson, EJ; Tuan, RS; Ko, FK",Electrospun nanofibrous structure: A novel scaffold for tissue engineering,"The architecture of an engineered tissue substitute plays an important role in modulating tissue growth. A novel poly(D,L-lactide-co-glycolide) (PLGA) structure with a unique architecture produced by an electrospinning process has been developed for tissue-engineering applications. Electrospinning is a process whereby ultra-fine fibers are formed in a high-voltage electrostatic field. The electrospun structure, composed of PLGA fibers ranging from 500 to 800 rim in diameter, features a morphologic similarity to the extracellular matrix (ECM) of natural tissue, which is characterized by a wide range of pore diameter distribution, high porosity, and effective mechanical properties. Such a structure meets the essential design criteria of an ideal engineered scaffold. The favorable cell-matrix interaction within the cellular construct supports the active biocompatibility of the structure. The electrospun nanofibrous structure is capable of supporting cell attachment and proliferation. Cells seeded on this structure tend to maintain phenotypic shape and guided growth according to nanofiber orientation. This novel biodegradable scaffold has potential applications for tissue engineering based upon its unique architecture, which acts to support and guide cell growth. (C) 2002 Wiley Periodicals, Inc.",10.1002/jbm.10167,49,yes,yes,no,no,yes,no,no,no,yes,no,yes,yes,no,yes,no,yes,yes,yes,yes,no,no,no,yes,yes,yes,yes,yes,no,yes,yes,no
J,"Fu, JW; Xu, QL; Low, JX; Jiang, CJ; Yu, JG",Ultrathin 2D/2D WO<sub>3</sub>/g-C<sub>3</sub>N<sub>4</sub> step-scheme H<sub>2</sub>-production photocatalyst,"The appropriate interfacial contact of heterojunction photocatalysts plays a critical role in transfer/separation of interfacial charge carriers. Design of two-dimensional (2D)/2D surface-to-surface heterojunction is an effective method for improving photocatalytic activity since greater contact area can enhance interfacial charge transfer rate. Herein, ultrathin 2D/2D WO3/g-C3N4 step-like composite heterojunction photocatalysts were fabricated by electrostatic self-assembly of ultrathin tungsten trioxide (WO3) and graphitic carbon nitride (g-C3N4) nanosheets. The ultrathin WO3 and g-C3N4 nanosheets were obtained by electrostatic-assisted ultrasonic exfoliation of bulk WO3 and a two-step thermal-etching of bulk g-C3N4, respectively. The thickness of ultrathin WO3 and g-C3N4 nanosheets are 2.5-3.5 nm, which is equivalent to 5-8 atomic or molecular layer thickness. This ultrathin layered heterojunction structure can enhance surface photocatalytic rate because photogenerated electrons and holes at heterogeneous interface more easily transfer to surface of photocatalysts. Therefore, the obtained ultrathin 2D/2D WO3/g-C3N4 step-scheme (S-scheme) heterojunction photocatalysts exhibited better Hz-production activity than pure g-C3N4 and WO3 with the same loading amount of Pt as cocatalyst. The mechanism and driving force of charge transfer and separation in S-scheme heterojunction photocatalysts are investigated and discussed. This investigation will provide new insight about designing and constructing novel S-scheme heterojunction photocatalysts.",10.1016/j.apcatb.2018.11.011,50,yes,no,yes,no,yes,no,yes,no,yes,no,yes,yes,no,no,no,yes,yes,yes,no,yes,yes,yes,no,yes,no,yes,no,yes,yes,yes,no
J,"Witte, F; Kaese, V; Haferkamp, H; Switzer, E; Meyer-Lindenberg, A; Wirth, CJ; Windhagen, H",In vivo corrosion of four magnesium alloys and the associated bone response,"Degrading metal alloys are a new class of implant materials suitable for bone surgery. The aim of this study was to investigate the degradation mechanism at the bone-implant interface of different degrading magnesium alloys in bone and to determine their effect on the surrounding bone. Sample rods of four different magnesium alloys and a degradable polymer as a control were implanted intramedullary into the femora of guinea pigs. After 6 and 18 weeks, uncalcified sections were generated for histomorphologic analysis. The bone-implant interface was characterized in uncalcified sections by scanning electron microscopy (SEM), element mapping and X-ray diffraction. Results showed that metallic implants made of magnesium alloys degrade in vivo depending on the composition of the alloying elements. While the corrosion layer of all magnesium alloys accumulated with biological calcium phosphates, the corrosion layer was in direct contact with the surrounding bone. The results further showed high mineral apposition rates and an increased bone mass around the magnesium rods, while no bone was induced in the surrounding soft tissue. From the results of this study, there is a strong rationale that in this research model, high magnesium ion concentration could lead to bone cell activation. (C) 2004 Elsevier Ltd. All rights reserved.",10.1016/j.biomaterials.2004.09.049,51,yes,no,no,no,yes,no,yes,no,yes,no,yes,yes,yes,yes,yes,no,yes,yes,no,yes,yes,yes,no,yes,yes,yes,no,no,no,yes,no
J,"Chandrasekhar, V; Andrews, JG; Gatherer, A",Femtocell Networks: A Survey,"The surest way to increase the system capacity of a wireless link is by getting the transmitter and receiver closer to each other, which creates the dual benefits of higher-quality links and more spatial reuse. In a network with nomadic users, this inevitably involves deploying more infrastructure, typically in the form of microcells, hot spots, distributed antennas, or relays. A less expensive alternative is the recent concept of femtocells - also called home base stations which are data access points installed by home users to get better indoor voice and data coverage. In this article we overview the technical and business arguments for femtocells and describe the state of the art on each front. We also describe the technical challenges facing femtocell networks and give some preliminary ideas for how to overcome them.",10.1109/MCOM.2008.4623708,52,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,no,yes,yes,yes
J,"Nascimento, JMP; Dias, JMB",Vertex component analysis: A fast algorithm to unmix hyperspectral data,"Given a set of mixed spectral (multispectral or hyperspectral) vectors, linear spectral mixture analysis, or linear unmixing, aims at estimating the number of reference substances, also called endmembers, their spectral signatures, and their abundance fractions. This paper presents a new method for unsupervised endmember extraction from hyperspectral data, termed vertex component analysis (VCA). The algorithm exploits two facts: 1) the endmembers are the vertices of a simplex and 2) the affine transformation of a simplex is also a simplex. In a series of experiments using simulated and real data, the VCA algorithm competes with state-of-the-art methods, with a computational complexity between one and two orders of magnitude lower than the best available method.",10.1109/TGRS.2005.844293,53,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,yes,no,no,yes,yes,yes,yes,no,no,no,yes,yes,yes,no,yes,no,no,yes,yes
J,"Likas, A; Vlassis, N; Verbeek, JJ",The global <i>k</i>-means clustering algorithm,We present the global k-means algorithm which is an incremental approach to clustering that dynamically adds one cluster center at a time through a deterministic global search procedure consisting of N (with N being the size of the data set) executions of the k-means algorithm from suitable initial positions. We also propose modifications of the method to reduce the computational load without significantly affecting solution quality. The proposed clustering methods are tested on well-known data sets and they compare favorably to the k-means algorithm with random restarts. (C) 2002 Pattern Recognition Society. Published by Elsevier Science Ltd. All rights reserved.,,54,yes,yes,no,no,yes,yes,yes,yes,no,no,yes,no,yes,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,no,yes,yes
J,"Fischer, D; Li, YX; Ahlemeyer, B; Krieglstein, J; Kissel, T",In vitro cytotoxicity testing of polycations: influence of polymer structure on cell viability and hemolysis.,"A comparative in vitro cytotoxicity study with different water-soluble, cationic macromolecules which have been described as gene delivery systems was performed. Cytotoxicity in L929 mouse fibroblasts was monitored using the MTT assay and the release of the cytosolic enzyme lactate dehydrogenase (LDH). Microscopic observations were carried out as indicators for cell viability. Furthermore, hemolysis of erythrocytes was quantified spectrophotometrically. To determine the nature of cell death induced by the polycations, the nuclear morphology after DAPI staining and the inhibition of the toxic effects by the caspase inhibitor zVAD.fmk were investigated. All assays yielded comparable results and allowed the following ranking of the polymers with regard to cytotoxicity: Poly(ethylenimine) = poly(L-lysine) > poly(diallyl-dimethyl-ammonium chloride) > diethylaminoethyl-dextran > poly (vinyl pyridinium bromide) > Starburst dendrimer > cationized albumin > native albumin. The magnitude of the cytotoxic effects of all polymers were found to be time- and concentration dependent. The molecular weight as well as the cationic charge density of the polycations were confirmed as key parameters for the interaction with the cell membranes and consequently, the cell damage. Evaluating the nature of cell death induced by poly(ethylenimine), we did not detect any indication for apoptosis suggesting that the polymer induced a necrotic cell reaction. Cell nuclei retained their size, chromatin was homogenously distributed and cell membranes lost their integrity very rapidly at an early stage. Furthermore, the broad spectrum caspase inhibitor zVAD.fmk did not inhibit poly(ethylenimine)-induced cell damage. Insights into the structure-toxicity relationship are necessary to optimize the cytotoxicity and biocompatibility of non-viral gene delivery systems. (C) 2002 Elsevier Science Ltd. All rights reserved.",10.1016/S0142-9612(02)00445-3,55,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
J,"Roh, W; Seol, JY; Park, J; Lee, B; Lee, J; Kim, Y; Cho, J; Cheun, K; Aryanfar, F",Millimeter-Wave Beamforming as an Enabling Technology for 5G Cellular Communications: Theoretical Feasibility and Prototype Results,"The ever growing traffic explosion in mobile communications has recently drawn increased attention to the large amount of underutilized spectrum in the millimeter-wave frequency bands as a potentially viable solution for achieving tens to hundreds of times more capacity compared to current 4G cellular networks. Historically, mmWave bands were ruled out for cellular usage mainly due to concerns regarding short-range and non-line-of-sight coverage issues. In this article, we present recent results from channel measurement campaigns and the development of advanced algorithms and a prototype, which clearly demonstrate that the mmWave band may indeed be a worthy candidate for next generation (5G) cellular systems. The results of channel measurements carried out in both the United States and Korea are summarized along with the actual free space propagation measurements in an anechoic chamber. Then a novel hybrid beamforming scheme and its link-and system-level simulation results are presented. Finally, recent results from our mmWave prototyping efforts along with indoor and outdoor test results are described to assert the feasibility of mmWave bands for cellular usage.",10.1109/MCOM.2014.6736750,56,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
J,"Arulkumaran, K; Deisenroth, MP; Brundage, M; Bharath, AA",Deep Reinforcement Learning <i>A brief survey</i>,"Deep reinforcement learning (DRL) is poised to revolutionize the field of artificial intelligence (AI) and represents a step toward building autonomous systems with a higher-level understanding of the visual world. Currently, deep learning is enabling reinforcement learning (RL) to scale to problems that were previously intractable, such as learning to play video games directly from pixels. DRL algorithms are also applied to robotics, allowing control policies for robots to be learned directly from camera inputs in the real world. In this survey, we begin with an introduction to the general field of RL, then progress to the main streams of value-based and policy-based methods. Our survey will cover central algorithms in deep RL, including the deep Q-network (DQN), trust region policy optimization (TRPO), and asynchronous advantage actor critic. In parallel, we highlight the unique advantages of deep neural networks, focusing on visual understanding via RL. To conclude, we describe several current areas of research within the field.",10.1109/MSP.2017.2743240,57,yes,yes,no,yes,yes,no,no,no,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,no,no,yes,yes,yes
J,"Tian, J",Reversible data embedding using a difference expansion,"Reversible data embedding has drawn lots of interest recently. Being reversible, the original digital content can be completely restored. In this paper, we present a novel reversible data-embedding method for digital images. We explore the redundancy in digital images to achieve very high embedding capacity, and keep y the distortion low.",10.1109/TCSVT.2003.815962,58,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes
J,"Lv, YS; Duan, YJ; Kang, WW; Li, ZX; Wang, FY",Traffic Flow Prediction With Big Data: A Deep Learning Approach,"Accurate and timely traffic flow information is important for the successful deployment of intelligent transportation systems. Over the last few years, traffic data have been exploding, and we have truly entered the era of big data for transportation. Existing traffic flow prediction methods mainly use shallow traffic prediction models and are still unsatisfying for many real-world applications. This situation inspires us to rethink the traffic flow prediction problem based on deep architecture models with big traffic data. In this paper, a novel deep-learning-based traffic flow prediction method is proposed, which considers the spatial and temporal correlations inherently. A stacked autoencoder model is used to learn generic traffic flow features, and it is trained in a greedy layerwise fashion. To the best of our knowledge, this is the first time that a deep architecture model is applied using autoencoders as building blocks to represent traffic flow features for prediction. Moreover, experiments demonstrate that the proposed method for traffic flow prediction has superior performance.",10.1109/TITS.2014.2345663,59,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,yes,no,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,no,yes,yes
J,"He, CB; Hu, YP; Yin, LC; Tang, C; Yin, CH",Effects of particle size and surface charge on cellular uptake and biodistribution of polymeric nanoparticles,"To elucidate the effects of particle size and surface charge on cellular uptake and biodistribution of polymeric nanoparticles (NPs), rhodamine B (RhB) labeled carboxymethyl chitosan grafted NPs (RhB-CMCNP) and chitosan hydrochloride grafted NPs (RhB-CHNP) were developed as the model negatively and positively charged polymeric NPs, respectively. These NPs owned well defined particle sizes (150-500 nm) and Zeta potentials (-40 mV - +35 mV). FITC labeled protamine sulfate (FITC-PS) loaded RhB-CMCNP and camptothecin (CPT) loaded RhB-CHNP with high encapsulation efficiency were prepared. The fluorescence stability in plasma and towards I was investigated, and the result indicated it was sufficient for qualitative and quantitative analysis. NPs with high surface charge and large particle size were phagocytized more efficiently by murine macrophage. Slight particle size and surface charge differences and different cell lines had significant implications in the cellular uptake of NPs, and various mechanisms were involved in the uptake process. In vivo biodistribution suggested that NPs with slight negative charges and particle size of 150 nm were tended to accumulate in tumor more efficiently. These results could serve as a guideline in the rational design of drug nanocarriers with maximized therapeutic efficacy and predictable in vivo properties, in which the control of particle size and surface charge was of significance. (C) 2010 Elsevier Ltd. All rights reserved.",10.1016/j.biomaterials.2010.01.065,60,yes,no,no,no,yes,yes,yes,no,yes,yes,yes,yes,yes,no,no,no,yes,yes,no,yes,no,no,yes,yes,yes,yes,yes,no,yes,yes,no
J,"Chen, WH; Yang, J; Guo, L; Li, SH",Disturbance-Observer-Based Control and Related Methods-An Overview,"Disturbance-observer-based control (DOBC) and related methods have been researched and applied in various industrial sectors in the last four decades. This survey, at first time, gives a systematic and comprehensive tutorial and summary on the existing disturbance/uncertainty estimation and attenuation techniques, most notably, DOBC, active disturbance rejection control, disturbance accommodation control, and composite hierarchical antidisturbance control. In all of these methods, disturbance and uncertainty are, in general, lumped together, and an observation mechanism is employed to estimate the total disturbance. This paper first reviews a number of widely used linear and nonlinear disturbance/uncertainty estimation techniques and then discusses and compares various compensation techniques and the procedures of integrating disturbance/uncertainty compensation with a (predesigned) linear/nonlinear controller. It also provides concise tutorials of the main methods in this area with clear descriptions of their features. The application of this group ofmethods in various industrial sections is reviewed, with emphasis on the commercialization of some algorithms. The survey is ended with the discussion of future directions.",10.1109/TIE.2015.2478397,61,yes,yes,no,yes,yes,no,no,no,yes,no,yes,yes,no,no,no,no,no,no,no,yes,no,no,no,no,no,yes,no,no,yes,no,no
J,"Das, SK; Putra, N; Thiesen, P; Roetzel, W",Temperature dependence of thermal conductivity enhancement for nanofluids,"Usual heat transfer fluids with suspended ultra fine particles of nanometer size are named as nanofluids, which have opened a new dimension in heat transfer processes. The recent investigations confirm the potential of nanofluids in enhancing heat transfer required for present age technology The present investigation goes detailed into investigating the increase of thermal conductivity with temperature for nano fluids with water as base fluid and particles of Al2O3 or CuO as suspension material. A temperature oscillation technique is utilized,for the measurement of thermal diffusivity and thermal conductivity is calculated from it. The results indicate an increase of enhancement characteristics with temperature, which makes the nanofluids even more attractive for applications with high energy density than usual room temperature measurements reported earlier.",10.1115/1.1571080,62,yes,no,yes,no,yes,no,yes,yes,no,no,yes,yes,yes,no,yes,yes,yes,yes,yes,no,yes,no,no,yes,yes,yes,no,no,yes,yes,no
J,"Richardson, TJ; Urbanke, RL",The capacity of low-density parity-check codes under message-passing decoding,"In this paper, we present a general method for determining the capacity of low-density parity-check (LDPC) codes under message-passing decoding when used over any binary-input memoryless channel with discrete or continuous output alphabets, Transmitting at rates below this capacity, a randomly chosen element of the given ensemble will achieve an arbitrarily small target probability of error with a probability that approaches one exponentially fast in the length of the code. (By concatenating with an appropriate outer code one can achieve a probability of error that approaches zero exponentially fast in the length of the code with arbitrarily small loss in rate.) Conversely, transmitting at rates above this capacity the probability of error is bounded away from zero by a strictly positive constant which is independent of the length of the code and of the number of iterations performed. Our results are based on the observation that the concentration of the performance of the decoder around its average performance, as observed by Luby et al. [1] in the case of a binary-symmetric channel and a binary message-passing algorithm, is a general phenomenon, For the particularly important case of belief-propagation decoders, we provide an effective algorithm to deter-mine the corresponding capacity to any desired degree of accuracy, The ideas presented in this paper are broadly applicable and extensions of the general method to low-density parity-check codes over larger alphabets, turbo codes, and other concatenated coding schemes are outlined.",10.1109/18.910577,63,yes,yes,no,yes,yes,yes,yes,yes,no,no,yes,no,no,no,no,yes,yes,yes,yes,no,no,no,no,no,no,yes,yes,no,yes,yes,yes
J,"Beckmann, CF; Smith, SA",Probabilistic independent component analysis for functional magnetic resonance imaging,"We present an integrated approach to probabilistic independent component analysis (ICA) for functional MRI (FMRI) data that allows for nonsquare mixing in the presence of Gaussian noise. In order to avoid overfitting, we employ objective estimation of the amount of Gaussian noise through Bayesian analysis of the true dimensionality of the data, i.e., the number of activation and non-Gaussian noise sources. This enables us to carry out probabilistic modeling and achieves an asymptotically unique decomposition of the data. It reduces problems of interpretation, as each final independent component is now much more likely to be due to only one physical or physiological process. We also describe other improvements to standard ICA, such as temporal prewhitening and variance normalization of timeseries, the latter being particularly useful in the context of dimensionality reduction when weak activation is present. We discuss the use of prior information about the spatiotemporal nature of the source processes, and an alternative-hypothesis testing approach for inference, using Gaussian mixture models. The performance of our approach is illustrated and evaluated on real and artificial FMRI data, and compared to the spatio-temporal accuracy of results obtained from classical ICA and GLM analyses.",10.1109/TMI.2003.822821,64,yes,no,no,yes,yes,yes,yes,yes,no,yes,yes,no,yes,no,no,yes,yes,no,yes,no,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes
J,"Huang, GB; Chen, L; Siew, CK",Universal approximation using incremental constructive feedforward networks with random hidden nodes,"According to conventional neural network theories, single-hidden-layer feedforward networks (SLFNs) with additive or radial basis function (RBF) hidden nodes are universal approximators when all the parameters of the networks are allowed adjustable. However, as observed in most neural network implementations, tuning all the parameters of the networks may cause learning complicated and inefficient, and it may be difficult to train networks with nondifferential activation functions such as threshold networks. Unlike conventional neural network theories, this paper proves in an incremental constructive method that in order to let SLFNs work as universal approximators, one may simply randomly choose hidden nodes and then only need to adjust the output weights linking the hidden layer and the output layer. In such SLFNs implementations, the activation functions for additive nodes can be any bounded nonconstant piecewise continuous functions g : R -> R and the activation functions for RBF nodes can be any integrable piecewise continuous functions g : R -> Rand f(R) g(x)dx not equal 0. The proposed incremental method is efficient not only for SFLNs with continuous (including nondifferentiable) activation functions but also for SLFNs with piecewise continuous (such as threshold) activation functions. Compared to other popular methods such a new network is fully automatic and users need not intervene the learning process by manually tuning control parameters.",10.1109/TNN.2006.875977,65,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,no,no,no,no,yes,no,no,no,no,yes,yes,yes,no,yes,yes,no
J,"Olivares, DE; Mehrizi-Sani, A; Etemadi, AH; CaÃ±izares, CA; Iravani, R; Kazerani, M; Hajimiragha, AH; Gomis-Bellmunt, O; Saeedifard, M; Palma-Behnke, R; JimÃ©nez-EstÃ©vez, GA; Hatziargyriou, ND",Trends in Microgrid Control,"The increasing interest in integrating intermittent renewable energy sources into microgrids presents major challenges from the viewpoints of reliable operation and control. In this paper, the major issues and challenges in microgrid control are discussed, and a review of state-of-the-art control strategies and trends is presented; a general overview of the main control principles (e.g., droop control, model predictive control, multi-agent systems) is also included. The paper classifies microgrid control strategies into three levels: primary, secondary, and tertiary, where primary and secondary levels are associated with the operation of the microgrid itself, and tertiary level pertains to the coordinated operation of the microgrid and the host grid. Each control level is discussed in detail in view of the relevant existing technical literature.",10.1109/TSG.2013.2295514,66,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,no,no,no,no
J,"Li, ZK; Duan, ZS; Chen, GR; Huang, L",Consensus of Multiagent Systems and Synchronization of Complex Networks: A Unified Viewpoint,"This paper addresses the consensus problem of multiagent systems with a time-invariant communication topology consisting of general linear node dynamics. A distributed observer-type consensus protocol based on relative output measurements is proposed. A new framework is introduced to address in a unified way the consensus of multiagent systems and the synchronization of complex networks. Under this framework, the consensus of multiagent systems with a communication topology having a spanning tree can be cast into the stability of a set of matrices of the same low dimension. The notion of consensus region is then introduced and analyzed. It is shown that there exists an observer-type protocol solving the consensus problem and meanwhile yielding an unbounded consensus region if and only if each agent is both stabilizable and detectable. A multistep consensus protocol design procedure is further presented. The consensus with respect to a time-varying state and the robustness of the consensus protocol to external disturbances are finally discussed. The effectiveness of the theoretical results is demonstrated through numerical simulations, with an application to low-Earth-orbit satellite formation flying.",10.1109/TCSI.2009.2023937,67,yes,yes,no,no,yes,no,yes,yes,no,no,yes,yes,no,no,no,no,yes,no,yes,no,no,no,no,no,no,yes,yes,no,no,no,yes
J,"Yager, RR",Pythagorean Membership Grades in Multicriteria Decision Making,"We first look at some nonstandard fuzzy sets, intuitionistic, and interval-valued fuzzy sets. We note both these allow a degree of commitment of less then one in assigning membership. We look at the formulation of the negation for these sets and show its expression in terms of the standard complement with respect to the degree of commitment. We then consider the complement operation. We describe its properties and look at alternative definitions of complement operations. We then focus on the Pythagorean complement. Using this complement, we introduce a class of nonstandard Pythagorean fuzzy subsets whose membership grades are pairs, (a, b) satisfying the requirement a(2) + b(2) <= 1. We introduce a variety of aggregation operations for these Pythagorean fuzzy subsets. We then look at multicriteria decision making in the case where the criteria satisfaction are expressed using Pythagorean membership grades. The issue of having to choose a best alternative in multicriteria decision making leads us to consider the problem of comparing Pythagorean membership grades.",10.1109/TFUZZ.2013.2278989,68,yes,yes,no,yes,yes,no,yes,no,yes,no,yes,yes,no,no,no,no,no,no,no,yes,no,no,no,no,no,no,no,no,no,yes,yes
J,"Moreau, L",Stability of multiagent systems with time-dependent communication links,"We study a simple but compelling model of network of agents interacting via time-dependent communication links. The model finds application in a variety of fields including synchronization, swarming and distributed decision making. In the model, each agent updates his current state based upon the current information received from neighboring agents. Necessary and/or sufficient conditions for the convergence of the individual agents' states to a common value are presented, thereby extending recent results reported in the literature.. The stability analysis is based upon a blend of graph-theoretic and system-theoretic tools with the notion of convexity playing a central role. The analysis is integrated within a formal framework of set-valued Lyapunov theory, which may be of independent interest. Among others, it is observed that more communication does not necessarily lead to faster convergence and may eventually even lead to a loss of convergence, even for the simple models discussed in the present paper.",10.1109/TAC.2004.841888,69,yes,yes,no,yes,yes,yes,yes,yes,no,no,yes,no,no,no,no,no,yes,yes,yes,no,yes,no,no,yes,yes,no,no,no,no,yes,yes
J,"Tiwari, RK; Das, MK",Heat transfer augmentation in a two-sided lid-driven differentially heated square cavity utilizing nanofluids,"The behaviour of nanofluids is investigated numerically inside a two-sided lid-driven differentially heated square cavity to gain insight into convective recirculation and flow processes induced by a nanofluid. A model is developed to analyze the behaviour of nanofluids taking into account the solid volume fraction Z. The transport equations are solved numerically with finite volume approach using SIMPLE algorithm. Comparisons with previously published work on the basis of special cases are performed and found to be in excellent agreement. The left and the right moving walls are maintained at different constant temperatures while the upper and the bottom walls are thermally insulated. Three case were considered depending on the direction of the moving walls. Governing parameters were 0.01 < Ri < 100 but due to space constraints only the results for 0. 1 < Ri < 10 are presented. It is found that both the Richardson number and the direction of the moving walls affect the fluid flow and heat transfer in the cavity. Copper-Water nanofluid is used with Pr = 6.2 and solid volume fraction Z is varied as 0.0%, 8%, 16% and 20%. Detailed results are presented for flow pattern and heat transfer curves. (c) 2006 Elsevier Ltd. All rights reserved.",10.1016/j.ijheatmasstransfer.2006.09.034,70,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,yes,yes,no,no,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,no,no,yes,no
J,"Kolmogorov, V; Zabih, R",What energy functions can be minimized via graph cuts?,"In the last few years, several new algorithms based on graph cuts have been developed to solve energy minimization problems in computer vision. Each of these techniques constructs a graph such that the minimum cut on the graph also minimizes the energy. Yet, because these graph constructions are complex and highly specific to a particular energy function, graph cuts have seen limited application to date. In this paper, we give a characterization of the energy functions that can be minimized by graph cuts. Our results are restricted to functions of binary variables. However, our work generalizes many previous constructions and is easily applicable to vision problems that involve large numbers of labels, such as stereo, motion, image restoration, and scene reconstruction. We give a precise characterization of what energy functions can be minimized using graph cuts, among the energy functions that can be written as a sum of terms containing three or fewer binary variables. We also provide a general-purpose construction to minimize such an energy function. Finally, we give a necessary condition for any energy function of binary variables to be minimized by graph cuts. Researchers who are considering the use of graph cuts to optimize a particular energy function can use our results to determine if this is possible and then follow our construction to create the appropriate graph. A software implementation is freely available.",10.1109/TPAMI.2004.1262177,71,yes,yes,no,yes,yes,no,yes,yes,no,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,yes,no,yes,yes
J,"Creswell, A; White, T; Dumoulin, V; Arulkumaran, K; Sengupta, B; Bharath, AA",Generative Adversarial Networks <i>An overview</i>,,10.1109/MSP.2017.2765202,72,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
J,"Chen, YS; Lin, ZH; Zhao, X; Wang, G; Gu, YF",Deep Learning-Based Classification of Hyperspectral Data,"Classification is one of the most popular topics in hyperspectral remote sensing. In the last two decades, a huge number of methods were proposed to deal with the hyperspectral data classification problem. However, most of them do not hierarchically extract deep features. In this paper, the concept of deep learning is introduced into hyperspectral data classification for the first time. First, we verify the eligibility of stacked autoencoders by following classical spectral information-based classification. Second, a new way of classifying with spatial-dominated information is proposed. We then propose a novel deep learning framework to merge the two features, from which we can get the highest classification accuracy. The framework is a hybrid of principle component analysis (PCA), deep learning architecture, and logistic regression. Specifically, as a deep learning architecture, stacked autoencoders are aimed to get useful high-level features. Experimental results with widely-used hyperspectral data indicate that classifiers built in this deep learning-based framework provide competitive performance. In addition, the proposed joint spectral-spatial deep neural network opens a new window for future research, showcasing the deep learning-based methods' huge potential for accurate hyperspectral data classification.",10.1109/JSTARS.2014.2329330,73,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,no,no,no,no,yes,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,yes,yes,
J,"Dahl, GE; Yu, D; Deng, L; Acero, A",Context-Dependent Pre-Trained Deep Neural Networks for Large-Vocabulary Speech Recognition,"We propose a novel context-dependent (CD) model for large-vocabulary speech recognition (LVSR) that leverages recent advances in using deep belief networks for phone recognition. We describe a pre-trained deep neural network hidden Markov model (DNN-HMM) hybrid architecture that trains the DNN to produce a distribution over senones (tied triphone states) as its output. The deep belief network pre-training algorithm is a robust and often helpful way to initialize deep neural networks generatively that can aid in optimization and reduce generalization error. We illustrate the key components of our model, describe the procedure for applying CD-DNN-HMMs to LVSR, and analyze the effects of various modeling choices on performance. Experiments on a challenging business search dataset demonstrate that CD-DNN-HMMs can significantly outperform the conventional context-dependent Gaussian mixture model (GMM)-HMMs, with an absolute sentence accuracy improvement of 5.8% and 9.2% (or relative error reduction of 16.0% and 23.2%) over the CD-GMM-HMMs trained using the minimum phone error rate (MPE) and maximum-likelihood (ML) criteria, respectively.",10.1109/TASL.2011.2134090,74,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
J,"Matas, J; Chum, O; Urban, M; Pajdla, T",Robust wide-baseline stereo from maximally stable extremal regions,"The wide-baseline stereo problem, i.e. the problem of establishing correspondences between a pair of images taken from different viewpoints is studied. A new set of image elements that are put into correspondence, the so called extremal regions, is introduced. Extremal regions possess highly desirable properties: the set is closed under (1) continuous (and thus projective) transformation of image coordinates and (2) monotonic transformation of image intensities. An efficient (near linear complexity) and practically fast detection algorithm (near frame rate) is presented for an affinely invariant stable subset of extremal regions, the maximally stable extremal regions (MSER). A new robust similarity measure for establishing tentative correspondences is proposed. The robustness ensures that invariants from multiple measurement regions (regions obtained by invariant constructions from extremal re ions), some that are significantly larger (and hence discriminative) than the MSERs, may be used to establish tentative correspondences. The high utility of MSERs, multiple measurement regions and the robust metric is demonstrated in wide-baseline experiments on image pairs from both indoor and outdoor scenes. Significant change of scale (3.5 X), illumination conditions, out-of-plane rotation, occlusion, locally anisotropic scale change and 3D translation of the viewpoint are all present in the test problems. Good estimates of epipolar geometry (average distance from corresponding points to the epipolar line below 0.09 of the inter-pixel distance) are obtained. (C) 2004 Elsevier B.V. All rights reserved.",10.1016/j.imavis.2004.02.006,75,yes,yes,no,no,yes,no,yes,no,yes,no,yes,yes,yes,no,no,yes,yes,yes,no,yes,no,no,yes,yes,yes,no,no,no,no,no,no
J,"Bulusu, N; Heidemann, J; Estrin, D",GPS-less low-cost outdoor localization for very small devices,"Instrumenting the physical world through large networks of wireless sensor nodes, particularly for applications like environmental monitoring of water and soil, requires that these nodes be very small, lightweight, untethered, and unobtrusive. The problem of localization, that is, determining where a given node is physically located in a network, is a challenging one, and yet extremely crucial for many of these applications. Practical considerations such as the small size, form factor, cost and power constraints of nodes preclude the reliance on GPS of all nodes in these networks. In this article we review localization techniques and evaluate the effectiveness of a very simple connectivity metric method for localization in outdoor environments that makes use of the inherent RF communications capabilities of these devices. A fixed number of reference points in the network with overlapping regions of coverage transmit periodic beacon signals. Nodes use a simple connectivity metric, which is more robust to environmental vagaries, to infer proximity to a given subset of these reference points. Nodes localize themselves to the centroid of their proximate reference points. The accuracy of localization is then dependent on the separation distance between two adjacent reference points and the transmission range of these reference points. Initial experimental results show that the accuracy for 90 percent of our data points is within one-third of the separation distance. However, future work is needed to extend the technique to more cluttered environments.",10.1109/98.878533,76,yes,no,yes,yes,yes,no,yes,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,no,no,no,yes,yes,yes,no,yes,yes,yes,yes,yes
J,"Middleton, JC; Tipton, AJ",Synthetic biodegradable polymers as orthopedic devices,"Polymer scientists, working closely with those in the device and medical fields, have made tremendous advances over the past 30 years in the use of synthetic materials in the body. In this article we will focus on properties of biodegradable polymers which make them ideally suited for orthopedic applications where a permanent implant is not desired. The materials with the greatest history of use are the poly(lactides) and poly(glycolides), and these will be covered in specific detail. The chemistry of the polymers, including synthesis and degradation, the tailoring of properties by proper synthetic controls such as copolymer composition, special requirements for processing and handling, and mechanisms of biodegradation will be covered. An overview of biocompatibility and approved devices of particular interest in orthopedics are also covered. (C) 2000 Elsevier Science Ltd. All rights reserved.",10.1016/S0142-9612(00)00101-0,77,yes,yes,no,yes,no,no,no,no,yes,no,yes,yes,no,no,no,no,no,no,no,yes,no,no,no,no,no,no,no,no,no,yes,no
J,"Mohsenian-Rad, AH; Wong, VWS; Jatskevich, J; Schober, R; Leon-Garcia, A",Autonomous Demand-Side Management Based on Game-Theoretic Energy Consumption Scheduling for the Future Smart Grid,"Most of the existing demand-side management programs focus primarily on the interactions between a utility company and its customers/users. In this paper, we present an autonomous and distributed demand-side energy management system among users that takes advantage of a two-way digital communication infrastructure which is envisioned in the future smart grid. We use game theory and formulate an energy consumption scheduling game, where the players are the users and their strategies are the daily schedules of their household appliances and loads. It is assumed that the utility company can adopt adequate pricing tariffs that differentiate the energy usage in time and level. We show that for a common scenario, with a single utility company serving multiple customers, the global optimal performance in terms of minimizing the energy costs is achieved at the Nash equilibrium of the formulated energy consumption scheduling game. The proposed distributed demand-side energy management strategy requires each user to simply apply its best response strategy to the current total load and tariffs in the power distribution system. The users can maintain privacy and do not need to reveal the details on their energy consumption schedules to other users. We also show that users will have the incentives to participate in the energy consumption scheduling game and subscribing to such services. Simulation results confirm that the proposed approach can reduce the peak-to-average ratio of the total energy demand, the total energy costs, as well as each user's individual daily electricity charges.",10.1109/TSG.2010.2089069,78,yes,yes,no,yes,yes,no,yes,yes,no,yes,yes,no,no,no,no,yes,yes,yes,yes,no,no,no,yes,yes,yes,yes,yes,yes,no,yes,yes
J,"Chen, X; Jiao, L; Li, WZ; Fu, XM",Efficient Multi-User Computation Offloading for Mobile-Edge Cloud Computing,"Mobile-edge cloud computing is a new paradigm to provide cloud computing capabilities at the edge of pervasive radio access networks in close proximity to mobile users. In this paper, we first study the multi-user computation offloading problem for mobile-edge cloud computing in a multi-channel wireless interference environment. We show that it is NP-hard to compute a centralized optimal solution, and hence adopt a game theoretic approach for achieving efficient computation offloading in a distributed manner. We formulate the distributed computation offloading decision making problem among mobile device users as a multi-user computation offloading game. We analyze the structural property of the game and show that the game admits a Nash equilibrium and possesses the finite improvement property. We then design a distributed computation offloading algorithm that can achieve a Nash equilibrium, derive the upper bound of the convergence time, and quantify its efficiency ratio over the centralized optimal solutions in terms of two important performance metrics. We further extend our study to the scenario of multi-user computation offloading in the multi-channel wireless contention environment. Numerical results corroborate that the proposed algorithm can achieve superior computation offloading performance and scale well as the user size increases.",10.1109/TNET.2015.2487344,79,yes,yes,no,no,yes,no,yes,no,yes,no,yes,yes,no,no,no,yes,yes,yes,yes,no,yes,no,yes,yes,yes,yes,yes,no,no,yes,yes
J,"Palensky, P; Dietrich, D","Demand Side Management: Demand Response, Intelligent Energy Systems, and Smart Loads","Energy management means to optimize one of the most complex and important technical creations that we know: the energy system. While there is plenty of experience in optimizing energy generation and distribution, it is the demand side that receives increasing attention by research and industry. Demand Side Management (DSM) is a portfolio of measures to improve the energy system at the side of consumption. It ranges from improving energy efficiency by using better materials, over smart energy tariffs with incentives for certain consumption patterns, up to sophisticated real-time control of distributed energy resources. This paper gives an overview and a taxonomy for DSM, analyzes the various types of DSM, and gives an outlook on the latest demonstration projects in this domain.",10.1109/TII.2011.2158841,80,yes,no,yes,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,no,yes,yes,yes
J,"Steffen, W; Crutzen, PJ; McNeill, JR",The Anthropocene: Are humans now overwhelming the great forces of nature,"We explore the development of the Anthropocene, the current epoch in which humans and our societies have become a global geophysical force. The Anthropocene began around 1800 with the onset of industrialization, the central feature of which was the enormous expansion in the use of fossil fuels. We use atmospheric carbon dioxide concentration as a single, simple indicator to track the progression of the Anthropocene. From a preindustrial value of 270-275 ppm, atmospheric carbon dioxide had risen to about 310 ppm by 1950. Since then the human enterprise has experienced a remarkable explosion, the Great Acceleration, with significant consequences for Earth System functioning. Atmospheric CO2 concentration has risen from 310 to 380 ppm since 1950, with about half of the total rise since the preindustrial era occurring in just the last 30 years. The Great Acceleration is reaching criticality. Whatever unfolds, the next few decades will surely be a tipping point in the evolution of the Anthropocene.",10.1579/0044-7447(2007)36[614:TAAHNO]2.0.CO;2,81,yes,no,no,no,yes,no,yes,yes,no,no,yes,yes,yes,no,no,no,yes,yes,yes,no,no,no,yes,yes,yes,yes,no,no,yes,yes,yes
J,"Keblinski, P; Phillpot, SR; Choi, SUS; Eastman, JA",Mechanisms of heat flow in suspensions of nano-sized particles (nanofluids),"Recent measurements on nanofluids have demonstrated that the thermal conductivity increases with decreasing grain size. However, Such increases cannot be explained by existing theories. We explore four possible explanations for this anomalous increase: Brownian motion of the particles, molecular-level layering of the liquid at the liquid/particle interface, the nature of heat transport in the nanoparticles. and the effects of nanoparticle clustering. We show that the key factors in understanding thermal properties of nanofluids are the ballistic, rather than diffusive, nature of heat transport in the nanoparticles, combined with direct or fluid-mediated clustering effects that provide paths for rapid heat transport. (C) 2001 Elsevier Science Ltd. All rights reserved.",10.1016/S0017-9310(01)00175-2,82,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,yes,no,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,no,no,yes,yes
J,"Gottschalk, F; Sonderer, T; Scholz, RW; Nowack, B","Modeled Environmental Concentrations of Engineered Nanomaterials (TiO<sub>2</sub>, ZnO, Ag, CNT, Fullerenes) for Different Regions","Engineered nanomaterials (ENM) are already used in many products and consequently released into environmental compartments. In this study, we calculated predicted environmental concentrations (PEC) based on a probabilistic material flow analysis from a life-cycle perspective of ENM-containing products. We modeled namo-TiO2, namo-ZnO, nano-Ag, carbon nanotubes (CNT), and fullerenes for the U.S., Europe and Switzerland. The environmental concentrations were calculated as probabilistic density functions and were compared to data from ecotoxicological studies. The simulated modes (most frequent values) range from 0.003 ng L-1 (fullerenes) to 21 ng L-1 (namo-TiO2) for surface waters and from 4 ng L-1 (fullerenes) to 4 mu g L-1 (nano-TiO2) for sewage treatment effluents. For Europe and the U.S., the annual increase of ENMs on sludge-treated soil ranges from 1 ng kg(-1) for fullerenes to 89 mu g kg(-1) for namo-TiO2. The results of this study indicate that risks to aquatic organisms may currently emanate from nano-Ag, namo-TiO2, and namo-ZnO in sewage treatment effluents for all considered regions and for nano-Ag in surface waters. For the other environmental compartments for which ecotoxicological data were available, no risks to organisms are presently expected.",10.1021/es9015553,83,yes,no,no,no,yes,no,yes,no,yes,no,yes,yes,no,no,no,no,yes,yes,no,yes,yes,yes,yes,yes,yes,no,no,no,yes,yes,yes
J,"Gilbert, TL",A phenomenological theory of damping in ferromagnetic materials,"In 1955, a phenomenological theory of ferromagnetism was well established and had been corroborated by a considerable amount of experimental data. However, there were problems in the phenomenological theory of the dynamics of the magnetization field. The Landau-Lifshitz equation for damping of the motion of the magnetization field could not account for the large noneddy-current damping in thin Permalloy sheets. The problem undertaken herein is a reformulation of the theory in a way that is more consistent with the theory of damping in other physical systems in order to be able to take large damping into account.",10.1109/TMAG.2004.836740,84,yes,yes,no,yes,yes,no,yes,no,yes,yes,yes,yes,no,no,no,no,no,no,no,yes,no,no,no,no,no,no,no,no,no,yes,no
J,"Swaroop, D; Hedrick, JK; Yip, PP; Gerdes, JC",Dynamic surface control for a class of nonlinear systems,"A new method is proposed for designing controllers with arbitrarily small tracking error for uncertain, mismatched nonlinear systems in the strict feedback form. This method is another ""synthetic input technique,"" similar to backstepping and multiple surface control methods, but with an important addition, r - 1 low pass filters are included in the design where r is the relative degree of the output to be controlled. It is shown that these low pass filters allo rv a design where the model is not differentiated, thus ending the complexity arising due to the ""explosion of terms"" that has made other methods difficult to implement in practice. The backstepping approach, while suffering from the problem of ""explosion of terms"" guarantees boundedness of tracking errors globally; however, the proposed approach, while being simpler to implement, can only guarantee boundedness of tracking error semiglobally, when the nonlinearities in the system are non-Lipschitz.",10.1109/TAC.2000.880994,85,yes,no,no,yes,yes,yes,yes,no,no,yes,yes,no,no,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,yes,yes,yes
J,"Al-Hourani, A; Kandeepan, S; Lardner, S",Optimal LAP Altitude for Maximum Coverage,"Low-altitude aerial platforms (LAPs) have recently gained significant popularity as key enablers for rapid deployable relief networks where coverage is provided by onboard radio heads. These platforms are capable of delivering essential wireless communication for public safety agencies in remote areas or during the aftermath of natural disasters. In this letter, we present an analytical approach to optimizing the altitude of such platforms to provide maximum radio coverage on the ground. Our analysis shows that the optimal altitude is a function of the maximum allowed pathloss and of the statistical parameters of the urban environment, as defined by the International Telecommunication Union. Furthermore, we present a closed-form formula for predicting the probability of the geometrical line of sight between a LAP and a ground receiver.",10.1109/LWC.2014.2342736,86,yes,no,yes,no,yes,no,yes,yes,no,no,yes,no,no,no,no,yes,no,no,yes,no,no,no,no,no,no,no,yes,no,no,yes,yes
J,"Femia, N; Petrone, G; Spagnuolo, G; Vitelli, M",Optimization of perturb and observe maximum power point tracking method,"Maximum power point tracking (MPPT) techniques are used in photovoltaic (PV) systems to maximize the PV array output power by tracking continuously the maximum power point (MPP) which depends on panels temperature and on irradiance conditions. The issue of MPPT has been addressed in different ways in the literature but, especially for low-cost implementations, the perturb and observe (P&O) maximum power point tracking algorithm is the most commonly used method due to its ease of implementation. A drawback of P&O is that, at steady state, the operating point oscillates around the MPP giving rise to the waste of some amount of available energy; moreover, it is well known that the P&O algorithm can be confused during those time intervals characterized by rapidly changing atmospheric conditions. In this paper it is shown that, in order to limit the negative effects associated to the above drawbacks, the P&O MPPT parameters must be customized to the dynamic behavior of the specific converter adopted. A theoretical analysis allowing the optimal choice of such parameters is also carried out. Results of experimental measurements are in agreement with the predictions of theoretical analysis.",10.1109/TPEL.2005.850975,87,yes,yes,no,yes,yes,no,no,no,yes,yes,yes,yes,no,no,no,no,yes,no,yes,no,no,no,no,no,no,yes,no,yes,no,yes,yes
J,"Dimarogonas, DV; Frazzoli, E; Johansson, KH",Distributed Event-Triggered Control for Multi-Agent Systems,"Event-driven strategies for multi-agent systems are motivated by the future use of embedded microprocessors with limited resources that will gather information and actuate the individual agent controller updates. The controller updates considered here are event-driven, depending on the ratio of a certain measurement error with respect to the norm of a function of the state, and are applied to a first order agreement problem. A centralized formulation is considered first and then its distributed counterpart, in which agents require knowledge only of their neighbors' states for the controller implementation. The results are then extended to a self-triggered setup, where each agent computes its next update time at the previous one, without having to keep track of the state error that triggers the actuation between two consecutive update instants. The results are illustrated through simulation examples.",10.1109/TAC.2011.2174666,88,yes,yes,no,no,yes,no,yes,yes,no,no,yes,no,no,no,no,no,yes,no,yes,no,no,no,no,no,no,no,no,no,no,yes,yes
J,"Cai, BL; Xu, XM; Jia, K; Qing, CM; Tao, DC",DehazeNet: An End-to-End System for Single Image Haze Removal,"Single image haze removal is a challenging ill-posed problem. Existing methods use various constraints/priors to get plausible dehazing solutions. The key to achieve haze removal is to estimate a medium transmission map for an input hazy image. In this paper, we propose a trainable end-to-end system called DehazeNet, for medium transmission estimation. DehazeNet takes a hazy image as input, and outputs its medium transmission map that is subsequently used to recover a haze-free image via atmospheric scattering model. DehazeNet adopts convolutional neural network-based deep architecture, whose layers are specially designed to embody the established assumptions/priors in image dehazing. Specifically, the layers of Maxout units are used for feature extraction, which can generate almost all haze-relevant features. We also propose a novel nonlinear activation function in DehazeNet, called bilateral rectified linear unit, which is able to improve the quality of recovered haze-free image. We establish connections between the components of the proposed DehazeNet and those used in existing methods. Experiments on benchmark images show that DehazeNet achieves superior performance over existing methods, yet keeps efficient and easy to use.",10.1109/TIP.2016.2598681,89,yes,no,yes,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,yes,yes,
J,"Nosratinia, A; Hunter, TE; Hedayat, A",Cooperative communication in wireless networks,"Transmit diversity generally requires more than one antenna at the transmitter. However, many wireless devices are limited by size or hardware complexity to one antenna. Recently, a new class of methods called cooperative communication has been proposed that enables single-antenna mobiles in a multi-user environment to share their antennas and generate a virtual multiple-antenna transmitter that allows them to achieve transmit diversity. This article presents an overview of the developments in this burgeoning field.",10.1109/MCOM.2004.1341264,90,yes,no,yes,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,no,yes,no,yes
J,"Yilmaz, M; Krein, PT","Review of Battery Charger Topologies, Charging Power Levels, and Infrastructure for Plug-In Electric and Hybrid Vehicles","This paper reviews the current status and implementation of battery chargers, charging power levels, and infrastructure for plug-in electric vehicles and hybrids. Charger systems are categorized into off-board and on-board types with unidirectional or bidirectional power flow. Unidirectional charging limits hardware requirements and simplifies interconnection issues. Bidirectional charging supports battery energy injection back to the grid. Typical on-board chargers restrict power because of weight, space, and cost constraints. They can be integrated with the electric drive to avoid these problems. The availability of charging infrastructure reduces on-board energy storage requirements and costs. On-board charger systems can be conductive or inductive. An off-board charger can be designed for high charging rates and is less constrained by size and weight. Level 1 (convenience), Level 2 (primary), and Level 3 (fast) power levels are discussed. Future aspects such as roadbed charging are presented. Various power level chargers and infrastructure configurations are presented, compared, and evaluated based on amount of power, charging time and location, cost, equipment, and other factors.",10.1109/TPEL.2012.2212917,91,yes,yes,no,no,yes,yes,yes,yes,no,no,yes,no,no,no,no,yes,no,no,no,no,no,no,no,no,no,yes,yes,no,yes,no,yes
J,"Khan, WA; Pop, I",Boundary-layer flow of a nanofluid past a stretching sheet,"The problem of laminar fluid flow which results from the stretching of a flat surface in a nanofluid has been investigated numerically. This is the first paper on stretching sheet in nanofluids. The model used for the nanofluid incorporates the effects of Brownian motion and thermophoresis. A similarity solution is presented which depends on the Prandtl number Pr, Lewis number Le, Brownian motion number Nb and thermophoresis number Nt. The variation of the reduced Nusselt and reduced Sherwood numbers with Nb and Nt for various values of Pr and Le is presented in tabular and graphical forms. It was found that the reduced Nusselt number is a decreasing function of each dimensionless number, while the reduced Sherwood number is an increasing function of higher Pr and a decreasing function of lower Pr number for each Le, Nb and Nt numbers. (C) 2010 Elsevier Ltd. All rights reserved.",10.1016/j.ijheatmasstransfer.2010.01.032,92,yes,yes,no,yes,yes,no,no,no,yes,no,yes,yes,no,no,no,yes,yes,yes,no,yes,no,no,yes,no,yes,no,no,no,yes,no,no
J,"Sinopoli, B; Schenato, L; Franceschetti, M; Poolla, K; Jordan, MI; Sastry, SS",Kalman filtering with intermittent observations,"Motivated by navigation and tracking applications within sensor networks, we consider the problem of performing Kalman filtering with intermittent observations. When data travel along unreliable communication channels in a large, wireless, multihop sensor network, the effect of communication delays and loss of information in the control loop cannot be neglected. We address this problem starting from the discrete Kalman filtering formulation, and modeling the arrival of the observation as a random process. We study the statistical convergence properties of the estimation error covariance, showing the existence of a critical value for the arrival rate of the observations, beyond which a transition to an unbounded state error covariance occurs. We also give upper and lower bounds on this expected state error covariance.",10.1109/TAC.2004.834121,93,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes
J,"Myronenko, A; Song, XB",Point Set Registration: Coherent Point Drift,"Point set registration is a key component in many computer vision tasks. The goal of point set registration is to assign correspondences between two sets of points and to recover the transformation that maps one point set to the other. Multiple factors, including an unknown nonrigid spatial transformation, large dimensionality of point set, noise, and outliers, make the point set registration a challenging problem. We introduce a probabilistic method, called the Coherent Point Drift (CPD) algorithm, for both rigid and nonrigid point set registration. We consider the alignment of two point sets as a probability density estimation problem. We fit the Gaussian mixture model (GMM) centroids (representing the first point set) to the data (the second point set) by maximizing the likelihood. We force the GMM centroids to move coherently as a group to preserve the topological structure of the point sets. In the rigid case, we impose the coherence constraint by reparameterization of GMM centroid locations with rigid parameters and derive a closed form solution of the maximization step of the EM algorithm in arbitrary dimensions. In the nonrigid case, we impose the coherence constraint by regularizing the displacement field and using the variational calculus to derive the optimal transformation. We also introduce a fast algorithm that reduces the method computation complexity to linear. We test the CPD algorithm for both rigid and nonrigid transformations in the presence of noise, outliers, and missing points, where CPD shows accurate results and outperforms current state-of-the-art methods.",10.1109/TPAMI.2010.46,94,yes,no,yes,no,yes,no,yes,no,yes,yes,yes,yes,no,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,no,yes,yes,
J,"RodrÃ­guez, RM; MartÃ­nez, L; Herrera, F",Hesitant Fuzzy Linguistic Term Sets for Decision Making,"Dealing with uncertainty is always a challenging problem, and different tools have been proposed to deal with it. Recently, a new model that is based on hesitant fuzzy sets has been presented to manage situations in which experts hesitate between several values to assess an indicator, alternative, variable, etc. Hesitant fuzzy sets suit the modeling of quantitative settings; however, similar situations may occur in qualitative settings so that experts think of several possible linguistic values or richer expressions than a single term for an indicator, alternative, variable, etc. In this paper, the concept of a hesitant fuzzy linguistic term set is introduced to provide a linguistic and computational basis to increase the richness of linguistic elicitation based on the fuzzy linguistic approach and the use of context-free grammars by using comparative terms. Then, a multicriteria linguistic decision-makingmodel is presented in which experts provide their assessments by eliciting linguistic expressions. This decision model manages such linguistic expressions by means of its representation using hesitant fuzzy linguistic term sets.",10.1109/TFUZZ.2011.2170076,95,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
J,"Schalk, G; McFarland, DJ; Hinterberger, T; Birbaumer, N; Wolpaw, JR","BCI2000: A general-purpose, brain-computer interface (BCI) system","Many laboratories have begun to develop brain-computer interface (BCI) systems that provide communication and control capabilities to people with severe motor disabilities. Further progress and realization of practical applications depends on systematic evaluations and comparisons of different brain signals, recording methods, processing algorithms, output formats, and operating protocols. However, the typical BCI system is designed specifically for one particular BCI method and is, therefore, not suited to the systematic studies that are essential for continued progress. In response to this problem, we have developed a documented general-purpose BCI research and development platform called BCI2000. BCI2000 can incorporate alone or in combination any brain signals, signal processing methods, output devices, and operating protocols. This report is intended to describe to investigators, biomedical engineers, and computer scientists the concepts that the BCI2000 system is based upon and gives examples of successful BCI implementations using this system. To date, we have used BCI2000 to create BCI systems for a variety of brain signals, processing methods, and applications. The data show that these systems function well in online operation and that BCI2000 satisfies the stringent real-time requirements of BCI systems. By substantially reducing labor and cost, BCI2000 facilitates the implementation of different BCI systems and other psychophysiological experiments. It is available with full documentation and free of charge for research or educational purposes and is currently being used in a variety of studies by many research groups.",10.1109/TBME.2004.827072,96,yes,no,yes,yes,yes,no,yes,no,yes,yes,yes,yes,no,no,no,yes,yes,yes,yes,no,no,no,no,yes,yes,yes,no,yes,yes,yes,
J,"Zettler, ER; Mincer, TJ; Amaral-Zettler, LA","Life in the ""Plastisphere"": Microbial Communities on Plastic Marine Debris","Plastics are the most abundant form of marine debris, with global production rising and documented impacts in some marine environments, but the influence of plastic on open ocean ecosystems is poorly understood, particularly for microbial communities. Plastic marine debris (PMD) collected at multiple locations in the North Atlantic was analyzed with scanning electron microscopy (SEM) and next generation sequencing to characterize the attached microbial communities. We unveiled a diverse microbial community of heterotrophs, autotrophs, predators, and symbionts, a community we refer to as the ""Plastisphere"". Pits visualized in the PMD surface conformed to bacterial shapes suggesting active hydrolysis of the hydrocarbon polymer. Small-subunit rRNA gene surveys identified several hydrocarbon degrading bacteria, supporting the possibility that microbes play a role in degrading PMD. Some Plastisphere members may be opportunistic pathogens (the authors, unpublished data) such as specific members of the genus Vibrio that dominated one of our plastic samples. Plastisphere communities are distinct from surrounding surface water, implying that plastic serves as a novel ecological habitat in the open ocean. Plastic has a longer half-life than most natural floating marine substrates, and a hydrophobic surface that promotes microbial colonization and biofilm formation, differing from autochthonous substrates in the upper layers of the ocean.",10.1021/es401288x,97,yes,no,no,no,yes,no,yes,no,yes,no,yes,yes,yes,yes,yes,no,yes,yes,yes,no,yes,no,no,yes,yes,yes,yes,no,yes,yes,yes
J,"Xu, ZS; Yager, RR",Some geometric aggregation operators based on intuitionistic fuzzy sets,"The weighted geometric (WG) operator and the ordered weighted geometric (OWG) operator are two common aggregation operators in the field of information fusion. But these two aggregation operators are usually used in situations where the given arguments are expressed as crisp numbers or linguistic values. In this paper, we develop some new geometric aggregation operators, such as the intuitionistic fuzzy weighted geometric (IFWG) operator, the intuitionistic fuzzy ordered weighted geometric (IFOWG) operator, and the intuitionistic fuzzy hybrid geometric (IFHG) operator, which extend the WG and OWG operators to accommodate the environment in which the given arguments are intuitionistic fuzzy sets which are characterized by a membership function and a non-membership function. Some numerical examples are given to illustrate the developed operators. Finally, we give an application of the IFHG operator to multiple attribute decision making based on intuitionistic fuzzy sets.",10.1080/03081070600574353,98,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,yes,no,no,no,no,yes,no,yes,no,no,no,no,no,no,yes,yes,no,yes,yes,yes
J,"Bercoff, J; Tanter, M; Fink, M",Supersonic shear imaging: A new technique for soft tissue elasticity mapping,"Supersonic shear imaging (SSI) is a new ultrasound-based technique for real-time visualization of soft tissue viscoelastic properties. Using ultrasonic focused beams, it is possible to remotely generate mechanical vibration sources radiating low-frequency, shear waves inside tissues. Relying on this concept, SSI proposes to create such a source and make it move at a supersonic speed. In analogy with the ""sonic boom"" created by a supersonic aircraft, the resulting shear waves will interfere constructively along a Mach cone, creating two intense plane shear waves. These waves propagate through the medium and are progressively distorted by tissue heterogeneities. An ultrafast scanner prototype is able to both generate this supersonic source and image (5000 frames/s) the propagation of the resulting shear waves. Using inversion algorithms, the shear elasticity of medium can be mapped quantitatively from this propagation movie. The SSI enables tissue elasticity mapping in less than 20 ins, even in strongly viscous medium like breast. Modalities such as shear compounding are im-plementable by tilting shear waves in different directions and improving the elasticity estimation. Results validating SSI in heterogeneous phantoms are presented. The first in vivo investigations made on healthy volunteers emphasize the potential clinical applicability of SSI for breast cancer detection.",10.1109/TUFFC.2004.1295425,99,yes,yes,no,no,yes,no,no,yes,no,no,yes,no,yes,yes,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,no,no,yes,yes,no
