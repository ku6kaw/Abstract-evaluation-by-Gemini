Publication Type,Authors,Title,Abstract,DOI,ID,rule1,rule2,rule3,rule4,rule5,rule6,rule7,rule8,rule9,rule10,rule11,rule12,rule13,rule14,rule15,rule16,rule17,rule18,rule19,rule20,rule21,rule22,rule23,rule24,rule25,rule26,rule27,rule28,rule29,rule30,rule31
J,"Clarkson, CR; Solano, N; Bustin, RM; Bustin, AMM; Chalmers, GRL; He, L; Melnichenko, YB; Radlinski, AP; Blach, TP","Pore structure characterization of North American shale gas reservoirs using USANS/SANS, gas adsorption, and mercury intrusion","Small-angle and ultra-small-angle neutron scattering (SANS and USANS), low-pressure adsorption (N-2 and CO2), and high-pressure mercury intrusion measurements were performed on a suite of North American shale reservoir samples providing the first ever comparison of all these techniques for characterizing the complex pore structure of shales. The techniques were used to gain insight into the nature of the pore structure including pore geometry, pore size distribution and accessible versus inaccessible porosity. Reservoir samples for analysis were taken from currently-active shale gas plays including the Barnett, Marcellus, Haynesville, Eagle Ford, Woodford, Muskwa, and Duvernay shales. Low-pressure adsorption revealed strong differences in BET surface area and pore volumes for the sample suite, consistent with variability in composition of the samples. The combination of CO2 and N-2 adsorption data allowed pore size distributions to be created for micro-meso-macroporosity up to a limit of similar to 1000 angstrom. Pore size distributions are either uni- or multi-modal. The adsorption-derived pore size distributions for some samples are inconsistent with mercury intrusion data, likely owing to a combination of grain compression during high-pressure intrusion, and the fact that mercury intrusion yields information about pore throat rather than pore body distributions. SANS/USANS scattering data indicate a fractal geometry (power-law scattering) for a wide range of pore sizes and provide evidence that nanometer-scale spatial ordering occurs in lower mesopore-micropore range for some samples, which may be associated with inter-layer spacing in clay minerals. SANS/USANS pore radius distributions were converted to pore volume distributions for direct comparison with adsorption data. For the overlap region between the two methods, the agreement is quite good. Accessible porosity in the pore size (radius) range 5 nm-10 mu m was determined for a Barnett shale sample using the contrast matching method with pressurized deuterated methane fluid. The results demonstrate that accessible porosity is pore-size dependent. (C) 2012 Elsevier Ltd. All rights reserved.",10.1016/j.fuel.2012.06.119,0,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
J,"Simonin, JP",On the comparison of pseudo-first order and pseudo-second order rate laws in the modeling of adsorption kinetics,"In most works in the current literature about liquid/solid adsorption kinetics, the respective abilities of pseudo-first order and pseudo-second kinetics for describing the data are compared. In nearly all cases, it is concluded that the latter surpasses the former. The aim of this work is to point out that more caution should be exercised in this comparison. Indeed, it appears that the method generally used is flawed and that it unfairly favors pseudo-second order kinetics. A different method is proposed to analyze experimental results. It is employed here to reexamine experimental data taken from the literature. (C) 2016 Elsevier B.V. All rights reserved.",10.1016/j.cej.2016.04.079,1,yes,yes,no,yes,yes,no,yes,yes,no,yes,yes,yes,yes,no,no,no,no,no,no,yes,no,no,no,no,no,no,no,no,no,yes,no
J,"Pal, P; Vaidyanathan, PP",Nested Arrays: A Novel Approach to Array Processing With Enhanced Degrees of Freedom,"A new array geometry, which is capable of significantly increasing the degrees of freedom of linear arrays, is proposed. This structure is obtained by systematically nesting two or more uniform linear arrays and can provide O(N-2) degrees of freedom using only physical sensors when the second-order statistics of the received data is used. The concept of nesting is shown to be easily extensible to multiple stages and the structure of the optimally nested array is found analytically. It is possible to provide closed form expressions for the sensor locations and the exact degrees of freedom obtainable from the proposed array as a function of the total number of sensors. This cannot be done for existing classes of arrays like minimum redundancy arrays which have been used earlier for detecting more sources than the number of physical sensors. In minimum-input-minimum-output (MIMO) radar, the degrees of freedom are increased by constructing a longer virtual array through active sensing. The method proposed here, however, does not require active sensing and is capable of providing increased degrees of freedom in a completely passive setting. To utilize the degrees of freedom of the nested co-array, a novel spatial smoothing based approach to DOA estimation is also proposed, which does not require the inherent assumptions of the traditional techniques based on fourth-order cumulants or quasi stationary signals. As another potential application of the nested array, a new approach to beamforming based on a nonlinear preprocessing is also introduced, which can effectively utilize the degrees of freedom offered by the nested arrays. The usefulness of all the proposed methods is verified through extensive computer simulations.",10.1109/TSP.2010.2049264,2,yes,no,no,yes,yes,no,yes,no,yes,no,yes,no,no,no,no,no,yes,no,yes,no,no,no,no,no,yes,yes,yes,no,no,yes,no
J,"Hartmann, NB; Hüffer, T; Thompson, RC; Hassellöv, M; Verschoor, A; Daugaard, AE; Rist, S; Karlsson, T; Brennholt, N; Cole, M; Herrling, MP; Hess, MC; Ivleva, NP; Lusher, AL; Wagner, M",Are We Speaking the Same Language? Recommendations for a Definition and Categorization Framework for Plastic Debris,"The accumulation of plastic litter in natural environments is a global issue. Concerns over potential negative impacts on the economy, wildlife, and human health provide strong incentives for improving the sustainable use of plastics. Despite the many voices raised on the issue, we lack a consensus on how to define and categorize plastic debris. This is evident for microplastics, where inconsistent size classes are used and where the materials to be included are under debate. While this is inherent in an emerging research field, an ambiguous terminology results in confusion and miscommunication that may compromise progress in research and mitigation measures. Therefore, we need to be explicit on what exactly we consider plastic debris. Thus, we critically discuss the advantages and disadvantages of a unified terminology, propose a definition and categorization framework, and highlight areas of uncertainty. Going beyond size classes, our framework includes physicochemical properties (polymer composition, solid state, solubility) as defining criteria and size, shape, color, and origin as classifiers for categorization. Acknowledging the rapid evolution of our knowledge on plastic pollution, our framework will promote consensus building within the scientific and regulatory community based on a solid scientific foundation.",10.1021/acs.est.8b05297,3,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,no,yes,yes,yes
J,"Shafi, M; Molisch, AF; Smith, PJ; Haustein, T; Zhu, PY; De Silva, P; Tufvesson, F; Benjebbour, A; Wunder, G","5G: A Tutorial Overview of Standards, Trials, Challenges, Deployment, and Practice","There is considerable pressure to define the key requirements of 5G, develop 5G standards, and perform technology trials as quickly as possible. Normally, these activities are best done in series but there is a desire to complete these tasks in parallel so that commercial deployments of 5G can begin by 2020. 5G will not be an incremental improvement over its predecessors; it aims to be a revolutionary leap forward in terms of data rates, latency, massive connectivity, network reliability, and energy efficiency. These capabilities are targeted at realizing highspeed connectivity, the Internet of Things, augmented virtual reality, the tactile internet, and so on. The requirements of 5G are expected to be met by new spectrum in the microwave bands (3.3-4.2 GHz), and utilizing large bandwidths available in mm-wave bands, increasing spatial degrees of freedom via large antenna arrays and 3-D MIMO, network densification, and new waveforms that provide scalability and flexibility to meet the varying demands of 5G services. Unlike the one size fits all 4G core networks, the 5G core network must be flexible and adaptable and is expected to simultaneously provide optimized support for the diverse 5G use case categories. In this paper, we provide an overview of 5G research, standardization trials, and deployment challenges. Due to the enormous scope of 5G systems, it is necessary to provide some direction in a tutorial article, and in this overview, the focus is largely user centric, rather than device centric. In addition to surveying the state of play in the area, we identify leading technologies, evaluating their strengths and weaknesses, and outline the key challenges ahead, with research test beds delivering promising performance but pre-commercial trials lagging behind the desired 5G targets.",10.1109/JSAC.2017.2692307,4,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,no,no,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,yes,yes,yes
J,"Lu, YF; Zhang, Y; Deng, YF; Jiang, W; Zhao, YP; Geng, JJ; Ding, LL; Ren, HQ",Uptake and Accumulation of Polystyrene Microplastics in Zebrafish (<i>Danio rerio</i>) and Toxic Effects in Liver,"Microplastics have become emerging contaminants, causing widespread concern about their potential toxic effects. In this study, the uptake and tissue accumulation of polystyrene microplastics (PS-MPs) in zebrafish were detected, and the toxic effects in liver were investigated. The results showed that after 7 days of exposure, 5 mu m diameter MPs accumulated in fish gills, liver, and gut, while 20 mu m diameter MPs accumulated only in fish gills and gut. Histopathological analysis showed that both 5 mu m and 70 nm PS-MPs caused inflammation and lipid accumulation in fish liver. PS-MPs also induced significantly increased activities of superoxide dismutase and catalase, indicating that, oxidative stress was induced after treatment with MPs. In addition, metabolomic analysis suggested that exposure to MPs induced alterations of metabolic profiles in fish liver and disturbed the lipid and energy metabolism. These findings provide new insights into the toxic effects of MPs on fish.",10.1021/acs.est.6b00183,5,yes,yes,no,no,yes,no,yes,no,yes,no,yes,yes,no,no,no,no,yes,yes,no,yes,yes,yes,no,yes,yes,yes,no,no,yes,yes,no
J,"Xydeas, CS; Petrovic, V",Objective image fusion performance measure,"A measure for objectively assessing the pixel level fusion performance is defined. The proposed metric reflects the quality of,visual information obtained from the fusion of input images and can he used to compare the performance of different image fusion algorithms. Experimental results clearly indicate that this metric is perceptually meaningful.",10.1049/el:20000267,6,yes,yes,no,no,yes,yes,yes,yes,no,no,yes,no,no,no,no,yes,yes,yes,yes,no,no,no,no,no,yes,yes,no,no,no,yes,no
J,"Ganti, RK; Ye, F; Lei, H",Mobile Crowdsensing: Current State and Future Challenges,"An emerging category of devices at the edge of the Internet are consumer-centric mobile sensing and computing devices, such as smartphones, music players, and in-vehicle sensors. These devices will fuel the evolution of the Internet of Things as they feed sensor data to the Internet at a societal scale. In this article, we examine a category of applications that we term mobile crowdsensing, where individuals with sensing and computing devices collectively share data and extract information to measure and map phenomena of common interest. We present a brief overview of existing mobile crowdsensing applications, explain their unique characteristics, illustrate various research challenges, and discuss possible solutions. Finally, we argue the need for a unified architecture and envision the requirements it must satisfy.",10.1109/MCOM.2011.6069707,7,yes,no,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,no,yes,yes,yes
J,"Lachheb, H; Puzenat, E; Houas, A; Ksibi, M; Elaloui, E; Guillard, C; Herrmann, JM","Photocatalytic degradation of various types of dyes (Alizarin S, Crocein Orange G, Methyl Red, Congo Red, Methylene Blue) in water by UV-irradiated titania","The photocatalytic degradation of five various dyes has been investigated in TiO2/UV aqueous suspensions. It was attempted to determine the feasibility of such a degradation by varying the chemical structures, either anthraquinonic (Alizarin S (AS)), or azoic (Crocein Orange G (OG), Methyl Red (MR), Congo Red (CR)) or heteropolyaromatic (Methylene Blue (MB)). In addition to a prompt removal of the colors, TiO2/UV-based photocatalysis was simultaneously able to fully oxidize the dyes, with a complete mineralization of carbon into CO2. Sulfur heteroatoms were converted into innocuous SO(4)(2-)ions. The mineralization of nitrogen was more complex. Nitrogen atoms in the -3 oxidation state, such as in amino-groups, remain at this reduction degree and produced NH4+ cations, subsequently and very slowly converted into NO3- ions. For azo-dye (OG, MR, CR) degradation, the complete mass balance in nitrogen indicated that the central -N=N- azo-group was converted in gaseous dinitrogen, which is the ideal issue for the elimination of nitrogen-containing pollutants, not only for environmental photocatalysis but also for any physicochemical method. The aromatic rings were submitted to successive attacks by photogenerated OH. radicals leading to hydroxylated metabolites before the ring opening and the final evolution of CO2 induced by repeated subsequent ""photo-Kolbe"" reactions with carboxylic intermediates. These results suggest that TiO2/UV photocatalysis maybe envisaged as a method for treatment of diluted colored waste waters not only for decolorization, but also for detoxification, in particular in textile industries in semi-arid countries. (C) 2002 Elsevier Science B.V. All rights reserved.",10.1016/S0926-3373(02)00078-4,8,yes,no,no,no,yes,no,yes,no,yes,no,yes,yes,yes,yes,no,no,yes,yes,no,yes,no,no,no,yes,yes,yes,no,yes,yes,yes,no
J,"Chen, YH; Krishna, T; Emer, JS; Sze, V",Eyeriss: An Energy-Efficient Reconfigurable Accelerator for Deep Convolutional Neural Networks,"Eyeriss is an accelerator for state-of-the-art deep convolutional neural networks (CNNs). It optimizes for the energy efficiency of the entire system, including the accelerator chip and off-chip DRAM, for various CNN shapes by reconfiguring the architecture. CNNs are widely used in modern AI systems but also bring challenges on throughput and energy efficiency to the underlying hardware. This is because its computation requires a large amount of data, creating significant data movement from on-chip and off-chip that is more energyconsuming than computation. Minimizing data movement energy cost for any CNN shape, therefore, is the key to high throughput and energy efficiency. Eyeriss achieves these goals by using a proposed processing dataflow, called row stationary (RS), on a spatial architecture with 168 processing elements. RS dataflow reconfigures the computation mapping of a given shape, which optimizes energy efficiency by maximally reusing data locally to reduce expensive data movement, such as DRAM accesses. Compression and data gating are also applied to further improve energy efficiency. Eyeriss processes the convolutional layers at 35 frames/s and 0.0029 DRAM access/multiply and accumulation (MAC) for AlexNet at 278 mW (batch size N = 4), and 0.7 frames/s and 0.0035 DRAM access/MAC for VGG-16 at 236 mW (N = 3).",10.1109/JSSC.2016.2616357,9,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
J,"Xia, GS; Hu, JW; Hu, F; Shi, BG; Bai, X; Zhong, YF; Zhang, LP; Lu, XQ",AID: A Benchmark Data Set for Performance Evaluation of Aerial Scene Classification,"Aerial scene classification, which aims to automatically label an aerial image with a specific semantic category, is a fundamental problem for understanding high-resolution remote sensing imagery. In recent years, it has become an active task in the remote sensing area, and numerous algorithms have been proposed for this task, including many machine learning and data-driven approaches. However, the existing data sets for aerial scene classification, such as UC-Merced data set and WHU-RS19, contain relatively small sizes, and the results on them are already saturated. This largely limits the development of scene classification algorithms. This paper describes the Aerial Image data set (AID): a large-scale data set for aerial scene classification. The goal of AID is to advance the state of the arts in scene classification of remote sensing images. For creating AID, we collect and annotate more than 10 000 aerial scene images. In addition, a comprehensive review of the existing aerial scene classification techniques as well as recent widely used deep learning methods is given. Finally, we provide a performance analysis of typical aerial scene classification and deep learning approaches on AID, which can be served as the baseline results on this benchmark.",10.1109/TGRS.2017.2685945,10,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,yes,yes,no,yes,no,yes,yes,yes,no,no,no,yes,no,yes,yes,no,yes,yes,yes,
J,"Jaouen, F; Proietti, E; Lefèvre, M; Chenitz, R; Dodelet, JP; Wu, G; Chung, HT; Johnston, CM; Zelenay, P",Recent advances in non-precious metal catalysis for oxygen-reduction reaction in polymer electrolyte fuel cells,"Hydrogen produced from water and renewable energy could fuel a large fleet of proton-exchange-fuel-cell vehicles in the future. However, the dependence on expensive Pt-based electrocatalysts in such fuel cells remains a major obstacle for a widespread deployment of this technology. One solution to overcome this predicament is to reduce the Pt content by a factor of ten by replacing the Pt-based catalysts with non-precious metal catalysts at the oxygen-reducing cathode. Fe-and Co-based electrocatalysts for this reaction have been studied for over 50 years, but they were insufficiently active for the high efficiency and power density needed for transportation fuel cells. Recently, several breakthroughs occurred that have increased the activity and durability of non-precious metal catalysts (NPMCs), which can now be regarded as potential competitors to Pt-based catalysts. This review focuses on the new synthesis methods that have led to these breakthroughs. A modeling analysis is also conducted to analyze the improvements required from NPMC-based cathodes to match the performance of Pt-based cathodes, even at high current density. While no further breakthrough in volume-specific activity of NPMCs is required, incremental improvements of the volume-specific activity and effective protonic conductivity within the fuel-cell cathode are necessary. Regarding durability, NPMCs with the best combination of durability and activity result in ca. 3 times lower fuel cell performance than the most active NPMCs at 0.80 V. Thus, major tasks will be to combine durability with higher activity, and also improve durability at cell voltages greater than 0.60 V.",10.1039/c0ee00011f,11,yes,no,no,yes,yes,no,yes,no,yes,yes,yes,yes,no,no,no,yes,yes,yes,no,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,no
J,"Allen, RG; Tasumi, M; Trezza, R",Satellite-based energy balance for mapping evapotranspiration with internalized calibration (METRIC) - Model,"Mapping evapotranspiration at high resolution with internalized calibration (METRIC) is a satellite-based image-processing model for calculating evapotranspiration (ET) as a residual of the surface energy balance. METRIC uses as its foundation the pioneering SEBAL energy balance process developed in The Netherlands by Bastiaanssen, where the near-surface temperature gradients are an indexed function of radiometric surface temperature, thereby eliminating the need for absolutely accurate surface temperature and the need for air-temperature measurements. The surface energy balance is internally calibrated using ground-based reference ET to reduce computational biases inherent to remote sensing-based energy balance and to provide congruency with traditional methods for ET. Slope and aspect functions and temperature lapsing are used in applications in mountainous terrain. METRIC algorithms are designed for relatively routine application by trained engineers and other technical professionals who possess a familiarity with energy balance and basic radiation physics. The primary inputs for the model are short-wave and long-wave (thermal) images from a satellite (e.g., Landsat and MODIS), a digital elevation model and ground-based weather data measured within or near the area of interest. ET ""maps"" (i.e., images) via METRIC provide the means to quantify ET on a field-by-field basis in terms of both the rate and spatial distribution. METRIC has some significant advantages over many traditional applications of satellite-based energy balance in that its calibration is made using reference ET, rather than the evaporative fraction. The use of reference ET for the extrapolation of instantaneous ET from periods of 24 h and longer compensates for regional advection effects by not tying the evaporative fraction to net radiation, since ET can exceed daily net radiation in many and or semi-arid locations. METRIC has some significant advantages over conventional methods of estimating ET from crop coefficient curves in that neither the crop development stages, nor the specific crop type need to be known with METRIC. In addition, energy balance can detect reduced ET caused by water shortage.",10.1061/(ASCE)0733-9437(2007)133:4(380),12,yes,yes,no,yes,no,no,no,no,no,no,yes,no,yes,yes,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,no,yes,yes,yes,yes
J,"Fischl, B; Liu, A; Dale, AM",Automated manifold surgery: Constructing geometrically accurate and topologically correct models of the human cerebral cortex,"Highly accurate surface models of the cerebral cortex are becoming increasingly important as tools in the investigation of the functional organization of the human brain. The construction of such models is difficult using current neuroimaging technology due to the high degree of cortical folding. Even single voxel misclassifications can result in erroneous connections being created between adjacent hanks of a sulcus, resulting in a topologically inaccurate model. These topological defects cause the cortical model to no longer be homeomorphic to a sheet, preventing the accurate inflation, flattening, or spherical morphing of the reconstructed cortex. Surface deformation techniques can guarantee the topological correctness of a model, but are time-consuming and may result in geometrically inaccurate models. in order to address this need we have developed a technique for taking a model of the cortex, detecting and fixing the topological defects while leaving that majority of the model intact, resulting in a surface that is both geometrically accurate and topologically correct.",10.1109/42.906426,13,yes,no,yes,yes,yes,no,yes,no,yes,yes,yes,yes,no,no,no,no,no,no,no,yes,no,no,no,no,yes,no,no,no,yes,yes,yes
J,"Yue, D; Tian, EG; Han, QL",A Delay System Method for Designing Event-Triggered Controllers of Networked Control Systems,"This note is concerned with event-triggered H-infinity controller design for networked control systems. A novel event-triggering scheme is proposed, which has some advantages over some existing schemes. A delay system model for the analysis is firstly constructed by investigating the effect of the network transmission delay. Then, based on this model, criteria for stability with an H-infinity norm bound and criteria for co-designing both the feedback gain and the trigger parameters are derived. These criteria are formulated in terms of linear matrix inequalities. Simulation results have shown that the proposed event-triggering scheme is superior to some existing event-triggering schemes in the literature.",10.1109/TAC.2012.2206694,14,yes,yes,no,yes,yes,no,yes,no,yes,no,yes,yes,no,no,no,yes,yes,yes,no,yes,no,no,no,yes,yes,no,yes,no,no,yes,no
J,"Mercelis, P; Kruth, JP",Residual stresses in selective laser sintering and selective laser melting,"Purpose - This paper presents an investigation into residual stresses in selective laser sintering (SLS) and selective laser melting (SLM), aiming at a better understanding of this phenomenon. Design/methodology/approach - First, the origin of residual stresses is explored and a simple theoretical model is developed to predict residual stress distributions. Next, experimental methods are used to measure the residual stress profiles in a set of test samples produced with different process parameters. Findings - Residual stresses are found to be very large in SLM parts. In general, the residual stress profile consists of two zones of large tensile stresses at the top and bottom of the part, and a large zone of intermediate compressive stress in between. The most important parameters determining the magnitude and shape of the residual stress profiles are the material properties, the sample and substrate height, the laser scanning strategy and the heating conditions. Research limitations/implications - All experiments were conducted on parts produced from stainless steel powder (316L) and quantitative results cannot be simply extrapolated to other materials. However, most qualitative results can still be generalized. Originality/value - This paper can serve as an aid in understanding the importance of residual stresses in SLS/SLM and other additive manufacturing processes involving a localized heat input. Some of the conclusions can be used to avoid problems associated with residual stresses.",10.1108/13552540610707013,15,yes,no,no,no,yes,yes,yes,no,yes,no,yes,yes,yes,no,yes,no,yes,yes,yes,no,no,no,yes,yes,yes,yes,yes,no,yes,yes,no
J,"Yager, RR",Generalized Orthopair Fuzzy Sets,"We note that orthopair fuzzy subsets are such that that their membership grades are pairs of values, from the unit interval, one indicating the degree of support for membership in the fuzzy set and the other support against membership. We discuss two examples, Atanassov's classic intuitionistic sets and a second kind of intuitionistic set called Pythagorean. We note that for classic intuitionistic sets the sum of the support for and against is bounded by one, while for the second kind, Pythagorean, the sum of the squares of the support for and against is bounded by one. Here we introduce a general class of these sets called q-rung orthopair fuzzy sets in which the sum of the qth power of the support for and the qth power of the support against is bonded by one. We note that as q increases the space of acceptable orthopairs increases and thus gives the user more freedom in expressing their belief about membership grade. We investigate various set operations as well as aggregation operations involving these types of sets.",10.1109/TFUZZ.2016.2604005,16,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,no,no,no,yes
J,"Koetter, R; Médard, M",An algebraic approach to network coding,"We take a new look at the issue of network capacity. It is shown that network coding is an essential ingredient in achieving the capacity of a network. Building on recent work by Li et al., who examined the network capacity of multicast networks, we extend the network coding framework to arbitrary networks and robust networking. For networks which are restricted to using linear network codes, we find necessary and sufficient conditions for the feasibility of any given set of connections over a given network. We also consider the problem of network recovery for nonergodic link failures. For the multicast setup we prove that there exist coding strategies that provide maximally robust networks and that do not require adaptation of the network interior to the failure pattern in question. The results are derived for both delay-free networks and networks with delays.",10.1109/TNET.2003.818197,17,yes,yes,no,yes,yes,no,yes,no,yes,no,yes,yes,no,no,no,no,no,no,no,yes,no,no,no,no,no,yes,no,no,yes,yes,yes
J,"Liu, CJ; Wechsler, H",Gabor feature based classification using the enhanced Fisher linear discriminant model for face recognition,"This paper introduces a novel Gabor-Fisher Classifier (GFC) for face recognition. The GFC method, which is robust to changes in illumination and facial expression, applies the Enhanced Fisher linear discriminant Model (EFM) to an augmented Gabor feature vector derived from the Gabor wavelet representation of face images. The novelty of this paper comes from 1) the derivation of an augmented Gabor feature vector, whose dimensionality is further reduced using the EFM by considering both data compression and recognition (generalization) performance; 2) the development of a Gabor-Fisher classifier for multi-class problems; and 3) extensive performance evaluation studies. In particular, we performed comparative studies of different similarity measures applied to various classifiers. We also performed comparative experimental studies of various face recognition schemes, including our novel GFC method, the Gabor wavelet method, the Eigenfaces method, the Fisherfaces method, the EFM method, the combination of Gabor and the Eigenfaces method, and the combination of Gabor and the Fisherfaces method. The feasibility of the new GFC method has been successfully tested on face recognition using 600 FERET frontal face images corresponding to 200 subjects, which were acquired under variable illumination and facial expressions. The novel GFC method achieves 100% accuracy on face recognition using only 62 features.",10.1109/TIP.2002.999679,18,yes,yes,no,yes,yes,yes,yes,no,yes,no,yes,yes,yes,no,no,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,no,yes,yes,yes
J,"Li, SQ; Mi, CC",Wireless Power Transfer for Electric Vehicle Applications,"Wireless power transfer (WPT) using magnetic resonance is the technology which could set human free from the annoying wires. In fact, the WPT adopts the same basic theory which has already been developed for at least 30 years with the term inductive power transfer. WPT technology is developing rapidly in recent years. At kilowatts power level, the transfer distance increases from several millimeters to several hundred millimeters with a grid to load efficiency above 90%. The advances make the WPT very attractive to the electric vehicle (EV) charging applications in both stationary and dynamic charging scenarios. This paper reviewed the technologies in the WPT area applicable to EV wireless charging. By introducing WPT in EVs, the obstacles of charging time, range, and cost can be easily mitigated. Battery technology is no longer relevant in the mass market penetration of EVs. It is hoped that researchers could be encouraged by the state-of-the-art achievements, and push forward the further development of WPT as well as the expansion of EV.",10.1109/JESTPE.2014.2319453,19,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,no,no,no,no,yes,yes,yes,yes,no,no,no,yes,yes,yes,yes,yes,yes,yes,yes,no
J,"Mishra, UK; Shen, L; Kazior, TE; Wu, YF",GaN-Based RF power devices and amplifiers,"The rapid development of the RF power electronics requires the introduction of wide bandgap material due to its potential in high Output power density, high operation voltage and high input impedance. GaN-based RF power devices have made substantial progresses in the last decade. This paper attempts to review the latest developments of the GaN HEMT technologies, including material growth, processing technologies, device epitaxial structures and MMIC designs, to achieve the state-of-the-art microwave and millimeter-wave performance. The reliability and manufacturing challenges are also discussed.",10.1109/JPROC.2007.911060,20,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,no,no,no,no,yes,no,no,no,no,no,no,no,no,no,yes,yes,no,yes,yes,yes
J,"Dollár, P; Appel, R; Belongie, S; Perona, P",Fast Feature Pyramids for Object Detection,"Multi-resolution image features may be approximated via extrapolation from nearby scales, rather than being computed explicitly. This fundamental insight allows us to design object detection algorithms that are as accurate, and considerably faster, than the state-of-the-art. The computational bottleneck of many modern detectors is the computation of features at every scale of a finely-sampled image pyramid. Our key insight is that one may compute finely sampled feature pyramids at a fraction of the cost, without sacrificing performance: for a broad family of features we find that features computed at octave-spaced scale intervals are sufficient to approximate features on a finely-sampled pyramid. Extrapolation is inexpensive as compared to direct feature computation. As a result, our approximation yields considerable speedups with negligible loss in detection accuracy. We modify three diverse visual recognition systems to use fast feature pyramids and show results on both pedestrian detection (measured on the Caltech, INRIA, TUD-Brussels and ETH data sets) and general object detection (measured on the PASCAL VOC). The approach is general and is widely applicable to vision algorithms requiring fine-grained multi-scale analysis. Our approximation is valid for images with broad spectra (most natural images) and fails for images with narrow band-pass spectra (e.g., periodic textures).",10.1109/TPAMI.2014.2300479,21,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,yes,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,yes,yes,yes
J,"Skogestad, S",Simple analytic rules for model reduction and PID controller tuning,"The aim of this paper is to present analytic rules for PID controller tuning that are simple and still result in good closed-loop behavior. The starting point has been the IMC-PID tuning rules that have achieved widespread industrial acceptance. The rule for the integral term has been modified to improve disturbance rejection for integrating processes. Furthermore, rather than deriving separate rules for each transfer function model, there is a just a single tuning rule for a first-order or second-order time delay model. Simple analytic rules for model reduction are presented to obtain a model in this form, including the ""half rule"" for obtaining the effective time delay. (C) 2002 Elsevier Science Ltd. All rights reserved.",10.1016/S0959-1524(02)00062-8,22,yes,yes,no,yes,yes,yes,yes,no,yes,no,yes,yes,no,no,no,yes,no,no,no,yes,no,no,no,no,no,no,no,no,no,yes,yes
J,"Rabczuk, T; Belytschko, T",Cracking particles: a simplified meshfree method for arbitrary evolving cracks,"A new approach for modelling discrete cracks in meshfree methods is described. In this method, the crack can be arbitrarily oriented, but its growth is represented discretely by activation of crack surfaces at individual particles, so no representation of the crack's topology is needed. The crack is modelled by a local enrichment of the test and trial functions with a sign function (a variant of the Heaviside step function), so that the discontinuities are along the direction of the crack. The discontinuity consists of cylindrical planes centred at the particles in three dimensions, lines centred at the particles in two dimensions. The model is applied to several 2D problems and compared to experimental data. Copyright (C) 2004 John Wiley Sons, Ltd.",10.1002/nme.1151,23,yes,yes,no,no,yes,yes,yes,no,yes,no,yes,yes,no,no,no,no,yes,no,no,yes,no,no,no,no,no,no,no,no,no,yes,no
J,"Qu, J; Zhao, X; Liang, YP; Zhang, TL; Ma, PX; Guo, BL","Antibacterial adhesive injectable hydrogels with rapid self-healing, extensibility and compressibility as wound dressing for joints skin wound healing","Designing wound dressing materials with outstanding therapeutic effects, self-healing, adhesiveness and suitable mechanical property has great practical significance in healthcare, especially for joints skin wound healing. Here, we designed a kind of self-healing injectable micelle/hydrogel composites with multi-functions as wound dressing for joint skin damage. By combining the dynamic Schiff base and copolymer micelle cross-linking in one system, a series of hydrogels were prepared by mixing quaternized chitosan (QCS) and benzaldehyde-terminated Pluronic (center dot)F127 (PF127-CHO) under physiological conditions. The inherent antibacterial property, pH-dependent biodegradation and release behavior were investigated to confirm multi-functions of wound dressing. The hydrogel dressings showed suitable stretchable and compressive property, comparable modulus with human skin, good adhesiveness and fast self-healing ability to bear deformation. The hydrogels exhibited efficient hemostatic performance and biocompatibility. Moreover, the curcumin loaded hydrogel showed good antioxidant ability and pH responsive release profiles. In vivo experiments indicated that curcumin loaded hydrogels significantly accelerated wound healing rate with higher granulation tissue thickness and collagen disposition and upregulated vascular endothelial growth factor (VEGF) in a full-thickness skin defect model. Taken together, the antibacterial adhesive hydrogels with self-healing and good mechanical property offer significant promise as dressing materials for joints skin wound healing.",10.1016/j.biomaterials.2018.08.044,24,yes,yes,no,no,yes,no,yes,no,yes,yes,yes,yes,no,no,no,yes,yes,yes,no,yes,no,no,yes,yes,yes,yes,no,no,yes,yes,
J,"Hassenzahl, M; Tractinsky, N",User experience - a research agenda,"Over the last decade, 'user experience' (UX) became a buzzword in the field of human computer interaction (HCI) and interaction design. As technology matured, interactive products became not only more useful and usable, but also fashionable, fascinating things to desire. Driven by the impression that a narrow focus on interactive products as tools does not capture the variety and emerging aspects of technology use, practitioners and researchers alike, seem to readily embrace the notion of UX as a viable alternative to traditional HCI. And, indeed, the term promises change and a fresh look, without being too specific about its definite meaning. The present introduction to the special issue on ` Empirical studies of the user experience' attempts to give a provisional answer to the question of what is meant by ` the user experience'. It provides a cursory sketch of UX and how we think UX research will look like in the future. It is not so much meant as a forecast of the future, but as a proposal - a stimulus for further UX research.",10.1080/01449290500330331,25,yes,no,no,yes,yes,no,no,yes,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,no,yes,yes,yes
J,"Yu, YJ; Acton, ST",Speckle reducing anisotropic diffusion,"This paper provides the derivation of speckle reducing anisotropic diffusion (SRAD), a diffusion method tailored to ultrasonic and radar imaging applications. SRAD is the edge-sensitive diffusion for speckled images, in the same way that conventional anisotropic diffusion is the edge-sensitive diffusion for images corrupted with additive noise. We first show that the Lee and Frost filters can be cast as partial differential equations, and then we derive SRAD by allowing edge-sensitive anisotropic diffusion within this context. Just as the Lee and Frost filters utilize the coefficient of variation in adaptive filtering, SRAD exploits the instantaneous coefficient of variation, which is shown to be a function of the local gradient magnitude and Laplacian operators. We validate the new algorithm using both synthetic and real linear scan ultrasonic imagery of the carotid artery. We also demonstrate the algorithm performance with real SAR data. The performance measures obtained by means of computer simulation of carotid artery images are compared with three existing speckle reduction schemes. In the presence of speckle noise, speckle reducing anisotropic diffusion excels over the traditional speckle removal filters and over the conventional anisotropic diffusion method in terms of mean preservation, variance reduction, and edge localization.",10.1109/TIP.2002.804279,26,yes,yes,no,yes,yes,yes,yes,yes,no,no,yes,no,yes,no,no,yes,yes,yes,yes,no,yes,yes,no,yes,yes,yes,yes,yes,no,yes,yes
J,"Ahmed, MN; Yamany, SM; Mohamed, N; Farag, AA; Moriarty, T",A modified fuzzy C-means algorithm for bias field estimation and segmentation of MRI data,"In this paper, we present a novel algorithm for fuzzy segmentation of magnetic resonance imaging (MRI) data and estimation of intensity inhomogeneities using fuzzy logic. MRI intensity inhomogeneities can be attributed to imperfections in the radio-frequency coils or to problems associated with the acquisition sequences. The result is a slowly varying shading artifact over the image that can produce errors with conventional intensity-based classification. Our algorithm is formulated by modifying the objective function of the standard fuzzy c-means (FCM) algorithm to compensate for such inhomogeneities and to allow the labeling of a pixel (voxel) to be influenced by the labels in its immediate neighborhood. The neighborhood effect acts as a regularizer and biases the solution toward piecewise-homogeneous labelings. Such a regularization is useful in segmenting scans corrupted by salt and pepper noise. Experimental results on both synthetic images and MR data are given to demonstrate the effectiveness and efficiency of the proposed algorithm.",10.1109/42.996338,27,yes,no,yes,yes,yes,yes,yes,yes,no,no,yes,no,yes,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,yes,yes,yes
J,"Montavon, G; Samek, W; Müller, KR",Methods for interpreting and understanding deep neural networks,"This paper provides an entry point to the problem of interpreting a deep neural network model and explaining its predictions. It is based on a tutorial given at ICASSP 2017. As a tutorial paper, the set of methods covered here is not exhaustive, but sufficiently representative to discuss a number of questions in interpretability, technical challenges, and possible applications. The second part of the tutorial focuses on the recently proposed layer-wise relevance propagation (LRP) technique, for which we provide theory, recommendations, and tricks, to make most efficient use of it on real data. (C) 2017 The Authors. Published by Elsevier Inc.",10.1016/j.dsp.2017.10.011,28,yes,yes,no,yes,yes,yes,yes,yes,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no
J,"Fredlake, CP; Crosthwaite, JM; Hert, DG; Aki, SNVK; Brennecke, JF",Thermophysical properties of imidazolium-based ionic liquids,"Ionic liquids (ILs) are salts that are liquid at low temperatures, usually including the region around room temperature. They are under intense investigation, especially as replacement solvents for reactions and separations, since they exhibit negligible vapor pressure and would not, therefore, contribute to air pollution. Clearly, basic thermophysical properties are vital for design and evaluation for these applications. We present density as a function of temperature, melting temperatures, glass-transition temperatures, decomposition temperatures, and heat capacities as a function of temperature for a series of 13 of the popular imidazolium-based ILs. The ionic liquids investigated here are 1-butyl-3-methylimidazolium tetrafluoroborate, 1-butyl-3-methylimidazolium hexafluorophosphate, 1-butyl-3-methylimidazolium chloride, 1-butyl-3-methylimidazolium bromide, 1-butyl-3-methylimidazolium dicyanamide, 1-butyl-3-methylimidazolium trifluoromethanesulfonate, 1-butyl-3-methylimidazolium tris(trifluoromethylsulfonyl)methide, 1-butyl-3-methylimidazolium bis(trifluoromethylsulfonyl)imide, 1-ethyl-3-methylimidazolium his(trifluoromethylsulfonyl)imide, 2,3-dimethyl-1-ethylimidazolium bis(trifluoromethylsulfonyl)imide, 2,3-dimethyl-1-propylimidazolium bis(trifluoromethylsulfonyl)imide, 1-butyl-2,3-dimethylimidazolium tetrafluoroborate, and 1-butyl-2,3-dimethylimidazolium hexafluorophosphate. The properties follow quite reasonable trends. For instance, density decreases as the length of the alkyl chain on the cation increases. For a given cation, the density increases as the molecular weight of the anion increases for the anions studied here. Many of the ILs tend to subcool easily, forming glasses at very low temperatures rather than exhibiting crystallization or melting transitions. The thermal stability increases with increasing anion size, and heat capacities increase with temperature and increasing number of atoms in the IL.",10.1021/je034261a,29,yes,no,no,no,yes,no,yes,yes,no,yes,yes,no,yes,no,no,yes,yes,yes,yes,no,no,no,yes,yes,yes,no,no,no,no,yes,yes
J,"Sim, T; Baker, S; Bsat, M","The CMU pose, illumination, and expression database","In the Fall of 2000, we collected a database of more than 40,000 facial images of 68 people. Using the Carnegie Mellon University 3D Room, we imaged each person across 13 different poses, under 43 different illumination conditions, and with four different expressions. We call this the CMU Pose, Illumination, and Expression (PIE) database. We describe the imaging hardware, the collection procedure, the organization of the images, several possible uses, and how to obtain the database.",10.1109/tpami.2003.1251154,30,no,no,no,no,no,no,no,no,yes,no,yes,yes,yes,yes,yes,no,no,no,no,yes,no,no,no,yes,no,no,no,no,yes,yes,
J,"Nitzl, C; Roldan, JL; Cepeda, G",Mediation analysis in partial least squares path modeling Helping researchers discuss more sophisticated models,"Purpose - Indirect or mediated effects constitute a type of relationship between constructs that often occurs in partial least squares (PLS) path modeling. Over the past few years, the methods for testing mediation have become more sophisticated. However, many researchers continue to use outdated methods to test mediating effects in PLS, which can lead to erroneous results. One reason for the use of outdated methods or even the lack of their use altogether is that no systematic tutorials on PLS exist that draw on the newest statistical findings. The paper aims to discuss these issues. Design/methodology/approach - This study illustrates the state-of-the-art use of mediation analysis in the context of PLS-structural equation modeling (SEM). Findings - This study facilitates the adoption of modern procedures in PLS-SEM by challenging the conventional approach to mediation analysis and providing more accurate alternatives. In addition, the authors propose a decision tree and classification of mediation effects. Originality/value - The recommended approach offers a wide range of testing options (e.g. multiple mediators) that go beyond simple mediation analysis alternatives, helping researchers discuss their studies in a more accurate way.",10.1108/IMDS-07-2015-0302,31,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,no,no,no,no,no,yes,yes,yes,no,no,no,no,no,yes,yes,yes,no,yes,yes,
J,"Benn, TM; Westerhoff, P",Nanoparticle silver released into water from commercially available sock fabrics,"Manufacturers of clothing articles employ nanosilver (n-Ag) as an antimicrobial agent, but the environmental impacts of n-Ag release from commercial products are unknown. The quantity and form of the nanomaterials released from consumer products should be determined to assess the environmental risks of nanotechnology. This paper investigates silver released from commercial clothing (socks) into water, and its fate in wastewater treatment plants (WWTPs). Six types of socks contained up to a maximum of 1360 mu g-Ag/g-sock and leached as much as 650 mu g of silver in 500 mL of distilled water. Microscopy conducted on sock material and wash water revealed the presence of silver particles from 10 to 500 nm in diameter. Physical separation and ion selective electrode (ISE) analyses suggest that both colloidal and ionic silver leach from the socks. Variable leaching rates among sock types suggests that the sock manufacturing process may control the release of silver, The adsorption of the leached silver to WWTP biomass was used to develop a model which predicts that a typical wastewater treatment facility could treat a high concentration of influent silver. However, the high silver concentration may limit the disposal of the biosolids as agricultural fertilizer.",10.1021/es7032718,32,yes,no,yes,no,yes,no,yes,no,yes,no,yes,yes,yes,yes,yes,no,yes,yes,no,yes,yes,yes,no,yes,yes,yes,no,no,yes,yes,no
J,"Picard, RW; Vyzas, E; Healey, J",Toward machine emotional intelligence: Analysis of affective physiological state,"The ability to recognize emotion is one of the hallmarks of emotional intelligence, an aspect of human intelligence that has been argued to be even more important than mathematical and verbal intelligences. This paper proposes that machine intelligence needs to include emotional intelligence and demonstrates results toward this goal: developing a machine's ability to recognize human affective state given four physiological signals. We describe difficult Issues unique to obtaining reliable affective data and collect a large set of data from a subject trying to elicit and experience each of eight emotional states, daily, over multiple weeks. This paper presents and compares multiple algorithms for feature-based recognition of emotional state from this data. We analyze four physiological signals that exhibit problematic day-to-day variations: The features of different emotions on the same day tend to cluster more tightly than do the features of the same emotion on different days. To handle the daily variations, we propose new features and algorithms and compare their performance, We find that the technique of seeding a Fisher Projection with the results of Sequential Floating Forward Search improves the performance of the Fisher Projection and provides the highest recognition rates reported to date for classification of affect from physiology: 81 percent recognition accuracy on eight classes of emotion, including neutral.",10.1109/34.954607,33,yes,no,no,no,yes,no,yes,yes,no,no,yes,yes,yes,no,yes,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,no,no,yes,yes
J,"Nguyen, KT; West, JL",Photopolymerizable hydrogels for tissue engineering applications,"Photopolymerized hydrogels are being investigated for a number of tissue engineering applications because of the ability to form these materials in situ in a minimally invasive manner such as by injection. In addition, hydrogels, three-dimensional networks of hydrophilic polymers that are able to swell large amounts of water, can be made to resemble the physical characteristics of soft tissues. Hydrogel materials also generally exhibit high permeability and good biocompatibility making, these materials attractive for use in cell encapsulation and tissue engineering applications. A number of hydrogel materials can be formed via photopolymerization processes mild enough to be carried out in the presence of living cells. This allows one to homogeneously seed cells throughout the scaffold material and to form hydrogels in situ. This review presents advantages of photopolymerization of hydrogels and describes the photoinitiators and materials in current use. Applications of photopolymerized hydrogels in tissue engineering that have been investigated are summarized. (C) 2002 Elsevier Science Ltd. All rights reserved.",10.1016/S0142-9612(02)00175-8,34,yes,no,no,yes,no,no,no,no,yes,no,yes,yes,no,no,no,no,no,no,no,yes,no,no,no,no,no,no,no,no,yes,no,no
J,"Medford, AJ; Vojvodic, A; Hummelshoj, JS; Voss, J; Abild-Pedersen, F; Studt, F; Bligaard, T; Nilsson, A; Norskov, JK",From the Sabatier principle to a predictive theory of transition-metal heterogeneous catalysis,"We discuss three concepts that have made it possible to develop a quantitative understanding of trends in transition-metal catalysis: scaling relations, activity maps, and the d-band model. Scaling relations are correlations between surface bond energies of different adsorbed species including transition states; they open the possibility of mapping the many parameters determining the rate of a full catalytic reaction onto a few descriptors. The resulting activity map can be viewed as a quantitative implementation of the classical Sabatier principle, which states that there is an optimum ""bond strength"" defining the best catalyst for a given reaction. In the modern version, the scaling relations determine the relevant ""bond strengths"" and the fact that these descriptors can be measured or calculated makes it a quantitative theory of catalysis that can be tested experimentally by making specific predictions of new catalysts. The quantitative aspect of the model therefore provides new possibilities in catalyst design. Finally, the d-band model provides an understanding of the scaling relations and variations in catalytic activity in terms of the electronic structure of the transition-metal surface. (C) 2015 Published by Elsevier Inc.",10.1016/j.jcat.2014.12.033,35,yes,yes,no,yes,no,no,no,no,no,no,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,no
J,"Chen, WH; Ballance, DJ; Gawthrop, PJ; O'Reilly, J",A nonlinear disturbance observer for robotic manipulators,"A new nonlinear disturbance observer (NDO) for robotic manipulators is derived in this paper. The global exponential stability of the proposed disturbance observer (DO) is guaranteed by selecting design parameters, which depend on the maximum velocity and physical parameters of robotic manipulators. This new observer overcomes the disadvantages of existing DO's, which are designed or analyzed by linear system techniques. It can be applied in robotic manipulators for various purposes such as friction compensation, independent joint control, sensorless torque control, and fault diagnosis. The performance of the proposed observer is demonstrated by the friction estimation and compensation for a two-link robotic manipulator. Both simulation and experimental results show the NDO works well.",10.1109/41.857974,36,yes,yes,no,yes,yes,no,yes,no,yes,no,yes,yes,no,yes,no,no,yes,yes,yes,no,no,no,no,yes,yes,no,no,no,yes,yes,
J,"Li, CM; Kao, CY; Gore, JC; Ding, ZH",Minimization of region-scalable fitting energy for image segmentation,"Intensity inhomogeneities often occur in real-world images and may cause considerable difficulties in image segmentation. In order to overcome the difficulties caused by intensity inhomogeneities, we propose a region-based active contour model that draws upon intensity information in local regions at a controllable scale. A data fitting energy is defined in terms of a contour and two fitting functions that locally approximate the image intensities on the two sides of the contour. This energy is then incorporated into a variational level set formulation with a level set regularization term, from which a curve evolution equation is derived for energy minimization. Due to a kernel function in the data fitting term, intensity information in local regions is extracted to guide the motion of the contour, which thereby enables our model to cope with intensity inhomogeneity. In addition, the regularity of the level set function is intrinsically preserved by the level set regularization term to ensure accurate computation and avoids expensive reinitialization of the evolving level set function. Experimental results for synthetic and real images show desirable performances of our method.",10.1109/TIP.2008.2002304,37,yes,yes,no,no,yes,no,yes,yes,no,no,yes,no,no,no,no,no,yes,yes,yes,no,no,no,no,no,yes,yes,no,no,no,yes,yes
J,"Huang, J; Ling, CX",Using AUC and accuracy in evaluating learning algorithms,"The area under the ROC ( Receiver Operating Characteristics) curve, or simply AUC, has been traditionally used in medical diagnosis since the 1970s. It has recently been proposed as an alternative single-number measure for evaluating the predictive ability of learning algorithms. However, no formal arguments were given as to why AUC should be preferred over accuracy. In this paper, we establish formal criteria for comparing two different measures for learning algorithms and we show theoretically and empirically that AUC is a better measure ( defined precisely) than accuracy. We then reevaluate well-established claims in machine learning based on accuracy using AUC and obtain interesting and surprising new results. For example, it has been well-established and accepted that Naive Bayes and decision trees are very similar in predictive accuracy. We show, however, that Naive Bayes is significantly better than decision trees in AUC. The conclusions drawn in this paper may make a significant impact on machine learning and data mining applications.",10.1109/TKDE.2005.50,38,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,yes,no,no,no,yes,yes,yes,yes,no,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes
J,"Tian, YH; Li, SP; Song, J; Ji, TJ; Zhu, MT; Anderson, GJ; Wei, JY; Nie, GJ",A doxorubicin delivery platform using engineered natural membrane vesicle exosomes for targeted tumor therapy,"Targeted drug delivery vehicles with low immunogenicity and toxicity are needed for cancer therapy. Here we show that exosomes, endogenous nano-sized membrane vesicles secreted by most cell types, can deliver chemotherapeutics such as doxorubicin (Dox) to tumor tissue in BALB/c nude mice. To reduce immunogenicity and toxicity, mouse immature dendritic cells (imDCs) were used for exosome production. Tumor targeting was facilitated by engineering the imDCs to express a well-characterized exosomal membrane protein (Lamp2b) fused to alpha v integrin-specific iRGD peptide (CRGDKGPDC). Purified exosomes from imDCs were loaded with Dox via electroporation, with an encapsulation efficiency of up to 20%. iRGD exosomes showed highly efficient targeting and Dox delivery to am integrin-positive breast cancer cells in vitro as demonstrated by confocal imaging and flow cytometry. Intravenously injected targeted exosomes delivered Dox specifically to tumor tissues, leading to inhibition of tumor growth without overt toxicity. Our results suggest that exosomes modified by targeting ligands can be used therapeutically for the delivery of Dox to tumors, thus having great potential value for clinical applications. (c) 2013 Elsevier Ltd. All rights reserved.",10.1016/j.biomaterials.2013.11.083,39,yes,no,no,no,yes,no,yes,no,yes,yes,yes,yes,no,no,no,yes,yes,yes,no,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes
J,"Lackner, S; Gilbert, EM; Vlaeminck, SE; Joss, A; Horn, H; van Loosdrecht, MCM",Full-scale partial nitritation/anammox experiences - An application survey,"Partial nitritation/anammox (PN/A) has been one of the most innovative developments in biological wastewater treatment in recent years. With its discovery in the 1990s a completely new way of ammonium removal from wastewater became available. Over the past decade many technologies have been developed and studied for their applicability to the PN/A concept and several have made it into full-scale. With the perspective of reaching 100 full-scale installations in operation worldwide by 2014 this work presents a summary of PN/A technologies that have been successfully developed, implemented and optimized for high-strength ammonium wastewaters with low C:N ratios and elevated temperatures. The data revealed that more than 50% of all PN/A installations are sequencing batch reactors, 88% of all plants being operated as single-stage systems, and 75% for sidestream treatment of municipal wastewater. Additionally an in-depth survey of 14 full-scale installations was conducted to evaluate practical experiences and report on operational control and troubleshooting. Incoming solids, aeration control and nitrate built up were revealed as the main operational difficulties. The information provided gives a unique/new perspective throughout all the major technologies and discusses the remaining obstacles. (C) 2014 Elsevier Ltd. All rights reserved.",10.1016/j.watres.2014.02.032,40,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
J,"Khor, E; Lim, LY",Implantable applications of chitin and chitosan,"Chitin, extracted primarily from shellfish sources, is a unique biopolymer based on the N-acetyl-glucosamine monomer. More than 40 years have lapsed since this biopolymer had aroused the interest of the scientific community around the world for its potential biomedical applications. Chitin, together with its variants, especially its deacetylated counterpart chitosan, has been shown to be useful as a wound dressing material, drug delivery vehicle and increasingly a candidate for tissue engineering. The promise for this biomaterial is vast and will continue to increase as the chemistry to extend its capabilities and new biomedical applications are investigated. It is interesting to note that a majority of this work has come from Asia. Japan has been the undisputed leader, but other Asian nations, namely Korea, Singapore, Taiwan and Thailand have also. made notable contributions. More recently, China has joined the club to become an increasingly major research source for chitin and chitosan in Asia, This review surveys select works of key groups in Asia developing chitin and chitosan materials for implantable biomedical applications. (C) 2003 Elsevier Science Ltd. All rights reserved.",10.1016/S0142-9612(03)00026-7,41,yes,no,yes,yes,yes,no,no,yes,no,no,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no
J,"Frank, AG; Dalenogare, LS; Ayala, NF",Industry 4.0 technologies: Implementation patterns in manufacturing companies,"Industry 4.0 has been considered a new industrial stage in which several emerging technologies are converging to provide digital solutions. However, there is a lack of understanding of how companies implement these technologies. Thus, we aim to understand the adoption patterns of Industry 4.0 technologies in manufacturing firms. We propose a conceptual framework for these technologies, which we divided into front-end and base technologies. Front-end technologies consider four dimensions: Smart Manufacturing, Smart Products, Smart Supply Chain and Smart Working, while base technologies consider four elements: internet of things, cloud services, big data and analytics. We performed a survey in 92 manufacturing companies to study the implementation of these technologies. Our findings show that Industry 4.0 is related to a systemic adoption of the front-end technologies, in which Smart Manufacturing plays a central role. Our results also show that the implementation of the base technologies is challenging companies, since big data and analytics are still low implemented in the sample studied. We propose a structure of Industry 4.0 technology layers and we show levels of adoption of these technologies and their implication for manufacturing companies.",10.1016/j.ijpe.2019.01.004,42,yes,no,yes,no,yes,yes,yes,yes,no,yes,yes,yes,yes,no,yes,no,yes,yes,yes,no,no,no,yes,yes,yes,yes,yes,no,yes,yes,yes
J,"Ding, ZG; Liu, YW; Choi, J; Sun, Q; Elkashlan, M; I, CL; Poor, HV",Application of Non-Orthogonal Multiple Access in LTE and 5G Networks,"As the latest member of the multiple access family, non-orthogonal multiple access (NOMA) has been recently proposed for 3GPP LIE and is envisioned to be an essential component of 5G mobile networks. The key feature of NOMA is to serve multiple users at the same time/frequency/code, but with different power levels, which yields a significant spectral efficiency gain over conventional orthogonal MA. The article provides a systematic treatment of this newly emerging technology, from its combination with MIMO technologies to cooperative NOMA, as well as the interplay between NOMA and cognitive radio. This article also reviews the state of the art in the standardization activities concerning the implementation of NOMA in LTE and 5G networks.",10.1109/MCOM.2017.1500657CM,43,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,no
J,"Altafini, C",Consensus Problems on Networks With Antagonistic Interactions,"In a consensus protocol an agreement among agents is achieved thanks to the collaborative efforts of all agents, expresses by a communication graph with nonnegative weights. The question we ask in this paper is the following: is it possible to achieve a form of agreement also in presence of antagonistic interactions, modeled as negative weights on the communication graph? The answer to this question is affirmative: on signed networks all agents can converge to a consensus value which is the same for all agents except for the sign. Necessary and sufficient conditions are obtained to describe cases in which this is possible. These conditions have strong analogies with the theory of monotone systems. Linear and non-linear Laplacian feedback designs are proposed.",10.1109/TAC.2012.2224251,44,yes,yes,no,no,yes,no,yes,yes,no,no,yes,yes,no,no,no,no,yes,yes,yes,no,no,no,no,no,no,no,no,no,no,yes,yes
J,"Kong, WC; Dong, ZY; Jia, YW; Hill, DJ; Xu, Y; Zhang, Y",Short-Term Residential Load Forecasting Based on LSTM Recurrent Neural Network,"As the power system is facing a transition toward a more intelligent, flexible, and interactive system with higher penetration of renewable energy generation, load forecasting, especially short-term load forecasting for individual electric customers plays an increasingly essential role in the future grid planning and operation. Other than aggregated residential load in a large scale, forecasting an electric load of a single energy user is fairly challenging due to the high volatility and uncertainty involved. In this paper, we propose a long short-term memory (LSTM) recurrent neural network-based framework, which is the latest and one of the most popular techniques of deep learning, to tackle this tricky issue. The proposed framework is tested on a publicly available set of real residential smart meter data, of which the performance is comprehensively compared to various benchmarks including the state-of-the-arts in the field of load forecasting. As a result, the proposed LSTM approach outperforms the other listed rival algorithms in the task of short-term load forecasting for individual residential households.",10.1109/TSG.2017.2753802,45,yes,no,no,yes,yes,no,yes,yes,no,yes,yes,no,yes,no,no,yes,yes,yes,yes,no,no,no,no,yes,no,no,yes,no,yes,yes,
J,"Zein, I; Hutmacher, DW; Tan, KC; Teoh, SH",Fused deposition modeling of novel scaffold architectures for tissue engineering applications,"Fused deposition modeling, a rapid prototyping technology, was used to produce novel scaffolds with honeycomb-like pattern, fully interconnected channel network, and controllable porosity and channel size. A bioresorbable polymer poly(epsilon -caprolactone) (PCL) was developed as a filament modeling material to produce porous scaffolds. made of layers of directionally aligned microfilaments, using this computer-controlled extrusion and deposition process. The PCL scaffolds were produced with a range of channel size 160-700 mum, filament diameter 260-370 mum and porosity 48-77%, and regular geometrical honeycomb pores, depending on the processing parameters. The scaffolds of different porosity also exhibited a pattern of compressive stress-strain behavior characteristic of porous solids under such loading. The compressive stiffness ranged from 4 to 77 MPa, yield strength from 0.4 to 3.6MPa and yield strain from 4% to 28%. Analysis of the measured data shows a high correlation between the scaffold porosity and the compressive properties based on a power-law relationship. (C) 2001 Elsevier Science Ltd. All rights reserved.",10.1016/S0142-9612(01)00232-0,46,yes,yes,no,no,yes,no,yes,no,yes,no,yes,yes,yes,no,no,yes,yes,yes,no,yes,no,no,yes,yes,yes,no,no,no,no,yes,no
J,"Cheng, G; Zhou, PC; Han, JW",Learning Rotation-Invariant Convolutional Neural Networks for Object Detection in VHR Optical Remote Sensing Images,"Object detection in very high resolution optical remote sensing images is a fundamental problem faced for remote sensing image analysis. Due to the advances of powerful feature representations, machine-learning-based object detection is receiving increasing attention. Although numerous feature representations exist, most of them are handcrafted or shallow-learning-based features. As the object detection task becomes more challenging, their description capability becomes limited or even impoverished. More recently, deep learning algorithms, especially convolutional neural networks (CNNs), have shown their much stronger feature representation power in computer vision. Despite the progress made in nature scene images, it is problematic to directly use the CNN feature for object detection in optical remote sensing images because it is difficult to effectively deal with the problem of object rotation variations. To address this problem, this paper proposes a novel and effective approach to learn a rotation-invariant CNN (RICNN) model for advancing the performance of object detection, which is achieved by introducing and learning a new rotation-invariant layer on the basis of the existing CNN architectures. However, different from the training of traditional CNN models that only optimizes the multinomial logistic regression objective, our RICNN model is trained by optimizing a new objective function via imposing a regularization constraint, which explicitly enforces the feature representations of the training samples before and after rotating to be mapped close to each other, hence achieving rotation invariance. To facilitate training, we first train the rotation-invariant layer and then domain-specifically fine-tune the whole RICNN network to further boost the performance. Comprehensive evaluations on a publicly available ten-class object detection data set demonstrate the effectiveness of the proposed method.",10.1109/TGRS.2016.2601622,47,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,no,yes,no,no,no,yes,yes,yes,no,no,no,no,yes,no,yes,yes,yes,no,yes,yes
J,"Li, ZJ; Gu, XN; Lou, SQ; Zheng, YF",The development of binary Mg-Ca alloys for use as biodegradable materials within bone,"Binary Mg-Ca alloys with various Ca contents were fabricated under different working conditions. X-ray diffraction (XRD) analysis and optical microscopy observations showed that Mg-xCa (x = 1-3 wt%) alloys were composed of two phases, alpha(Mg) and Mg2Ca. The results of tensile tests and in vitro corrosion tests indicated that the mechanical properties could be adjusted by controlling the Ca content and processing treatment. The yield strength (YS), ultimate tensile strength (UTS) and elongation decreased with increasing Ca content. The UTS and elongation of as-cast Mg-1Ca alloy (71.38 +/- 3.01 MPa and 1.87 +/- 0.14%) were largely improved after hot rolling (166.7 +/- 3.01 MPa and 3 +/- 0.78%) and hot extrusion (239.63 +/- 7.21 MPa and 10.63 +/- 0.64%). The in vitro corrosion test in simulated body fluid (SBF) indicated that the microstructure and working history of Mg-xCa alloys strongly affected their corrosion behaviors. An increasing content of Mg2Ca phase led to a higher corrosion rate whereas hot rolling and hot extrusion could reduce it. The cytotoxicity evaluation using L-929 cells revealed that Mg-1Ca alloy did not induce toxicity to cells, and the viability of cells for Mg-1Ca alloy extraction medium was better than that of control. Moreover, Mg-1Ca alloy pins, with commercial pure Ti pins as control, were implanted into the left and right rabbit femoral shafts, respectively, and observed for 1, 2 and 3 months. High activity of ostroblast and osteocytes were observed around the Mg-1Ca alloy pins as shown by hematoxylin and eosin stained tissue sections. Radiographic examination revealed that the Mg-1Ca alloy pins gradually degraded in vivo within 90 days and the newly formed bone was clearly seen at month 3. Both the in vitro and in vivo corrosion suggested that a mixture of Mg(OH)(2) and hydroxyapatite formed on the surface of Mg-1Ca alloy with the extension of immersion/implantation time. In addition, no significant difference (p > 0.05) of serum magnesium was detected at different degradation stages. All these results revealed that Mg-1Ca alloy had the acceptable biocompatibility as a new kind of biodegradable implant material. Based on the above results, a solid alloy/liquid solution interface model was also proposed to interpret the biocorrosion process and the associated hydroxyapatite mineralization. (c) 2007 Elsevier Ltd. All rights reserved.",10.1016/j.biomaterials.2007.12.021,48,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
J,"Bligaard, T; Norskov, JK; Dahl, S; Matthiesen, J; Christensen, CH; Sehested, J",The Bronsted-Evans-Polanyi relation and the volcano curve in heterogeneous catalysis,"A number of elementary reactions at metal surfaces show a linear Bronsted-Evans-Polanyi relation between the activation energy and the reaction energy, and reactions belonging to the same class even follow the same relation. We investigate the implications of this finding on the kinetics of surface-catalyzed chemical processes. We focus in particular on the variation in the activity from one metal to the next. By analyzing a number of simple microkinetic models we show that the reaction rate under given reaction conditions shows a maximum as a function of the dissociative adsorption energy of the key reactant, and that for most conditions this maximum is in the same range of reaction energies. We also provide a database of chemisorption energies calculated using density-functional theory for a number of simple gas molecules on 13 different transition metals. An important part of the analysis consists of developing a general framework for analyzing the maximum rate. We use these concepts to rationalize trends in the catalytic activity of a number of metals for the methanation process. (C) 2004 Elsevier Inc. All rights reserved.",10.1016/j.jcat.2004.02.034,49,yes,yes,no,yes,yes,no,yes,no,yes,no,yes,yes,yes,no,yes,no,yes,yes,no,yes,yes,yes,no,yes,yes,yes,no,yes,no,yes,yes
J,"Rodriguez, J; Kazmierkowski, MP; Espinoza, JR; Zanchetta, P; Abu-Rub, H; Young, HA; Rojas, CA",State of the Art of Finite Control Set Model Predictive Control in Power Electronics,"This paper addresses to some of the latest contributions on the application of Finite Control Set Model Predictive Control (FCS-MPC) in Power Electronics. In FCS-MPC, the switching states are directly applied to the power converter, without the need of an additional modulation stage. The paper shows how the use of FCS-MPC provides a simple and efficient computational realization for different control objectives in Power Electronics. Some applications of this technology in drives, active filters, power conditioning, distributed generation and renewable energy are covered. Finally, attention is paid to the discussion of new trends in this technology and to the identification of open questions and future research topics.",10.1109/TII.2012.2221469,50,yes,yes,no,yes,yes,no,no,yes,no,no,yes,no,no,no,no,no,no,no,yes,no,no,no,no,no,yes,yes,no,yes,yes,no,
J,"Lesser, GR; Roelvink, JA; van Kester, JATM; Stelling, GS",Development and validation of a three-dimensional morphological model,"Computer modeling of sediment transport patterns is generally recognized as a valuable tool for understanding and predicting morphological developments. In practice, state-of-the-art computer models are one- or two-dimensional (depth-averaged) and have a limited ability to model many of the important three-dimensional flow phenomena found in nature. This paper presents the implementation and validation of sediment transport formulations within the proven DELFT3D three-dimensional (hydrostatic, free surface) flow solver. The paper briefly discusses the operation of the DELFT3D-FLOW module, presents the key features of the formulations used to model both suspended and bedload transport of noncohesive sediment, and describes the implemented morphological updating scheme. The modeling of the three-dimensional effects of waves is also discussed. Following the details of the implementation, the results of a number of validation studies are presented. The model is shown to perform well in several theoretical, laboratory, and real-life situations. (C) 2004 Elsevier B.V. All rights reserved.",10.1016/j.coastaleng.2004.07.014,51,yes,no,yes,yes,yes,no,yes,yes,no,no,yes,yes,no,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,no,no,yes,no
J,"Liu, J; Musialski, P; Wonka, P; Ye, JP",Tensor Completion for Estimating Missing Values in Visual Data,"In this paper, we propose an algorithm to estimate missing values in tensors of visual data. The values can be missing due to problems in the acquisition process or because the user manually identified unwanted outliers. Our algorithm works even with a small amount of samples and it can propagate structure to fill larger missing regions. Our methodology is built on recent studies about matrix completion using the matrix trace norm. The contribution of our paper is to extend the matrix case to the tensor case by proposing the first definition of the trace norm for tensors and then by building a working algorithm. First, we propose a definition for the tensor trace norm that generalizes the established definition of the matrix trace norm. Second, similarly to matrix completion, the tensor completion is formulated as a convex optimization problem. Unfortunately, the straightforward problem extension is significantly harder to solve than the matrix case because of the dependency among multiple constraints. To tackle this problem, we developed three algorithms: simple low rank tensor completion (SiLRTC), fast low rank tensor completion (FaLRTC), and high accuracy low rank tensor completion (HaLRTC). The SiLRTC algorithm is simple to implement and employs a relaxation technique to separate the dependant relationships and uses the block coordinate descent (BCD) method to achieve a globally optimal solution; the FaLRTC algorithm utilizes a smoothing scheme to transform the original nonsmooth problem into a smooth one and can be used to solve a general tensor trace norm minimization problem; the HaLRTC algorithm applies the alternating direction method of multipliers (ADMMs) to our problem. Our experiments show potential applications of our algorithms and the quantitative evaluation indicates that our methods are more accurate and robust than heuristic approaches. The efficiency comparison indicates that FaLTRC and HaLRTC are more efficient than SiLRTC and between FaLRTC and HaLRTC the former is more efficient to obtain a low accuracy solution and the latter is preferred if a high-accuracy solution is desired.",10.1109/TPAMI.2012.39,52,yes,no,no,yes,yes,no,yes,yes,no,no,yes,yes,no,no,no,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,no,yes,yes,
J,"Sample, AP; Meyer, DA; Smith, JR","Analysis, Experimental Results, and Range Adaptation of Magnetically Coupled Resonators for Wireless Power Transfer","Wireless power technology offers the promise of cutting the last cord, allowing users to seamlessly recharge mobile devices as easily as data are transmitted through the air. Initial work on the use of magnetically coupled resonators for this purpose has shown promising results. We present new analysis that yields critical insight into the design of practical systems, including the introduction of key figures of merit that can be used to compare systems with vastly different geometries and operating conditions. A circuit model is presented along with a derivation of key system concepts, such as frequency splitting, the maximum operating distance (critical coupling), and the behavior of the system as it becomes undercoupled. This theoretical model is validated against measured data and shows an excellent average coefficient of determination (R-2) of 0.9875. An adaptive frequency tuning technique is demonstrated, which compensates for efficiency variations encountered when the transmitter-to-receiver distance and/or orientation are varied. The method demonstrated in this paper allows a fixed-load receiver to be moved to nearly any position and/or orientation within the range of the transmitter and still achieve a near-constant efficiency of over 70% for a range of 0-70 cm.",10.1109/TIE.2010.2046002,53,yes,no,yes,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,no,yes,yes,yes
J,"Gong, YC; Lazebnik, S; Gordo, A; Perronnin, F",Iterative Quantization: A Procrustean Approach to Learning Binary Codes for Large-Scale Image Retrieval,"This paper addresses the problem of learning similarity-preserving binary codes for efficient similarity search in large-scale image collections. We formulate this problem in terms of finding a rotation of zero-centered data so as to minimize the quantization error of mapping this data to the vertices of a zero-centered binary hypercube, and propose a simple and efficient alternating minimization algorithm to accomplish this task. This algorithm, dubbed iterative quantization (ITQ), has connections to multiclass spectral clustering and to the orthogonal Procrustes problem, and it can be used both with unsupervised data embeddings such as PCA and supervised embeddings such as canonical correlation analysis (CCA). The resulting binary codes significantly outperform several other state-of-the-art methods. We also show that further performance improvements can result from transforming the data with a nonlinear kernel mapping prior to PCA or CCA. Finally, we demonstrate an application of ITQ to learning binary attributes or ""classemes"" on the ImageNet data set.",10.1109/TPAMI.2012.193,54,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,yes,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,yes,yes,yes
J,"Candès, EJ; Tao, T",The Power of Convex Relaxation: Near-Optimal Matrix Completion,"This paper is concerned with the problem of recovering an unknown matrix from a small fraction of its entries. This is known as the matrix completion problem, and comes up in a great number of applications, including the famous Netflix Prize and other similar questions in collaborative filtering. In general, accurate recovery of a matrix from a small number of entries is impossible, but the knowledge that the unknown matrix has low rank radically changes this premise, making the search for solutions meaningful. This paper presents optimality results quantifying the minimum number of entries needed to recover a matrix of rank r exactly by any method whatsoever (the information theoretic limit). More importantly, the paper shows that, under certain incoherence assumptions on the singular vectors of the matrix, recovery is possible by solving a convenient convex program as soon as the number of entries is on the order of the information theoretic limit (up to logarithmic factors). This convex program simply finds, among all matrices consistent with the observed entries, that with minimum nuclear norm. As an example, we show that on the order of nr log(n) samples are needed to recover a random n x n matrix of rank by any method, and to be sure, nuclear norm minimization succeeds as soon as the number of entries is of the form nr log(n).",10.1109/TIT.2010.2044061,55,yes,no,yes,no,yes,no,yes,yes,no,no,yes,yes,yes,no,no,no,no,no,no,yes,no,no,no,yes,no,no,yes,yes,no,yes,yes
J,"Sarkis, J; Zhu, QH; Lai, KH",An organizational theoretic review of green supply chain management literature,"Green supply chain management (GSCM) has gained increasing attention within both academia and industry. As the literature grows, finding new directions by critically evaluating the research and identifying future directions becomes important in advancing knowledge for the field. Using organizational theories to help categorize the literature provides opportunities to address both the objectives of understanding where the field currently stands and identifying research opportunities and directions. After providing a background discussion on GSCM, we categorize and review recent GSCM literature under nine broad organizational theories, with a special emphasis on investigation of adoption, diffusion and outcomes of GSCM practices. Within this review framework, we also identify GSCM research questions that are worthy of investigation. Additional organizational theories which are considered valuable for future GSCM research are also identified with a conclusion for this review. (C) 2010 Elsevier B.V. All rights reserved.",10.1016/j.ijpe.2010.11.010,56,yes,no,yes,yes,yes,no,yes,no,yes,yes,yes,yes,no,no,no,no,no,no,no,yes,no,no,no,no,yes,no,no,yes,yes,yes,
J,"Nistér, D",An efficient solution to the five-point relative pose problem,"An efficient algorithmic solution to the classical five-point relative pose problem is presented. The problem is to find the possible solutions for relative camera pose between two calibrated views given five corresponding points. The algorithm consists of computing the coefficients of a tenth degree polynomial in closed form and, subsequently, finding its roots. It is the first algorithm well-suited for numerical implementation that also corresponds to the inherent complexity of the problem. We investigate the numerical precision of the algorithm. We also study its performance under noise in minimal as well as overdetermined cases. The performance is compared to that of the well-known 8 and 7-point methods and a 6-point scheme. The algorithm is used in a robust hypothesize-and-test framework to estimate structure and motion in real-time with low delay. The real-time system uses solely visual input and has been demonstrated at major conferences.",10.1109/TPAMI.2004.17,57,yes,yes,no,yes,yes,yes,yes,yes,no,no,yes,no,no,no,no,no,yes,no,yes,no,no,no,no,no,no,yes,yes,no,no,yes,yes
J,"Li, ST; Kang, XD; Hu, JW",Image Fusion with Guided Filtering,"A fast and effective image fusion method is proposed for creating a highly informative fused image through merging multiple images. The proposed method is based on a two-scale decomposition of an image into a base layer containing large scale variations in intensity, and a detail layer capturing small scale details. A novel guided filtering-based weighted average technique is proposed to make full use of spatial consistency for fusion of the base and detail layers. Experimental results demonstrate that the proposed method can obtain state-of-the-art performance for fusion of multispectral, multifocus, multimodal, and multiexposure images.",10.1109/TIP.2013.2244222,58,yes,yes,no,no,yes,yes,yes,yes,no,no,yes,no,no,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,no,no,no,no,yes,yes
J,"Kerr, YH; Waldteufel, P; Wigneron, JP; Martinuzzi, JM; Font, J; Berger, M",Soil moisture retrieval from space: The Soil Moisture and Ocean Salinity (SMOS) mission,"Microwave radiometry at low frequencies (L-band: 1.4 GHz, 21 cm) is an established technique for estimating surface soil moisture and sea surface salinity with a suitable sensitivity. However, from space, large antennas (several meters) are required to achieve an adequate spatial resolution at L-band. So as to reduce the problem of putting into orbit a large filled antenna, the possibility of using antenna synthesis methods has been investigated. Such a system, relying on a deployable structure, has now proved to be feasible and has led to the Soil Moisture and Ocean Salinity (SMOS) mission, which is described in this paper. The main objective of the SMOS mission is to deliver key variables of the land surfaces (soil moisture fields), and of ocean surfaces (sea surface salinity fields). The SMOS mission is based on a dual polarized L-band radiometer using aperture synthesis (two-dimensional [2-D] interferometer) so as to achieve a ground resolution of 50 km at the swath edges coupled with multiangular acquisitions. The radiometer will enable frequent and global coverage of the globe and deliver surface soil moisture fields over land and sea surface salinity over the oceans. The SMOS mission was proposed to the European Space Agency (ESA) in the framework of the Earth Explorer Opportunity Missions. It was selected for a tentative launch in 2005. The goal of this paper is to present the main aspects of the baseline mission(1) and describe how soil moisture will be retrieved from SMOS data.",10.1109/36.942551,59,yes,no,yes,yes,yes,no,yes,yes,no,no,yes,yes,no,yes,no,no,no,no,no,no,no,no,yes,no,yes,yes,no,no,yes,yes,
J,"Jain, A; Nandakumar, K; Ross, A",Score normalization in multimodal biometric systems,"Multimodal biometric systems consolidate the evidence presented by multiple biometric sources and typically provide better recognition performance compared to systems based on a single biometric modality. Although information fusion in a multimodal system can be performed at various levels, integration at the matching score level is the most common approach due to the ease in accessing and combining the scores generated by different matchers. Since the matching scores output by the various modalities are heterogeneous, score normalization is needed to transform these scores into a common domain, prior to combining them. In this paper, we have studied the performance of different normalization techniques and fusion rules in the context of a multimodal biometric system based on the face, fingerprint and hand-geometry traits of a user. Experiments conducted on a database of 100 users indicate that the application of min-max, z-score, and tanh normalization schemes followed by a simple sum of scores fusion method results in better recognition performance compared to other methods. However, experiments also reveal that the min-max and z-score normalization techniques are sensitive to outliers in the data, highlighting the need for a robust and efficient normalization procedure like the tanh normalization. It was also observed that multimodal systems utilizing user-specific weights perform better compared to systems that assign the same set of weights to the multiple biometric traits of all users. (c) 2005 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.",10.1016/j.patcog.2005.01.012,60,yes,no,no,yes,yes,no,yes,no,yes,no,yes,yes,yes,no,no,yes,yes,yes,yes,no,yes,no,no,yes,yes,yes,yes,yes,no,yes,yes
J,"Nabar, RU; Bölcskei, H; Kneubühler, FW",Fading relay channels:: Performance limits and space-time signal design,"Cooperative diversity is a transmission technique, where multiple terminals pool their,resources to form a virtual antenna array that realizes spatial diversity gain in a distributed fashion. In this paper, we examine the basic building block of cooperative diversity systems, a simple fading relay channel where the source, destination, and relay terminals are each equipped with single antenna transceivers. We consider three different time-division multiple-access-based cooperative protocols that vary the degree of broadcasting and receive collision. The relay terminal operates in either the amplify-and-forward (AF) or decode-and-forward (DF) modes. For each protocol, we study the ergodic and outage capacity behavior (assuming Gaussian code books) under the AF and DF modes of relaying. We analyze the spatial diversity performance of the various protocols and find that full spatial diversity (second-order in this case) is achieved by certain protocols provided that appropriate power control is employed. Our analysis unifies previous results reported in the literature and establishes the superiority (both from a capacity, as well as a diversity point-of-view) of a new protocol proposed in this paper. The second part of the paper is devoted to (distributed) space-time code design for fading relay channels operating in the AF mode. We show that the corresponding code design criteria consist of the traditional rank and determinant criteria for the case of colocated antennas, as well as appropriate power control rules. Consequently space-time codes designed for the case of colocated multiantenna. channels can be used to realize cooperative diversity provided that appropriate power control is employed.",10.1109/JSAC.2004.830922,61,yes,no,no,no,yes,no,yes,yes,no,no,yes,yes,no,no,no,yes,yes,yes,yes,no,yes,no,no,yes,yes,yes,yes,yes,no,yes,yes
J,"Li, CM; Xu, CY; Gui, CF; Fox, MD",Distance Regularized Level Set Evolution and Its Application to Image Segmentation,"Level set methods have been widely used in image processing and computer vision. In conventional level set formulations, the level set function typically develops irregularities during its evolution, which may cause numerical errors and eventually destroy the stability of the evolution. Therefore, a numerical remedy, called reinitialization, is typically applied to periodically replace the degraded level set function with a signed distance function. However, the practice of reinitialization not only raises serious problems as when and how it should be performed, but also affects numerical accuracy in an undesirable way. This paper proposes a new variational level set formulation in which the regularity of the level set function is intrinsically maintained during the level set evolution. The level set evolution is derived as the gradient flow that minimizes an energy functional with a distance regularization term and an external energy that drives the motion of the zero level set toward desired locations. The distance regularization term is defined with a potential function such that the derived level set evolution has a unique forward-and-backward (FAB) diffusion effect, which is able to maintain a desired shape of the level set function, particularly a signed distance profile near the zero level set. This yields a new type of level set evolution called distance regularized level set evolution (DRLSE). The distance regularization effect eliminates the need for reinitialization and thereby avoids its induced numerical errors. In contrast to complicated implementations of conventional level set formulations, a simpler and more efficient finite difference scheme can be used to implement the DRLSE formulation. DRLSE also allows the use of more general and efficient initialization of the level set function. In its numerical implementation, relatively large time steps can be used in the finite difference scheme to reduce the number of iterations, while ensuring sufficient numerical accuracy. To demonstrate the effectiveness of the DRLSE formulation, we apply it to an edge-based active contour model for image segmentation, and provide a simple narrowband implementation to greatly reduce computational cost.",10.1109/TIP.2010.2069690,62,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,no,no,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,yes,yes,
J,"Lane, ND; Miluzzo, E; Lu, H; Peebles, D; Choudhury, T; Campbell, AT",A Survey of Mobile Phone Sensing,"Mobile phones or smartphones are rapidly becoming the central computer and communication device in people's lives. Application delivery channels such as the Apple AppStore are transforming mobile phones into App Phones, capable of downloading a myriad of applications in an instant. Importantly, today's smartphones are programmable and come with a growing set of cheap powerful embedded sensors, such as an accelerometer, digital compass, gyroscope, GPS, microphone, and camera, which are enabling the emergence of personal, group, and community-scale sensing applications. We believe that sensor-equipped mobile phones will revolutionize many sectors of our economy, including business, healthcare, social networks, environmental monitoring, and transportation. In this article we survey existing mobile phone sensing algorithms, applications, and systems. We discuss the emerging sensing paradigms, and formulate an architectural framework for discussing a number of the open issues and challenges emerging in the new area of mobile phone sensing research.",10.1109/MCOM.2010.5560598,63,yes,no,yes,no,yes,no,yes,yes,no,no,yes,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,
J,"Tzanetakis, G; Cook, P",Musical genre classification of audio signals,"Musical genres are categorical labels created by humans to characterize pieces of music. A musical genre is characterized by the common characteristics shared by its members. These characteristics typically are related to the instrumentation, rhythmic structure, and harmonic content of the music. Genre hierarchies are commonly used to structure the large collections of music available on the Web. Currently musical genre annotation is performed manually. Automatic musical genre classification can assist or replace the human user in this process and would be a valuable addition to music information retrieval systems. In addition, automatic musical genre classification provides a framework for developing and evaluating features for any type of content-based analysis of musical signals. In this paper, the automatic classification of audio signals into an hierarchy of musical genres is explored. More specifically, three feature sets for representing timbral texture, rhythmic content and pitch content are proposed. The performance and relative importance of the proposed features is investigated by training statistical pattern recognition classifiers using real-world audio collections. Both whole file and real-time frame-based classification schemes are described. Using the proposed feature sets, classification of 61% for ten musical genres is achieved. This result is comparable to results reported for human musical genre classification.",10.1109/TSA.2002.800560,64,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
J,"Gu, ZW; Cheng, J; Fu, HZ; Zhou, K; Hao, HY; Zhao, YT; Zhang, TY; Gao, SH; Liu, J",CE-Net: Context Encoder Network for 2D Medical Image Segmentation,"Medical image segmentation is an important step in medical image analysis. With the rapid development of a convolutional neural network in image processing, deep learning has been used for medical image segmentation, such as optic disc segmentation, blood vessel detection, lung segmentation, cell segmentation, and so on. Previously, U-net based approaches have been proposed. However, the consecutive pooling and strided convolutional operations led to the loss of some spatial information. In this paper, we propose a context encoder network (CE-Net) to capture more high-level information and preserve spatial information for 2D medical image segmentation. CE-Net mainly contains three major components: a feature encoder module, a context extractor, and a feature decoder module. We use the pretrained ResNet block as the fixed feature extractor. The context extractor module is formed by a newly proposed dense atrous convolution block and a residual multi-kernel pooling block. We applied the proposed CE-Net to different 2D medical image segmentation tasks. Comprehensive results show that the proposed method outperforms the original U-Net method and other state-of-the-art methods for optic disc segmentation, vessel detection, lung segmentation, cell contour segmentation, and retinal optical coherence tomography layer segmentation.",10.1109/TMI.2019.2903562,65,yes,no,yes,yes,yes,no,yes,yes,no,no,yes,yes,no,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,no,yes,no,yes,yes,yes
J,"Fu, MY; Xie, LH",The sector bound approach to quantized feedback control,"This paper studies a number of quantized feedback design problems for linear systems. We consider the case where quantizers are static (memoryless). The common aim of these design problems is to stabilize the given system or to achieve certain performance with the coarsest quantization density. Our main discovery is that the classical sector bound approach is nonconservative for studying these design problems. Consequently, we are able to convert many quantized feedback design problems to well-known robust control problems with sector bound uncertainties. In particular, we derive the coarsest quantization densities for stabilization for multiple-input-multiple-output systems in both state feedback and output feedback cases; and we also derive conditions for quantized feedback control for quadratic cost and H-infinity performances.",10.1109/TAC.2005.858689,66,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,yes,no,no,no,yes,yes,yes,yes,no,no,no,no,yes,no,yes,yes,yes,no,yes,yes
J,"McCarty, PL; Bae, J; Kim, J",Domestic Wastewater Treatment as a Net Energy Producer-Can This be Achieved?,"In seeking greater sustainability in water resources management, wastewater is now being considered more as a resource than as a waste-a resource for water, for plant nutrients, and for energy. Energy, the primary focus of this article, can be obtained from wastewater's organic as well as from its thermal content. Also, using wastewater's nitrogen and P nutrients for plant fertilization, rather than wasting them, helps offset the high energy cost of producing synthetic fertilizers. Microbial fuel cells offer potential for direct biological conversion of wastewater's organic materials into electricity, although significant improvements are needed for this process to be competitive with anaerobic biological conversion of wastewater organics into biogas, a renewable fuel used in electricity generation. Newer membrane processes coupled with complete anaerobic treatment of wastewater offer the potential for wastewater treatment to become a net generator of energy, rather than the large energy consumer that it is today.",10.1021/es2014264,67,yes,yes,no,yes,no,no,no,no,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,no,no,yes,no,no,yes
J,"Abbasi, AA; Younis, M",A survey on clustering algorithms for wireless sensor networks,"The past few years have witnessed increased interest in the potential use of wireless sensor networks (WSNs) in applications such as disaster management, combat field reconnaissance, border protection and security surveillance. Sensors in these applications are expected to be remotely deployed in large numbers and to operate autonomously in unattended environments. To support scalability, nodes are often grouped into disjoint and mostly non-overlapping clusters. In this paper, we present a taxonomy and general classification of published clustering schemes. We survey different clustering algorithms for WSNs; highlighting their objectives, features, complexity, etc. We also compare of these clustering algorithms based on metrics such as convergence rate, cluster stability, cluster overlapping, location-awareness and support for node mobility. (C) 2007 Published by Elsevier B.V.",10.1016/j.comcom.2007.05.024,68,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes
J,"Benotti, MJ; Trenholm, RA; Vanderford, BJ; Holady, JC; Stanford, BD; Snyder, SA",Pharmaceuticals and Endocrine Disrupting Compounds in US Drinking Water,"The drinking water for more than 28 million people was screened for a diverse group of pharmaceuticals, potential endocrine disrupting compounds (EDCs), and other unregulated organic contaminants. Source water, finished drinking water, and distribution system (tap) water from 19 U.S. water utilities was analyzed for 51 compounds between 2006 and 2007. The 11 most frequently detected compounds were atenolol, atrazine, carbamazepine, estrone, gemfibrozil, meprobamate, naproxen, phenytoin, sulfamethoxazole, TCEP, and trimethoprim. Median concentrations of these compounds were less than 10 ng/L, except for sulfamethoxazole in source water (12 ng/L), TCEP in source water (120 ng/L), and atrazine in source, finished, and distribution system water (32, 49, and 49 ng/L). Atrazine was detected in source waters far removed from agricultural application where wastewater was the only known source of organic contaminants. The occurrence of compounds in finished drinking water was controlled by the type of chemical oxidation (ozone or chlorine) used at each plant. At one drinking water treatment plant, summed monthly concentrations of the detected analytes in source and finished water are reported. Atenolol, atrazine, DEET, estrone, meprobamate, and trimethoprim can serve as indicator compounds representing potential contamination from other pharmaceuticals and EDCs and can gauge the efficacy of treatment processes.",10.1021/es801845a,69,yes,no,no,no,no,no,no,no,yes,no,yes,yes,yes,no,no,no,yes,yes,no,yes,no,no,yes,yes,yes,yes,no,no,no,yes,yes
J,"Echard, B; Gayton, N; Lemaire, M",AK-MCS: An active learning reliability method combining Kriging and Monte Carlo Simulation,"An important challenge in structural reliability is to keep to a minimum the number of calls to the numerical models. Engineering problems involve more and more complex computer codes and the evaluation of the probability of failure may require very time-consuming computations. Metamodels are used to reduce these computation times. To assess reliability, the most popular approach remains the numerous variants of response surfaces. Polynomial Chaos [1] and Support Vector Machine [2] are also possibilities and have gained considerations among researchers in the last decades. However, recently, Kriging, originated from geostatistics, have emerged in reliability analysis. Widespread in optimisation, Kriging has just started to appear in uncertainty propagation [3] and reliability [4,5] studies. It presents interesting characteristics such as exact interpolation and a local index of uncertainty on the prediction which can be used in active learning methods. The aim of this paper is to propose an iterative approach based on Monte Carlo Simulation and Kriging metamodel to assess the reliability of structures in a more efficient way. The method is called AK-MCS for Active learning reliability method combining Kriging and Monte Carlo Simulation. It is shown to be very efficient as the probability of failure obtained with AK-MCS is very accurate and this, for only a small number of calls to the performance function. Several examples from literature are performed to illustrate the methodology and to prove its efficiency particularly for problems dealing with high non-linearity, non-differentiability, non-convex and non-connex domains of failure and high dimensionality. (C) 2011 Elsevier Ltd. All rights reserved.",10.1016/j.strusafe.2011.01.002,70,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,no,no,no,no,yes,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,yes,yes,
J,"Krasner, SW; Weinberg, HS; Richardson, SD; Pastor, SJ; Chinn, R; Sclimenti, MJ; Onstad, GD; Thruston, AD",Occurrence of a new generation of disinfection byproducts,"A survey of disinfection byproduct (DBP) occurrence in the United States was conducted at 12 drinking water treatment plants. In addition to currently regulated DBPs, more than 50 DBPs that rated a high priority for potential toxicity were studied. These priority DBPs included iodinated trihalomethanes (THMs), other halomethanes, a nonregulated haloacid, haloacetonitriles, haloketones, halonitromethanes, haloaldehydes, halogenated furanones, haloamides, and nonhalogenated carbonyls. The purpose of this study was to obtain quantitative occurrence information for new DBPs (beyond those currently regulated and/or studied) for prioritizing future health effects studies. An effort was made to select plants treating water that was high in total organic carbon and/or bromide to enable the detection of priority DBPs that contained bromine and/or iodine. THMs and haloacetic acids (HAAs) represented the two major classes of halogenated DBPs formed on a weight basis. Haloacetaldehydes represented the third major class formed in many of the waters. In addition to obtaining quantitative occurrence data, important new information was discovered or confirmed at full-scale plants on the formation and control of DBPs with alternative disinfectants to chlorine. Although the use of alternative disinfectants (ozone, chlorine dioxide, and chloramines) minimized the formation of the four regulated THMs, trihalogenated HAAs, and total organic halogen (TOX), several priority DBPs were formed at higher levels with the alternative disinfectants as compared with chlorine. For example, the highest levels of iodinated THMs-which are not part of the four regulated THMs-were found at a plant that used chloramination with no prechlorination. The highest concentration of dichloroacetaldehyde was at a plant that used chloramines and ozone; however, this disinfection scheme reduced the formation of trichloroacetaldehyde. Preozonation was found to increase the formation of trihalonitromethanes. In addition to the chlorinated furanones that have been measured previously, brominated furanones-which have seldom been analyzed- were detected, especially in high-bromide waters. The presence of bromide resulted in a shift to the formation of other bromine-containing DBPs not normally measured (e.g., brominated ketones, acetaldehydes, nitromethanes, acetamides). Collectively, similar to 30 and 39% of the TOX and total organic bromine, respectively, were accounted for (on a median basis) by the sum of the measured halogenated DBPs. In addition, 28 new, previously unidentified DBPs were detected. These included brominated and iodinated haloacids, a brominated ketone, and chlorinated and iodinated aldehydes.",10.1021/es060353j,71,yes,no,no,no,yes,no,yes,no,yes,yes,yes,yes,yes,no,yes,no,yes,yes,no,yes,no,no,yes,yes,yes,no,no,yes,yes,yes,yes
J,"Hensher, DA; Greene, WH",The Mixed Logit model: The state of practice,"The mixed logit model is considered to be the most promising state of the art discrete choice model currently available. Increasingly researchers and practitioners are estimating mixed logit models of various degrees of sophistication with mixtures of revealed preference and stated choice data. It is timely to review progress in model estimation since the learning curve is steep and the unwary are likely to fall into a chasm if not careful. These chasms are very deep indeed given the complexity of the mixed logit model. Although the theory is relatively clear, estimation and data issues are far from clear. Indeed there is a great deal of potential mis-inference consequent on trying to extract increased behavioural realism from data that are often not able to comply with the demands of mixed logit models. Possibly for the first time we now have an estimation method that requires extremely high quality data if the analyst wishes to take advantage of the extended behavioural capabilities of such models. This paper focuses on the new opportunities offered by mixed logit models and some issues to be aware of to avoid misuse of such advanced discrete choice methods by the practitioner.",10.1023/A:1022558715350,72,yes,yes,no,yes,yes,no,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no
J,"Park, HS; Jun, CH",A simple and fast algorithm for K-medoids clustering,"This paper proposes a new algorithm for K-medoids clustering which runs like the K-means algorithm and tests several methods for selecting initial medoids. The proposed algorithm calculates the distance matrix once and uses it for finding new medoids at every iterative step. To evaluate the proposed algorithm, we use some real and artificial data sets and compare with the results of other algorithms in terms of the adjusted Rand index. Experimental results show that the proposed algorithm takes a significantly reduced time ill computation with comparable performance against the partitioning around medoids. (C) 2008 Elsevier Ltd. All rights reserved.",10.1016/j.eswa.2008.01.039,73,yes,yes,no,no,yes,yes,yes,no,yes,no,yes,yes,yes,no,no,yes,yes,yes,no,yes,no,no,no,yes,no,yes,no,yes,no,no,yes
J,"Cortés, P; Kazmierkowski, MP; Kennel, RM; Quevedo, DE; Rodríguez, J",Predictive Control in Power Electronics and Drives,"Predictive control is a very wide class of controllers that have found rather recent application in the control of power converters. Research on this topic has been increased in the last years due to the possibilities of today's microprocessors used for the control. This paper presents the application of different predictive control methods to power electronics and drives. A simple classification of the most important types of predictive control is introduced, and each one of them is explained including some application examples. Predictive control presents several advantages that make it suitable for the control of power converters and drives. The different control schemes and applications presented in this paper illustrate the effectiveness and flexibility of predictive control.",10.1109/TIE.2008.2007480,74,yes,no,yes,no,yes,no,yes,yes,no,no,yes,no,no,no,no,no,yes,yes,yes,no,no,no,no,no,yes,yes,no,no,no,yes,
J,"Lee, KS; Geem, ZW",A new meta-heuristic algorithm for continuous engineering optimization: harmony search theory and practice,"Most engineering optimization algorithms are based on numerical linear and nonlinear programming methods that require substantial gradient information and usually seek to improve the solution in the neighborhood of a starting point. These algorithms, however, reveal a limited approach to complicated real-world optimization problems. If there is more than one local optimum in the problem, the result may depend on the selection of an initial point, and the obtained optimal solution may not necessarily be the global optimum. This paper describes a new harmony search (HS) meta-heuristic algorithm-based approach for engineering optimization problems with continuous design variables. This recently developed HS algorithm is conceptualized using the musical process of searching for a perfect state of harmony. It uses a stochastic random search instead of a gradient search so that derivative information is unnecessary. Various engineering optimization problems, including mathematical function minimization and structural engineering optimization problems, are presented to demonstrate the effectiveness and robustness of the HS algorithm. The results indicate that the proposed approach is a powerful search and optimization technique that may yield better solutions to engineering problems than those obtained using current algorithms. (c) 2004 Elsevier B.V. All rights reserved.",10.1016/j.cma.2004.09.007,75,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,yes,yes,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,no,yes,yes
J,"Cho, SK; Moon, HJ; Kim, CJ","Creating, transporting, cutting, and merging liquid droplets by electrowetting-based actuation for digital microfluidic circuits","This paper reports the completion of four fundamental fluidic operations considered essential to build digital microfluidic circuits, which can be used for lab-on-a-chip or micro total analysis system (muTAS): 1) creating, 2) transporting, 3) cutting, and 4) merging liquid droplets, all by electrowetting, i.e., controlling the wetting property of the surface through electric potential. The surface used in this report is, more specifically, an electrode covered with dielectrics, hence, called electrowetting-on-dielectric (EWOD). All the fluidic movement is confined between two plates, which we call parallel-plate channel, rather than through closed channels or on open surfaces. While transporting and merging droplets are easily verified, we discover that there exists a design criterion for a given set of materials beyond which the droplet simply cannot be cut by EWOD mechanism. The condition for successful cutting is theoretically analyzed by examining the channel gap, the droplet size and the degree of contact angle change by electrowetting on dielectric (EWOD). A series of experiments is run and verifies the criterion. A smaller channel gap, a larger droplet size and a larger change in the contact angle enhance the necking of the droplet, helping the completion of the cutting process. Creating droplets from a pool of liquid is highly related to cutting, but much more challenging. Although droplets may be created by simply pulling liquid out of a reservoir, the location of cutting is sensitive to initial conditions and turns out unpredictable. This problem of an inconsistent cutting location is overcome by introducing side electrodes, which pull the liquid perpendicularly to the main fluid path before activating the cutting. All four operations are carried out in air environment at 25 V-dc applied voltage.",10.1109/JMEMS.2002.807467,76,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
J,"Bai, YL; Wierzbicki, T",A new model of metal plasticity and fracture with pressure and Lode dependence,"Classical metal plasticity theory assumes that the hydrostatic pressure has no or negligible effect on the material strain hardening, and that the flow stress is independent of the third deviatoric stress invariant (or Lode angle parameter). However, recent experiments on metals have shown that both the pressure effect and the effect of the third deviatoric stress invariant should be included in the constitutive description of the material. A general form of asymmetric metal plasticity, considering both the pressure sensitivity and the Lode dependence, is postulated. The calibration method for the new metal plasticity is discussed. Experimental results on aluminum 2024-T351 are shown to validate the new material model. From the similarity between yielding surface and fracture locus, a new 3D asymmetric fracture locus, in the space of equivalent fracture strain, stress triaxiality and the Lode angle parameter, is postulated. Two methods of calibration of the fracture locus are discussed. One is based oil classical round specimens and flat specimens in uniaxial tests, and the other one uses the newly designed butterfly specimen under biaxial testing. Test results of Bao (2003) [Bao, Y., 2003. Prediction of ductile crack formation in uncracked bodies. PhD Thesis, Massachusetts Institute of Technology] on aluminum 2024-T351, and test data points of A710 steel from butterfly specimens under biaxial testing validated the postulated asymmetric 3D fracture locus. (c) 2007 Elsevier Ltd. All rights reserved.",10.1016/j.ijplas.2007.09.004,77,yes,no,yes,yes,yes,no,yes,no,yes,no,yes,yes,yes,yes,yes,no,yes,yes,no,yes,no,no,no,no,no,yes,no,yes,no,yes,yes
J,"Azpiroz, JM; Mosconi, E; Bisquert, J; De Angelis, F",Defect migration in methylammonium lead iodide and its role in perovskite solar cell operation,"In spite of the unprecedented advance of organohalide lead perovskites in the photovoltaics scenario, many of the characteristics of this class of materials, including their slow photoconductivity response, solar cell hysteresis, and switchable photocurrent, remain poorly understood. Many experimental hints point to defect migration as a plausible mechanism underlying these anomalous properties. By means of state-of-the-art first-principles computational analyses carried out on the tetragonal MAPbI(3) (MA = methylammonium) perovskite and on its interface with TiO2, we demonstrate that iodine vacancies and interstitials may easily diffuse across the perovskite crystal, with migration activation energies as low as similar to 0.1 eV. Under working conditions, iodine-related defects are predicted to migrate at the electrodes on very short time scales (<1 mu s). MA and Pb vacancies, with calculated activation barriers of similar to 0.5 and 0.8 eV, respectively, could be responsible for the slow response inherent to perovskites, with typical calculated migration times of the order of tens of ms to minutes. By investigating realistic models of the perovskite/TiO2 interface we show that negatively charged defects, e.g. MA vacancies, close to the electron transport layer (TiO2 in our case) modify the perovskite electronic state landscape, hampering charge extraction at selective contacts, thus possibly contributing to the observed solar cell hysteresis. We further demonstrate the role of the electron transport layer in affecting the initial concentration of defects close to the selective contacts, highlighting how charge separation at the perovskite/TiO2 interface may further change the defect distribution. We believe that this work, identifying the mobile species in perovskite solar cells, their migration across the perovskite material, and their effect on the operational mechanism of the device, may pave the way for the development of new materials and solar cell architectures with improved and stabilized efficiencies.",10.1039/c5ee01265a,78,yes,no,no,yes,yes,no,yes,no,no,yes,yes,no,yes,no,no,no,yes,yes,yes,no,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,yes
J,"Suss, ME; Porada, S; Sun, X; Biesheuvel, PM; Yoon, J; Presser, V",Water desalination <i>via</i> capacitive deionization: what is it and what can we expect from it?,"Capacitive deionization (CDI) is an emerging technology for the facile removal of charged ionic species from aqueous solutions, and is currently being widely explored for water desalination applications. The technology is based on ion electrosorption at the surface of a pair of electrically charged electrodes, commonly composed of highly porous carbon materials. The CDI community has grown exponentially over the past decade, driving tremendous advances via new cell architectures and system designs, the implementation of ion exchange membranes, and alternative concepts such as flowable carbon electrodes and hybrid systems employing a Faradaic (battery) electrode. Also, vast improvements have been made towards unraveling the complex processes inherent to interfacial electrochemistry, including the modelling of kinetic and equilibrium aspects of the desalination process. In our perspective, we critically review and evaluate the current state-of-the-art of CDI technology and provide definitions and performance metric nomenclature in an effort to unify the fast-growing CDI community. We also provide an outlook on the emerging trends in CDI and propose future research and development directions.",10.1039/c5ee00519a,79,yes,no,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,yes,no,no,no,no,no,no,no,no,no,yes,yes,no,yes,yes,yes
J,"Carslaw, DC; Ropkins, K",<i>openair</i> - An R package for air quality data analysis,"openair is an R package primarily developed for the analysis of air pollution measurement data but which is also of more general use in the atmospheric sciences. The package consists of many tools for importing and manipulating data, and undertaking a wide range of analyses to enhance understanding of air pollution data. In this paper we consider the development of the package with the purpose of showing how air pollution data can be analysed in more insightful ways. Examples are provided of importing data from UK air pollution networks, source identification and characterisation using bivariate polar plots, quantitative trend estimates and the use of functions for model evaluation purposes. We demonstrate how air pollution data can be analysed quickly and efficiently and in an interactive way, freeing time to consider the problem at hand. One of the central themes of openair is the use of conditioning plots and analyses, which greatly enhance inference possibilities. Finally, some consideration is given to future developments. (C) 2011 Elsevier Ltd. All rights reserved.",10.1016/j.envsoft.2011.09.008,80,yes,yes,no,no,yes,no,yes,no,yes,no,yes,yes,yes,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,no,no,yes,yes,yes,yes
J,"Menne, MJ; Durre, I; Vose, RS; Gleason, BE; Houston, TG",An Overview of the Global Historical Climatology Network-Daily Database,"A database is described that has been designed to fulfill the need for daily climate data over global land areas. The dataset, known as Global Historical Climatology Network (GHCN)-Daily, was developed for a wide variety of potential applications, including climate analysis and monitoring studies that require data at a daily time resolution (e.g., assessments of the frequency of heavy rainfall, heat wave duration, etc.). The dataset contains records from over 80 000 stations in 180 countries and territories, and its processing system produces the official archive for U.S. daily data. Variables commonly include maximum and minimum temperature, total daily precipitation, snowfall, and snow depth; however, about two-thirds of the stations report precipitation only. Quality assurance checks are routinely applied to the full dataset, but the data are not homogenized to account for artifacts associated with the various eras in reporting practice at any particular station (i.e., for changes in systematic bias). Daily updates are provided for many of the station records in GHCN-Daily. The dataset is also regularly reconstructed, usually once per week, from its 20+ data source components, ensuring that the dataset is broadly synchronized with its growing list of constituent sources. The daily updates and weekly reprocessed versions of GHCN-Daily are assigned a unique version number, and the most recent dataset version is provided on the GHCN-Daily website for free public access. Each version of the dataset is also archived at the NOAA/National Climatic Data Center in perpetuity for future retrieval.",10.1175/JTECH-D-11-00103.1,81,yes,no,no,yes,yes,no,yes,no,yes,yes,yes,yes,yes,no,no,no,yes,yes,no,yes,no,no,yes,yes,yes,yes,no,no,yes,no,no
J,"Shi, QJ; Razaviyayn, M; Luo, ZQ; He, C",An Iteratively Weighted MMSE Approach to Distributed Sum-Utility Maximization for a MIMO Interfering Broadcast Channel,"Consider the multiple-input multiple-output (MIMO) interfering broadcast channel whereby multiple base stations in a cellular network simultaneously transmit signals to a group of users in their own cells while causing interference to each other. The basic problem is to design linear beamformers that can maximize the system throughput. In this paper, we propose a linear transceiver design algorithm for weighted sum-rate maximization that is based on iterative minimization of weighted mean-square error (MSE). The proposed algorithm only needs local channel knowledge and converges to a stationary point of the weighted sumrate maximization problem. Furthermore, the algorithm and its convergence can be extended to a general class of sum-utility maximization problem. The effectiveness of the proposed algorithm is validated by numerical experiments.",10.1109/TSP.2011.2147784,82,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,yes,yes,no,yes,no,no,no,no,no,no,yes,yes,no,yes,yes,yes
J,"Borji, A; Itti, L",State-of-the-Art in Visual Attention Modeling,"Modeling visual attention-particularly stimulus-driven, saliency-based attention-has been a very active research area over the past 25 years. Many different models of attention are now available which, aside from lending theoretical contributions to other fields, have demonstrated successful applications in computer vision, mobile robotics, and cognitive systems. Here we review, from a computational perspective, the basic concepts of attention implemented in these models. We present a taxonomy of nearly 65 models, which provides a critical comparison of approaches, their capabilities, and shortcomings. In particular, 13 criteria derived from behavioral and computational studies are formulated for qualitative comparison of attention models. Furthermore, we address several challenging issues with models, including biological plausibility of the computations, correlation with eye movement datasets, bottom-up and top-down dissociation, and constructing meaningful performance measures. Finally, we highlight current research trends in attention modeling and provide insights for future.",10.1109/TPAMI.2012.89,83,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,yes,no,no,no,no,no,no,no,no,no,yes,yes,no,yes,no,yes
J,"Yang, SY; Bryant, A; Mawby, P; Xiang, DW; Ran, L; Tavner, P",An Industry-Based Survey of Reliability in Power Electronic Converters,"A questionnaire survey was carried out to determine the industrial requirements and expectations of reliability in power electronic converters. The survey was subjective and conducted with a number of high-profile semiconductor manufacturers, integrators, and users in the aerospace, automation, motor drive, utility power, and other industry sectors. According to the survey, power semiconductor devices ranked the most fragile components. It was concluded that main stresses were from the environment, transients, and heavy loads, which should be considered during power electronic system design and normal operation. This paper has also highlighted that there is a significant need identified by the responders for better reliability-monitoring methods and indicators.",10.1109/TIA.2011.2124436,84,yes,yes,no,no,yes,no,yes,no,yes,no,yes,yes,yes,no,yes,no,yes,yes,no,yes,no,no,no,yes,yes,no,no,no,no,yes,no
J,"Mohsenian-Rad, AH; Leon-Garcia, A",Optimal Residential Load Control With Price Prediction in Real-Time Electricity Pricing Environments,"Real-time electricity pricing models can potentially lead to economic and environmental advantages compared to the current common flat rates. In particular, they can provide end users with the opportunity to reduce their electricity expenditures by responding to pricing that varies with different times of the day. However, recent studies have revealed that the lack of knowledge among users about how to respond to time-varying prices as well as the lack of effective building automation systems are two major barriers for fully utilizing the potential benefits of real-time pricing tariffs. We tackle these problems by proposing an optimal and automatic residential energy consumption scheduling framework which attempts to achieve a desired trade-off between minimizing the electricity payment and minimizing the waiting time for the operation of each appliance in household in presence of a real-time pricing tariff combined with inclining block rates. Our design requires minimum effort from the users and is based on simple linear programming computations. Moreover, we argue that any residential load control strategy in real-time electricity pricing environments requires price prediction capabilities. This is particularly true if the utility companies provide price information only one or two hours ahead of time. By applying a simple and efficient weighted average price prediction filter to the actual hourly-based price values used by the Illinois Power Company from January 2007 to December 2009, we obtain the optimal choices of the coefficients for each day of the week to be used by the price predictor filter. Simulation results show that the combination of the proposed energy consumption scheduling design and the price predictor filter leads to significant reduction not only in users' payments but also in the resulting peak-to-average ratio in load demand for various load scenarios. Therefore, the deployment of the proposed optimal energy consumption scheduling schemes is beneficial for both end users and utility companies.",10.1109/TSG.2010.2055903,85,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
J,"Seabaugh, AC; Zhang, Q",Low-Voltage Tunnel Transistors for Beyond CMOS Logic,"Steep subthreshold swing transistors based on interband tunneling are examined toward extending the performance of electronics systems. In particular, this review introduces and summarizes progress in the development of the tunnel field-effect transistors (TFETs) including its origin, current experimental and theoretical performance relative to the metal-oxide-semiconductor field-effect transistor (MOSFET), basic current-transport theory, design tradeoffs, and fundamental challenges. The promise of the TFET is in its ability to provide higher drive current than the MOSFET as supply voltages approach 0.1 V.",10.1109/JPROC.2010.2070470,86,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,no,no
J,"Sisinni, E; Saifullah, A; Han, S; Jennehag, U; Gidlund, M","Industrial Internet of Things: Challenges, Opportunities, and Directions","Internet of Things (IoT) is an emerging domain that promises ubiquitous connection to the Internet, turning common objects into connected devices. The IoT paradigm is changing the way people interact with things around them. It paves the way for creating pervasively connected infrastructures to support innovative services and promises better flexibility and efficiency. Such advantages are attractive not only for consumer applications, but also for the industrial domain. Over the last few years, we have been witnessing the IoT paradigm making its way into the industry marketplace with purposely designed solutions. In this paper, we clarify the concepts of IoT, Industrial IoT, and Industry 4.0. We highlight the opportunities brought in by this paradigm shift as well as the challenges for its realization. In particular, we focus on the challenges associated with the need of energy efficiency, real-time performance, coexistence, interoperability, and security and privacy. We also provide a systematic overview of the state-of-the-art research efforts and potential research directions to solve Industrial IoT challenges.",10.1109/TII.2018.2852491,87,yes,no,no,yes,yes,no,no,no,yes,yes,yes,yes,no,no,no,no,no,no,no,yes,no,no,no,no,no,yes,yes,no,yes,yes,yes
J,"Kang, GD; Cao, YM",Application and modification of poly(vinylidene fluoride) (PVDF) membranes - A review,"Poly(vinylidene fluoride) (PVDF) membranes have been extensively applied to scientific research and industrial process due to its outstanding properties such as high thermal stability, good chemical resistance and membrane forming properties. This article provides an overview of recent progress On the application and modification of PVDF membranes. The applications include water treatment, membrane distillation, gas separation, pollutants removal, bioethanol recovery, separator for lithium ion battery, support for preparing composite membranes, etc. Subsequently, On the basis of two major problems of PVDF membranes in applications, i.e., membrane fouling and membrane wetting, the hydrophilic modification and hydrophobic modification methods are comprehensively reviewed. Finally, the key issues associated with the modification of PVDF membranes for actual applications are discussed. This paper may provide an insight for the development of PVDF membranes in future. (C) 2014 Elsevier B.V. All rights reserved.",10.1016/j.memsci.2014.03.055,88,yes,yes,no,yes,yes,no,yes,no,yes,no,yes,yes,no,no,no,no,no,no,no,yes,no,no,no,no,no,yes,no,no,yes,yes,no
J,"Leveson, N",A new accident model for engineering safer systems,"New technology is making fundamental changes in the etiology of accidents and is creating a need for changes in the explanatory mechanisms used. We need better and less subjective understanding of why accidents occur and how to prevent future ones. The most effective models will go beyond assigning blame and instead help engineers to learn as much as possible about all the factors involved, including those related to social and organizational structures. This paper presents a new accident model founded on basic systems theory concepts. The use of such a model provides a theoretical foundation for the introduction of unique new types of accident analysis, hazard analysis, accident prevention strategies including new approaches to designing for safety, risk assessment techniques, and approaches to designing performance monitoring and safety metrics. (C) 2003 Elsevier Ltd. All rights reserved.",10.1016/S0925-7535(03)00047-X,89,yes,no,yes,no,yes,no,yes,yes,no,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,no,yes,no,yes
J,"Mo, JH; Walrand, J",Fair end-to-end window-based congestion control,"In this paper, we demonstrate the existence of fair end-to-end window-based congestion control protocols for packet-switched networks with first come-first served routers. Our definition of fairness generalizes proportional fairness and includes arbitrarily close approximations of mac-min fairness. The protocols use only information that is available to end hosts and are designed to converge reasonably fast. Our study is based on a multiclass fluid model of the network. The convergence of the protocols is proved using a Lyapunov function. The technical challenge is in the practical implementation of the protocols.",10.1109/90.879343,90,yes,yes,no,no,yes,yes,yes,yes,no,no,yes,no,no,no,no,no,yes,no,yes,no,yes,yes,no,no,yes,no,no,no,yes,yes,
J,"Medhat, W; Hassan, A; Korashy, H",Sentiment analysis algorithms and applications: A survey,"Sentiment Analysis (SA) is an ongoing field of research in text mining field. SA is the computational treatment of opinions, sentiments and subjectivity of text. This survey paper tackles a comprehensive overview of the last update in this field. Many recently proposed algorithms' enhancements and various SA applications are investigated and presented briefly in this survey. These articles are categorized according to their contributions in the various SA techniques. The related fields to SA (transfer learning, emotion detection, and building resources) that attracted researchers recently are discussed. The main target of this survey is to give nearly full image of SA techniques and the related fields with brief details. The main contributions of this paper include the sophisticated categorizations of a large number of recent articles and the illustration of the recent trend of research in the sentiment analysis and its related areas. (C) 2014 Production and hosting by Elsevier B.V.",10.1016/j.asej.2014.04.011,91,yes,no,yes,yes,yes,no,yes,yes,no,no,yes,yes,no,no,no,no,yes,yes,yes,no,no,no,no,no,no,yes,yes,no,no,no,yes
J,"Moorthy, AK; Bovik, AC",Blind Image Quality Assessment: From Natural Scene Statistics to Perceptual Quality,"Our approach to blind image quality assessment (IQA) is based on the hypothesis that natural scenes possess certain statistical properties which are altered in the presence of distortion, rendering them un-natural; and that by characterizing this un-naturalness using scene statistics, one can identify the distortion afflicting the image and perform no-reference (NR) IQA. Based on this theory, we propose an (NR)/blind algorithm-the Distortion Identification-based Image Verity and INtegrity Evaluation (DIIVINE) index-that assesses the quality of a distorted image without need for a reference image. DIIVINE is based on a 2-stage framework involving distortion identification followed by distortion-specific quality assessment. DIIVINE is capable of assessing the quality of a distorted image across multiple distortion categories, as against most NR IQA algorithms that are distortion-specific in nature. DIIVINE is based on natural scene statistics which govern the behavior of natural images. In this paper, we detail the principles underlying DIIVINE, the statistical features extracted and their relevance to perception and thoroughly evaluate the algorithm on the popular LIVE IQA database. Further, we compare the performance of DIIVINE against leading full-reference (FR) IQA algorithms and demonstrate that DIIVINE is statistically superior to the often used measure of peak signal-to-noise ratio (PSNR) and statistically equivalent to the popular structural similarity index (SSIM). A software release of DIIVINE has been made available online: http://live.ece.utexas.edu/research/quality/DIIVINE_release.zip for public use and evaluation.",10.1109/TIP.2011.2147325,92,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
J,"Kulekci, MK",Magnesium and its alloys applications in automotive industry,"The objective of this study is to review and evaluate the applications of magnesium in the automotive industry that can significantly contribute to greater fuel economy and environmental conservation. In the study, the current advantages, limitations, technological barriers and future prospects of Mg alloys in the automotive industry are given. The usage of magnesium in automotive applications is also assessed for the impact on environmental conservation. Recent developments in coating and alloying of Mg improved the creep and corrosion resistance properties of magnesium alloys for elevated temperature and corrosive environments. The results of the study conclude that reasonable prices and improved properties of Mg and its alloys will lead to massive use of magnesium. Compared to using alternative materials, using Mg alloys results in a 22% to 70% weight reduction. Lastly, the use of magnesium in automotive components is increasing as knowledge of forming processes of Mg alloys increases.",10.1007/s00170-007-1279-2,93,yes,no,no,yes,yes,yes,yes,no,yes,no,yes,yes,no,no,no,no,yes,yes,yes,no,no,no,yes,yes,yes,yes,yes,yes,yes,no,yes
J,"Han, SH; Lee, JH",An overview of peak-to-average power ratio reduction techniques for multicarrier transmission,"High peak-to-average power ratio of the transmit signal is a major drawback of multicarrier transmission such as OFDM or DMT. This article describes some of the important PAPR reduction techniques for multicarrier transmission including amplitude clipping and filtering, coding, partial transmit sequence, selected mapping, interleaving, tone reservation, tone injection, and active constellation extension. Also, we make some remarks on the criteria for PAPR reduction technique selection and briefly address the problem of PAPR reduction in OFDMA and MIMO-OFDM.",,94,yes,yes,no,no,no,no,no,no,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,no,yes,yes,yes
J,"Hainfeld, JF; Slatkin, DN; Smilowitz, HM",The use of gold nanoparticles to enhance radiotherapy in mice,"Mice bearing subcutaneous EMT-6 mammary carcinomas received a single intravenous injection of 1.9 nm diameter gold particles (up to 2.7 g Au/kg body weight), which elevated concentrations of gold to 7 mg Au/g in tumours. Tumour-to-normal-tissue gold concentration ratios remained similar to8:1 during several minutes of 250 kVp x-ray therapy. One-year survival was 86% versus 20% with x-rays alone and 0% with gold alone. The increase in tumours safely ablated was dependent on the amount of gold injected. The gold nanoparticles were apparently non-toxic to mice and were largely cleared from the body through the kidneys. This novel use of small gold nanoparticles permitted achievement of the high metal content in tumours necessary for significant high-Z radioenhancement.",10.1088/0031-9155/49/18/N03,95,yes,yes,no,no,no,no,no,no,yes,no,yes,yes,yes,no,no,yes,yes,yes,no,yes,no,no,no,yes,yes,no,no,no,yes,yes,no
J,"Batstone, DJ; Keller, J; Angelidaki, I; Kalyuzhnyi, SV; Pavlostathis, SG; Rozzi, A; Sanders, WTM; Siegrist, H; Vavilin, VA",The IWA Anaerobic Digestion Model No 1 (ADM1),"The IWA Anaerobic Digestion Modelling Task Group was established in 1997 at the 8th World Congress on,Anaerobic Digestion (Sendai, Japan) with the goal of developing a generalised anaerobic digestion model. The structured model includes multiple steps describing biochemical as well as physicochemical processes. The biochemical steps include disintegration from homogeneous particulates to carbohydrates, proteins and lipids; extracellular hydrolysis of these particulate substrates to sugars, amino acids, and long chain fatty acids (LCFA), respectively; acidogenesis from sugars and amino acids to volatile fatty acids (VFAs) and hydrogen; acetogenesis of LCFA and VFAs to acetate; and separate methanogenesis steps from acetate and hydrogen/CO2. The physico-chemical equations describe ion association and dissociation, and gas-liquid transfer. Implemented as a differential and algebraic equation (DAE) set, there are 26 dynamic state concentration variables, and 8 implicit algebraic variables per reactor vessel or element. Implemented as differential equations (DE) only, there are 32 dynamic concentration state variables.",,96,yes,yes,no,no,yes,no,yes,no,yes,no,yes,yes,no,no,no,no,no,no,no,yes,no,no,no,yes,no,no,no,no,no,yes,yes
J,"Saad, MA; Bovik, AC; Charrier, C",Blind Image Quality Assessment: A Natural Scene Statistics Approach in the DCT Domain,"We develop an efficient general-purpose blind/no-reference image quality assessment (IQA) algorithm using a natural scene statistics (NSS) model of discrete cosine transform (DCT) coefficients. The algorithm is computationally appealing, given the availability of platforms optimized for DCT computation. The approach relies on a simple Bayesian inference model to predict image quality scores given certain extracted features. The features are based on an NSS model of the image DCT coefficients. The estimated parameters of the model are utilized to form features that are indicative of perceptual quality. These features are used in a simple Bayesian inference approach to predict quality scores. The resulting algorithm, which we name BLIINDS-II, requires minimal training and adopts a simple probabilistic model for score prediction. Given the extracted features from a test image, the quality score that maximizes the probability of the empirically determined inference model is chosen as the predicted quality score of that image. When tested on the LIVE IQA database, BLIINDS-II is shown to correlate highly with human judgments of quality, at a level that is competitive with the popular SSIM index.",10.1109/TIP.2012.2191563,97,yes,yes,no,yes,yes,yes,yes,yes,no,no,yes,yes,yes,no,no,yes,yes,yes,no,yes,no,no,no,yes,yes,yes,yes,yes,yes,yes,yes
J,"Montaldo, G; Tanter, M; Bercoff, J; Benech, N; Fink, M",Coherent Plane-Wave Compounding for Very High Frame Rate Ultrasonography and Transient Elastography,"The emergence of ultrafast frame rates in ultrasonic! imaging has been recently made possible by the development of new imaging modalities such as transient elastography. Data acquisition rates reaching more than thousands (if images per second enable the real-time visualization of shear mechanical waves propagating in biological tissues, which convey in-formation about local viscoelastic properties of tissue. The first proposed approach for reaching such ultrafast frame rates consists of transmitting plane waves into the medium. However, because the beamforming process is then restricted to the receive mode, the echographic images obtained in the ultrafast mode suffer from a low quality in terms of resolution and contrast and affect the robustness of the transient elastography mode. It is here proposed to improve the beamforming process by using it coherent recombination of compounded plane-wave transmissions to recover high-quality echographic images without, degrading the high frame rare capabilities. A theoretical model is derived for the comparison between the proposed method and the conventional B-mode imaging in terms of contrast, signal-to-noise ratio, and resolution. Our model predicts that; a significantly smaller number of insonifications, 10 times lower, is sufficient to reach oil image quality comparable to conventional B-mode. Theoretical predictions are confirmed by in vitro experiments performed in tissue-mimicking phantoms. Such results raise the appeal of coherent compounds for use with standard imaging modes Such as B-mode or color flow. Moreover, in the context of transient elastography, ultrafast frame rates can be preserved while increasing the image quality compared with flat insonifications. Improvements oil the transient elastography mode are presented and discussed.",10.1109/TUFFC.2009.1067,98,yes,no,yes,yes,yes,no,yes,yes,no,no,yes,yes,no,yes,no,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes
J,"Huber, MM; Canonica, S; Park, GY; Von Gunten, U",Oxidation of pharmaceuticals during ozonation and advanced oxidation processes,"This study investigates the oxidation of pharmaceuticals during conventional ozonation and advanced oxidation processes (AOPs) applied in drinking water treatment. In a first step, second-order rate constants for the reactions of selected pharmaceuticals with ozone (k(O3)) and OH radicals (k(OH)) were determined in bench-scale experiments (in brackets apparent k(O3) at pH 7 and T = 20 degreesC): bezafibrate (590 +/- 50 M-1 s(-1)), carbamazepine (similar to3 x 10(5) M-1 s(-1)), diazepam (0.75 +/- 0.15 M-1 s(-1)), diclofenac (similar to1 X 10(6) M-1 s(-1)), 17alpha-ethinylestradiol (similar to3 x 10(6) M-1 s(-1)), ibuprofen (9.6 +/- 1.0 M-1 s(-1)), iopromide (<0.8 M-1 s(-1)), sulfamethoxazole (similar to2.5 x 10(6) M-1 s(-1)), and roxithromycin (similar to7 x 10(4) M-1 s(-1)). For five of the pharmaceuticals the apparent k(O3) at pH 7 was >5 x 10(4) M-1 s(-1), indicating that these compounds are completely transformed during ozonation processes. Values for kOH ranged from 3.3 to 9.8 x 10(9) M-1 s(-1). Compared to other important micropollutants such as MTBE and atrazine, the selected pharmaceuticals reacted about two to three times faster with OH radicals. In the second part of the study, oxidation kinetics of the selected pharmaceuticals were investigated in ozonation experiments performed in different natural waters. It could be shown that the second-order rate constants determined in pure aqueous solution could be applied to predict the behavior of pharmaceuticals dissolved in natural waters. Overall it can be concluded that ozonation and AOPs are promising processes for an efficient removal of pharmaceuticals in drinking waters.",10.1021/es025896h,99,yes,no,no,no,yes,no,yes,no,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,yes,no,no,no,yes,yes,yes,yes,yes,no,yes,yes,yes
