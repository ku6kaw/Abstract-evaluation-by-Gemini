Publication Type,Authors,Title,Abstract,DOI,ID,rule1,rule2,rule3,rule4,rule5,rule6,rule7,rule8,rule9,rule10,rule11,rule12,rule13,rule14,rule15,rule16,rule17,rule18,rule19,rule20,rule21,rule22,rule23,rule24,rule25,rule26,rule27,rule28,rule29,rule30,rule31
J,"Feng, QL; Wu, J; Chen, GQ; Cui, FZ; Kim, TN; Kim, JO",A mechanistic study of the antibacterial effect of silver ions on <i>Escherichia coli</i> and <i>Staphylococcus aureus</i>,"To investigate the mechanism of inhibition of silver ions on microorganisms, two strains of bacteria, namely Gram-negative Escherichia coli (E. coli and Gram-positive Staphylococcus aureus (S. aureus), were treated with AgNO3 and studied using combined electron microscopy and X-ray microanalysis. Similar morphological changes occurred in both E.coli and S. aureus cells after Ag+ treatment. The cytoplasm membrane detached from the cell wall. A remarkable electron-light region appeared in the center of the cells, which contained condensed deoxyribonucleic acid (DNA) molecules. There are many small electron-dense granules either surrounding the cell wall or depositing inside the cells. The existence of elements of silver and sulfur in the electron-dense granules and cytoplasm detected by X-ray microanalysis suggested the antibacterial mechanism of silver: DNA lost its replication ability and the protein became inactivated after Ag+ treatment. The slighter morphological changes of S. aureus compared with E. coli recommended a defense system of S. aureus against the inhibitory effects of Ag+ ions. (C) 2000 John Wiley & Sons, Inc.",10.1002/1097-4636(20001215)52:4<662::AID-JBM10>3.0.CO;2-3,0,yes,yes,no,no,yes,yes,yes,no,yes,no,yes,yes,yes,yes,no,no,yes,yes,no,yes,yes,yes,no,yes,yes,yes,no,no,no,yes,yes
J,"Tabuada, P",Event-triggered real-time scheduling of stabilizing control tasks,"In this note, we revisit the problem of scheduling stabilizing control tasks on embedded processors. We start from the paradigm that a real-time scheduler could be regarded as a feedback controller that decides which task is executed at any given instant. This controller has for objective guaranteeing that (control unrelated) software tasks meet their deadlines and that stabilizing control tasks asymptotically stabilize the plant. We investigate a simple event-triggered scheduler based on this feedback paradigm and show how it leads to guaranteed performance thus relaxing the more traditional periodic execution requirements.",10.1109/TAC.2007.904277,1,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,no,no,no,yes,no,no,no,no,no,no,no,yes,no,yes,yes,yes
J,"Fax, JA; Murray, RM",Information flow and cooperative control of vehicle formations,"We consider the problem of cooperation among a collection of vehicles performing a shared task using intervehicle communication to coordinate their actions. Tools from algebraic graph theory prove useful in modeling the communication network and relating its topology to formation stability. We prove a Nyquist criterion that uses the eigenvalues of the graph Laplacian matrix to determine the effect of the communication topology on formation stability. We also propose a method for decentralized information exchange between vehicles. This approach realizes a dynamical system that supplies each vehicle with a common reference to be used for cooperative motion. We prove a separation principle that decomposes formation stability into two components: Stability of the is achieved information flow for the given graph and stability of an individual vehicle for the given controller. The information flow can thus be rendered highly robust to changes in the graph, enabling tight formation control despite limitations in intervehicle communication capability.",10.1109/TAC.2004.834433,2,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,yes,no,no,no,no,no,no,yes,no,no,no,no,no,no,yes,yes,no,yes,yes,yes
J,"Eperon, GE; Stranks, SD; Menelaou, C; Johnston, MB; Herz, LM; Snaith, HJ",Formamidinium lead trihalide: a broadly tunable perovskite for efficient planar heterojunction solar cells,"Perovskite-based solar cells have attracted significant recent interest, with power conversion efficiencies in excess of 15% already superceding a number of established thin-film solar cell technologies. Most work has focused on a methylammonium lead trihalide perovskites, with a bandgaps of similar to 1.55 eV and greater. Here, we explore the effect of replacing the methylammonium cation in this perovskite, and show that with the slightly larger formamidinium cation, we can synthesise formamidinium lead trihalide perovskites with a bandgap tunable between 1.48 and 2.23 eV. We take the 1.48 eV-bandgap perovskite as most suited for single junction solar cells, and demonstrate long-range electron and hole diffusion lengths in this material, making it suitable for planar heterojunction solar cells. We fabricate such devices, and due to the reduced bandgap we achieve high short-circuit currents of >23 mA cm(-2), resulting in power conversion efficiencies of up to 14.2%, the highest efficiency yet for solution processed planar heterojunction perovskite solar cells. Formamidinium lead triiodide is hence promising as a new candidate for this class of solar cell.",10.1039/c3ee43822h,3,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,yes,no,no,no,yes,yes,yes,yes,no,no,no,yes,yes,yes,yes,yes,yes,yes,yes,yes
J,"Menze, BH; Jakab, A; Bauer, S; Kalpathy-Cramer, J; Farahani, K; Kirby, J; Burren, Y; Porz, N; Slotboom, J; Wiest, R; Lanczi, L; Gerstner, E; Weber, MA; Arbel, T; Avants, BB; Ayache, N; Buendia, P; Collins, DL; Cordier, N; Corso, JJ; Criminisi, A; Das, T; Delingette, H; Demiralp, Ã‡; Durst, CR; Dojat, M; Doyle, S; Festa, J; Forbes, F; Geremia, E; Glocker, B; Golland, P; Guo, XT; Hamamci, A; Iftekharuddin, KM; Jena, R; John, NM; Konukoglu, E; Lashkari, D; Mariz, JA; Meier, R; Pereira, S; Precup, D; Price, SJ; Raviv, TR; Reza, SMS; Ryan, M; Sarikaya, D; Schwartz, L; Shin, HC; Shotton, J; Silva, CA; Sousa, N; Subbanna, NK; Szekely, G; Taylor, TJ; Thomas, OM; Tustison, NJ; Unal, G; Vasseur, F; Wintermark, M; Ye, DH; Zhao, L; Zhao, BS; Zikic, D; Prastawa, M; Reyes, M; Van Leemput, K",The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS),"In this paper we report the set-up and results of the Multimodal Brain Tumor Image Segmentation Benchmark (BRATS) organized in conjunction with the MICCAI 2012 and 2013 conferences. Twenty state-of-the-art tumor segmentation algorithms were applied to a set of 65 multi-contrast MR scans of low-and high-grade glioma patients-manually annotated by up to four raters-and to 65 comparable scans generated using tumor image simulation software. Quantitative evaluations revealed considerable disagreement between the human raters in segmenting various tumor sub-regions (Dice scores in the range 74%-85%), illustrating the difficulty of this task. We found that different algorithms worked best for different sub-regions (reaching performance comparable to human inter-rater variability), but that no single algorithm ranked in the top for all sub-regions simultaneously. Fusing several good algorithms using a hierarchical majority vote yielded segmentations that consistently ranked above all individual algorithms, indicating remaining opportunities for further methodological improvements. The BRATS image data and manual annotations continue to be publicly available through an online evaluation system as an ongoing benchmarking resource.",10.1109/TMI.2014.2377694,4,yes,no,no,no,yes,no,yes,no,yes,yes,yes,yes,yes,no,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes
J,"Weishaar, JL; Aiken, GR; Bergamaschi, BA; Fram, MS; Fujii, R; Mopper, K",Evaluation of specific ultraviolet absorbance as an indicator of the chemical composition and reactivity of dissolved organic carbon,"Specific UV absorbance (SUVA) is defined as the UV absorbance of a water sample at a given wavelength normalized for dissolved organic carbon (DOC) concentration. Our data indicate that SUVA, determined at 254 nm, is strongly correlated with percent aromaticity as determined by C-13 NMR for 13 organic matter isolates obtained from a variety of aquatic environments. SUVA, therefore, is shown to be a useful parameter for estimating the dissolved aromatic carbon content in aquatic systems. Experiments involving the reactivity of DOC with chlorine and tetramethylammoniurn hydroxide (TMAH), however, show a wide range of reactivity for samples with similar SUVA values. These results indicate that, while SUVA measurements are good predictors of general chemical characteristics of DOC, they do not provide information about reactivity of DOC derived from different types of source materials. Sample pH, nitrate, and iron were found to influence SUVA measurements.",10.1021/es030360x,5,yes,yes,no,no,yes,no,yes,no,yes,no,yes,yes,yes,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,no,no,yes,yes,no
J,"Zanella, A; Bui, N; Castellani, A; Vangelista, L; Zorzi, M",Internet of Things for Smart Cities,"The Internet of Things (IoT) shall be able to incorporate transparently and seamlessly a large number of different and heterogeneous end systems, while providing open access to selected subsets of data for the development of a plethora of digital services. Building a general architecture for the IoT is hence a very complex task, mainly because of the extremely large variety of devices, link layer technologies, and services that may be involved in such a system. In this paper, we focus specifically to an urban IoT system that, while still being quite a broad category, are characterized by their specific application domain. Urban IoTs, in fact, are designed to support the Smart City vision, which aims at exploiting the most advanced communication technologies to support added-value services for the administration of the city and for the citizens. This paper hence provides a comprehensive survey of the enabling technologies, protocols, and architecture for an urban IoT. Furthermore, the paper will present and discuss the technical solutions and best-practice guidelines adopted in the Padova Smart City project, a proof-of-concept deployment of an IoT island in the city of Padova, Italy, performed in collaboration with the city municipality.",10.1109/JIOT.2014.2306328,6,yes,yes,no,yes,yes,no,no,no,no,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,
J,"Gupta, HV; Kling, H; Yilmaz, KK; Martinez, GF",Decomposition of the mean squared error and NSE performance criteria: Implications for improving hydrological modelling,"The mean squared error (MSE) and the related normalization, the Nash-Sutcliffe efficiency (NSE), are the two criteria most widely used for calibration and evaluation of hydrological models with observed data. Here, we present a diagnostically interesting decomposition of NSE (and hence MSE), which facilitates analysis of the relative importance of its different components in the context of hydrological modelling, and show how model calibration problems can arise due to interactions among these components. The analysis is illustrated by calibrating a simple conceptual precipitation-runoff model to daily data for a number of Austrian basins having a broad range of hydro-meteorological characteristics. Evaluation of the results clearly demonstrates the problems that can be associated with any calibration based on the NSE (or MSE) criterion. While we propose and test an alternative criterion that can help to reduce model calibration problems, the primary purpose of this Study is not to present an improved measure of model performance. Instead, we seek to show that there are systematic problems inherent with any optimization based on formulations related to the MSE. The analysis and results have implications to the manner in which we calibrate and evaluate environmental models, we discuss these and suggest possible ways forward that may move us towards an improved and diagnostically meaningful approach to model performance evaluation and identification. (C) 2009 Elsevier B.V. All rights reserved.",10.1016/j.jhydrol.2009.08.003,7,yes,yes,no,no,yes,no,yes,no,yes,yes,yes,yes,yes,no,no,yes,yes,yes,no,yes,no,no,no,no,yes,yes,yes,yes,yes,yes,
J,"Qin, SJ; Badgwell, TA",A survey of industrial model predictive control technology,"This paper provides an overview of commercially available model predictive control (MPC) technology, both linear and nonlinear, based primarily on data provided by MPC vendors. A brief history of industrial MPC technology is presented first, followed by results of our vendor survey of MPC control and identification technology. A general MPC control algorithm is presented, and approaches taken by each vendor for the different aspects of the calculation are described. Identification technology is reviewed to determine similarities and differences between the various approaches. MPC applications performed by each vendor are summarized by application area. The final section presents a vision of the next generation of MPC technology, with an emphasis on potential business and research opportunities. (C) 2002 Elsevier Science Ltd. All rights reserved.",10.1016/S0967-0661(02)00186-7,8,yes,yes,no,yes,yes,no,yes,no,yes,no,yes,yes,yes,no,yes,no,yes,no,no,yes,no,no,no,no,yes,yes,no,yes,no,yes,
J,"Gu, JX; Wang, ZH; Kuen, J; Ma, LY; Shahroudy, A; Shuai, B; Liu, T; Wang, XX; Wang, G; Cai, JF; Chen, T",Recent advances in convolutional neural networks,"In the last few years, deep learning has led to very good performance on a variety of problems, such as visual recognition, speech recognition and natural language processing. Among different types of deep neural networks, convolutional neural networks have been most extensively studied. Leveraging on the rapid growth in the amount of the annotated data and the great improvements in the strengths of graphics processor units, the research on convolutional neural networks has been emerged swiftly and achieved state-of-the-art results on various tasks. In this paper, we provide a broad survey of the recent advances in convolutional neural networks. We detailize the improvements of CNN on different aspects, including layer design, activation function, loss function, regularization, optimization and fast computation. Besides, we also introduce various applications of convolutional neural networks in computer vision, speech and natural language processing. (C) 2017 Elsevier Ltd. All rights reserved.",10.1016/j.patcog.2017.10.013,9,yes,yes,no,yes,yes,no,no,no,yes,no,yes,yes,no,no,no,no,no,no,no,yes,no,no,no,no,no,no,no,no,yes,yes,yes
J,"Ji, SW; Xu, W; Yang, M; Yu, K",3D Convolutional Neural Networks for Human Action Recognition,"We consider the automated recognition of human actions in surveillance videos. Most current methods build classifiers based on complex handcrafted features computed from the raw inputs. Convolutional neural networks (CNNs) are a type of deep model that can act directly on the raw inputs. However, such models are currently limited to handling 2D inputs. In this paper, we develop a novel 3D CNN model for action recognition. This model extracts features from both the spatial and the temporal dimensions by performing 3D convolutions, thereby capturing the motion information encoded in multiple adjacent frames. The developed model generates multiple channels of information from the input frames, and the final feature representation combines information from all channels. To further boost the performance, we propose regularizing the outputs with high-level features and combining the predictions of a variety of different models. We apply the developed models to recognize human actions in the real-world environment of airport surveillance videos, and they achieve superior performance in comparison to baseline methods.",10.1109/TPAMI.2012.59,10,yes,no,yes,yes,yes,no,yes,yes,no,no,yes,yes,yes,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,no,yes,yes,yes,yes,
J,"Mirjalili, S; Gandomi, AH; Mirjalili, SZ; Saremi, S; Faris, H; Mirjalili, SM",Salp Swarm Algorithm: A bio-inspired optimizer for engineering design problems,This work proposes two novel optimization algorithms called Salp Swarm Algorithm (SSA) and Multiobjective Salp Swarm Algorithm (MSSA) for solving optimization problems with single and multiple objectives. The main inspiration of SSA and MSSA is the swarming behaviour of salps when navigating and foraging in oceans. These two algorithms are tested on several mathematical optimization functions to observe and confirm their effective behaviours in finding the optimal solutions for optimization problems. The results on the mathematical functions show that the SSA algorithm is able to improve the initial random solutions effectively and converge towards the optimum. The results of MSSA show that this algorithm can approximate Pareto optimal solutions with high convergence and coverage. The paper also considers solving several challenging and computationally expensive engineering design problems (e.g. airfoil design and marine propeller design) using SSA and MSSA. The results of the real case studies demonstrate the merits of the algorithms proposed in solving real-world problems with difficult and unknown search spaces. (C) 2017 Elsevier Ltd. All rights reserved.,10.1016/j.advengsoft.2017.07.002,11,yes,yes,no,no,yes,no,yes,yes,no,no,yes,no,yes,no,no,no,yes,yes,yes,no,no,no,yes,no,yes,yes,no,no,yes,yes,no
J,"Frigo, M; Johnson, SG",The design and implementation of FFTW3,"FFTW is an implementation of the discrete Fourier transform (LEFT) that adapts to the hardware in order to maximize performance. This paper shows that such an approach can yield an implementation that is competitive with hand-optimized libraries, and describes the software structure that makes our current FFTW3 version flexible and adaptive. We further discuss a new algorithm for real-data DFTs of prime size, a new way of implementing DFTs by means of machine-specific single-instruction, multiple-data (SIMD) instructions, and how a special-purpose compiler can derive optimized implementations of the discrete cosine and sine transforms automatically from a DFT algorithm.",10.1109/JPROC.2004.840301,12,yes,yes,no,no,yes,no,yes,yes,no,no,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,
J,"Phillips, PJ; Moon, H; Rizvi, SA; Rauss, PJ",The FERET evaluation methodology for face-recognition algorithms,"Two of the most critical requirements in support of producing reliable face-recognition systems are a large database of facial images and a testing procedure to evaluate systems. The Face Recognition Technology (FERET) program has addressed both issues through the FERET database of facial images and the establishment of the FERET tests. To date, 14,126 images from 1,199 individuals are included in the FERET database, which is divided into development and sequestered portions of the database. In September 1996, the FERET program administered the third in a series of FERET face-recognition tests. The primary objectives of the third test were to 1) assess the slate of the art, 2) identify future areas of research, and 3) measure algorithm performance.",10.1109/34.879790,13,yes,yes,no,yes,yes,no,yes,no,yes,no,yes,yes,yes,no,no,yes,no,no,no,yes,no,no,no,yes,no,no,no,no,yes,yes,no
J,"Esram, T; Chapman, PL",Comparison of photovoltaic array maximum power point tracking techniques,"The many different techniques for maximum power point tracking of photovoltaic (PV) arrays are discussed. The techniques are taken from the literature dating back to the earliest methods. It is shown that at least 19 distinct methods have been introduced in the literature, with many variations on implementation. This paper should serve as a convenient reference for future work in PV power generation.",10.1109/TEC.2006.874230,14,yes,yes,no,yes,yes,no,no,no,yes,no,no,yes,no,no,no,no,no,no,no,yes,no,no,no,no,yes,yes,no,yes,yes,no,yes
J,"Melgani, F; Bruzzone, L",Classification of hyperspectral remote sensing images with support vector machines,"This paper addresses the problem of the classification of hyperspectral remote sensing images by support vector machines (SVMs). First, we propose a theoretical discussion and experimental analysis aimed at understanding and assessing the potentialities of SVM classifiers in hyperdimensional feature spaces. Then, we assess the effectiveness of SVMs with respect to conventional feature-reduction-based approaches and their performances in hypersubspaces of various dimensionalities. To sustain such an analysis, the performances of SVMs are compared with those of two other nonparametric classifiers (i.e., radial basis function neural networks and the K-nearest neighbor classifier). Finally, we study the potentially critical issue of applying binary SVMs to multiclass problems in hyperspectral data. In particular, four different multiclass strategies are analyzed and compared: the one-against-all, the one:against-one, and two hierarchical tree-based strategies. Different performance indicators have been used to support our experimental studies in a detailed and accurate way, i.e., the classification accuracy, the computational time, the stability to parameter setting, and the complexity of the multiclass architecture. The results obtained on a real Airborne Visible/Infrared Imaging Spectroradiometer hyperspectral dataset allow to conclude that, whatever the multiclass strategy adopted, SVMs are a valid and effective alternative to conventional pattern recognition approaches (feature-reduction procedures combined with a classification method) for the classification of hyperspectral remote sensing data.",10.1109/TGRS.2004.831865,15,yes,yes,no,yes,yes,no,yes,no,yes,no,yes,yes,yes,no,no,yes,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,yes,yes,
J,"Prince, M",Does active learning work? A review of the research,"This study examines the evidence for the effectiveness of active learning. It defines the common forms of active learning most relevant for engineering faculty and critically examines the core element of each method. It is found that there is broad but uneven support for the core elements of active, collaborative, cooperative and problem-based learning.",10.1002/j.2168-9830.2004.tb00809.x,16,yes,yes,no,yes,yes,yes,yes,no,yes,no,yes,yes,no,no,no,no,yes,yes,no,yes,no,no,no,yes,yes,no,no,no,no,yes,no
J,"Wernet, G; Bauer, C; Steubing, B; Reinhard, J; Moreno-Ruiz, E; Weidema, B",The ecoinvent database version 3 (part I): overview and methodology,"Good background data are an important requirement in LCA. Practitioners generally make use of LCI databases for such data, and the ecoinvent database is the largest transparent unit-process LCI database worldwide. Since its first release in 2003, it has been continuously updated, and version 3 was published in 2013. The release of version 3 introduced several significant methodological and technological improvements, besides a large number of new and updated datasets. The aim was to expand the content of the database, set the foundation for a truly global database, support regionalized LCIA, offer multiple system models, allow for easier integration of data from different regions, and reduce maintenance efforts. This article describes the methodological developments. Modeling choices and raw data were separated in version 3, which enables the application of different sets of modeling choices, or system models, to the same raw data with little effort. This includes one system model for Consequential LCA. Flow properties were added to all exchanges in the database, giving more information on the inventory and allowing a fast calculation of mass and other balances. With version 3.1, the database is generally water-balanced, and water use and consumption can be determined. Consumption mixes called market datasets were consistently added to the database, and global background data was added, often as an extrapolation from regional data. In combination with hundreds of new unit processes from regions outside Europe, these changes lead to an improved modeling of global supply chains, and a more realistic distribution of impacts in regionalized LCIA. The new mixes also facilitate further regionalization due to the availability of background data for all regions. With version 3, the ecoinvent database substantially expands the goals and scopes of LCA studies it can support. The new system models allow new, different studies to be performed. Global supply chains and market datasets significantly increase the relevance of the database outside of Europe, and regionalized LCA is supported by the data. Datasets are more transparent, include more information, and support, e.g., water balances. The developments also support easier collaboration with other database initiatives, as demonstrated by a first successful collaboration with a data project in Qu,bec. Version 3 has set the foundation for expanding ecoinvent from a mostly regional into a truly global database and offers many new insights beyond the thousands of new and updated datasets it also introduced.",10.1007/s11367-016-1087-8,17,yes,no,yes,yes,yes,no,yes,no,yes,yes,yes,yes,yes,no,no,no,yes,yes,no,yes,no,no,no,yes,yes,yes,yes,yes,yes,yes,
J,"Kreutz, D; Ramos, FMV; VerÃ­ssimo, PE; Rothenberg, CE; Azodolmolky, S; Uhlig, S",Software-Defined Networking: A Comprehensive Survey,"The Internet has led to the creation of a digital society, where (almost) everything is connected and is accessible from anywhere. However, despite their widespread adoption, traditional IP networks are complex and very hard to manage. It is both difficult to configure the network according to predefined policies, and to reconfigure it to respond to faults, load, and changes. To make matters even more difficult, current networks are also vertically integrated: the control and data planes are bundled together. Software-defined networking (SDN) is an emerging paradigm that promises to change this state of affairs, by breaking vertical integration, separating the network's control logic from the underlying routers and switches, promoting (logical) centralization of network control, and introducing the ability to program the network. The separation of concerns, introduced between the definition of network policies, their implementation in switching hardware, and the forwarding of traffic, is key to the desired flexibility: by breaking the network control problem into tractable pieces, SDN makes it easier to create and introduce new abstractions in networking, simplifying network management and facilitating network evolution. In this paper, we present a comprehensive survey on SDN. We start by introducing the motivation for SDN, explain its main concepts and how it differs from traditional networking, its roots, and the standardization activities regarding this novel paradigm. Next, we present the key building blocks of an SDN infrastructure using a bottom-up, layered approach. We provide an in-depth analysis of the hardware infrastructure, southbound and northbound application programming interfaces (APIs), network virtualization layers, network operating systems (SDN controllers), network programming languages, and network applications. We also look at cross-layer problems such as debugging and troubleshooting. In an effort to anticipate the future evolution of this new paradigm, we discuss the main ongoing research efforts and challenges of SDN. In particular, we address the design of switches and control platforms-with a focus on aspects such as resiliency, scalability, performance, security, and dependability-as well as new opportunities for carrier transport networks and cloud providers. Last but not least, we analyze the position of SDN as a key enabler of a software-defined environment.",10.1109/JPROC.2014.2371999,18,yes,no,yes,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,yes,yes,yes,yes
J,"Comaniciu, D; Ramesh, V; Meer, P",Kernel-based object tracking,"A new approach toward target representation and localization, the central component in visual tracking of nonrigid objects, is proposed. The feature histogram-based target representations are regularized by spatial masking with an isotropic kernel. The masking induces spatially-smooth similarity functions suitable for gradient-based optimization, hence, the target localization problem can be formulated using the basin of attraction of the local maxima. We employ a metric derived from the Bhattacharyya coefficient as similarity measure, and use the mean shift procedure to perform the optimization. In the presented tracking examples, the new method successfully coped with camera motion, partial occlusions, clutter, and target scale variations. Integration with motion filters and data association techniques is also discussed. We describe only a few of the potential applications: exploitation of background information, Kalman tracking using motion models, and face tracking.",10.1109/TPAMI.2003.1195991,19,yes,yes,no,no,yes,yes,yes,yes,no,no,yes,no,no,no,no,no,yes,yes,yes,no,yes,no,no,yes,yes,yes,yes,no,yes,yes,yes
J,"Palomares, V; Serras, P; Villaluenga, I; Hueso, KB; Carretero-GonzÃ¡lez, J; Rojo, T","Na-ion batteries, recent advances and present challenges to become low cost energy storage systems","Energy production and storage have become key issues concerning our welfare in daily life. Present challenges for batteries are twofold. In the first place, the increasing demand for powering systems of portable electronic devices and zero-emission vehicles stimulates research towards high energy and high voltage systems. In the second place, low cost batteries are required in order to advance towards smart electric grids that integrate discontinuous energy flow from renewable sources, optimizing the performance of clean energy sources. Na-ion batteries can be the key for the second point, because of the huge availability of sodium, its low price and the similarity of both Li and Na insertion chemistries. In spite of the lower energy density and voltage of Na-ion based technologies, they can be focused on applications where the weight and footprint requirement is less drastic, such as electrical grid storage. Much work has to be done in the field of Na-ion in order to catch up with Li-ion technology. Cathodic and anodic materials must be optimized, and new electrolytes will be the key point for Na-ion success. This review will gather the up-to-date knowledge about Na-ion battery materials, with the aim of providing a wide view of the systems that have already been explored and a starting point for the new research on this battery technology.",10.1039/c2ee02781j,20,yes,no,no,yes,yes,no,no,yes,no,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,no,no,yes,no,no
J,"Boykov, Y; Kolmogorov, V",An experimental comparison of min-cut/max-flow algorithms for energy minimization in vision,"After [15], [31], [19], [8], [25], [5], minimum cut/maximum flow algorithms on graphs emerged as an increasingly useful tool for exact or approximate energy minimization in low-level vision. The combinatorial optimization literature provides many min-cut/max-flow algorithms with different polynomial time complexity. Their practical efficiency, however, has to date been studied mainly outside the scope of computer vision. The goal of this paper is to provide an experimental comparison of the efficiency of min-cut/maxflow algorithms for applications in vision. We compare the running times of several standard algorithms, as well as a new algorithm that we have recently developed. The algorithms we study include both Goldberg-Tarjan style ""push-relabel"" methods and algorithms based on Ford-Fulkerson style ""augmenting paths."" We benchmark these algorithms on a number of typical graphs in the contexts of image restoration, stereo, and segmentation. In many cases, our new algorithm works several times faster than any of the other methods, making near real-time performance possible. An implementation of our max-flow/min-cut algorithm is available upon request for research purposes.",10.1109/TPAMI.2004.60,21,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,yes,yes,no,no,yes,yes,yes,yes,no,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,yes
J,"Pan, SJ; Tsang, IW; Kwok, JT; Yang, QA",Domain Adaptation via Transfer Component Analysis,"Domain adaptation allows knowledge from a source domain to be transferred to a different but related target domain. Intuitively, discovering a good feature representation across domains is crucial. In this paper, we first propose to find such a representation through a new learning method, transfer component analysis (TCA), for domain adaptation. TCA tries to learn some transfer components across domains in a reproducing kernel Hilbert space using maximum mean miscrepancy. In the subspace spanned by these transfer components, data properties are preserved and data distributions in different domains are close to each other. As a result, with the new representations in this subspace, we can apply standard machine learning methods to train classifiers or regression models in the source domain for use in the target domain. Furthermore, in order to uncover the knowledge hidden in the relations between the data labels from the source and target domains, we extend TCA in a semisupervised learning setting, which encodes label information into transfer components learning. We call this extension semisupervised TCA. The main contribution of our work is that we propose a novel dimensionality reduction framework for reducing the distance between domains in a latent space for domain adaptation. We propose both unsupervised and semisupervised feature extraction approaches, which can dramatically reduce the distance between domain distributions by projecting data onto the learned transfer components. Finally, our approach can handle large datasets and naturally lead to out-of-sample generalization. The effectiveness and efficiency of our approach are verified by experiments on five toy datasets and two real-world applications: cross-domain indoor WiFi localization and cross-domain text classification.",10.1109/TNN.2010.2091281,22,yes,no,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,no,yes,no,yes,no,no,no,no,no,no,yes,yes,yes,yes,yes,yes
J,"Egbert, GD; Erofeeva, SY",Efficient inverse Modeling of barotropic ocean tides,"A computationally efficient relocatable system for generalized inverse (GI) modeling of barotropic ocean tides is described. The GI penalty functional is minimized using a representer method, which requires repeated solution of the forward and adjoint linearized shallow water equations (SWEs). To make representer computations efficient, the SWEs are solved in the frequency domain by factoring the coefficient matrix for a finite-difference discretization of the second-order wave equation in elevation. Once this matrix is factored representers can be calculated rapidly. By retaining the first-order SWE system (defined in terms of both elevations and currents) in the definition of the discretized GI penalty functional, complete generality in the choice of dynamical error covariances is retained. This allows rational assumptions about errors in the SWE, with soft momentum balance constraints (e. g., to account for inaccurate parameterization of dissipation), but holds mass conservation constraints. While the dynamical calculations involve elevations alone, depth-averaged currents can be directly assimilated into the tidal model with this approach. The efficient representer calculation forms the basis for the Oregon State University (OSU) Tidal Inversion Software (OTIS). OTIS includes software for generating grids, prior model covariances, and boundary conditions; for time stepping the nonlinear shallow water equations to generate a first guess or prior solution; for preliminary processing of TOPEX/Poseidon altimeter data; for solution of the GI problem; and for computation of posterior error bars. Approximate GI solution methods, based on using a reduced set of representers, allow very large datasets to be inverted. OTIS regional and local GI tidal modeling (with grids containing up to 10(5) nodes) require only a few hours on a common desktop workstation. Use of OTIS is illustrated by developing a new regional-scale (1/68) model of tides in the Indonesian Seas.",10.1175/1520-0426(2002)019<0183:EIMOBO>2.0.CO;2,23,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,yes,yes,no,yes,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,yes,yes,no
J,"Vamvatsikos, D; Cornell, CA",Incremental dynamic analysis,"Incremental dynamic analysis (IDA) is a parametric analysis method that has recently emerged in several different forms to estimate more thoroughly structural performance under seismic loads. It involves subjecting a structural model to one (or more) ground motion record(s), each scaled to multiple levels of intensity, thus producing one (or more) curve(s) of response parameterized versus intensity level. To establish a common frame of reference, the fundamental concepts are analysed, a unified terminology is proposed. suitable algorithms are presented, and properties of the IDA curve are looked into for both single-degree-of-freedom and multi-degree-of-freedom structures. In addition, summarization techniques for multi-record IDA studies and the association of the IDA study with the conventional static pushover analysis and the yield reduction R-factor are discussed. Finally, in the framework of performance-based earthquake engineering, the assessment of demand and capacity is viewed through the lens of an IDA study. Copyright (C) 2001 John Wiley Sons, Ltd.",10.1002/eqe.141,24,yes,yes,no,yes,yes,no,yes,no,yes,no,yes,yes,no,no,no,no,yes,yes,no,yes,no,no,no,no,no,no,no,no,no,yes,yes
J,"Browne, MA; Crump, P; Niven, SJ; Teuten, E; Tonkin, A; Galloway, T; Thompson, R",Accumulation of Microplastic on Shorelines Woldwide: Sources and Sinks,"Plastic debris < 1 mm (defined here as microplastic) is accumulating in marine habitats. Ingestion of microplastic provides a potential pathway for the transfer of pollutants, monomers, and plastic-additives to organisms with uncertain consequences for their health. Here, we show that microplastic contaminates the shorelines at 18 sites worldwide representing six continents from the poles to the equator, with more material in densely populated areas, but no clear relationship between the abundance of miocroplastics and the mean size-distribution of natural particulates. An important source of microplastic appears to be through sewage contaminated by fibers from washing clothes. Forensic evaluation of microplastic from sediments showed that the proportions of polyester and acrylic fibers used in clothing resembled those found in habitats that receive sewage-discharges and sewage-effluent itself. Experiments sampling wastewater from domestic washing machines demonstrated that a single garment can produce > 1900 fibers per wash. This suggests that a large proportion of microplastic fibers found in the marine environment may be derived from sewage as a consequence of washing of clothes. As the human population grows and people use more synthetic textiles, contamination of habitats and animals by microplastic is likely to increase.",10.1021/es201811s,25,yes,no,yes,no,yes,no,yes,no,yes,no,yes,yes,yes,no,yes,no,yes,yes,yes,no,no,no,yes,yes,yes,yes,yes,no,yes,yes,yes
J,"Izhikevich, EM",Simple model of spiking neurons,"A model is presented that reproduces spiking and bursting behavior of known types of cortical neurons. The model combines the biologically plausibility of Hodgkin-Huxley-type dynamics and the computational efficiency of integrate-and-fire neurons. Using this model, one can simulate tens of thousands of spiking cortical neurons in real time (1 ms resolution) using a desktop PC.",10.1109/TNN.2003.820440,26,yes,yes,no,yes,yes,no,no,yes,no,no,yes,no,no,yes,no,yes,yes,yes,yes,no,no,no,no,yes,yes,no,no,no,no,yes,yes
J,"Delp, SL; Anderson, FC; Arnold, AS; Loan, P; Habib, A; John, CT; Guendelman, E; Thelen, DG",OpenSim: open-source software to create and analyze dynamic Simulations of movement,"Dynamic simulations of movement allow one to study neuromuscular coordination, analyze athletic performance, and estimate internal loading of the musculoskeletal system. Simulations can also be used to identify the sources of pathological movement and establish a scientific basis for treatment planning. We have developed a freely available, open-source software system (OpenSim) that lets users develop models of musculoskeletal structures and create dynamic simulations of a wide variety of movements. We are using this system to simulate the dynamics of individuals with pathological gait and to explore the biomechanical effects of treatments. OpenSim provides a platform on which the biomechanics community can build a library of simulations that can be exchanged, tested, analyzed, and improved through a multi-institutional collaboration. Developing software that enables a concerted effort from many investigators poses technical and sociological challenges. Meeting those challenges will accelerate the discovery of principles that govern movement control and improve treatments for individuals with movement pathologies.",10.1109/TBME.2007.901024,27,yes,no,yes,no,yes,no,yes,no,yes,yes,yes,yes,no,yes,no,no,no,no,no,yes,no,no,no,no,no,yes,no,no,yes,yes,yes
J,"Celik, IB; Ghia, U; Roache, PJ; Freitas, CJ",Procedure for estimation and reporting of uncertainty due to discretization in CFD applications,"Since 1990, the Fluids Engineering Division of ASME has pursued activities concerning the detection, estimation and control of numerical uncertainty and/or error in computational fluid dynamics (CFD) studies. The first quality-control measures in this area were issued in 1986 (1986, ""Editorial Policy Statement on Control of Numerical Accuracy,"" ASME J. Fluids Eng., 108, p. 2) and revised in 1993 (1993, ""Journal of Fluids Engineering Editorial Policy Statement on the Control of Numerical Accuracy,"" ASME J. Fluids Eng., 115, pp. 339-340). Given the continued increase in CFD related publications, and the many significant advancements in computational techniques and computer technology, it has become necessary to revisit the issue and formulate a more detailed policy to further improve the quality of publications in this area. This brief note provides specific guidelines for prospective authors for calculation and reporting of discretization error estimates in CFD simulations where experimental data may or may not be available for comparison. The underlying perspective is that CFD-related studies will eventually aim to predict the outcome of a physical event for which experimental data is not available. It should be emphasized that the requirements outlined in this note do not preclude those already published in the previous two policy statements. It is also important to keep in mind that the procedure recommended in this note cannot possibly encompass all possible scenarios or applications.",10.1115/1.2960953,28,yes,yes,no,yes,yes,no,yes,yes,no,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,no,no,yes,yes
J,"Chandrashekar, G; Sahin, F",A survey on feature selection methods,"Plenty of feature selection methods are available in literature due to the availability of data with hundreds of variables leading to data with very high dimension. Feature selection methods provides us a way of reducing computation time, improving prediction performance, and a better understanding of the data in machine learning or pattern recognition applications. In this paper we provide an overview of some of the methods present in literature. The objective is to provide a generic introduction to variable elimination which can be applied to a wide array of machine learning problems. We focus on Filter, Wrapper and Embedded methods. We also apply some of the feature selection techniques on standard datasets to demonstrate the applicability of feature selection techniques. (C) 2013 Elsevier Ltd. All rights reserved.",10.1016/j.compeleceng.2013.11.024,29,yes,no,yes,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes
J,"Klein, S; Staring, M; Murphy, K; Viergever, MA; Pluim, JPW",elastix: A Toolbox for Intensity-Based Medical Image Registration,"Medical image registration is an important task in medical image processing. It refers to the process of aligning data sets, possibly from different modalities (e. g., magnetic resonance and computed tomography), different time points (e. g., follow-up scans), and/or different subjects (in case of population studies). A large number of methods for image registration are described in the literature. Unfortunately, there is not one method that works for all applications. We have therefore developed elastix, a publicly available computer program for intensity-based medical image registration. The software consists of a collection of algorithms that are commonly used to solve medical image registration problems. The modular design of elastix allows the user to quickly configure, test, and compare different registration methods for a specific application. The command-line interface enables automated processing of large numbers of data sets, by means of scripting. The usage of elastix for comparing different registration methods is illustrated with three example experiments, in which individual components of the registration method are varied.",10.1109/TMI.2009.2035616,30,yes,no,no,yes,yes,no,yes,no,yes,no,yes,yes,no,no,no,no,yes,no,no,yes,no,no,no,no,no,yes,no,no,yes,yes,yes
J,"Zhang, QQ; Ying, GG; Pan, CG; Liu, YS; Zhao, JL","Comprehensive Evaluation of Antibiotics Emission and Fate in the River Basins of China: Source Analysis, Multimedia Modeling, and Linkage to Bacterial Resistance","Antibiotics are widely used in humans and animals, but there is a big concern about their negative impacts on ecosystem and human health after use. So far there is a lack of information on emission inventory and environmental fate of antibiotics in China. We studied national consumption, emissions, and multimedia fate of 36 frequently detected antibiotics in China by market survey, data analysis, and level III fugacity modeling tools. Based on our survey, the total usage for the 36 chemicals was 92700 tons in 2013, an estimated 54000 tons of the antibiotics was excreted by human and animals, and eventually 53800 tons of them entered into the receiving environment following various wastewater treatments. The fugacity model successfully predicted environmental concentrations (PECs) in all 58 river basins of China, which are comparable to the reported measured environmental concentrations (MECs) available in some basins. The bacterial resistance rates in the hospitals and aquatic environments were found to be related to the PECs and antibiotic usages, especially for those antibiotics used in the most recent period. This is the first comprehensive study which demonstrates an alarming usage and emission of various antibiotics in China.",10.1021/acs.est.5b00729,31,yes,no,yes,no,yes,no,yes,no,yes,yes,yes,yes,yes,no,yes,no,yes,yes,no,yes,yes,yes,no,yes,yes,yes,no,no,yes,yes,yes
J,"Polyakov, A",Nonlinear Feedback Design for Fixed-Time Stabilization of Linear Control Systems,Two types of nonlinear control algorithms are presented for uncertain linear plants. Controllers of the first type are stabilizing polynomial feedbacks that allow to adjust a guaranteed convergence time of system trajectories into a prespecified neighborhood of the origin independently on initial conditions. The control design procedure uses block control principles and finite-time attractivity properties of polynomial feedbacks. Controllers of the second type are modifications of the second order sliding mode control algorithms. They provide global finite-time stability of the closed-loop system and allow to adjust a guaranteed settling time independently on initial conditions. Control algorithms are presented for both single-input and multi-input systems. Theoretical results are supported by numerical simulations.,10.1109/TAC.2011.2179869,32,yes,yes,no,no,yes,yes,yes,yes,no,no,yes,no,no,no,no,no,yes,no,yes,no,no,no,no,no,no,yes,yes,no,no,no,yes
J,"Bruneau, M; Chang, SE; Eguchi, RT; Lee, GC; O'Rourke, TD; Reinhorn, AM; Shinozuka, M; Tierney, K; Wallace, WA; von Winterfeldt, D",A framework to quantitatively assess and enhance the seismic resilience of communities,"This paper presents a conceptual framework to define seismic resilience of communities and quantitative measures of resilience that can be useful for a coordinated research effort focusing on enhancing this resilience. This framework relies on the complementary measures of resilience: ""Reduced failure probabilities,"" ""Reduced consequences from failures,"" and ""Reduced time to recovery."" The framework also includes quantitative measures of the ""ends"" of robustness and rapidity, and the ""means"" of resourcefulness and redundancy, and integrates those measures into the four dimensions of community resilience-technical, organizational, social, and economic-all of which can be used to quantify measures of resilience for various types of physical and organizational systems. Systems diagrams then establish the tasks required to achieve these objectives. This framework can be useful in future research to determine the resiliency of different units of analysis and systems, and to develop resiliency targets and detailed analytical procedures to generate these values.",10.1193/1.1623497,33,yes,yes,no,no,yes,yes,yes,no,no,no,yes,no,no,no,no,yes,no,no,no,no,no,no,no,no,yes,no,no,yes,no,no,yes
J,"Reynolds, DA; Quatieri, TF; Dunn, RB",Speaker verification using adapted Gaussian mixture models,"In this paper we describe the major elements of MIT Lincoln Laboratory's Gaussian mixture model (GMM)-based speaker verification system used successfully in several NIST Speaker Recognition Evaluations (SREs). The system is built around the likelihood ratio test for verification, using simple but effective GMMs for likelihood functions, a universal background model (UBM) for alternative speaker representation, and a form of Bayesian adaptation to derive speaker models from the UBM. The development and use of a handset detector and score normalization to greatly improve verification performance is also described and discussed. Finally representative performance benchmarks and system behavior experiments on NIST SRE corpora are presented. (C) 2000 Academic Press.",10.1006/dspr.1999.0361,34,yes,yes,no,no,yes,yes,yes,no,yes,no,yes,yes,yes,no,no,no,yes,no,no,yes,no,no,no,yes,no,yes,no,no,yes,yes,yes
J,"Laneman, JN; Wornell, GW",Distributed space-time-coded protocols for exploiting cooperative diversity in wireless networks,"We develop and analyze space-time coded cooperative diversity protocols for combating multipath fading across multiple protocol layers in a wireless network. The protocols exploit spatial diversity available among a collection of distributed terminals that relay messages for one another in such a manner that the destination terminal can average the fading, even though it is unknown a priori which terminals will be involved. In particular, a source initiates transmission to its destination, and many relays potentially receive the transmission. Those terminals that can fully decode the transmission utilize a space-time code to cooperatively relay to the destination. We demonstrate that these protocols achieve full spatial diversity in the number of cooperating terminals, not just the number of decoding relays, and can be used effectively for higher spectral efficiencies than repetition-based schemes. We discuss issues related to space-time code design for these protocols, emphasizing codes that readily allow for appealing distributed versions.",10.1109/TIT.2003.817829,35,yes,yes,no,no,yes,yes,yes,yes,no,no,yes,yes,no,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,no,yes,yes,yes
J,"Xu, LD; He, W; Li, SC",Internet of Things in Industries: A Survey,"Internet of Things (IoT) has provided a promising opportunity to build powerful industrial systems and applications by leveraging the growing ubiquity of radio-frequency identification (RFID), and wireless, mobile, and sensor devices. A wide range of industrial IoT applications have been developed and deployed in recent years. In an effort to understand the development of IoT in industries, this paper reviews the current research of IoT, key enabling technologies, major IoT applications in industries, and identifies research trends and challenges. A main contribution of this review paper is that it summarizes the current state-of-the-art IoT in industries systematically.",10.1109/TII.2014.2300753,36,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,no,yes,yes,yes
J,"Kouro, S; Malinowski, M; Gopakumar, K; Pou, J; Franquelo, LG; Wu, B; Rodriguez, J; PÃ©rez, MA; Leon, JI",Recent Advances and Industrial Applications of Multilevel Converters,"Multilevel converters have been under research and development for more than three decades and have found successful industrial application. However, this is still a technology under development, and many new contributions and new commercial topologies have been reported in the last few years. The aim of this paper is to group and review these recent contributions, in order to establish the current state of the art and trends of the technology, to provide readers with a comprehensive and insightful review of where multilevel converter technology stands and is heading. This paper first presents a brief overview of well-established multilevel converters strongly oriented to their current state in industrial applications to then center the discussion on the new converters that have made their way into the industry. In addition, new promising topologies are discussed. Recent advances made in modulation and control of multilevel converters are also addressed. A great part of this paper is devoted to show nontraditional applications powered by multilevel converters and how multilevel converters are becoming an enabling technology in many industrial sectors. Finally, some future trends and challenges in the further development of this technology are discussed to motivate future contributions that address open problems and explore new possibilities.",10.1109/TIE.2010.2049719,37,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,no,yes,no,yes
J,"Shelhamer, E; Long, J; Darrell, T",Fully Convolutional Networks for Semantic Segmentation,"Convolutional networks are powerful visual models that yield hierarchies of features. We show that convolutional networks by themselves, trained end-to-end, pixels-to-pixels, improve on the previous best result in semantic segmentation. Our key insight is to build ""fully convolutional"" networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning. We define and detail the space of fully convolutional networks, explain their application to spatially dense prediction tasks, and draw connections to prior models. We adapt contemporary classification networks (AlexNet, the VGG net, and GoogLeNet) into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task. We then define a skip architecture that combines semantic information from a deep, coarse layer with appearance information from a shallow, fine layer to produce accurate and detailed segmentations. Our fully convolutional networks achieve improved segmentation of PASCAL VOC (30% relative improvement to 67.2% mean IU on 2012), NYUDv2, SIFT Flow, and PASCAL-Context, while inference takes one tenth of a second for a typical image.",10.1109/TPAMI.2016.2572683,38,yes,yes,no,yes,yes,no,yes,no,yes,no,yes,yes,yes,no,no,yes,yes,yes,no,yes,no,no,yes,yes,yes,no,yes,no,yes,yes,yes
J,"Arikan, E",Channel Polarization: A Method for Constructing Capacity-Achieving Codes for Symmetric Binary-Input Memoryless Channels,"A method is proposed, called channel polarization, to construct code sequences that achieve the symmetric capacity I(W) of any given binary-input discrete memoryless channel (B-DMC) W. The symmetric capacity is the highest rate achievable subject to using the input letters of the channel with equal probability. Channel polarization refers to the fact that it is possible to synthesize, out of N independent copies of a given B-DMC W, a second set of N binary-input channels {W(N)((i)) : 1 <= i <= N} such that, as N becomes large, the fraction of indices i for which I(W(N)((i))) is near 1 approaches I(W) and the fraction for which I(W(N)((i))) is near 0 approaches 1 - I(W). The polarized channels {W(N)((i))} are well-conditioned for channel coding: one need only send data at rate 1 through those with capacity near 1 and at rate 0 through the remaining. Codes constructed on the basis of this idea are called polar codes. The paper proves that, given any B-DMC W with I(W) > 0 and any target rate R < I(W), there exists a sequence of polar codes {C(n); n >= 1} such that (C(n) has block-length N = 2(n), rate >= R, and probability of block error under successive cancellation decoding bounded as P(e) (N, R) <= O (N(-1/4)) independently of the code rate. This performance is achievable by encoders and decoders with complexity O(N log N) for each.",10.1109/TIT.2009.2021379,39,yes,no,no,no,yes,yes,yes,no,no,no,yes,no,no,no,no,yes,yes,yes,yes,no,no,no,yes,yes,yes,yes,yes,no,yes,yes,yes
J,"HirschmÃ¼ller, H",Stereo processing by Semiglobal Matching and Mutual Information,"This paper describes the Semiglobal Matching ( SGM) stereo method. It uses a pixelwise, Mutual Information (MI)-based matching cost for compensating radiometric differences of input images. Pixelwise matching is supported by a smoothness constraint that is usually expressed as a global cost function. SGM performs a fast approximation by pathwise optimizations from all directions. The discussion also addresses occlusion detection, subpixel refinement, and multibaseline matching. Additionally, postprocessing steps for removing outliers, recovering from specific problems of structured environments, and the interpolation of gaps are presented. Finally, strategies for processing almost arbitrarily large images and fusion of disparity images using orthographic projection are proposed. A comparison on standard stereo images shows that SGM is among the currently top-ranked algorithms and is best, if subpixel accuracy is considered. The complexity is linear to the number of pixels and disparity range, which results in a runtime of just 1-2 seconds on typical test images. An in depth evaluation of the MI-based matching cost demonstrates a tolerance against a wide range of radiometric transformations. Finally, examples of reconstructions from huge aerial frame and pushbroom images demonstrate that the presented ideas are working well on practical problems.",10.1109/TPAMI.2007.1166,40,yes,yes,no,no,no,no,no,no,no,no,yes,yes,yes,no,no,yes,yes,yes,yes,no,no,no,yes,yes,yes,yes,yes,no,yes,yes,no
J,"Hespanha, JP; Naghshtabrizi, P; Xu, YG",A survey of recent results in networked control systems,"Networked control systems (NCSs) are spatially distributed systems for which the communication between sensors, actuators, and controllers is supported by a shared communication network. We review several recent results on estimation, analysis, and controller synthesis for NCSs. The results surveyed address channel limitations in terms of packet-rates, sampling, network delay, and packet dropouts. The results are presented in a tutorial fashion, comparing alternative methodologies.",10.1109/JPROC.2006.887288,41,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,no
J,"Deb, K",An efficient constraint handling method for genetic algorithms,"Many real-world starch and optimization problems involve inequality and/or equality constraints and are thus posed as constrained optimization problems. In trying to solve constrained optimization problems using genetic algorithms (GAs) or classical optimization methods, penalty function methods have been the most popular approach, because of their simplicity and ease of implementation. However, since the penalty function approach is generic and applicable to any type of constraint (linear or nonlinear), their performance is not always satisfactory. Thus, researchers have developed sophisticated penalty functions specific to the problem at hand and the search algorithm used for optimization. However, the most difficult aspect of the penalty function approach is to find appropriate penalty parameters needed to guide the search towards the constrained optimum. In this paper, GA's population-based approach and ability to make pair-wise comparison in tournament selection operator are exploited to devise a penalty function approach that does not require any penalty parameter. Careful comparisons among feasible and infeasible solutions are made so as to provide a search direction towards the feasible region. Once sufficient feasible solutions are found, a niching method (along with a controlled mutation operator) is used to maintain diversity among feasible solutions. This allows a real-parameter GA's crossover operator to continuously find better feasible solutions, gradually leading the search near the true optimum solution. GAs with this constraint handling approach have been tested on nine problems commonly used in the literature, including an engineering design problem. In all cases, the proposed approach has been able to repeatedly find solutions closer to the true optimum solution than that reported earlier. (C) 2000 Elsevier Science S.A. All rights reserved.",10.1016/S0045-7825(99)00389-8,42,yes,no,yes,yes,yes,no,yes,no,yes,yes,yes,yes,yes,no,no,no,yes,yes,no,yes,no,no,no,no,yes,yes,yes,no,yes,yes,
J,"Zheng, LZ; Tse, DNC",Diversity and multiplexing: A fundamental tradeoff in multiple-antenna channels,"Multiple antennas can be used for increasing the amount of diversity or the number of degrees of freedom in wireless communication systems. In this paper, we propose the point of view that both types of gains can be simultaneously obtained for a given multiple-antenna channel, but there is a fundamental tradeoff between how much of each any coding scheme can get. For the richly scattered Rayleigh-fading channel, we give a simple characterization of the optimal tradeoff curve and use it to evaluate the performance of existing multiple antenna schemes.",10.1109/TIT.2003.810646,43,yes,yes,no,no,yes,no,yes,yes,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes
J,"Sheikh, HR; Bovik, AC",Image information and visual quality,"Measurement of visual quality is of fundamental importance to numerous image and video processing applications. The goal of quality assessment (QA) research is to design algorithms that can automatically assess the quality of images or videos in a perceptually consistent manner. Image QA algorithms generally interpret image quality as fidelity or similarity with a ""reference"" or ""perfect"" image in some perceptual space. Such ""full-reference"" QA methods attempt to achieve consistency in quality prediction by modeling salient physiological and psychovisual features of the human visual system (HVS), or by signal fidelity measures. In this paper, we approach the image QA problem as an information fidelity problem. Specifically, we propose to quantify the loss of image information to the distortion process and explore the relationship between image information and visual quality. QA systems are invariably involved with judging the visual quality of ""natural"" images and videos that are meant for ""human consumption."" Researchers have developed sophisticated models to capture the statistics of such natural signals. Using these models, we previously presented an information fidelity criterion for image QA that related image quality with the amount of information shared between a reference and a distorted image. In this paper, we propose an image information measure that quantifies the information that is present in the reference image and how much of this reference information can be extracted from the distorted image. Combining these two quantities, we propose a visual information fidelity measure for image QA. We validate the performance of our algorithm with an extensive subjective study involving 779 images and show that our method outperforms recent state-of-the-art image QA algorithms by a sizeable margin in our simulations. The code and the data from the subjective study are available at the LIVE website.",10.1109/TIP.2005.859378,44,yes,no,yes,yes,yes,no,yes,yes,no,no,yes,no,yes,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,no,yes,yes,
J,"Ricker, GR; Winn, JN; Vanderspek, R; Latham, DW; Bakos, GA; Bean, JL; Berta-Thompson, ZK; Brown, TM; Buchhave, L; Butler, NR; Butler, RP; Chaplin, WJ; Charbonneau, D; Christensen-Dalsgaard, J; Clampin, M; Deming, D; Doty, J; De Lee, N; Dressing, C; Dunham, EW; Endl, M; Fressin, F; Ge, J; Henning, T; Holman, MJ; Howard, AW; Ida, S; Jenkins, JM; Jernigan, G; Johnson, JA; Kaltenegger, L; Kawai, N; Kjeldsen, H; Laughlin, G; Levine, AM; Lin, D; Lissauer, JJ; MacQueen, P; Marcy, G; McCullough, PR; Morton, TD; Narita, N; Paegert, M; Palle, E; Pepe, F; Pepper, J; Quirrenbach, A; Rinehart, SA; Sasselov, D; Sato, B; Seager, S; Sozzetti, A; Stassun, KG; Sullivan, P; Szentgyorgyi, A; Torres, G; Udry, S; Villasenor, J",Transiting Exoplanet Survey Satellite,"The Transiting Exoplanet Survey Satellite (TESS) will search for planets transiting bright and nearby stars. TESS has been selected by NASA for launch in 2017 as an Astrophysics Explorer mission. The spacecraft will be placed into a highly elliptical 13.7-day orbit around the Earth. During its 2-year mission, TESS will employ four wide-field optical charge-coupled device cameras to monitor at least 200,000 main-sequence dwarf stars with I-C approximate to 4-13 for temporary drops in brightness caused by planetary transits. Each star will be observed for an interval ranging from 1 month to 1 year, depending mainly on the star's ecliptic latitude. The longest observing intervals will be for stars near the ecliptic poles, which are the optimal locations for follow-up observations with the James Webb Space Telescope. Brightness measurements of preselected target stars will be recorded every 2 min, and full frame images will be recorded every 30 min. TESS stars will be 10 to 100 times brighter than those surveyed by the pioneering Kepler mission. This will make TESS planets easier to characterize with follow-up observations. TESS is expected to find more than a thousand planets smaller than Neptune, including dozens that are comparable in size to the Earth. Public data releases will occur every 4 months, inviting immediate community-wide efforts to study the new planets. The TESS legacy will be a catalog of the nearest and brightest stars hosting transiting planets, which will endure as highly favorable targets for detailed investigations. (C) The Authors. Published by SPIE under a Creative Commons Attribution 3.0 Unported License. Distribution or reproduction of this work in whole or in part requires full attribution of the original publication, including its DOI.",10.1117/1.JATIS.1.1.014003,45,yes,no,no,yes,yes,yes,yes,no,no,yes,yes,no,yes,yes,yes,no,yes,yes,no,no,no,no,yes,yes,yes,yes,no,yes,yes,yes,yes
J,"He, KM; Zhang, XY; Ren, SQ; Sun, J",Spatial Pyramid Pooling in Deep Convolutional Networks for Visual Recognition,"Existing deep convolutional neural networks (CNNs) require a fixed-size (e.g., 224x224) input image. This requirement is ""artificial"" and may reduce the recognition accuracy for the images or sub-images of an arbitrary size/scale. In this work, we equip the networks with another pooling strategy, ""spatial pyramid pooling"", to eliminate the above requirement. The new network structure, called SPP-net, can generate a fixed-length representation regardless of image size/scale. Pyramid pooling is also robust to object deformations. With these advantages, SPP-net should in general improve all CNN-based image classification methods. On the ImageNet 2012 dataset, we demonstrate that SPP-net boosts the accuracy of a variety of CNN architectures despite their different designs. On the Pascal VOC 2007 and Caltech101 datasets, SPP-net achieves state-of-the-art classification results using a single full-image representation and no fine-tuning. The power of SPP-net is also significant in object detection. Using SPP-net, we compute the feature maps from the entire image only once, and then pool features in arbitrary regions (sub-images) to generate fixed-length representations for training the detectors. This method avoids repeatedly computing the convolutional features. In processing test images, our method is 24-102x faster than the R-CNN method, while achieving better or comparable accuracy on Pascal VOC 2007. In ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2014, our methods rank #2 in object detection and #3 in image classification among all 38 teams. This manuscript also introduces the improvement made for this competition.",10.1109/TPAMI.2015.2389824,46,yes,no,yes,no,yes,no,yes,yes,no,no,yes,yes,yes,no,no,yes,yes,yes,yes,no,no,no,yes,yes,yes,yes,yes,yes,yes,yes,yes
J,"Villalva, MG; Gazoli, JR; Ruppert, E",Comprehensive Approach to Modeling and Simulation of Photovoltaic Arrays,"This paper proposes a method of modeling and simulation of photovoltaic arrays. The main objective is to find the parameters of the nonlinear I-V equation by adjusting the curve at three points: open circuit, maximum power, and short circuit. Given these three points, which are provided by all commercial array datasheets, the method finds the best I-V equation for the single-diode photovoltaic (PV) model including the effect of the series and parallel resistances, and warranties that the maximum power of the model matches with the maximum power of the real array. With the parameters of the adjusted I-V equation, one can build a PV circuit model with any circuit simulator by using basic math blocks. The modeling method and the proposed circuit model are useful for power electronics designers who need a simple, fast, accurate, and easy-to-use modeling method for using in simulations of PV systems. In the first pages, the reader will find a tutorial on PV devices and will understand the parameters that compose the single-diode PV model. The modeling method is then introduced and presented in details. The model is validated with experimental data of commercial PV arrays.",10.1109/TPEL.2009.2013862,47,yes,yes,no,no,yes,no,yes,no,yes,no,yes,no,yes,no,no,yes,yes,no,no,yes,no,no,no,yes,yes,yes,yes,no,no,yes,yes
J,"Dehak, N; Kenny, PJ; Dehak, R; Dumouchel, P; Ouellet, P",Front-End Factor Analysis for Speaker Verification,"This paper presents an extension of our previous work which proposes a new speaker representation for speaker verification. In this modeling, a new low-dimensional speaker-and channel-dependent space is defined using a simple factor analysis. This space is named the total variability space because it models both speaker and channel variabilities. Two speaker verification systems are proposed which use this new representation. The first system is a support vector machine-based system that uses the cosine kernel to estimate the similarity between the input data. The second system directly uses the cosine similarity as the final decision score. We tested three channel compensation techniques in the total variability space, which are within-class covariance normalization (WCCN), linear discriminate analysis (LDA), and nuisance attribute projection (NAP). We found that the best results are obtained when LDA is followed by WCCN. We achieved an equal error rate (EER) of 1.12% and MinDCF of 0.0094 using the cosine distance scoring on the male English trials of the core condition of the NIST 2008 Speaker Recognition Evaluation dataset. We also obtained 4% absolute EER improvement for both-gender trials on the 10 s-10 s condition compared to the classical joint factor analysis scoring.",10.1109/TASL.2010.2064307,48,yes,yes,no,yes,yes,no,yes,no,yes,no,yes,yes,yes,no,no,yes,yes,yes,no,yes,no,no,yes,yes,yes,no,yes,no,no,yes,yes
J,"Gross, J; Sadowski, G",Perturbed-chain SAFT: An equation of state based on a perturbation theory for chain molecules,"A modified SAFT equation of state is developed by applying the perturbation theory of Barker and Henderson to a hard-chain reference fluid. With conventional one-fluid mixing rules, the equation of state is applicable to mixtures of small spherical molecules such as gases, nonspherical solvents, and chainlike polymers. The three pure-component parameters required for nonassociating molecules were identified for 78 substances by correlating vapor pressures and Liquid volumes. The equation of state gives good fits to these properties and agrees well with caloric properties. When applied to vapor-liquid equilibria of mixtures, the equation of state shows substantial predictive capabilities and good precision for correlating mixtures. Comparisons to the SAFT version of Huang and Radosz reveal a clear improvement of the proposed model. A brief comparison with the Peng-Robinson model is also given for vapor-liquid equilibria of binary systems, confirming the good performance of the suggested equation of state. The applicability of the proposed model to polymer systems was demonstrated for high-pressure liquid-liquid equilibria of a polyethylene mixture. The pure-component parameters of polyethylene were obtained by extrapolating pure-component parameters of the n-alkane series to high molecular weights.",10.1021/ie0003887,49,yes,yes,no,yes,yes,no,yes,no,yes,no,yes,yes,yes,no,yes,yes,yes,yes,yes,no,no,no,yes,yes,yes,yes,no,yes,no,yes,yes
J,"Peterson, AA; Abild-Pedersen, F; Studt, F; Rossmeisl, J; Norskov, JK",How copper catalyzes the electroreduction of carbon dioxide into hydrocarbon fuels,"Density functional theory calculations explain copper's unique ability to convert CO2 into hydrocarbons, which may open up (photo-)electrochemical routes to fuels.",10.1039/c0ee00071j,50,yes,yes,no,no,no,no,no,no,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,no,no,yes,no,yes,yes
J,"Carrasco, JM; Franquelo, LG; Bialasiewicz, JT; GalvÃ¡n, E; Portillo, R; Prats, MM; LeÃ³n, JI; Moreno-Alfonso, N",Power-electronic systems for the grid integration of renewable energy sources:: A survey,"The use of distributed energy resources is increasingly being pursued as a supplement and an alternative to large conventional central power stations. The specification of a power-electronic interface is subject to requirements related not only to the renewable energy source itself but also to its effects on the power-system operation, especially where the intermittent energy source constitutes a significant part of the total system capacity. In this paper, new trends in power electronics for the integration of wind and photovoltaic (PV) power generators are presented. A review of the appropriate storage-system technology used for the integration of intermittent renewable energy sources is also introduced. Discussions about common and future trends in renewable energy systems based on reliability and maturity of each technology are presented.",10.1109/TIE.2006.878356,51,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,no
J,"Liu, GC; Lin, ZC; Yan, SC; Sun, J; Yu, Y; Ma, Y",Robust Recovery of Subspace Structures by Low-Rank Representation,"In this paper, we address the subspace clustering problem. Given a set of data samples (vectors) approximately drawn from a union of multiple subspaces, our goal is to cluster the samples into their respective subspaces and remove possible outliers as well. To this end, we propose a novel objective function named Low-Rank Representation (LRR), which seeks the lowest rank representation among all the candidates that can represent the data samples as linear combinations of the bases in a given dictionary. It is shown that the convex program associated with LRR solves the subspace clustering problem in the following sense: When the data is clean, we prove that LRR exactly recovers the true subspace structures; when the data are contaminated by outliers, we prove that under certain conditions LRR can exactly recover the row space of the original data and detect the outlier as well; for data corrupted by arbitrary sparse errors, LRR can also approximately recover the row space with theoretical guarantees. Since the subspace membership is provably determined by the row space, these further imply that LRR can perform robust subspace clustering and error correction in an efficient and effective way.",10.1109/TPAMI.2012.88,52,yes,yes,no,no,yes,no,yes,yes,no,no,yes,no,yes,no,no,no,yes,yes,yes,no,no,no,no,no,no,yes,yes,no,no,yes,yes
J,"Altman, GH; Diaz, F; Jakuba, C; Calabro, T; Horan, RL; Chen, JS; Lu, H; Richmond, J; Kaplan, DL",Silk-based biomaterials,"Silk from the silkworm, Bombyx mori, has been used as biomedical suture material for centuries. The unique mechanical properties of these fibers provided important clinical repair options for many applications. During the past 20 years, some biocompatibility problems have been reported for silkworm silk; however, contamination from residual sericin (glue-like proteins) was the likely cause. More recent studies with well-defined silkworm silk fibers and films suggest that the core silk fibroin fibers exhibit comparable biocompatibility in vitro and in vivo with other commonly used biomaterials such as polylactic acid and collagen. Furthermore, the unique mechanical properties of the silk fibers, the diversity of side chain chemistries for 'decoration' with growth and adhesion factors, and the ability to genetically tailor the protein provide additional rationale for the exploration of this family of fibrous proteins for biomaterial applications. For example, in designing scaffolds for tissue engineering these properties are particularly relevant and recent results with bone and ligament formation in vitro support the potential role for this biomaterial in future applications. To date, studies with silks to address biomaterial and matrix scaffold needs have focused on silkworm silk. With the diversity of silk-like fibrous proteins from spiders and insects, a range of native or bioengineered variants can be expected for application to a diverse set of clinical needs. (C) 2002 Elsevier Science Ltd. All rights reserved.",10.1016/S0142-9612(02)00353-8,53,yes,no,no,yes,no,no,no,no,yes,no,yes,yes,no,no,no,no,no,no,no,yes,no,no,no,no,yes,no,no,yes,no,yes,yes
J,"Wu, G; van der Helm, FCT; Veeger, HEJ; Makhsous, M; Van Roy, P; Anglin, C; Nagels, J; Karduna, AR; McQuade, K; Wang, XG; Werner, FW; Buchholz, B","ISB recommendation on definitions of joint coordinate systems of various joints for the reporting of human joint motion - Part II: shoulder, elbow, wrist and hand","In this communication, the Standardization and Terminology Committee (STC) of the International Society of Biomechanics proposes a definition of a joint coordinate system (JCS) for the shoulder, elbow, wrist, and hand. For each joint, a standard for the local axis system in each articulating segment or bone is generated. These axes then standardize the JCS. The STC is publishing these recommendations so as to encourage their use, to stimulate feedback and discussion, and to facilitate further revisions. Adopting these standards will lead to better communication among researchers and clinicians. (c) 2004 Elsevier Ltd. All rights reserved.",10.1016/j.jbiomech.2004.05.042,54,yes,yes,no,no,yes,yes,yes,yes,no,yes,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,no,yes,yes,yes
J,"Shuman, DI; Narang, SK; Frossard, P; Ortega, A; Vandergheynst, P",The Emerging Field of Signal Processing on Graphs,,10.1109/MSP.2012.2235192,55,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
J,"Do, MN; Vetterli, M",The contourlet transform: An efficient directional multiresolution image representation,"The limitations of commonly used separable extensions of one-dimensional transforms, such as the Fourier and wavelet transforms, in capturing the geometry of image edges are well known. In this paper, we pursue a ""true"" two-dimensional transform that can capture the intrinsic geometrical structure that is key in visual information. The main challenge in exploring geometry in images comes from the discrete nature of the data. Thus, unlike other approaches, such as curvelets, that first develop a transform in the continuous domain and then discretize for sampled data, our approach starts with a discrete-domain construction and then studies its convergence to an expansion in the continuous domain. Specifically, we construct a discrete-domain multiresolution and multidirection expansion using nonseparable filter banks, in much the same way that wavelets were derived from filter banks. This construction results in a flexible multiresolution, local, and directional image expansion using contour segments, and, thus, it is named the contourlet transform. The discrete contourlet transform has a fast iterated filter bank algorithm that requires an order N operations for N-pixel images. Furthermore, we establish a precise link between the developed filter bank and the associated continuous-domain contourlet expansion via a directional multiresolution analysis framework. We show that with parabolic scaling and sufficient directional vanishing moments, contourlets achieve the optimal approximation rate for piecewise smooth functions with discontinuities along twice continuously differentiable curves. Finally, we show some numerical experiments demonstrating the potential of contourlets in several image processing applications.",10.1109/TIP.2005.859376,56,yes,no,no,yes,yes,no,yes,no,yes,yes,yes,yes,no,no,no,no,yes,no,yes,no,no,no,no,no,yes,no,yes,no,no,yes,yes
J,"Kreuer, KD",On the development of proton conducting polymer membranes for hydrogen and methanol fuel cells,"The transport properties and the swelling behaviour of NAFION and different sulfonated polyetherketones are explained in terms of distinct differences on the microstructures and in the pK(a) of the acidic functional groups. The less pronounced hydrophobic/hydrophilic separation of sulfonated polyetherketones compared to NAFION corresponds to narrower, less connected hydrophilic channels and to larger separations between less acidic sulfonic acid functional groups. At high water contents, this is shown to significantly reduce electroosmotic drag and water permeation whilst maintaining high proton conductivity. Blending of sulfonated polyetherketones with other polyaryls even further reduces the solvent permeation (a factor of 20 compared to NAFION), increases the membrane flexibility in the dry state and leads to an improved swelling behaviour. Therefore, polymers based on sulfonated polyetherketones are not only interesting low-cost alternative membrane material for hydrogen fuel cell applications, they may also help to reduce the problems associated with high water drag and high methanol cross-over in direct liquid methanol fuel cells (DMFC). The relatively high conductivities observed for oligomers containing imidazole as functional groups may be exploited in fully polymeric proton conducting systems with no volatile proton solvent operating at temperatures significantly beyond 100 degreesC, where methanol vapour may be used as a fuel in DMFCs. (C) 2001 Elsevier Science B.V. All rights reserved.",10.1016/S0376-7388(00)00632-3,57,yes,no,no,no,yes,no,yes,no,yes,no,yes,yes,no,no,no,yes,yes,yes,no,yes,no,no,yes,yes,yes,yes,yes,yes,yes,no,no
J,"Staal, J; AbrÃ moff, MD; Niemeijer, M; Viergever, MA; van Ginneken, B",Ridge-based vessel segmentation in color images of the retina,"A method is presented for automated segmentation of vessels in two-dimensional color images of the retina. This method can be used in computer analyses of retinal images, e.g., in automated screening for diabetic retinopathy. The system is based on extraction of image ridges, which coincide approximately with vessel centerlines. The ridges are used to compose primitives in the form of line elements. With the line elements an image is partitioned into patches by assigning each image pixel to the closest line element. Every line element constitutes a local coordinate frame for its corresponding patch. For every pixel, feature vectors are computed that make use of properties of the patches and the line elements. The feature vectors are classified using a kNN-classifier and sequential forward feature selection. The algorithm was tested on a database consisting of 40 manually labeled images. The method achieves an area under the receiver operating characteristic curve of 0.952. The method is compared with two recently published rule-based methods of Hoover et al. [1] and Jiang et al. [2]. The results show that our method is significantly better than the two rule-based methods (p < 0.01). The accuracy of our method is 0.944 versus 0.947 for a second observer.",10.1109/TMI.2004.825627,58,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,yes,yes,no,no,yes,yes,yes,yes,no,no,no,yes,yes,yes,no,yes,no,no,yes,yes
J,"Kalal, Z; Mikolajczyk, K; Matas, J",Tracking-Learning-Detection,"This paper investigates long-term tracking of unknown objects in a video stream. The object is defined by its location and extent in a single frame. In every frame that follows, the task is to determine the object's location and extent or indicate that the object is not present. We propose a novel tracking framework (TLD) that explicitly decomposes the long-term tracking task into tracking, learning, and detection. The tracker follows the object from frame to frame. The detector localizes all appearances that have been observed so far and corrects the tracker if necessary. The learning estimates the detector's errors and updates it to avoid these errors in the future. We study how to identify the detector's errors and learn from them. We develop a novel learning method (P-N learning) which estimates the errors by a pair of ""experts"": 1) P-expert estimates missed detections, and 2) N-expert estimates false alarms. The learning process is modeled as a discrete dynamical system and the conditions under which the learning guarantees improvement are found. We describe our real-time implementation of the TLD framework and the P-N learning. We carry out an extensive quantitative evaluation which shows a significant improvement over state-of-the-art approaches.",10.1109/TPAMI.2011.239,59,yes,no,no,no,yes,no,yes,yes,no,no,yes,no,no,no,no,no,yes,yes,yes,no,no,no,no,yes,no,no,no,yes,no,yes,yes
S,"Blin, F",The theory of affordances,"In the last decade, the term ""affordance"", coined by the ecological psychologist James Gibson (1986), has become a buzzword in CALL research. Often used to denote possibilities offered by technologies, the concept has been imported into CALL from cognate domains, such as human-computer Interaction (HCI). However, the CALL community has yet to engage in in-depth discussions on its meaning and usefulness for CALL research and design. The concept remains confusing, often misunderstood, and, at times, misused. This chapter provides an introduction to the concept of affordances, with a view to clarify its meaning and potential applications within CALL. Following a brief overview of Gibson's theory of affordance, it presents and discusses leading HCI interpretations and conceptualizations of affordance that are particularly relevant to CALL researchers and designers. More specifically, it explicates HCI cognitivist and post-cognitivist views of affordances before exploring their relation to CALL affordances and their possible place within a CALL research agenda focusing more particularly on learner-computer interactions.",10.1075/lsse.2.03bli,60,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,no,yes,no,no
J,"Boccardi, F; Heath, RW; Lozano, A; Marzetta, TL; Popovski, P",Five Disruptive Technology Directions for 5G,"New research directions will lead to fundamental changes in the design of future fifth generation (5G) cellular networks. This article describes five technologies that could lead to both architectural and component disruptive design changes: device-centric architectures, millimeter wave, massive MIMO, smarter devices, and native support for machine-to-machine communications. The key ideas for each technology are described, along with their potential impact on 5G and the research challenges that remain.",10.1109/MCOM.2014.6736746,61,yes,yes,no,no,yes,no,no,yes,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,no
J,"Anipsitakis, GP; Dionysiou, DD",Radical generation by the interaction of transition metals with common oxidants,"Nine transition metals were tested for the activation of three oxidants and the generation of inorganic radical species such as sulfate, peroxymonosulfate, and hydroxyl radicals. From the 27 combinations, 14 M/Ox couples demonstrated significant reactivity toward transforming a model organic substrate such as 2,4-dichlorophenol and are further discussed here. It was found that COO and Ru(III) are the best metal catalysts for the activation of peroxymonosulfate. As expected on the basis of the Fenton reagent, Fe(III) and Fe(II) were the most efficient transition metals for the activation of hydrogen peroxide. Finally, Ag(I) showed the best results toward activating persulfate. Quenching studies with specific alcohols (tert-butyl alcohol and ethanol) were also performed to identify the primary radical species formed from the reactive M/Ox interactions. The determination of these transient species allowed us to postulate the rate-determining step of the redox reactions taking place when a metal is coupled with an oxidant in aqueous solution. It was found that when Co(II), Ru(III), and Fe(II) interact with peroxymonosulfate, freely diffusible sulfate radicals are the primary species formed. The same was proven for the interaction of Ag(I) with persulfate, but in this case caged or bound to the metal sulfate radicals might be formed as well. The conjunction of Ce(III), Mn(II), and Ni(II) with peroxymonosulfate showed also to generate caged or bound to the metal sulfate radicals. A combination of sulfate and hydroxyl radicals was formed from the conjunction of V(III) with peroxymonosulfate and from Fe(II) with persulfate. Finally, the conjunction of Fe(III), FOIL and Ru(III) with hydrogen peroxide led primarily to the generation of hydroxyl radicals. It is also suggested here that the redox behavior of a particular metal in solution cannot be predicted based exclusively on its size and charge. Additional phenomena such as metal hydrolysis as well as complexation with other counterions present in solution might affect the thermodynamics of the overall process and are further discussed here.",10.1021/es035121o,62,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
J,"Julier, S; Uhlmann, J; Durrant-Whyte, HF",A new method for the nonlinear transformation of means and covariances in filters and estimators,This paper describes a new approach for generalizing the Kalman filter to nonlinear systems. A set of samples are used to parameterize the mean and covariance of a (not necessarily Gaussian) probability distribution. The method yields a filter that is more accurate than an extended Kalman filter (EKF) and easier to implement than an EKF or a Gauss second-order filter. Its effectiveness is demonstrated using an example.,10.1109/9.847726,63,yes,yes,no,yes,yes,yes,yes,yes,no,no,yes,no,no,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,no,yes,no,no,yes,no
J,"Khanafer, K; Vafai, K; Lightstone, M",Buoyancy-driven heat transfer enhancement in a two-dimensional enclosure utilizing nanofluids,"Heat transfer enhancement in a two-dimensional enclosure utilizing nanofluids is investigated for various pertinent parameters. A model is developed to analyze heat transfer performance of nanofluids inside an enclosure taking into account the solid particle dispersion. The transport equations are solved numerically using the finite-volume approach along with the alternating direct implicit procedure. Comparisons with previously published work on the basis of special cases are performed and found to be in excellent agreement. The effect of suspended ultrafine metallic nanoparticles on the fluid flow and heat transfer processes within the enclosure is analyzed and effective thermal conductivity enhancement maps are developed for various controlling parameters. In addition, an analysis of variants based on the thermophysical properties of nanofluid is developed and presented. It is shown that the variances within different models have substantial effects on the results. Finally, a heat transfer correlation of the average Nusselt number for various Grashof numbers and volume fractions is presented. (C) 2003 Elsevier Ltd. All rights reserved.",10.1016/S0017-9310(03)00156-X,64,yes,yes,no,yes,yes,no,yes,no,yes,no,yes,yes,no,no,no,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,no,no,no,no,no
J,"Zeng, Y; Zhang, R; Lim, TJ",Wireless Communications with Unmanned Aerial Vehicles: Opportunities and Challenges,"Wireless communication systems that include unmanned aerial vehicles promise to provide cost-effective wireless connectivity for devices without infrastructure coverage. Compared to terrestrial communications or those based on high-altitude platforms, on-demand wireless systems with low-altitude UAVs are in general faster to deploy, more flexibly reconfigured, and likely to have better communication channels due to the presence of short-range line-of-sight links. However, the utilization of highly mobile and energy-constrained UAVs for wireless communications also introduces many new challenges. In this article, we provide an overview of UAV-aided wireless communications, by introducing the basic networking architecture and main channel characteristics, highlighting the key design considerations as well as the new opportunities to be exploited.",10.1109/mcom.2016.7470933,65,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,no,yes,yes,yes
J,"Ho, YS; McKay, G",The kinetics of sorption of divalent metal ions onto sphagnum moss peat,"A pseudo-second order rate equation describing the kinetics of sorption of divalent metal ions onto sphagnum moss peat at different initial metal ion concentrations and pear doses has been developed. The kinetics of sorption were followed based on the amounts of metal sorbed at various time intervals. Results show that sorption (chemical bonding) might be rate-limiting in the sorption of divalent metal ions onto peat during agitated batch contact time experiments. The rate constant, the equilibrium sorption capacity and the initial sorption rate were calculated. From these parameters, an empirical model for predicting the sorption capacity of metal ions sorbed was derived. (C) 2000 Elsevier Science Ltd. All rights reserved.",10.1016/S0043-1354(99)00232-8,66,yes,yes,no,no,yes,yes,yes,no,yes,no,yes,yes,yes,no,yes,yes,yes,yes,no,yes,no,no,no,yes,yes,yes,no,no,no,yes,no
J,"Moody, GA; Mark, RG",The impact of the MIT-BIH arrhythmia database,,10.1109/51.932724,67,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
J,"Wu, Y; Lim, J; Yang, MH",Object Tracking Benchmark,"Object tracking has been one of the most important and active research areas in the field of computer vision. A large number of tracking algorithms have been proposed in recent years with demonstrated success. However, the set of sequences used for evaluation is often not sufficient or is sometimes biased for certain types of algorithms. Many datasets do not have common ground-truth object positions or extents, and this makes comparisons among the reported quantitative results difficult. In addition, the initial conditions or parameters of the evaluated tracking algorithms are not the same, and thus, the quantitative results reported in literature are incomparable or sometimes contradictory. To address these issues, we carry out an extensive evaluation of the state-of-the-art online object-tracking algorithms with various evaluation criteria to understand how these methods perform within the same framework. In this work, we first construct a large dataset with ground-truth object positions and extents for tracking and introduce the sequence attributes for the performance analysis. Second, we integrate most of the publicly available trackers into one code library with uniform input and output formats to facilitate large-scale performance evaluation. Third, we extensively evaluate the performance of 31 algorithms on 100 sequences with different initialization settings. By analyzing the quantitative results, we identify effective approaches for robust tracking and provide potential future research directions in this field.",10.1109/TPAMI.2014.2388226,68,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,yes,yes,no,no,yes,yes,yes,yes,no,yes,no,yes,no,yes,yes,yes,yes,no,yes,yes
J,"He, XF; Yan, SC; Hu, YX; Niyogi, P; Zhang, HJ",Face recognition using Laplacianfaces,"We propose an appearance-based face recognition method called the Laplacianface approach. By using Locality Preserving Projections (LPP), the face images are mapped into a face subspace for analysis. Different from Principal Component Analysis (PCA) and Linear Discriminant Analysis (LDA) which effectively see only the Euclidean structure of face space, LPP finds an embedding that preserves local information, and obtains a face subspace that best detects the essential face manifold structure. The Laplacianfaces are the optimal linear approximations to the eigenfunctions of the Laplace Beltrami operator on the face manifold. In this way, the unwanted variations resulting from changes in lighting, facial expression, and pose may be eliminated or reduced. Theoretical analysis shows that PCA, LDA, and LPP can be obtained from different graph models. We compare the proposed Laplacianface approach with Eigenface and Fisherface methods on three different face data sets. Experimental results suggest that the proposed Laplacianface approach provides a better representation and achieves lower error rates in face recognition.",10.1109/TPAMI.2005.55,69,yes,no,no,yes,yes,no,yes,yes,no,no,yes,no,yes,no,no,yes,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,yes,yes,
J,"Nedic, A; Ozdaglar, A",Distributed Subgradient Methods for Multi-Agent Optimization,"We study a distributed computation model for optimizing a sum of convex objective functions corresponding to multiple agents. For solving this (not necessarily smooth) optimization problem, we consider a subgradient method that is distributed among the agents. The method involves every agent minimizing his/her own objective function while exchanging information locally with other agents in the network over a time-varying topology. We provide convergence results and convergence rate estimates for the subgradient method. Our convergence rate results explicitly characterize the tradeoff between a desired accuracy of the generated approximate optimal solutions and the number of iterations needed to achieve the accuracy.",10.1109/TAC.2008.2009515,70,yes,yes,no,no,yes,no,yes,yes,no,no,yes,no,no,no,no,no,yes,yes,yes,no,yes,no,no,no,no,no,no,no,yes,yes,yes
J,"Luo, ZQ; Ma, WK; So, AMC; Ye, YY; Zhang, SZ",Semidefinite Relaxation of Quadratic Optimization Problems,,10.1109/MSP.2010.936019,71,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
J,"Entekhabi, D; Njoku, EG; O'Neill, PE; Kellogg, KH; Crow, WT; Edelstein, WN; Entin, JK; Goodman, SD; Jackson, TJ; Johnson, J; Kimball, J; Piepmeier, JR; Koster, RD; Martin, N; McDonald, KC; Moghaddam, M; Moran, S; Reichle, R; Shi, JC; Spencer, MW; Thurman, SW; Tsang, L; Van Zyl, J",The Soil Moisture Active Passive (SMAP) Mission,"The Soil Moisture Active Passive (SMAP) mission is one of the first Earth observation satellites being developed by NASA in response to the National Research Council's Decadal Survey. SMAP will make global measurements of the soil moisture present at the Earth's land surface and will distinguish frozen from thawed land surfaces. Direct observations of soil moisture and freeze/thaw state from space will allow significantly improved estimates of water, energy, and carbon transfers between the land and the atmosphere. The accuracy of numerical models of the atmosphere used in weather prediction and climate projections are critically dependent on the correct characterization of these transfers. Soil moisture measurements are also directly applicable to flood assessment and drought monitoring. SMAP observations can help monitor these natural hazards, resulting in potentially great economic and social benefits. SMAP observations of soil moisture and freeze/thaw timing will also reduce a major uncertainty in quantifying the global carbon balance by helping to resolve an apparent missing carbon sink on land over the boreal latitudes. The SMAP mission concept will utilize L-band radar and radiometer instruments sharing a rotating 6-m mesh reflector antenna to provide high-resolution and high-accuracy global maps of soil moisture and freeze/thaw state every two to three days. In addition, the SMAP project will use these observations with advanced modeling and data assimilation to provide deeper root-zone soil moisture and net ecosystem exchange of carbon. SMAP is scheduled for launch in the 2014-2015 time frame.",10.1109/JPROC.2010.2043918,72,yes,no,yes,yes,yes,no,yes,no,yes,yes,yes,yes,no,yes,yes,no,no,no,no,no,no,no,no,no,no,yes,no,no,yes,yes,no
J,"Bangor, A; Kortum, PT; Miller, JT",An empirical evaluation of the System Usability Scale,"This article presents nearly 10 year's worth of System Usability Scale (SUS) data collected on numerous products in all phases of the development lifecycle. The SUS, developed by Brooke (1996), reflected a strong need in the usability community for a tool that could quickly and easily collect a user's subjective rating of a product's usability. The data in this study indicate that the SUS fulfills that need. Results from the analysis of this large number of SUS scores show that the SUS is a highly robust and versatile tool for usability professionals. The article presents these results and discusses their implications, describes nontraditional uses of the SUS, explains a proposed modification to the SUS to provide an adjective rating that correlates with a given score, and provides details of what constitutes an acceptable SUS score.",10.1080/10447310802205776,73,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,yes,no,no,yes,yes,yes,yes,no,no,no,no,yes,yes,yes,no,no,yes,yes,no
J,"Adadi, A; Berrada, M",Peeking Inside the Black-Box: A Survey on Explainable Artificial Intelligence (XAI),"At the dawn of the fourth industrial revolution, we are witnessing a fast and widespread adoption of artificial intelligence (AI) in our daily life, which contributes to accelerating the shift towards a more algorithmic society. However, even with such unprecedented advancements, a key impediment to the use of AI-based systems is that they often lack transparency. Indeed, the black-box nature of these systems allows powerful predictions, but it cannot be directly explained. This issue has triggered a new debate on explainable AI (XAI). A research field holds substantial promise for improving trust and transparency of AI-based systems. It is recognized as the sine qua non for AI to continue making steady progress without disruption. This survey provides an entry point for interested researchers and practitioners to learn key aspects of the young and rapidly growing body of research related to XAI. Through the lens of the literature, we review the existing approaches regarding the topic, discuss trends surrounding its sphere, and present major research trajectories.",10.1109/ACCESS.2018.2870052,74,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,no,no,no,no,no,no,no,yes,no,no,no,no,no,no,yes,yes,no,yes,yes,yes
J,"Holzapfel, GA; Gasser, TC; Ogden, RW",A new constitutive framework for arterial wall mechanics and a comparative study of material models,"In this paper we develop a new constitutive law for the description of the (passive) mechanical response of arterial tissue. The artery is modeled as a thick-walled nonlinearly elastic circular cylindrical tube consisting of two layers corresponding to the media and adventitia (the solid mechanically relevant layers in healthy tissue). Each layer is treated as a fiber-reinforced material with the fibers corresponding to the collagenous component of the material and symmetrically disposed with respect to the cylinder axis. The resulting constitutive law is orthotropic in each layer. Fiber orientations obtained from a statistical analysis of histological sections from each arterial layer are used. A specific form of the law, which requires only three material parameters for each layer, is used to study the response of an artery under combined axial extension, inflation and torsion. The characteristic and very important residual stress in an artery in vitro is accounted for by assuming that the natural (unstressed and unstrained) configuration of the material corresponds to an open sector of a tube, which is then closed by an initial bending to form a load-free, but stressed, circular cylindrical configuration prior to application of the extension, inflation and torsion. The effect of residual stress on the stress distribution through the deformed arterial wall in the physiological state is examined. The model is fitted to available data on arteries and its predictions are assessed for the considered combined loadings. It is explained how the new model is designed to avoid certain mechanical, mathematical and computational deficiencies evident in currently available phenomenological models. A critical review of these models is provided by way of background to the development of the new model.",10.1023/A:1010835316564,75,yes,no,no,yes,yes,yes,yes,yes,no,no,yes,yes,yes,no,yes,no,yes,no,no,yes,no,no,no,no,yes,yes,yes,no,no,yes,yes
J,"Camp, T; Boleng, J; Davies, V",A survey of mobility models for ad hoc network research,"In the performance evaluation of a protocol for an ad hoc network, the protocol should be tested under realistic conditions including, but not limited to, a sensible transmission range, limited buffer space for the storage of messages, representative data traffic models and realistic movements of the mobile users (i.e. a mobility model). This paper is a survey of mobility models that are used in the simulations of ad hoc networks. We describe several mobility models that represent mobile nodes whose movements are independent of each other (i.e. entity mobility models) and several mobility models that represent mobile nodes whose movements are dependent on each other (i.e. group mobility models). The goal of this paper is to present a number of mobility models in order to offer researchers more informed choices when they are deciding on a mobility model to use in their performance evaluations. Lastly, we present simulation results that illustrate the importance of choosing a mobility model in the simulation of an ad hoc network protocol. Specifically, we illustrate how the performance results of an ad hoc network protocol drastically change as a result of changing the mobility model simulated. Copyright (C) 2002 John Wiley Sons, Ltd.",10.1002/wcm.72,76,yes,yes,no,no,yes,no,yes,yes,no,yes,yes,no,no,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,no,no,yes,yes
J,"Richard, JP",Time-delay systems: an overview of some recent advances and open problems,"After presenting some motivations for the study of time-delay system, this paper recalls modifications (models, stability, structure) arising from the presence of the delay phenomenon. A brief overview of some control approaches is then provided, the sliding mode and time-delay controls in particular. Lastly, some open problems are discussed: the constructive use of the delayed inputs, the digital implementation of distributed delays, the control via the delay, and the handling of information related to the delay value. (C) 2003 Elsevier Ltd. All rights reserved.",10.1016/S0005-1098(03)00167-5,77,yes,yes,no,yes,no,no,no,no,yes,no,no,yes,no,no,no,no,no,no,no,yes,no,no,no,no,no,no,no,no,no,no,no
J,"Luo, X; Wang, JH; Dooner, M; Clarke, J",Overview of current development in electrical energy storage technologies and the application potential in power system operation,"Electrical power generation is changing dramatically across the world because of the need to reduce greenhouse gas emissions and to introduce mixed energy sources. The power network faces great challenges in transmission and distribution to meet demand with unpredictable daily and seasonal variations. Electrical Energy Storage (EES) is recognized as underpinning technologies to have great potential in meeting these challenges, whereby energy is stored in a certain state, according to the technology used, and is converted to electrical energy when needed. However, the wide variety of options and complex characteristic matrices make it difficult to appraise a specific EES technology for a particular application. This paper intends to mitigate this problem by providing a comprehensive and clear picture of the state-of-the-art technologies available, and where they would be suited for integration into a power generation and distribution system. The paper starts with an overview of the operation principles, technical and economic performance features and the current research and development of important EES technologies, sorted into six main categories based on the types of energy stored. Following this, a comprehensive comparison and an application potential analysis of the reviewed technologies are presented. (C) 2014 The Authors. Published by Elsevier Ltd.",10.1016/j.apenergy.2014.09.081,78,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes
J,"Yang, J; Zhang, D; Frangi, AF; Yang, JY",Two-dimensional PCA: A new approach to appearance-based face representation and recognition,"In this paper, a new technique coined two-dimensional principal component analysis (2DPCA) is developed for image representation. As opposed to PCA, 2DPCA is based on 2D image matrices rather than 1 D vectors so the image matrix does not need to be transformed into a vector prior to feature extraction. Instead, an image covariance matrix is constructed directly using the original image matrices, and its eigenvectors are derived for image feature extraction. To test 2DPCA and evaluate its performance, a series of experiments were performed on three face image databases: ORL, AR, and Yale face databases. The recognition rate across all trials was higher using 2DPCA than PCA. The experimental results also indicated that the extraction of image features is computationally more efficient using 2DPCA than PCA.",10.1109/TPAMI.2004.1261097,79,yes,yes,no,yes,yes,yes,yes,yes,no,no,yes,yes,yes,no,no,yes,yes,yes,no,yes,no,no,yes,yes,no,no,no,yes,no,yes,yes
J,"Jain, AK; Ross, A; Prabhakar, S",An introduction to biometric recognition,"A wide variety of systems requires reliable personal recognition schemes to either confirm or determine the identity of an individual requesting their services. The purpose of such schemes is to ensure that the rendered services are accessed only by a legitimate user and no one else. Examples of such applications include secure access to buildings, computer systems, laptops, cellular phones, and ATMs. In the absence of robust personal recognition schemes, these systems are vulnerable to the wiles of an impostor. Biometric recognition or, simply, biometrics refers to the automatic recognition of individuals based on their physiological and/or behavioral characteristics. By using biometrics, it is possible to confirm or establish an individual's identity based on ""who she is,"" rather than by ""what she possesses"" (e.g., an ID card) or ""what she remembers"" (e.g., a password). In this paper, we give a brief overview of the field of biometrics and summarize some of its advantages, disadvantages, strengths, limitations, and related privacy concerns.",10.1109/TCSVT.2003.818349,80,yes,yes,no,yes,yes,no,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,no,no,yes,yes
J,"Rocabert, J; Luna, A; Blaabjerg, F; RodrÃ­guez, P",Control of Power Converters in AC Microgrids,"The enabling of ac microgrids in distribution networks allows delivering distributed power and providing grid support services during regular operation of the grid, as well as powering isolated islands in case of faults and contingencies, thus increasing the performance and reliability of the electrical system. The high penetration of distributed generators, linked to the grid through highly controllable power processors based on power electronics, together with the incorporation of electrical energy storage systems, communication technologies, and controllable loads, opens new horizons to the effective expansion of microgrid applications integrated into electrical power systems. This paper carries out an overview about microgrid structures and control techniques at different hierarchical levels. At the power converter level, a detailed analysis of the main operation modes and control structures for power converters belonging to microgrids is carried out, focusing mainly on grid-forming, grid-feeding, and grid-supporting configurations. This analysis is extended as well toward the hierarchical control scheme of microgrids, which, based on the primary, secondary, and tertiary control layer division, is devoted to minimize the operation cost, coordinating support services, meanwhile maximizing the reliability and the controllability of microgrids. Finally, the main grid services that microgrids can offer to the main network, as well as the future trends in the development of their operation and control for the next future, are presented and discussed.",10.1109/TPEL.2012.2199334,81,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
J,"El Ayach, O; Rajagopal, S; Abu-Surra, S; Pi, ZY; Heath, RW",Spatially Sparse Precoding in Millimeter Wave MIMO Systems,"Millimeter wave (mmWave) signals experience orders-of-magnitude more pathloss than the microwave signals currently used in most wireless applications and all cellular systems. MmWave systems must therefore leverage large antenna arrays, made possible by the decrease in wavelength, to combat pathloss with beamforming gain. Beamforming with multiple data streams, known as precoding, can be used to further improve mmWave spectral efficiency. Both beamforming and precoding are done digitally at baseband in traditional multiantenna systems. The high cost and power consumption of mixed-signal devices in mmWave systems, however, make analog processing in the RF domain more attractive. This hardware limitation restricts the feasible set of precoders and combiners that can be applied by practical mmWave transceivers. In this paper, we consider transmit precoding and receiver combining in mmWave systems with large antenna arrays. We exploit the spatial structure of mmWave channels to formulate the precoding/combining problem as a sparse reconstruction problem. Using the principle of basis pursuit, we develop algorithms that accurately approximate optimal unconstrained precoders and combiners such that they can be implemented in low-cost RF hardware. We present numerical results on the performance of the proposed algorithms and show that they allow mmWave systems to approach their unconstrained performance limits, even when transceiver hardware constraints are considered.",10.1109/TWC.2014.011714.130846,82,yes,no,yes,yes,yes,no,yes,yes,no,yes,yes,no,no,no,no,no,yes,yes,yes,no,no,no,no,yes,no,yes,yes,yes,yes,yes,yes
J,"Kjaer, SB; Pedersen, JK; Blaabjerg, F",A review of single-phase grid-connected inverters for photovoltaic modules,"This review focuses on inverter technologies for connecting photovoltaic (PV) modules to a single-phase grid. The inverters are categorized into four classifications: 1) the number of power processing stages in cascade; 2) the type of power decoupling between the PV module(s) and the single-phase grid; 3) whether they utilizes a transformer (either line or high frequency) or not; and 4) the type of grid-connected power stage. Various inverter topologies are presented, compared, and evaluated against demands, lifetime, component ratings, and cost. Finally, some of the topologies are pointed out as the best candidates for either single PV module or multiple PV module applications.",10.1109/TIA.2005.853371,83,yes,yes,no,no,yes,yes,yes,yes,no,no,yes,no,no,no,no,yes,no,yes,yes,no,no,no,no,no,yes,yes,no,no,yes,yes,
J,"Figueiredo, MAT; Nowak, RD; Wright, SJ",Gradient Projection for Sparse Reconstruction: Application to Compressed Sensing and Other Inverse Problems,"Many problems in signal processing and statistical inference involve finding sparse solutions to under-determined, or ill-conditioned, linear systems of equations. A standard approach consists in minimizing an objective function which includes a quadratic (squared l(2)) error term combined with a sparseness-inducing (l(1)) regularization term. Basis pursuit, the least absolute shrinkage and selection operator (LASSO), wavelet-based deconvolution, and compressed sensing are a few well-known examples of this approach. This paper proposes gradient projection (GP) algorithms for the bound-constrained quadratic programming (BCQP) formulation of these problems. We test variants of this approach that select the line search parameters in different ways, including techniques based on the Barzilai-Borwein method. Computational experiments show that these GP approaches perform well in a wide range of applications, often being significantly faster (in terms of computation time) than competing methods. Although the performance of GP methods tends to degrade as the regularization term is de-emphasized, we show how they can be embedded in a continuation scheme to recover their efficient practical performance.",10.1109/JSTSP.2007.910281,84,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,yes,no,no,no,yes,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,no,yes,yes
J,"Andrews, JG; Baccelli, F; Ganti, RK",A Tractable Approach to Coverage and Rate in Cellular Networks,"Cellular networks are usually modeled by placing the base stations on a grid, with mobile users either randomly scattered or placed deterministically. These models have been used extensively but suffer from being both highly idealized and not very tractable, so complex system-level simulations are used to evaluate coverage/outage probability and rate. More tractable models have long been desirable. We develop new general models for the multi-cell signal-to-interference-plus-noise ratio (SINR) using stochastic geometry. Under very general assumptions, the resulting expressions for the downlink SINR CCDF (equivalent to the coverage probability) involve quickly computable integrals, and in some practical special cases can be simplified to common integrals (e. g., the Q-function) or even to simple closed-form expressions. We also derive the mean rate, and then the coverage gain (and mean rate loss) from static frequency reuse. We compare our coverage predictions to the grid model and an actual base station deployment, and observe that the proposed model is pessimistic (a lower bound on coverage) whereas the grid model is optimistic, and that both are about equally accurate. In addition to being more tractable, the proposed model may better capture the increasingly opportunistic and dense placement of base stations in future networks.",10.1109/TCOMM.2011.100411.100541,85,yes,no,yes,yes,yes,no,yes,no,yes,yes,yes,yes,yes,no,no,yes,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,yes,yes,yes
J,"Wu, QQ; Zhang, R",Intelligent Reflecting Surface Enhanced Wireless Network via Joint Active and Passive Beamforming,"Intelligent reflecting surface (IRS) is a revolutionary and transformative technology for achieving spectrum and energy efficient wireless communication cost-effectively in the future. Specifically, an IRS consists of a large number of low-cost passive elements each being able to reflect the incident signal independently with an adjustable phase shift so as to collaboratively achieve three-dimensional (3D) passive beamforming without the need of any transmit radio-frequency (RF) chains. In this paper, we study an IRS-aided single-cell wireless system where one IRS is deployed to assist in the communications between a multi-antenna access point (AP) and multiple single-antenna users. We formulate and solve new problems to minimize the total transmit power at the AP by jointly optimizing the transmit beamforming by active antenna array at the AP and reflect beamforming by passive phase shifters at the IRS, subject to users' individual signal-to-interference-plus-noise ratio (SINR) constraints. Moreover, we analyze the asymptotic performance of IRS's passive beamforming with infinitely large number of reflecting elements and compare it to that of the traditional active beamforming/relaying. Simulation results demonstrate that an IRS-aided MIMO system can achieve the same rate performance as a benchmark massive MIMO system without using IRS, but with significantly reduced active antennas/RF chains. We also draw useful insights into optimally deploying IRS in future wireless systems.",10.1109/TWC.2019.2936025,86,yes,no,no,no,yes,no,yes,yes,no,no,yes,no,no,no,no,yes,yes,yes,yes,no,no,no,no,yes,no,yes,yes,yes,yes,yes,yes
J,"Davison, AJ; Reid, ID; Molton, ND; Stasse, O",MonoSLAM: Real-time single camera SLAM,"We present a real-time algorithm which can recover the 3D trajectory of a monocular camera, moving rapidly through a previously unknown scene. Our system, which we dub MonoSLAM, is the first successful application of the SLAM methodology from mobile robotics to the ""pure vision"" domain of a single uncontrolled camera, achieving real time but drift-free performance inaccessible to Structure from Motion approaches. The core of the approach is the online creation of a sparse but persistent map of natural landmarks within a probabilistic framework. Our key novel contributions include an active approach to mapping and measurement, the use of a general motion model for smooth camera movement, and solutions for monocular feature initialization and feature orientation estimation. Together, these add up to an extremely efficient and robust algorithm which runs at 30 Hz with standard PC and camera hardware. This work extends the range of robotic systems in which SLAM can be usefully applied, but also opens up new areas. We present applications of MonoSLAM to real-time 3D localization and mapping for a high-performance full-size humanoid robot and live augmented reality with a hand-held camera.",10.1109/TPAMI.2007.1049,87,yes,no,no,yes,yes,no,yes,yes,no,no,yes,no,no,yes,no,yes,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,yes,yes,yes
J,"Houas, A; Lachheb, H; Ksibi, M; Elaloui, E; Guillard, C; Herrmann, JM",Photocatalytic degradation pathway of methylene blue in water,"The TiO(2)/UV photocatalytic degradation of methylene blue (MB) has been investigated in aqueous heterogeneous suspensions. In addition to a prompt removal of the color, TiO(2)/LTV-based photocatalysis was simultaneously able to oxidize the dye, with an almost complete mineralization of carbon and of nitrogen and sulfur heteroatoms into CO(2) NH(4)(+), NO(3)(-) and SO(4)(2-) respectively. A detailed degradation pathway has been determined by a careful identification of intermediate products, in particular aromatics, whose successive hydroxylations lead to the aromatic ring opening. These results suggest that TiO(2)/UV photocatalysis may be envisaged as a method for treatment of diluted waste waters in textile industries. (C) 2001 Elsevier Science B.V, All rights reserved.",10.1016/S0926-3373(00)00276-9,88,yes,yes,no,no,yes,no,yes,no,yes,no,yes,yes,no,no,no,no,yes,yes,no,yes,yes,yes,no,yes,yes,yes,no,no,yes,yes,no
J,"Leyland, A; Matthews, A",On the significance of the <i>H/E</i> ratio in wear control:: a nanocomposite coating approach to optimised tribological behaviour,"Although hardness has long been regarded as a primary material property which defines wear resistance, there is strong evidence to suggest that the elastic modulus can also have an important influence on wear behaviour. In particular, the elastic strain to failure, which is related to the ratio of hardness (H) and elastic modulus (E), has been shown by a number of authors to be a more suitable parameter for predicting wear resistance than is hardness alone. There is presently considerable interest in the development of nanostructured and nanolayered coatings, due to the fact that materials with extreme mechanical properties (which are difficult to synthesise by other methods) can be created, particularly when using plasma-assisted vacuum processing techniques. Until now, scientific research has been directed mainly towards the achievement of ultra-high hardness, with associated high elastic modulus, the latter of which, conventional fracture mechanics theory would suggest, is also desirable for wear improvement (by preventing crack propagation). In this study, we discuss the concept of nanocomposite coatings with high hardness and low elastic modulus, which can exhibit improved toughness, and are therefore better suited for optimising the wear resistance of 'real' industrial substrate materials (i.e. steels and Light alloys, with similarly low moduli). Recent advances in the development of ceramic-ceramic, ceramic-amorphous and ceramic-metal nanocomposite coatings are summarised and discussed in terms of their relevance to practical applications. We also discuss the significance of elastic strain to failure (which is related to H/E) and fracture toughness in determining tribological behaviour and introduce the topic of metallic nanocomposite coatings which, although not necessarily exhibiting extreme hardness, may provide superior wear resistance when deposited on the types of substrate material which industry needs to use. (C) 2000 Elsevier Science S.A. All rights reserved.",10.1016/S0043-1648(00)00488-9,89,yes,no,no,yes,yes,no,yes,no,no,no,yes,no,no,no,no,yes,no,no,no,no,no,no,no,no,no,yes,no,yes,yes,yes,yes
J,"Kuhl, KP; Cave, ER; Abram, DN; Jaramillo, TF",New insights into the electrochemical reduction of carbon dioxide on metallic copper surfaces,"We report new insights into the electrochemical reduction of CO2 on a metallic copper surface, enabled by the development of an experimental methodology with unprecedented sensitivity for the identification and quantification of CO2 electroreduction products. This involves a custom electrochemical cell designed to maximize product concentrations coupled to gas chromatography and nuclear magnetic resonance for the identification and quantification of gas and liquid products, respectively. We studied copper across a range of potentials and observed a total of 16 different CO2 reduction products, five of which are reported here for the first time, thus providing the most complete view of the reaction chemistry reported to date. Taking into account the chemical identities of the wide range of C-1-C-3 products generated and the potential-dependence of their turnover frequencies, mechanistic information is deduced. We discuss a scheme for the formation of multicarbon products involving enol-like surface intermediates as a possible pathway, accounting for the observed selectivity for eleven distinct C2+ oxygenated products including aldehydes, ketones, alcohols, and carboxylic acids.",10.1039/c2ee21234j,90,yes,no,no,yes,yes,no,yes,no,yes,yes,yes,yes,no,yes,yes,no,yes,yes,yes,no,yes,no,yes,yes,yes,yes,yes,no,yes,yes,yes
J,"Yan, SC; Xu, D; Zhang, BY; Zhang, HJ; Yang, Q; Lin, S",Graph embedding and extensions: A general framework for dimensionality reduction,"Over the past few decades, a large family of algorithms-supervised or unsupervised; stemming from statistics or geometry theory-has been designed to provide different solutions to the problem of dimensionality reduction. Despite the different motivations of these algorithms, we present in this paper a general formulation known as graph embedding to unify them within a common framework. In graph embedding, each algorithm can be considered as the direct graph embedding or its linear/kernel/tensor extension of a specific intrinsic graph that describes certain desired statistical or geometric properties of a data set, with constraints from scale normalization or a penalty graph that characterizes a statistical or geometric property that should be avoided. Furthermore, the graph embedding framework can be used as a general platform for developing new dimensionality reduction algorithms. By utilizing this framework as a tool, we propose a new supervised dimensionality reduction algorithm called Marginal Fisher Analysis in which the intrinsic graph characterizes the intraclass compactness and connects each data point with its neighboring points of the same class, while the penalty graph connects the marginal points and characterizes the interclass separability. We show that MFA effectively overcomes the limitations of the traditional Linear Discriminant Analysis algorithm due to data distribution assumptions and available projection directions. Real face recognition experiments show the superiority of our proposed MFA in comparison to LDA, also for corresponding kernel and tensor extensions.",10.1109/TPAMI.2007.250598,91,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,no,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,no,yes,no,yes,yes,yes
J,"Komine, T; Nakagawa, M",Fundamental analysis for visible-light communication system using LED lights,"White LED offers advantageous properties such as high brightness, reliability, lower power consumption and long lifetime. White LEDs are expected to serve in the next generation of lamps. An indoor visible-light communication system utilizing white LED lights has been proposed from our laboratory. In the proposed system, these devices are used not only for illuminating rooms but also for an optical wireless communication system. Generally, plural lights are installed in our room. So, their optical path difference must be considered. In this paper, we discuss about the influence of interference and reflection. Based on numerical analyses, we show that the system will expect as indoor communication of next generation(1).",10.1109/TCE.2004.1277847,92,yes,no,yes,yes,yes,no,yes,yes,no,no,yes,yes,no,no,no,no,no,no,no,yes,no,no,no,no,no,no,no,no,yes,yes,yes
J,"Zhang, ML; Zhou, ZH",ML-KNN: A lazy learning approach to multi-label leaming,"Multi-label learning originated from the investigation of text categorization problem, where each document may belong to several predefined topics simultaneously. In multi-label learning, the training set is composed of instances each associated with a set of labels, and the task is to predict the label sets of unseen instances through analyzing training instances with known label sets. In this paper, a multi-label lazy learning approach named ML-KNN is presented, which is derived from the traditional K-nearest neighbor (KNN) algorithm. In detail, for each unseen instance, its K nearest neighbors in the training set are firstly identified. After that, based on statistical information gained from the label sets of these neighboring instances, i.e. the number of neighboring instances belonging to each possible class, maximum a posteriori (MAP) principle is utilized to determine the label set for the unseen instance. Experiments on three different real-world multi-label learning problems, i.e. Yeast gene functional analysis, natural scene classification and automatic web page categorization, show that ML-KNN achieves superior performance to some well-established multi-label learning algorithms. (c) 2007 Pattern Recognition Society. Published by Elsevier Ltd. All rights reserved.",10.1016/j.patcog.2006.12.019,93,yes,yes,no,yes,yes,no,yes,no,yes,no,yes,yes,yes,no,no,no,yes,yes,no,yes,no,no,no,yes,no,no,yes,no,no,no,no
J,"MartÃ¬nez, AM; Kak, AC",PCA versus LDA,"In the context of the appearance-based paradigm for object recognition, it is generally believed that algorithms based on LDA (Linear Discriminant Analysis) are superior to those based on PCA (Principal Components Analysis). in this communication, we show that this is not always the case. We present our case first by using intuitively plausible arguments and, then. by showing actual results on a face database. Our overall conclusion is that when the training data set is small, PCA can outperform LDA and, also, that PCA is less sensitive to different training data sets.",10.1109/34.908974,94,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,no,yes,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,yes,yes,yes,yes
J,"Polyanskiy, Y; Poor, HV; VerdÃº, S",Channel Coding Rate in the Finite Blocklength Regime,"This paper investigates the maximal channel coding rate achievable at a given blocklength and error probability. For general classes of channels new achievability and converse bounds are given, which are tighter than existing bounds for wide ranges of parameters of interest, and lead to tight approximations of the maximal achievable rate for blocklengths n as short as 100. It is also shown analytically that the maximal rate achievable with error probability c is closely approximated by C -root V/n Q(-1()c) where C is the capacity, V is a characteristic of the channel referred to as channel dispersion, and Q is the complementary Gaussian cumulative distribution function.",10.1109/TIT.2010.2043769,95,yes,yes,no,yes,yes,yes,yes,yes,no,no,yes,no,no,no,no,yes,yes,yes,yes,no,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes
J,"Schwarz, H; Marpe, D; Wiegand, T",Overview of the Scalable Video Coding extension of the H.264/AVC standard,"With the introduction of the H.264/AVC video coding standard, significant improvements have recently been demonstrated in video compression capability. The Joint Video Team of the ITU-T VCEG and the ISO/IEC MPEG has now also standardized a Scalable Video Coding (SVC) extension of the H.264/AVC standard. SVC enables the transmission and decoding of partial bit streams to provide video services with lower temporal or spatial resolutions or reduced fidelity while retaining a reconstruction quality that is high relative to the rate of the partial bit streams. Hence, SVC provides functionalities such as graceful degradation in lossy transmission environments as well as bit rate, format, and power adaptation. These functionalities provide enhancements to transmission and storage applications. SVC has achieved significant improvements in coding efficiency with an increased degree of supported scalability relative to the scalable profiles of prior video coding standards. This paper provides an overview of the basic concepts for extending H.264/AVC towards SVC. Moreover, the basic tools for providing temporal, spatial, and quality scalability are described in detail and experimentally analyzed regarding their efficiency and complexity.",10.1109/TCSVT.2007.905532,96,yes,yes,no,yes,yes,no,no,no,yes,no,yes,yes,no,no,no,yes,yes,no,no,yes,no,no,no,no,no,no,no,no,yes,no,no
J,"Tropp, JA",Greed is good: Algorithmic results for sparse approximation,"This article presents new results on using a greedy algorithm, orthogonal matching pursuit (OMP), to solve the sparse approximation problem over redundant dictionaries. It provides a sufficient condition under which both OMP and Donoho's basis pursuit (BP) paradigm can recover the optimal representation of an exactly sparse signal. It leverages this theory to show that both OMP and BP succeed for every sparse input signal from a wide class of dictionaries. These quasi-incoherent dictionaries offer a natural generalization of incoherent dictionaries, and the cumulative coherence function is introduced to quantify the level of incoherence. This analysis unifies all the recent results on BP and extends them to OMP. Furthermore, the paper develops a sufficient condition under which OMP can identify atoms from an optimal approximation of a nonsparse signal. From there, it argues that OMP is an approximation algorithm for the sparse problem over a quasi-incoherent dictionary. That is, for every input signal, OMP calculates a sparse approximant whose error is only a small factor worse than the minimal error that can be attained with the same number of terms.",10.1109/TIT.2004.834793,97,yes,yes,no,yes,yes,no,yes,yes,no,no,yes,yes,no,no,no,no,no,no,no,no,no,no,no,no,no,yes,yes,no,no,no,no
J,"Wang, MY; Wang, XM; Guo, DM",A level set method for structural topology optimization,"This paper presents a new approach to structural topology optimization. We represent the structural boundary by a level set model that is embedded in a scalar function of a higher dimension. Such level set models are flexible in handling complex topological changes and are concise in describing the boundary shape of the structure. Furthermore, a well-founded mathematical procedure leads to a numerical algorithm that describes a structural optimization as a sequence of motions of the implicit boundaries converging to an optimum solution and satisfying specified constraints. The result is a 3D topology optimization technique that demonstrates outstanding flexibility of handling topological changes, fidelity of boundary representation and degree of automation. We have implemented the algorithm with the use of several robust and efficient numerical techniques of level set methods. The benefit and the advantages of the proposed method are illustrated with several 2D examples that are widely used in the recent literature of topology optimization, especially in the homogenization based methods. (C) 2002 Elsevier Science B.V. All rights reserved.",10.1016/S0045-7825(02)00559-5,98,yes,yes,no,yes,yes,yes,yes,no,yes,no,yes,yes,no,no,no,no,yes,yes,yes,no,no,no,no,yes,yes,yes,yes,no,no,yes,yes
J,"Ngo, HQ; Larsson, EG; Marzetta, TL",Energy and Spectral Efficiency of Very Large Multiuser MIMO Systems,"A multiplicity of autonomous terminals simultaneously transmits data streams to a compact array of antennas. The array uses imperfect channel-state information derived from transmitted pilots to extract the individual data streams. The power radiated by the terminals can be made inversely proportional to the square-root of the number of base station antennas with no reduction in performance. In contrast if perfect channel-state information were available the power could be made inversely proportional to the number of antennas. Lower capacity bounds for maximum-ratio combining (MRC), zero-forcing (ZF) and minimum mean-square error (MMSE) detection are derived. An MRC receiver normally performs worse than ZF and MMSE. However as power levels are reduced, the cross-talk introduced by the inferior maximum-ratio receiver eventually falls below the noise level and this simple receiver becomes a viable option. The tradeoff between the energy efficiency (as measured in bits/J) and spectral efficiency (as measured in bits/channel use/terminal) is quantified for a channel model that includes small-scale fading but not large-scale fading. It is shown that the use of moderately large antenna arrays can improve the spectral and energy efficiency with orders of magnitude compared to a single-antenna system.",10.1109/TCOMM.2013.020413.110848,99,yes,yes,no,no,no,no,no,no,no,no,yes,yes,no,no,no,yes,yes,yes,yes,no,yes,no,yes,yes,yes,yes,yes,no,yes,yes,no
