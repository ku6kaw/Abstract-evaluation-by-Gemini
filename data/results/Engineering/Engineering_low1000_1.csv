ID,Abstract,rule1,rule2,rule3,rule4,rule5,rule6,rule7,rule8,rule9,rule10,rule11,rule12,rule13,rule14,rule15,rule16,rule17,rule18,rule19,rule20,rule21,rule22,rule23,rule24,rule25,rule26,rule27,rule28,rule29,rule30,rule31,rule32,rule33
0,"This letter investigates the optimal tradeoff between user experience and communications and computation resource consumptions in designing efficient mobile edge computing (MEC) systems which are based on orthogonal frequency division multiple access (OFDMA) and operating in time division duplexing (TDD) mode. First, we establish a communication model for offloading scalable tasks in TDD-OFDMA systems. Then, we formulate the system utility maximization problem with respect to the service level selection and resource allocation. Finally, we propose two algorithms to obtain a globally optimal solution and a low-complexity suboptimal solution, respectively, using convex optimization and difference of convex (DC) programming.",yes,no,no,no,yes,no,yes,yes,no,no,yes,yes,no,no,no,no,yes,no,no,yes,yes,yes,no,no,yes,yes,yes,yes,no,no,yes,yes,
1,"For emergency situations, the network system based on wireless multihop networks such as a mobile ad hoc network (MANET) has been developing to exchange messages among users without the aid of the infrastructure networks. However, many MANET-based systems have been evaluated through the simulation experiments. In this paper, we propose an evaluation framework combining simulator and game engine to simulate MANET-based systems in more realistic environment and present the case study of the evaluation framework.",yes,no,no,yes,yes,no,yes,no,yes,no,yes,yes,no,no,no,no,yes,yes,yes,no,no,no,no,no,yes,yes,yes,yes,no,no,yes,yes,
2,"An Oseen-type post-processed mixed finite element method based on a subgrid model is presented for the simulation of time-dependent incompressible Navier-Stokes equations. This method first solves a subgrid stabilized nonlinear Navier-Stokes system on a mesh of size H to obtain an approximate solution pair (u(H)(x, T), p(H)(x, T)) at the given final time T, and then post-processes the solution (u(H)(x, T), p(H)(x, T)) by solving a stabilized Oseen problem on a finer mesh or in higher-order finite element spaces. We prove stability of the stabilized method, derive error estimates for the post-processed solutions, give some numerical results to verify the theoretical predictions and demonstrate the effectiveness of the proposed method.",no,no,no,yes,yes,no,yes,no,no,no,yes,yes,no,no,no,no,yes,yes,yes,no,yes,no,yes,no,yes,yes,yes,yes,no,no,yes,yes,
3,"This work presents a quadratic boundary integral equation formulation for isotropic damage analysis of components subjected to mechanical, thermal and centrifugal loads. To evaluate domain-related integrals due to the damage effects, the radial integration method (RIM) based on the use of the approximating the normalized displacements in the domain integrals by a series of prescribed radial basis functions (RBF) is adopted. The density of micro-defects is assumed to be small in the material. The scalar damage parameter expressed in an exponential evolution equation is utilized. Numerical examples including a rectangular plate, thick-walled cylinder and rotating disk problems under the thermal loads are given.",yes,no,no,no,no,no,yes,no,no,no,yes,yes,no,no,no,no,yes,no,no,yes,yes,no,no,yes,no,yes,no,yes,no,no,yes,yes,no
4,"China, who was in charge of most of the poloidal field (PF) conductor unit lengths manufacturing for the ITER Project, has supplied all the required PF conductors and finished the PF package successfully. Around 130 t of NbTi strands were supplied and used for the PF conductors. During the package execution process, the Chinese Domestic Agency (CNDA) has organized the verification for the NbTi strand acceptance tests based on the requirements of the ITER procurement arrangement (PA). The verification tasks for NbTi strands were undertaken by the Institute of Plasma Physics Chinese Academy of Sciences (ASIPP). In total, about 550 billets of NbTi strands have been verified and supplied for the PF conductors. The verification levels fit the ITER PA requirements. The test results showed that the quality of the NbTi strands has been well controlled. In addition, in order to supply essential data for the conductor performance prediction and analysis, a full critical current I-c characterization of the NbTi strands, which requires a measurement of I-c versus field, B and temperature, T, has been obtained using the test facilities from the National Institute of Standards and Technology (NIST) and ASIPP. The parameterization using the Bottura scaling law for the strand with I-c close to the average value from the verification results has been analyzed. The test methods and strand performances are reviewed and summarized in this article.",yes,no,no,no,no,no,yes,no,yes,yes,yes,yes,yes,no,no,no,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,yes,no,no,yes,yes,no
5,"Several deterministic models have been proposed in the literature to solve the machine loading problem (MLP), which considers a set of product types to be produced on a set of machines using a set of tool types, and determines the quantity of each product type to be produced at each time period and the corresponding machine tool loading configuration. However, processing times are subject to random increases, which could impair the quality of a deterministic solution. Thus, we propose a robust MLP counterpart, searching for an approach that properly describes the uncertainty set of model parameters and, at the same time, ensures practical application. We exploit the cardinality-constrained approach, which considers a simple uncertainty set where all uncertain parameters belong to an interval, and allows tuning the robustness level by bounding the number of parameters that assume the worst value. The resulting plans provide accurate estimations on the minimum production level that a system achieves even in the worst conditions. The applicability of the robust MLP and the impact of robustness level have been tested on several problem variants, considering single- vs multi-machine and single vs multi-period MLPs. We also consider the execution of the plans in a set of scenarios to evaluate the practical implications of MLP robustness. Results show the advantages of the robust formulation, in terms of improved feasibility of the plans, identification of the most critical tools and products, and evaluation of the maximum achievable performance in relation to the level of protection. Moreover, low computational times guarantee the applicability of the proposed robust MLP counterpart.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
6,"Patient video taken at home can provide valuable insights into the recovery progress during a programme of physical therapy, but is very time consuming for clinician review. Our work focussed on (i) enabling any patient to share information about progress at home, simply by sharing video and (ii) building intelligent systems to support Physical Therapists (PTs) in reviewing this video data and extracting the necessary detail. This paper reports the development of the system, appropriate for future clinical use without reliance on a technical team, and the clinician involvement in that development. We contribute an interactive content-based video retrieval system that significantly reduces the time taken for clinicians to review videos, using human head movement as an example. The system supports query-by-movement (clinicians move their own body to define search queries) and retrieves the essential fine-grained movements needed for clinical interpretation. This is done by comparing sequences of image-based pose estimates (here head rotations) through a distance metric (here Frechet distance) and presenting a ranked list of similar movements to clinicians for review. In contrast to existing intelligent systems for retrospective review of human movement, the system supports a flexible analysis where clinicians can look for any movement that interests them. Evaluation by a group of PTs with expertise in training movement control showed that 96% of all relevant movements were identified with time savings of as much as 99.1% compared to reviewing target videos in full. The novelty of this contribution includes retrospective progress monitoring that preserves context through video, and content-based video retrieval that supports both fine-grained human actions and query-by-movement. Future research, including large clinician-led studies, will refine the technical aspects and explore the benefits in terms of patient outcomes, PT time, and financial savings over the course of a programme of therapy. It is anticipated that this clinician-led approach will mitigate the reported slow clinical uptake of technology with resulting patient benefit. (C) 2019 Elsevier Ltd. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
7,"Orthogonal signal-division multiplexing (OSDM) has recently emerged as a promising alternative to orthogonal frequency division multiplexing (OFDM) for high-rate wireless communications. Although providing more flexibility in system design, it suffers from a special interference structure, namely intervector interference (IVI), when channel time variations are present. In this paper, we first derive the general OSDM signal model over time-varying channels, and then show that a time-domain window can be used to enhance the diagonal-block-banded (DBB) approximation of the channel matrix in a transformed domain. Furthermore, based on the DBB matrix enhancement, a low-complexity OSDM equalization algorithm is designed. Simulation results indicate that the proposed equalizer has significant performance advantages over that using the direct DBB approximation. (C) 2019 Elsevier B.V. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
8,"The dynamic analysis of induction motors is supported by well-known theories: the two-axes transformation, and the space vector theory. Yet some inconsistencies with the theory of dynamic systems exist. The machine eigenvalues suggest the existence of two damped oscillators, physically not understandable. The respective eigenfrequencies change with the angular velocity of the reference frame. This contradicts the understanding that eigenfrequencies are inherent system properties. Physically, the dynamics depend on the continuous distribution of magnetic energy and its spatial displacement during transient processes. Information on the system dynamics is lost when dividing the continuum of magnetic energy into discrete portions. Complex state variables associate the dynamics to the propagation in space of distributed magnetic fields. The dynamic analysis reveals the existence single-complex eigenvalues. These define a novel class of system identifiers. They are characterized by having only one imaginary part instead of a conjugate complex pair. The use of complex state variables conveys insight and physical understanding of the dynamic processes within the machine. The approach constitutes an extension to the theory of dynamic systems.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
9,"One key issue of the fifth mobile communication generation (5G) is to elaborate an appropriate new waveform. Ideally, this waveform should preserve the two main advantages of the Orthogonal Frequency Division Multiplexing (OFDM) scheme, namely low latency and complexity. Along this line of thought, we propose in this paper an OFDM-type window, i.e. identical symbol time duration and equivalent spectral efficiency as OFDM. This optimal waveform with respect to the time -frequency localization criterion is analyzed using a Filtered MultiTone (FMT) framework. For this design criterion, comparisons are carried out between our optimized FMT solution, OFDM and the Root Raised Cosine window. (C) 2019 Elsevier B.V. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
10,"Nonlinear bifurcation theory is very powerful and efficient to deal with multifarious nonlinear phenomena emerging from physics, biology, engineering, and economics. However, the execution of augmented system for bifurcation points will be very complicated for a system with too many variables. The purpose of this paper is to give a new optimization based method for computation of fold and Hopf bifurcation points and discuss their applications in stability analysis of power system. The validity of the proposed method has been testified by a WSCC9-bus power system in which the load increment at any bus was taken as a parameter.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
11,"This paper proposes a family of single-stage converters consisting of three different converters, each of which is able to produce a variety of waveforms through the waveform-subtraction technique. We brand this converter family as waveform-subtraction based single-stage converter (WSSC). By using only a single-stage converter, the proposed waveform generation technique is able to realize dcdcac conversions and suppress input current ripple, meeting the needs of modernized power grid with renewable energy sources. At the same time, converters in this WSSC family are capable of generating a range of shapes, such as triangular, rectangular, and sawtooth waveforms, with simple structures, demonstrating its suitability of being applied in the electrochemical industry, e.g., in the electroplating process. Furthermore, the proposed family converters also realize substantially better input current ripple suppression compared to other conventional converters. In order to prove the validity and efficacy of the proposed WSSC and the theory underpinning it, in this paper, extensive simulations and analyses are conducted to verify the theoretical foundation of the proposed WSSC strategy, and the prototype of a converter from the proposed converter family is built and tested in our laboratory, which validates the functionality of the WSSC.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
12,"Smoothed finite element method (S-FEM) is a new general numerical method which has been applied to solve various practical engineering problems. It combines standard finite element method (FEM) and meshfree techniques based on the weaken-weak (W2) formulation. This project, for the first time, develops a preprocessor software package SFEM-Pre for creating types of two-dimensional (2D) and three-dimensional (3D) S-FEM models following strictly the S-FEM theory. Because the software architecture of our 3D processor is the same as our 2D preprocessor, we will mainly introduce the 2D preprocessor in terms of software design for easier description, but the examples will include both 2D and 3D cases to fully demonstrate and validate the whole preprocessor of S-FEM. Our 2D preprocessor package is equipped with a graphical user interface (GUI) for easy use, and with a connectivity database for efficient computation. Schemes are developed for not only automatically meshes the problem domains using our GUI, but also accepts various geometry files made available from some existing commercial software packages, such as ABAQUS (R) and HyperMesh (R). In order to improve the efficiency of our preprocessor, a parallel triangulation mesh generator has also been developed based on the advancing front technique (AFT) to create triangular meshes for complex geometry, and at the same time to create six types of connectivity needed for various S-FEM models. In addition, a database is implemented in our code to record all these connectivity to avoid duplicated calculation. Finally, intensive numerical experiments are conducted to validate the efficiency, accuracy and stability of our preprocessor codes. It is shown that with our preprocessor, an S-FEM can be created automatically without much human intervention for geometry of arbitrary complexity.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
13,"This study determined an explicit tolerance for bottom flanges of tub girders giving computed first yield moment including the strength reduction due to initial out-of-flatness of tub girders higher than the flexural design capacity for the limit state of bottom flange local buckling in current standards. Finite-element analysis (FEA) was used to construct flexural strength-reduction curves for tub girders with various out-of-flatness magnitudes covering a range of girder cross sections and spans. Tub bottom flange slenderness ratios between 25 and 120 were modeled as covering the practical range. Models were built with coexisting out-of-flatness in both webs and flanges. The appropriate residual stress pattern was created using heat analysis. Models were laterally supported to ensure the local buckling limit state controls. Both 344.7-MPa (Grade 50 Steel) and 689.4-MPa (Grade 100 Steel) yield steel plates were considered with elastic-perfectly plastic material behavior. Large deflection theory was used to iteratively capture the secondary moments due to out-of-flatness. The current tolerance of D/150 out-of-flatness for the fascia web of an I-shaped plate girder was shown to implicitly accept a 20% strength reduction. Results showed that compressive flexural design formulas for tub girders in current standards conservatively reduce the strength to account for local buckling. Code adoption of b(f)/200 is recommended for the tub girder bottom flange out-of-flatness tolerance, where b(f) represents the bottom flange width. (C) 2019 American Society of Civil Engineers.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
14,"Reduced-rank adaptive beamforming is a well established and efficient methodology, notably for disturbance covariance matrices which are the sum of a strong low-rank component (interference) and a scaled identity matrix (thermal noise). Eigenvalue or singular decomposition is often used to achieve rank reduction. In this paper, we study and analyze an alternative, namely a partial Cholesky factorization, as a means to retrieve interference subspace and to compute reduced-rank beamformers. First, we study the angles between the true subspace and that obtained from partial Cholesky factorization of the covariance matrix. Then, a statistical analysis is carried out in finite samples. Using properties of partitioned Wishart matrices, we provide a stochastic representation of the beamformer based on partial Cholesky factorization and of the corresponding signal to interference and noise ratio loss. We show that the latter follows approximately a beta distribution, similarly to the beamformer based on eigenvalue decomposition. Finally, numerical simulations are presented which indicate that a reduced-rank adaptive beam former based on partial Cholesky factorization incurs almost no loss, and can even perform better in some scenarios than its eigenvalue or singular value-based counterpart. (C) 2019 Elsevier B.V. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
15,"Pricing and inventory management make up together revenue management, which is a significant effort to boost revenues out of available resources. Firms use various forms of dynamic pricing, including personalized pricing, markdowns, promotions, coupons, discounts, and clearance sales, to respond to market fluctuations and demand uncertainty. In this paper, we study a temporary price increase policy, a form of dynamic pricing, for a non-perishable product, a practice used by several giant retailers such as Amazon, Walmart, and Apple. We develop a continuous review inventory model that allows for joint replenishment and pricing decisions, where the lead time is not zero. A replenishment decision controls supply, while a pricing decision controls demand. A manager exercises a temporary price increase to slow demand and avoid a stock-out situation while waiting for a shipment, which may not necessarily increase revenues, but decrease stock-out costs. The problem is to solve for the optimal replenishment and the pricing policy parameters that maximize the long-run expected profit. That is, when and how much to order and when to raise the price. In this paper, the inventory level and time trigger a price increase. We solve many numerical examples and perform extensive sensitivity analyses. Our results show that compared to a model that focuses on fixed pricing, our model brings an additional increase in profit of about 13%. (C) 2019 Elsevier Inc. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
16,"Liquid leakage assessment is usually difficult, what can be overwhelmed through leakage testing using gases. This happens in many situations of practical interest of pressure-difference driven liquid leakage. Starting from physical principles and laws, analytical expressions relate the liquid and gas leakages occurring through the same leak geometry. Pressure differences driven the liquid and gas leakages can be different. Process of obtaining the analytical expressions highlights the physics behind the process of leakage testing and the involved variables and principles. Obtained analytical expressions relate the governing variables, allowing calculations for results treatment, interpretation, correlation or uncertainty analysis. Developments and results presented in the paper fulfill a gap of the literature concerning the liquid leakage assessment and testing using gases, and of the users' manuals of the leakage testing equipment. This additional knowledge and information allows equipment use and leak tests conduction with greater confidence, and supported results analyses, criticism and treatment. (C) 2019 Elsevier Ltd. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
17,"This paper shows the development of a fuzzy system applied to low-cost microcontroller to assist in the identification of different intensities of air flow from the AWM2100 sensor, whose operation presents variation in the output voltage due to the variation of the external temperature and also a nonlinear response of the output voltage as function of the variation of the air flow. In order to verify the operation of the proposed work, the fuzzy system was developed in C language for the PIC18F4550 microcontroller using techniques that guarantee great precision in the defuzzification process and the results were obtained by practical tests and PROTEUS software simulations. (C) 2019 Elsevier Ltd. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
18,"This paper proposes three polytomous item explanatory models with random item errors in Item Response Theory (IRT), by extending the Linear Logistic Test Model with item error (LLTM + epsilon) approach to polytomous data. The proposed models, also regarded as polytomous random item effects models, can take the uncertainty in explanation and/or the random nature of item parameters into account for polytomous items. To develop the models, the concepts and types of polytomous random item effects are investigated and then added into the existing polytomous item explanatory models. For estimation of the proposed models with crossed random effects for polytomous data, a Bayesian inference method is adopted for data analysis. An empirical example demonstrates practical implications and applications of the proposed models to the Verbal Aggression data. The empirical findings show that the proposed models with random item errors perform better than the existing models without random item errors in terms of the goodness-of-fit and reconstructing the step difficulties and also demonstrate methodological and practical differences of the proposed models in interpreting the item property effects in each of the item location explanatory Many-Facet Rasch Model and the step difficulty explanatory Linear Partial Credit Model approaches. (C) 2019 Elsevier Ltd. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
19,"Detailed transient behaviors of mass and heat transfer processes are required to solve partial differential equations. When those partial differential equations are coupled, they are still difficult to solve in time domain. For linear mass and heat transfer processes, their Laplace-domain solutions are obtainable and, when they are approximated by rational polynomials in the Laplace variable s, the problems can be transformed to a set of ordinary differential equations solved easily in time domain for various initial conditions. In this approximation, the conventional Pade method based on the Tayler series expansion of the Laplace-domain solutions has been well developed and effective. However, for some mass and heat transfer processes in the semi-infinite geometry, the Pade approximation is not applicable because the Laplace-domain solutions involving exp(-sqrt(s)) are not analytic at s = 0. Here, for such processes, analytical methods to approximate exp(-sqrt(s)) by rational polynomials are proposed. First it is expanded in series in terms of cosh(-1)(2(k)sqrt(s)) which converges fast. This series, when truncated, is analytic at s = 0 and its Pade approximations are available. The proposed method enables partial differential equations be replaced to a set of ordinary differential equations, reducing computations considerably for coupled partial differential equations. Performances of the proposed method are illustrated with several realistic mass and heat transfer processes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
20,"Current probabilistic methods for maximum and minimum run lengths in a hydrologic time series need further development. Using the first-order Markov chain model and an extreme-value theory for randomly occurring events, this study investigates probabilistic properties of both extreme run lengths in a stationary hydrologic time series. The interaction between negative run length, positive run length, total run length, life span, and number of total runs was analyzed. As a result, a joint probabilistic space was defined for negative (or positive) and total run lengths, and a corrector was established for an existing cumulative distribution function (CDF) of negative run length. Lengths of incomplete runs were considered appropriately, especially when no total run occurred during the life span. A generalized CDF was formulated for each extreme value, and simplified versions of the generalized CDF were proposed as practical approximate methods, including expectation approximations and limiting approximations. Results of computational examples indicated that expectation approximations generally provided better results than limiting approximations for maximum negative run lengths, and the non-negligible probability of no total run occurring during the life span may have a significant influence on CDFs.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
21,"Silicoaluminophosphate (SAPO-n) molecular sieves are important microporous materials for chemical processes like MTO. Classical synthesis route for SAPO-n, i.e. hydrothermal method, generally requires dozens of hours (> 24 h). In this work, we reported a chemical approach to significantly reduce required crystallization time to 40-120 min by adding citric acid (CA) in synthesis gel. The time consumed with the proposed process is comparable with that by special heating intensification method while it is simpler, cheaper, and greener than latter. The ultrafast crystallization was attributed to the non-classical nucleation theory inspired by kinetic analysis, in which chelation interaction between CA and Al3+ favored metastable phase generation evidenced by XRD and Al-27 NMR. Other chelate agents (tartaric acid, ethylenediaminetetraacetic acid) with multi carbonic group also showed promising interaction. Moreover, the superior crystallization promotion effect could be applicable in the synthesis of other SAPO-n molecular sieves like SAPO-11, which indicates its great potentials in the future. With further optimization by structure promoter, the obtained SAPO-34 demonstrated sub-micron particle size, high ratio isolated Q(0) state Si specie, and hierarchical structure, characterized by the SEM, XPS, Si-29 NMR, TEM, and N-2-isotherms. The promoted physiochemical properties favored superior performance during MTO test. This work opens up a new perspective to synthesize SAPO-n molecular sieves by a simple chemical approach in a highly efficient and environment friendly manner.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
22,"Fine structure splitting (FSS) is a bottleneck in quantum dot (QD) based solid-state entangled photon pair sources for application in quantum key distribution (QKD). In QDs, entangle photon pairs are generated through a cascaded emission process: biexciton to exciton to the ground state. The FSS of the excitonic states destroys the entanglement of the photon pairs; hence, it needs to be eliminated. For numerical investigation of FSS and design optimization, a multiscale-multiphysics many-body calculation is required. In this article, we report the coupling of a full configuration interaction (FCI) method with a 10-band ( $sp<^>{ {3}}$ $s<^>\ast $ -spin) tight-binding (TB) model to calculate the excitonic energetics of realistically sized InGaN/GaN dot-in-nanowire structures. Model benchmarking has been done against a recently reported InGaN/GaN multiple quantum well (MQW) structure in the ${a}$ -plane orientation. Computational methodology of implementing a hexagonal-base truncated pyramid shaped QD has been presented. The effects of QD shape/thickness, material composition, and crystal growth direction (polar ${c}$ -plane and non-polar ${m}$ -plane and ${a}$ -plane) on the FSS of InGaN/GaN based photon emitters have been investigated. Polarization profiles of the emitted photons from the excitonic transitions have been derived quantum mechanically from transition dipole moments. With the smallest FSS, the non-polar ${m}$ -plane device has been found to be most promising for the QKD application.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
23,"The balanced incomplete block design (BIBD) problem is a difficult combinatorial problem with a large number of symmetries, which add complexity to its resolution. In this paper, we propose a dual (integer) problem representation that serves as an alternative to the classical binary formulation of the problem. We attack this problem incrementally: firstly, we propose basic algorithms (i.e. local search techniques and genetic algorithms) intended to work separately on the two different search spaces (i.e. binary and integer); secondly, we propose two hybrid schemes: an integrative approach (i.e. a memetic algorithm) and a collaborative model in which the previous methods work in parallel, occasionally exchanging information. Three distinct two-dimensional structures are proposed as communication topology among the algorithms involved in the collaborative model, as well as a number of migration and acceptance criteria for sending and receiving data. An empirical analysis comparing a large number of instances of our schemes (with algorithms possibly working on different search spaces and with/without symmetry breaking methods) shows that some of these algorithms can be considered the state of the art of the metaheuristic methods applied to finding BIBDs. Moreover, our cooperative proposal is a general scheme from which distinct algorithmic variants can be instantiated to handle symmetrical optimisation problems. For this reason, we have also analysed its key parameters, thereby providing general guidelines for the design of efficient/robust cooperative algorithms devised from our proposal. (C) 2019 Elsevier Ltd. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
24,"Two different approaches are used to assess the impacts associated with natural hazards and climate change in cities. A bottom-up approach uses high resolution data on constituent assets within the urban area. In contrast, a top-down approach uses less detailed information but is consequently more readily transferable. Here, we compare damage curves generated by each approach for coastal flooding in London. To compare them, we fit a log-logistic regression with three parameters to the calculated damage curves. We find that the functions are remarkably similar in their shape, albeit with different inflection points and a maximum damage that differs by 13%-25%. If rescaled, the curves agree almost exactly, which enables damage assessment to be undertaken following the calculation of the three parameters.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
25,"Chlorosilane gas transport in ambient hydrogen in a slim vertical cold wall chemical vapor deposition reactor was real-time monitored using a quartz crystal microbalance (QCM) using its behaviour responding to the properties of the gas mixture. The QCM frequency quickly decreased by introducing the trichlorosilane gas, while it slowly decreased by the dichlorosilane gas. The QCM frequency behavior was explained by the gas flow condition, such as the plug flow and recirculating flow, in the reactor. The relationship was consistent with the gas flow calculations, because the heavy and light gases could directly flow downward and recirculate, respectively, in the chamber due to natural convection. The information obtained from the QCM frequency behavior is expected to be utilized for the real-time gas monitoring and for the process design.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
26,"Suppressing zero-order term and twin-image is a crucial technique in in-line digital holography, which can obtain more accurate reconstructed images. A robust and effective algorithm to suppress zero-order term and twin-image in in-line digital holography is proposed in this paper, which combines a phase retrieval method and spatial spectrum filtering in a single hologram. In order to more accurately distinguish the effective information and noise information (zero-order term and twin-images), we propose a synthetic threshold condition of frequency domain and spatial domain in the iterative process. Several experiments have been carried out to validate the effectiveness of the proposed algorithm. The results demonstrate that the proposed algorithm not only has better visual effects, but also has a better accuracy.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
27,"This study is aimed to optimize a golf clubhead for the purposes of maximizing the driving distance. Since the sensitivity-based approaches cannot be applied in impact problem, the authors developed an optimization system by using basis vector method. The relation between the eigenfrequencies and the coefficient of restitution is examined with finite element method (FEM) models numerically at first. Based on evaluating the contribution of eigenmodes, the authors proposed an approach to create the basis vectors using the sensitivity functions of eigenvalues. Computational results are presented for demonstrating the effectiveness of the proposed approach.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
28,"An on-line calibration device for atmospheric gas analyzers is developed by combining the dynamic gas mixtures preparation system of membrane permeation which is situated in the automated air monitoring station with a standard admixing air matrix method. The continuous, standard admixing air matrix and real-time online calibration of SO2, NO2, CO gas analyzers for automated air monitoring stations are realized with the calibration uncertainties less than 3% (k = 2). At the same time, in the calibration device, the service life of the newly invented membrane permeation system is several times longer than that of the traditional method. (C) 2019 Elsevier Ltd. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
29,"Fine dust contributes to many physical diseases in coal miners, and it is hard to remove effectively. In this paper, the gas-solid two-phase flow theory and the discrete phase model are used to numerically simulate and analyze that the effects of velocity and the separation distance of vortex sheet to turbulence intensity, yield of vorticity, and particles trajectory. It can enhance the turbulent intensity and vorticity yield by setting up vortex sheets, so that the collision probability of particles increases. Entrance airflow velocity were 6, 9, 12 m center dot s(-1), separation distance of vortex sheets were no sheets, 20 cm and 30 cm in conditions of simulation and experiment. By experiments, it was initially verified that the fine dust in the turbulent flow was agglomerated or blocked, and the efficiency of agglomeration and blocking was obtained. The efficiency of agglomeration and blocking was from 17.51% to 73.13%, and when the entrance airflow velocity was 12 m center dot s(-1), separation distance was 20 cm, 73.13% was the highest efficiency. This will provide an idea for designing effective dust collector in mine, and help to solute fine dust pollution problems.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
30,"In copper concentrate, size distribution of rougher concentrate, the amount of locked chalcopyrite particles, and regrinding circuit performance affect the efficiency of further scavenger and cleaner steps. Mineralogy of the locked chalcopyrite particles throughout the rougher section were examined in different size fractions. Results indicated that more than 70% of copper was floated in the first rougher cells, after which copper and pyrite decreased in concentration, while silica increased. It was found that regrinding the concentrate of first rougher and scavenger cells to ?44??m, and the rest of the cells to ?75??m can yield the highest recovery.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
31,"A two-layer cyclic pressure-temperature swing adsorption system was designed for effective water vapor removal from air or helium. The system consists of two fixed bed adsorption columns, each containing two layers of adsorbents consisting of silica gel and zeolite molecular sieves 13x. To gain in-depth insights about the process, a descriptive model considering mass, energy and momentum balances, along with kinetic and equilibrium equations has been developed. The results of computer simulation showed that the layered bed, containing silica gel and molecular sieves 13x, offers both a longer water breakthrough time and significantly enhanced two-layered bed desorption performance compared with those for the one-layered bed. The influence of total gas pressure during the adsorption step, and height of the adsorbent layers on the process efficiency were studied. The cyclic steady state cycles were obtained under various conditions by a cyclic iteration method. Condensation of desorbed water in the adsorbent bed during regeneration has been considered. Theoretical study indicated no water vapor condensation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
32,"With continued growth in air traffic, airports worldwide are expanding their runway infrastructure. This leads to the problem of determining an appropriate location and height for an Air Traffic Control (ATC) tower that can provide the right vantage point for coordinating runway and taxiway movements. The challenge involves finding the right location and optimal height that can satisfy the visibility and obstruction constraints for a complex airport-airside environment with multiple runways and civil infrastructure under different weather conditions. This article formulates the ATC tower location and height problem as a Mixed-Integer-Programming (MIP) model while considering the visibility and obstruction constraints. Singapore Changi Airport's proposed third runway extension is used as a case study to determine the set of location and height of ATC Tower using the proposed approach. A visual analytic test is conducted in an ATC tower simulator for different tower locations and heights under varying visibility conditions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
33,"In this study, we analyze the absence epileptic seizures using the data recorded from different layers of somatosensory cortex of absence epileptic rats. We aim to (1) extract the epileptic activities or sources generating the seizures, and (2) investigate the temporal changes of seizures. To achieve our goals, we describe the recorded seizures by a linear superposition of static and dynamic sources. The static sources are stable and have a fixed structure, while the dynamic sources can be intermittent, and may be with different locations. Retrieving the sources and their structures from the recorded seizures helps us to achieve the desired analysis. Experimental results show the existence of a static source and three specific dynamic sources during the recorded seizures. The dynamic sources randomly activate with the static source and one of them disappears towards the end of the seizures. Moreover, it is shown that the spatial locations of the sources are similar in different absence epileptic rats. (C) 2019 Elsevier B.V. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
34,"One of the reasons why photovoltaic technology is not massively installed is its variation in production. This variation is due to intermittences in the solar resource. Based on real data from the microgrid of the Renewable Energy Development Center (CEDER, Spain) and another scenario in Xalapa (Mexico), the study determines the solar intermittences produced and grouped monthly. The period of data acquisition, in the first study, was from May 30th, 2012 to March 3rd, 2015 with the help of a Baseline Surface Radiation Network (BSNR) team; in the second, 2014 measurements were obtained from a meteorological station certified by the National Meteorological System (SMN). The analysis is based on the determination of monthly frames of reference for radiation by third-degree spline adjustments with smoothing, using the JUMP statistical application software (JMP (C) 2009, SAS Institute, version 8.0.2). The results of the analyses have provided important information to understand the unstable appearance of solar radiation and, in turn, will be the basis of a control system to optimize photovoltaic production.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
35,"When an oak board is exposed to a change in the relative humidity of the ambient air, moisture transfer occurs. Consequentially, the internal moisture content distribution changes continuously, which induces bending of the board over time. With increasing asymmetry in the internal moisture content distribution, induced by an increasing difference in relative humidity over the board thickness, the board's curvature increases. In case the board is subjected to two different sinusoidal fluctuations in relative humidity on its opposite sides, the bending response is a superposition of two sinusoidal fluctuations. The influences of different fluctuation frequencies, amplitudes, and phase shifts on the macroscopic bending are theoretically predicted and experimentally explored. Moisture transport characteristics are derived from a frequency analysis of the macroscopic bending response, whereas the equilibrium bending configuration provides the linear hygroscopic expansion coefficient. Furthermore, the effect of hysteresis during sinusoidal relative humidity fluctuations is explored. The results are used in a case study to predict the deformation of an oak door separating an indoor and outdoor environment, with differently varying relative humidity on both sides of the door.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
36,"1-read/1-write (1R1W) register file (RF) is a popular memory configuration in modern feature rich SoCs requiring significant amount of embedded memory. A memory compiler is constructed using the 8T RF bitcell spanning a range of instances from 32 b to 72 Kb. An 8T low-leakage bitcell of 0.106 mu m(2) is used in a 14 nm FinFET technology with a 70 nm contacted gate pitch for high-density (HD) two-port (TP) RF memory compiler which achieves 5.66 Mb/mm(2) array density for a 72 Kb array which is the highest reported density in 14 nm FinFET technology. The density improvement is achieved by using techniques such as leaf-cell optimization (eliminating transistors), better architectural planning, top level connectivity through leaf-cell abutment and minimizing the number of unique leaf-cells. These techniques are fully compatible with memory compiler usage over the required span. Leakage power is minimized by using power-switches without degrading the density mentioned above. Self-induced supply voltage collapse technique is applied for write and a four stack static keeper is used for read Vmin improvement. Fabricated test chips using 14 nm process have demonstrated 2.33 GHz performance at 1.1 V/25 degrees C operation. Overall V-min, of 550 mV is achieved with this design at 25 degrees C. The inbuilt power-switch improves leakage power by 12x in simulation. Approximately 8% die area of a leading 14 nm SoC in commercialization is occupied by these compiled RF instances.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
37,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
38,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
39,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
40,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
41,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
42,"While PIV allows the extraction of instantaneous streamlines, the availability of typically thousands of patterns hampers a statistical understanding of the underlying flow topology. A particular application is oscillating gas jets, encountered in scientific and industrial studies dealing with mass transfer and flow control. Multiple methods, such as statistical moments (including mean, variance, skewness, and kurtosis), proper orthogonal decomposition (POD), and Hartigan's dip test are common post-processing methodologies. However, as demonstrated in this paper, they do not provide sufficient in-depth information from a statistical perspective to attribute probabilities to potential flow topologies. In this work, a novel approach to describe probability distributions based on extracted streamline patterns is proposed. Based on the available streamline patterns, the convolution with adaptive Gaussian kernels reveals the probability density function of the flow topology. The proposed methodology, as well as more traditional post-processing approaches, are assessed on the basis of synthetic flow fields and experimental PIV data of oscillating impinging gas jets, demonstrating the added value of the streamline probability map in characterising the scrutinised flow. [GRAPHICS] .",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
43,"The effects of heating temperature in ultraviolet irradiation process (hereafter named as UV temperature) on photon-activated precursor YBa2Cu3O7-x (YBCO) films were investigated systemically. The results from FT-IR spectra, carbon content, the XPS spectra of Cu 2p and O1s reflected that the photochemical reactions were inhibited by high UV temperature. And we proposed a model to analyze and explain the mechanism of how the UV temperature affect the photochemical reactions. Finally, the YBCO films irradiated at 100 or 150 degrees C had higher Jc values (about 7.0 MA/cm(2) at 77 K and 0 T) than samples UV-irradiated under high UV temperatures (beyond 200 degrees C), which showed lower Jc values due to the weakening of oxidation progress. Consequently, a temperature window of 100-150 degrees C in UV irradiation process maybe suitable for the deep UV irradiation method used in YBCO preparation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
44,"Radioactive effluent is generated through a nuclear fuel cycle involving the use of radioactive materials in nuclear power plants. The concentration of the nuclear effluent is of concern if it is discharged into a natural water body and potentially used for human consumption. The present study involves numerical simulation of hydrodynamic parameters for prediction of near-field concentrations of tritium at various sampling points in a natural lake system in India. The modeling software with volume of fluid (VOF) two-phase model, for tracking the fraction of each fluid element, and k-epsilon model, as turbulence closure, is used to analyze the dispersion of tritium in the lake domain. The simulated results are validated using data on velocity and tritium (H3) concentrations measured at sampling locations in the lake system. The simulated hydrodynamic parameters are reported to be in agreement with their measured values at sampling locations, particularly with a wind effect on the lake surface. The simulated values of hydrodynamic parameters as well as tritium concentrations are found to be within +/- 10% of their respective measured values in the lake domain. The safe disposal practices of tritium within the lake system are indicated because simulated effluent concentrations are well within the permissible limits of international standards. The numerical model would be useful for real-time operation and management of the chosen lake system in future while simulating the concentration of tritium at different sampling locations, monitoring their concentrations within permissible limits, and ensuring passage of safe water further downstream in the canal system for municipal, industrial, and irrigation usages.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
45,"DC machines have been in operation for more than 100 years. Engineers and technicians understand the dc-motor structure and components since they have experience rebuilding, testing, and making performance adjustments to them. Those that understand commutation, [2], [4] the commutation zone (CZ), and the characteristics of the carbon brush are few in number. Traditionally, the lack of a visible arc has been the defining quality of good commutation; hence, the term ""black."" The knowledge gap and relatively high-level physical science involved with commutation have led to an art known as ""black magic"" for achieving the invisible-arc condition [5], [6]. Black magic refers to both the brush coloration and commutation. The purpose of this article is to define the CZ and present the critical components that create it. An explanation of specific brush properties and their contribution to successful commutation is included.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
46,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
47,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
48,"In this study, single-crystalline III-V semiconductor/reduced graphene oxide (RGO) hybrid microtubes have been successfully fabricated via the self-rolling of the dip-coated RGO layers together with the bottom InGaAs/GaAs strained bilayers, which makes the self-rolled-up RGO layers as the innermost walls. Structural and optical characterizations were performed using scanning electron microscopy (SEM) and micro-Raman spectroscopy, respectively, revealing that similar to 30 nm-thick RGO layers were rolled-up into InGaAs/GaAs microtubes and the highly-ordered hybrid microtube array were also realized. Moreover, spectral redshifts of Raman characteristic peaks of both GaAs and RGO were observed in two rolling behaviors, i.e., partly releasing and rolling, both demonstrating the strain transition phenomenon. Our study offers a feasible route for the future 3D integration of RGO onto Lab-on-a-chip, Lab-in-a-tube and etc.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
49,"This study investigated the effects of cue plausibility in a baggage screening task. 120 participants had to indicate whether a prohibited item was present in a series of grey-scaled X-ray images of baggage. They were assisted by a support system, which pointed at the location of a suspicious object. A 2 x 2 x 2 between-subjects design was used. Cue plausibility for false alarms (i.e. how the cued object was similar to a prohibited item) and support system reliability were manipulated at two levels (high/low). Furthermore, half of participants were provided with a rationale about automation failures (RAF) to reduce their negative impact on trust and performance. The results showed lower performance and more compliance with automation suggestions when cues were implausible than plausible. The RAF increased the response time and did not improve detection performance. Overall, this suggests that effective (computer-based) training is needed to reduce the negative effect of plausible cues.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
50,"Constant-modulus signals such as m-sequences are known to have good autocorrelation properties, as well as good peak-to-average power ratio that allows for full utilization of the transmitter's power. However, the broadband ambiguity surface for such signals exhibit high sidelobe levels that are undesirable in applications where the signal is subject to broadband Doppler. We formulate an optimization problem to minimize the maximum sidelobe levels of such signals over a set of delay-Doppler values. This problem is non-convex and difficult to solve. We explore a convex regularization of the problem that can readily be solved using semi-definite programming, and show that optimal or near-optimal signals can be designed using this method. We further explore some heuristic methods to reduce computational and memory complexity of the solution, to enable us to design longer signals. We demonstrate the advantage of our signal design over conventional unimodular signals for target detection in strong clutter in a continuous active sonar application. (C) 2019 Elsevier B.V. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
51,"In this chapter we present the second moment methods for evaluating project performance functions where random variables can be continuous and/or discrete. We provide a comprehensive review of the method in context of its accuracy when compared to the results from the Monte Carlo simulation. Furthermore, we analyze the effect of correlations among the random variables and the linearization of the project performance functions.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
52,"In this chapter we discuss the implementation of Monte Carlo simulation evaluating of project performance functions such as the total project cost and the total project duration. We focus on the key considerations that are often ignored when Monte Carlo simulation is implemented in project risk analysis - the effect of correlation and the sample size selection. Further, we provide the methods to determine if the correlation matrix is positive-semi definite, if not, how to fix it. Finally we show the method to evaluate the effect of sample size on the confidence intervals of decision variables.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
53,In this chapter we extend our discussion on the assumption of statistical independence among the work packages and provide the theoretical justification why such assumption can lead to poor results. We also provide an overview of autoregressive models and the examples of how such models can be applied to forecasting of project outcomes and ultimately risk assessment and management.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
54,"In this chapter we discuss the sensitivity of the project performance outcomes such as the total project cost to the uncertainty in work packages. We provide two approaches to this critical step for developing risk mitigation strategies, one based on calculating derivatives of the total variance with the respect to work package of interest, and the other one based on the correlation between the total cost and the work package. Further, this chapter introduces another important analysis for designing proper mitigation strategies - determining the effects of common cause events on the correlation and ultimately on the total cost.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
55,In this chapter we discuss the application of the second moment method in scheduling networks. The issue we focus here is on finding the probability distribution for the project completion time when there are multiple network paths in the project and therefore the critical path is itself uncertain. We present an approximate method to this problem and discuss its validity in a larger managerial context.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
56,"In this chapter we introduce the concept of contingency and management reserves. We provide the formal definition and a discussion on its use and misuse. We further provide the mathematical formulation of the contingency and the contingency factor, the consideration of contingency in program management, and the effect of correlation.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
57,In this chapter we discuss methods for updating and managing project contingency as the outcomes work packages become known. More specifically we provide bivariate and multivariate formulation with a number of examples to illustrate different situations in which the presented methods can be implemented.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
58,"In this chapter we introduce statistical project control methods. We focus on the problems of determining whether project-generated data fall within or outside specification limits. The examples included in this chapter address construction quality problems, earned-value management, and project performance prediction.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
59,"In this chapter we discuss methods for forecasting future job progress. More specifically we focus on forecasting two important project performance criteria - completion time and cost-at-completion, on the basis of past progress data. We introduce a class of S-curves that is suitable for representing job progress as well as discuss how to develop the confidence intervals around the forecasts. In addition we show how Bayesian methods can be used to update the parameters of the S-curve models.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
60,In this chapter we discuss the effect of learning on project efficiency and/or productivity. We introduce the concept of learning curves and provide the modeling approaches to forecast project completion time and cost. We use examples from projects characterized with repetitive tasks and where the learning effect is highly visible such as tunneling.,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
61,"Through a joint standards development process of the IEEE and the Canadian Standards Association (CSA), two new standards have been completed: a certification standard, IEEE Standard 844.1-2017/CSA C22.2 No. 293.1-17, Standard for Skin Effect Trace Heating of Pipelines, Vessels, Equipment, and Structures-General, Testing, Marking, and Documentation, and an application guide standard, IEEE Standard 844.2-2017/CSA C22.2 No. C293.2-17, Standard for Skin Effect Trace Heating of Pipelines, Vessels, Equipment, and Structures-Application Guide for Design, Installation, Testing, Commissioning, and Maintenance. The standards detail requirements that have been added or clarified for the process of certifying skin-effect trace heating systems. This article summarizes new applications as well as new recommended installation practices in the application guide. Reflections on the direction of this joint standard development and a look ahead to future endeavors are shared.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
62,"True random number generators (TRNGs) provide a wide area of applications and can be fabricated on the basis of magnetic tunnel junctions (MTJs). This work represents the modeling of TRNG readout optimization, where the induced digital random bit is detected within only a single computational period. The period contains two sub-cycles: write and joined read & reset cycles. The system has a valuable potential to become stochastically independent after calibrating at the desired working point against the factors, which cause to the signal deviations: temperature-induced, material degradation or other problems.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
63,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
64,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
65,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
66,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
67,"Low-rank matrix recovery has become a popular research topic with various applications in recent years. One of the most popular methods to dual with this problem for overcoming its NP-hardness is to relax it into some tractable optimization problems. In this paper, we consider a nonconvex relaxation, the Schatten-p quasi-norm minimization (0 < p < 1), and discuss conditions for the equivalence between the original problem and this nonconvex relaxation. Specifically, based on null space analysis, we propose a p-spherical section property for the exact and approximate recovery via the Schatten-p quasi-norm minimization (0 < p < 1).",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
68,"Monitoring of energy consumption is a critical application at a telecom tower site. This paper presents a novel power monitoring application. In addition to power consumption measurement, power monitoring could be useful in preventing the pilferage of diesel used to run generators at a tower site. The problem of diesel pilferage has been analyzed, and a concealed power monitoring solution has been presented. The monitoring algorithm can be integrated with the pulse width modulation controller used in switch-mode power supply rectifier. The measurement philosophy has been validated, designed, and experimentally tested. Simulink models of power supply at a tower site have been used for validation. A prototype for the above-mentioned system has been designed using MATLAB and a microcontroller. The combination of these two tools emulates a power quality analyzer. Power quality analysis is the central theme of this solution. The difference in power quality and the impact of load on the power source have been used to construct features for this solution. The proposed solution has been experimentally tested by recording input power waveforms of an ac-to-dc converter.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
69,"In this paper the detailed OAT (one-at-a-time) sensitivity analysis of a nonlinear fire truck suspension system is carried out with numerical simulation. As output to measure sensitivity the RMS of acceleration was chosen, which can be calculated with numerical simulations easily. The degree of sensitivity was measured with a sensitivity index and based on it sensitivity Fuzzy-sets were established. The membership of each parameter to the Fuzzy sets is calculated and based on it, it was determined which parameters are the most sensitive. With the presented results it is shown that the proposed method is suitable for testing mathematical models as well.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
70,"In this paper, the Wigner-Kirkwood quantum theory and the Weeks-Chandler-Andersen (WCA) effective diameter method in Classical DFT are employed to account for the effects of quantum corrections on the Helmholtz free energy of bulk and confined fluids. Initially, experimental data are exploited toward accurate prediction of pressure-volume isotherms and vapor-liquid equilibrium in bulk fluids. In the second part, the effects of quantum correction on the structure and thermodynamic properties of fluids confined in slit pores are investigated. Our results show that quantum effects may come into account by considering the effective size of the particles and also intermolecular interaction which both of them have direct effects on the density distribution of molecules in the slit pore. Furthermore, the excess adsorption of fluids at a fixed bulk density is shown to increase with quantum effect, but this trend is reversed with increasing wall fluid interaction because of the entropy and energy effects. Also, it is found that the excess adsorption and interfacial tension of the fluid against the solid surface of fluids exhibit oscillatory behaviors with maximum and minimum values for half integer and integer values of pore width. This oscillatory behavior disappears at high values of pore width with increasing quantum effect. Another finding of the present study indicates that the interfacial tensions of the fluid against the solid surface for a classical fluid are negative but quantum effect increases it and shifts its sign to positive. Finally, it is shown that the locus of phase transition is shifted toward higher bulk densities as a result of increasing quantum effect. (C) 2019 Elsevier B.V. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
71,"Contaminant such as pesticides, veterinary products, industrial compounds, food additives, personal care products, and pharmaceuticals may cause a negative effect when comes into contact with the environment. The presence of these compounds can be generated toxic effects in the aquatic system and cause an irreparable ecological alteration. Antibiotic compounds are one of the main pollutants found in the aquatic systems, because they are often inadequately prescribed and as a part of antibiotics is not completely consumed or degraded in human and animal bodies. Their residues can be entered in aquatic systems by wastewater treatment plants. The presences of antibiotics in aquatic systems have been linked to increasing microorganism antibiotic resistance through different mutations. Advanced oxidation processes have been proposed for the treatment of antibiotic in aqueous systems, including solar photocatalysis. Several parameters are necessary to take into account in solar photocatalysis treatment to eliminate antibiotics, since these compounds display different physicochemical and biological properties. This chapter discusses the effect of parameters and pathways (transformation products) of solar photocatalysis of antibiotic groups usually found in aquatic systems as macrolides, sulfones, lincosamides, and quinolone.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
72,"Shallow urban road tunnels with top vents represent environmentally friendly and energy-saving technology. To date, four such tunnels are operational in Nanjing, and their intra-tunnel air quality has been widely acclaimed. However, no prescriptive design methods have been developed for this technology. Natural ventilation at the top of the tunnels is caused by the pressure difference inside and outside the top vents. Thus, a prerequisite to the development of scientific design methods for such tunnels is a complete understanding and representation of the pressure wave distribution pattern in the tunnels. Based on an analogy with an electric dipole, we propose a pressure-induced dipole theory and construct an intra-tunnel pressure distribution model. An experimental platform is developed to evaluate the pressure distribution inside tunnels under 6 operational conditions. The results suggest the following. (1) The proposed pressure-induced dipole theory can well describe and explain the pressure wave distribution rules in road tunnels. (2) With a uniform and continuous traffic flow, the real-time pressure on each point in the tunnels demonstrates periodical asymmetrical quasi-sinusoidal pulsation, where the cycle is given as T = (S + L)/v. (3) Periodical pressure pulsation with decaying amplitude exists around the top vents. With large top vents, the pressure exchange between the inside and outside of the tunnels is significant.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
73,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
74,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
75,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
76,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
77,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
78,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
79,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
80,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
81,"Background and Objective: Kinematic and dynamic modeling of any physical process is critical especially for the design phase of associated control units and the prediction of their performance levels. In this paper, a dynamical model and a development frame including interactions with the objects for a tendon-driven underactuated hand are developed and examined. Using the proposed dynamic model, free movement and the object interaction of the underactuated hand can be simulated with a single, integrated simulation step in the simulation frame. Methods: Lagrangian Method is used to model the dynamic behavior of the underactuated fingers and the thumb under tendon dependency in a 3D coordinate system. Then, as an important extension to the modeling studies that can be found in the literature, the interaction of the hand with an object that co-exists in its workspace is modeled in terms of contact forces acting on the joints of the fingers. The unified dynamic model is simulated by using the Simulink platform. Results: The simulations showed that the adaptability of the underactuated mechanism and joint torque levels are modeled and examined realistically. The flexion movement of the fingers resulted in realistic torque levels which can be handled by commercially-off-the-shelf actuators. Various tendon forces were examined in terms of the distance of the individual phalanx to the object and their contact instants. Applying an increasing input force with 1.617 N/s ramp slope, finger flexion movement was obtained in 1s. In another simulation scenario, compliance of the underactuated mechanism to an object was examined. With 0.66 N/s tendon force input ramp, proximal, middle and distal phalanx contacted an object in 1.3 s, 2.35 s and 2.75 s, respectively. Conclusions: Presented features obtained by the simulation platform are especially useful to researchers working on the development of control methods for underactuated prosthetic hands and robot manipulators. Through the simulations of experimental scenarios, a detailed analysis of dynamic responses of each finger phalanges can be carried out properly in any level of the design phase. (C) 2019 Elsevier B.V. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
82,"Bar and joint frameworks provide useful models to the structure of building, metals, glasses, crystal states materials, nano-materials, and some biological systems. Using the symmetry and the periodicity of the structures, their rigidity is a problem of long-standing interest in kinematics, statics, and optimization. We considered the skeletal of a wide class of 3-dimensional tiling with the special assumption that the original polygonal faces are allowed to deform in a way that faces remaining central symmetrical and not necessarily planar. Some vectors that represent the parallel edges with the bracing elements as auxiliary framework characterize the mobility of this framework. A new theorem provides a necessary and sufficient condition for the rigidity of the tiling framework applying face diagonals as bracing elements. This result implies an efficient algorithm for the rigidity of the braced tiling structure. Based on simple elements, we construct new mechanisms which move as the skeleton tiling structure with the planar and the central symmetrical assumption. In the applications we regard the bracing elements as actuators; we provide a method controlling the motion of braced reconfigurable meta-materials and the rhombic type origami. (C) 2019 Elsevier Ltd. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
83,"A small-area composite-varactor-based digitally tunable capacitor operated with positive and negative control voltages is proposed to remove several drawbacks resulting from the metal-insulator-metal (MIM) capacitor of the conventional switched capacitor array (SCA). It was constructed with several composite-varactor branches in parallel, each of which consists of p-type (P+/Pwell) and n-type (N+/Nwell) accumulation-mode varactors in a cascode configuration. The optimum ratio of the channel width between p-type and n-type accumulation-mode varactors was investigated through the simulation in order to maximize a quality factor (Q-factor) of the tunable capacitor at the maximum capacitance (C-MAX) state. The number of composite-varactor unit in each branch was designed to be binary-weighted, and the total capacitance can vary linearly by digitally turning on and off both varactors. It was firstly implemented in 65-nm bulk CMOS process, and showed comparable tuning range, Q-factor, and harmonic distortion performances while reducing the silicon area by half and eliminating the MIM capacitor in comparison with the conventional SCA. In the measurement, the proposed tunable capacitor showed a Q-factor of 60.3 at C-MAX state and a tuning range of 2.8 at 2 GHz frequency band. In addition, it was perfectly capable of handling a high power signal up to 0 dBm with excellent second and third-order harmonic distortion of greater than 70 dBc at the minimum capacitance (C-MIN) state and 77 dBc at C-MAX state.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
84,"yCompensation data from workers' compensation boards are very useful for orienting occupational health and safety (OHS) prevention and research. This study examines the impact of compensation data maturity on OHS indicators. Specifically, administrative data from the Quebec workers' compensation board (CNESST) relating to 117,990 occupational injuries that occurred in Quebec in 2006 are used to produce various OHS indicators. The indicators are produced using data with three years' maturity and then recalculated for each additional six-month data period up to nine years' maturity. It is shown that extending the data period has a significant impact on some OHS indicators but little impact on rank within the target industries. Besides shedding new light on the impact of the maturity of the data used, the study identifies the types of injury whose consequences are the most underestimated when a short data maturity is used. The results presented in the study may be useful to many users of occupational injury compensation data.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
85,"As an emerging manufacture technology, block copolymer directed self-assembly (DSA) is promising for via layer fabrication. Meanwhile, redundant via insertion is considered as an essential step for yield improvement. For better reliability and manufacturability, in this paper, we first concurrently consider DSA guiding template cost assignment with multiple redundant via and dummy via insertion. Firstly, by analyzing the structure property of guiding templates, we propose a building-block based solution expression to discard redundant solutions. Then, honoring the compact solution expression, we construct a conflict graph with dummy via insertion, and then formulate the problem to an integer linear programming (ILP). In addition, to optimize the guiding template cost, we incorporate it into the objective of ILP by introducing vertex weight and edge weight in conflict graph. To make a good trade-off between solution quality and runtime, we relax the ILP to an unconstrained nonlinear programming (UNP). Finally, a line search optimization algorithm is proposed to solve the UNP. Experimental results verify the effectiveness of our new solution expression and the efficiency of our proposed algorithm. Specifically, our guiding template cost optimization method can save 18% total guiding template cost.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
86,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
87,"Cuckoo Search (CS) is a recently proposed metaheuristic algorithm to solve optimization problems. For improving its performance both on the efficiency of searching and the speed of convergence, we proposed an improved Cuckoo Search algorithm based on the teaching-learning strategy (TLCS). For a better balance between intensification and diversification, both a dynamic weight factor and an out-of-bound project strategies are also introduced into TLCS. The results of numerical experiment demonstrate that our improved TLCS performs better than the basic CS and other two improved CS methods appearing in literatures.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
88,"Blind separation of convolutive mixtures has many applications in the areas of acoustics, communications, biomedical signal processing. Spatio-temporal decorrelation is a useful preprocessing technique that can reduce the blind separation problem into a simpler orthogonal matrix estimation problem. However, it is computationally expensive for its large unknown parameter set. Realtime spatio-temporal decorrelation method remains an open issue for years. In this paper, we focus on accelerating the adaptation process in the FIR filter based decorrelation method. Firstly, the update equation is decoupled into spatial decorrelation and temporal decorrelation. Then, their respective convergence conditions are systematically analyzed using eigenvalue decomposing method. Based on it, a fast algorithm for FIR filter network with spatio-temporal decoupled adaptive step-sizes is proposed. Comprehensive simulations are performed on both synthetic data and real world captured sEMG data. We have compared the proposed algorithm with the fixed step size method, IIR filter with natural gradient, and the annealed step size method. The factors including number of iteration, number of channel, computational time, selection of filter order and window size are elaborately compared and discussed. The results verified the reliable performance of our method on accelerating the adaptation process for spatio-temporal decorrelation simultaneously compared to classical methods. (C) 2019 Elsevier Inc. All rights reserved.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
89,"A technology has been developed that utilizes CO < sub > 2 </sub > in concrete curing to improve the concrete properties. This commercialized process is used by more than 50 ready-mix and concrete product sites across the United States and Canada. Ready mix and concrete product companies are currently using commercial, food-grade CO < sub > 2 </sub > at a high cost. The long-term objective is to extract CO < sub > 2 </sub > from cement plants and then utilize it in ready-mix concrete and concrete products made with the cement that produced the CO < sub > 2 < sub >, thus closing the loop. This concept has been presented as one of the numerous projects in the Carbon XPrize and has been selected as one of the 27 projects approved for round 2.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
90,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
91,"This study deals with the tracking control problem of a large class of multi input multi output (MIMO) nonlinear systems with unknown dynamics and subject to unknown disturbances. First, two interval type-2 adaptive fuzzy systems (IT2-AFSs) are constructed to efficiently estimate the unknown nonlinear dynamics. Then, based on IT2-AFSs and super-twisting algorithm (STA), a new robust adaptive fuzzy-reaching STC law (AF-RSTCL) has been added to the global control law to improve the robustness of the studied systems in the presence of approximation errors and unknown disturbances. In order to avoid the chattering phenomenon and guarantee simultaneously the best tracking performance, the gains of the designed AF-RSTCL are optimally online estimated. The adaptive parameters of the global synthesized control law are deduced from the stability analysis in the sense of Lyapunov. Finally, an example of simulation is used to confirm the effectiveness of the developed method in achieving the predetermined objectives of the tracking control.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
92,"This paper reports results of the impact of a quayside floating system on overtopping. The approach is experimental and analytical. Rectangular floaters in heave motion were considered at various distances from a vertical wall. Floaters with different widths and heights were tested. The effect of the draft and the floater's distance to the wall on overtopping quantification was considered in intermediate water conditions. First, overtopping evolution as a function of the wave period was found to be correlated with the floater behavior. The overtopping increased at the resonance period of the floater but decreased at larger periods. The experimental results were then compared with a linear analytical model based on potential flow theory, where the wave height at the seawall was given using the Van der Meer formula. An improvement of the analytical model was obtained by introducing a term corresponding to pressure losses between the floater and seawall. The experimental results are in good agreement with the corrected analytical model: the evolution is similar, with an averaged standard deviation of 1.2 for large wavelengths. The present results show that the wave period and distance of the floater to the vertical wall are significant parameters for overtopping. Overtopping is reduced by the presence of the quayside floater for small distances to the vertical wall and large wave periods when the floater follows waves.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
93,"In this paper we have comprehensive study on the interplay among radiation loss, transverse disorder (diagonal and off-diagonal) and Kerr-type nonlinearity on the light propagation in 1D array of optical waveguides. Our numerical results demonstrate the presence of three distinguished regimes of transverse light expansion at different propagation distances. At short propagation distance, the Kerr-type nonlinearity are dominated and results in the transverse localization of light through the self-trapping mechanism. Radiation loss, causes the light escape from the injected guides, affect the light expansion in middle distance via broadening the light beam width. At longer distance the disorder terms led to the transverse localization of light, again. Also, we compared the propagation of light in edge and middle modes in the presence of the above effects. Our results show that the propagation distance of first localized regime for edge modes is larger than the middle modes since the edge modes can exchange energy with one of the left or right waveguides, while for middle modes there are two ways for energy exchange. Therefore the discrete diffraction can be diminished the nonlinear effects in middle modes faster than the edge modes.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
94,"E-waste collected from households must be properly processed in recycling plants to acquire high-purity output materials and hazardous substances removed. It requires a systematic approach to the disassembly process and wastes classification and categorization. Big variety of shapes and materials used in the equipment need processing lines including manual and automated sections. The main purpose of the machines used on the processing lines is to shred equipment into small size fraction and then separate each material depending on the physical properties. In such case, the output material from the E-waste disassembling plants can be recycled and used in new parts or components. This chapter includes a description of methods of disassembly focused on E-waste recycling in compliance with environmental standards. The required steps of the end-of-life products disassembly vary depending on the category of waste equipment. To show these differences, the chapter includes two case studies showing the configuration of a layout of E-waste processing lines with possible options to reconfigure them. The variants of the system's configuration depend on the volume of the waste stream, labor cost, and required purity of output materials. Economic efficiency indicator of E-waste processing indicates big differences in potential profit from recycling E-waste mainly depending on labor cost. Example of calculation of this indicator has been presented in this chapter on cooling appliances recycling for four European countries.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
95,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
96,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
97,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
98,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
99,"A mathematical model is needed to represent the complex behavior of MFC into a set of simple mathematical formulations so as to optimally characterize the impact of operational and design constraints on the output [1-3]. Such mathematical modeling is done in two ways: engineering and statistical approaches as shown in Fig. 2.1. Ensemble models can also be formulated by integrating both engineering and statistical models. The different operational parameters can be, bacterial growth rate, reaction rate, pH value, temperature, substrate concentration of the influent etc. while the design parameters are the surface area, sizes and materials (of electrodes), size of biofilm, electron donor variants, external resistance, membrane variants etc. MFCs are categorized into different types on the basis of chamber model, variants of microorganism cultures, substrate supply modes, and ion and electron transfer [4]. The various formulations of MFCs are shown in Fig. 2.2 for the ease of readers.",,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,
